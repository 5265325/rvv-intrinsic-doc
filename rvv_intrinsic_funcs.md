<!--NOTE: This file is generated by rvv_intrinsic_gen.py-->

### [RVV C extension types]()

**Prototypes:**
``` C
vint8m1_t
vint8m2_t
vint8m4_t
vint8m8_t
vint16m1_t
vint16m2_t
vint16m4_t
vint16m8_t
vint32m1_t
vint32m2_t
vint32m4_t
vint32m8_t
vint64m1_t
vint64m2_t
vint64m4_t
vint64m8_t
vuint8m1_t
vuint8m2_t
vuint8m4_t
vuint8m8_t
vuint16m1_t
vuint16m2_t
vuint16m4_t
vuint16m8_t
vuint32m1_t
vuint32m2_t
vuint32m4_t
vuint32m8_t
vuint64m1_t
vuint64m2_t
vuint64m4_t
vuint64m8_t
vfloat16m1_t
vfloat16m2_t
vfloat16m4_t
vfloat16m8_t
vfloat32m1_t
vfloat32m2_t
vfloat32m4_t
vfloat32m8_t
vfloat64m1_t
vfloat64m2_t
vfloat64m4_t
vfloat64m8_t
```
### [RVV C extension mask types]()
- The Syntax is `vbool<MLEN>_t`
 - `vbool1_t`
 - `vbool2_t`
 - `vbool4_t`
 - `vbool8_t`
 - `vbool16_t`
 - `vbool32_t`
 - `vbool64_t`

# RVV intrinsic Functions:

## Configuration-Setting Functions:

### [Set `vl` and `vtype` Functions]()

**Prototypes:**
``` C
size_t vsetvl_8m1 (size_t avl);
size_t vsetvl_8m2 (size_t avl);
size_t vsetvl_8m4 (size_t avl);
size_t vsetvl_8m8 (size_t avl);
size_t vsetvl_16m1 (size_t avl);
size_t vsetvl_16m2 (size_t avl);
size_t vsetvl_16m4 (size_t avl);
size_t vsetvl_16m8 (size_t avl);
size_t vsetvl_32m1 (size_t avl);
size_t vsetvl_32m2 (size_t avl);
size_t vsetvl_32m4 (size_t avl);
size_t vsetvl_32m8 (size_t avl);
size_t vsetvl_64m1 (size_t avl);
size_t vsetvl_64m2 (size_t avl);
size_t vsetvl_64m4 (size_t avl);
size_t vsetvl_64m8 (size_t avl);
```
### [Set the vl to VLMAX with specific vtype]()

**Prototypes:**
``` C
size_t vsetvlmax_8m1 ();
size_t vsetvlmax_8m2 ();
size_t vsetvlmax_8m4 ();
size_t vsetvlmax_8m8 ();
size_t vsetvlmax_16m1 ();
size_t vsetvlmax_16m2 ();
size_t vsetvlmax_16m4 ();
size_t vsetvlmax_16m8 ();
size_t vsetvlmax_32m1 ();
size_t vsetvlmax_32m2 ();
size_t vsetvlmax_32m4 ();
size_t vsetvlmax_32m8 ();
size_t vsetvlmax_64m1 ();
size_t vsetvlmax_64m2 ();
size_t vsetvlmax_64m4 ();
size_t vsetvlmax_64m8 ();
```
### [Read the vl]()

**Prototypes:**
``` C
size_t vreadvl ();
```
## Vector Loads and Stores Functions:

### [Vector Unit-Stride Load Functions]()

**Prototypes:**
``` C
vint8m1_t vloadb_i8m1 (const int8_t *base);
vint8m2_t vloadb_i8m2 (const int8_t *base);
vint8m4_t vloadb_i8m4 (const int8_t *base);
vint8m8_t vloadb_i8m8 (const int8_t *base);
vint16m1_t vloadb_i16m1 (const int8_t *base);
vint16m2_t vloadb_i16m2 (const int8_t *base);
vint16m4_t vloadb_i16m4 (const int8_t *base);
vint16m8_t vloadb_i16m8 (const int8_t *base);
vint32m1_t vloadb_i32m1 (const int8_t *base);
vint32m2_t vloadb_i32m2 (const int8_t *base);
vint32m4_t vloadb_i32m4 (const int8_t *base);
vint32m8_t vloadb_i32m8 (const int8_t *base);
vint64m1_t vloadb_i64m1 (const int8_t *base);
vint64m2_t vloadb_i64m2 (const int8_t *base);
vint64m4_t vloadb_i64m4 (const int8_t *base);
vint64m8_t vloadb_i64m8 (const int8_t *base);
vuint8m1_t vloadb_u8m1 (const uint8_t *base);
vuint8m2_t vloadb_u8m2 (const uint8_t *base);
vuint8m4_t vloadb_u8m4 (const uint8_t *base);
vuint8m8_t vloadb_u8m8 (const uint8_t *base);
vuint16m1_t vloadb_u16m1 (const uint8_t *base);
vuint16m2_t vloadb_u16m2 (const uint8_t *base);
vuint16m4_t vloadb_u16m4 (const uint8_t *base);
vuint16m8_t vloadb_u16m8 (const uint8_t *base);
vuint32m1_t vloadb_u32m1 (const uint8_t *base);
vuint32m2_t vloadb_u32m2 (const uint8_t *base);
vuint32m4_t vloadb_u32m4 (const uint8_t *base);
vuint32m8_t vloadb_u32m8 (const uint8_t *base);
vuint64m1_t vloadb_u64m1 (const uint8_t *base);
vuint64m2_t vloadb_u64m2 (const uint8_t *base);
vuint64m4_t vloadb_u64m4 (const uint8_t *base);
vuint64m8_t vloadb_u64m8 (const uint8_t *base);
vint16m1_t vloadh_i16m1 (const int16_t *base);
vint16m2_t vloadh_i16m2 (const int16_t *base);
vint16m4_t vloadh_i16m4 (const int16_t *base);
vint16m8_t vloadh_i16m8 (const int16_t *base);
vint32m1_t vloadh_i32m1 (const int16_t *base);
vint32m2_t vloadh_i32m2 (const int16_t *base);
vint32m4_t vloadh_i32m4 (const int16_t *base);
vint32m8_t vloadh_i32m8 (const int16_t *base);
vint64m1_t vloadh_i64m1 (const int16_t *base);
vint64m2_t vloadh_i64m2 (const int16_t *base);
vint64m4_t vloadh_i64m4 (const int16_t *base);
vint64m8_t vloadh_i64m8 (const int16_t *base);
vuint16m1_t vloadh_u16m1 (const uint16_t *base);
vuint16m2_t vloadh_u16m2 (const uint16_t *base);
vuint16m4_t vloadh_u16m4 (const uint16_t *base);
vuint16m8_t vloadh_u16m8 (const uint16_t *base);
vuint32m1_t vloadh_u32m1 (const uint16_t *base);
vuint32m2_t vloadh_u32m2 (const uint16_t *base);
vuint32m4_t vloadh_u32m4 (const uint16_t *base);
vuint32m8_t vloadh_u32m8 (const uint16_t *base);
vuint64m1_t vloadh_u64m1 (const uint16_t *base);
vuint64m2_t vloadh_u64m2 (const uint16_t *base);
vuint64m4_t vloadh_u64m4 (const uint16_t *base);
vuint64m8_t vloadh_u64m8 (const uint16_t *base);
vint32m1_t vloadw_i32m1 (const int32_t *base);
vint32m2_t vloadw_i32m2 (const int32_t *base);
vint32m4_t vloadw_i32m4 (const int32_t *base);
vint32m8_t vloadw_i32m8 (const int32_t *base);
vint64m1_t vloadw_i64m1 (const int32_t *base);
vint64m2_t vloadw_i64m2 (const int32_t *base);
vint64m4_t vloadw_i64m4 (const int32_t *base);
vint64m8_t vloadw_i64m8 (const int32_t *base);
vuint32m1_t vloadw_u32m1 (const uint32_t *base);
vuint32m2_t vloadw_u32m2 (const uint32_t *base);
vuint32m4_t vloadw_u32m4 (const uint32_t *base);
vuint32m8_t vloadw_u32m8 (const uint32_t *base);
vuint64m1_t vloadw_u64m1 (const uint32_t *base);
vuint64m2_t vloadw_u64m2 (const uint32_t *base);
vuint64m4_t vloadw_u64m4 (const uint32_t *base);
vuint64m8_t vloadw_u64m8 (const uint32_t *base);
vint8m1_t vload_i8m1 (const int8_t *base);
vint8m2_t vload_i8m2 (const int8_t *base);
vint8m4_t vload_i8m4 (const int8_t *base);
vint8m8_t vload_i8m8 (const int8_t *base);
vint16m1_t vload_i16m1 (const int16_t *base);
vint16m2_t vload_i16m2 (const int16_t *base);
vint16m4_t vload_i16m4 (const int16_t *base);
vint16m8_t vload_i16m8 (const int16_t *base);
vint32m1_t vload_i32m1 (const int32_t *base);
vint32m2_t vload_i32m2 (const int32_t *base);
vint32m4_t vload_i32m4 (const int32_t *base);
vint32m8_t vload_i32m8 (const int32_t *base);
vint64m1_t vload_i64m1 (const int64_t *base);
vint64m2_t vload_i64m2 (const int64_t *base);
vint64m4_t vload_i64m4 (const int64_t *base);
vint64m8_t vload_i64m8 (const int64_t *base);
vuint8m1_t vload_u8m1 (const uint8_t *base);
vuint8m2_t vload_u8m2 (const uint8_t *base);
vuint8m4_t vload_u8m4 (const uint8_t *base);
vuint8m8_t vload_u8m8 (const uint8_t *base);
vuint16m1_t vload_u16m1 (const uint16_t *base);
vuint16m2_t vload_u16m2 (const uint16_t *base);
vuint16m4_t vload_u16m4 (const uint16_t *base);
vuint16m8_t vload_u16m8 (const uint16_t *base);
vuint32m1_t vload_u32m1 (const uint32_t *base);
vuint32m2_t vload_u32m2 (const uint32_t *base);
vuint32m4_t vload_u32m4 (const uint32_t *base);
vuint32m8_t vload_u32m8 (const uint32_t *base);
vuint64m1_t vload_u64m1 (const uint64_t *base);
vuint64m2_t vload_u64m2 (const uint64_t *base);
vuint64m4_t vload_u64m4 (const uint64_t *base);
vuint64m8_t vload_u64m8 (const uint64_t *base);
vfloat16m1_t vload_f16m1 (const float16_t *base);
vfloat16m2_t vload_f16m2 (const float16_t *base);
vfloat16m4_t vload_f16m4 (const float16_t *base);
vfloat16m8_t vload_f16m8 (const float16_t *base);
vfloat32m1_t vload_f32m1 (const float32_t *base);
vfloat32m2_t vload_f32m2 (const float32_t *base);
vfloat32m4_t vload_f32m4 (const float32_t *base);
vfloat32m8_t vload_f32m8 (const float32_t *base);
vfloat64m1_t vload_f64m1 (const float64_t *base);
vfloat64m2_t vload_f64m2 (const float64_t *base);
vfloat64m4_t vload_f64m4 (const float64_t *base);
vfloat64m8_t vload_f64m8 (const float64_t *base);
// masked functions
vint8m1_t vloadb_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vloadb_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vloadb_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vloadb_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vloadb_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base);
vint16m2_t vloadb_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base);
vint16m4_t vloadb_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base);
vint16m8_t vloadb_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base);
vint32m1_t vloadb_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base);
vint32m2_t vloadb_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base);
vint32m4_t vloadb_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base);
vint32m8_t vloadb_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base);
vint64m1_t vloadb_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base);
vint64m2_t vloadb_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base);
vint64m4_t vloadb_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base);
vint64m8_t vloadb_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base);
vuint8m1_t vloadb_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vloadb_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vloadb_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vloadb_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vloadb_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base);
vuint16m2_t vloadb_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base);
vuint16m4_t vloadb_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base);
vuint16m8_t vloadb_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base);
vuint32m1_t vloadb_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base);
vuint32m2_t vloadb_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base);
vuint32m4_t vloadb_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base);
vuint32m8_t vloadb_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base);
vuint64m1_t vloadb_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base);
vuint64m2_t vloadb_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base);
vuint64m4_t vloadb_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base);
vuint64m8_t vloadb_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base);
vint16m1_t vloadh_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vloadh_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vloadh_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vloadh_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vloadh_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base);
vint32m2_t vloadh_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base);
vint32m4_t vloadh_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base);
vint32m8_t vloadh_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base);
vint64m1_t vloadh_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base);
vint64m2_t vloadh_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base);
vint64m4_t vloadh_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base);
vint64m8_t vloadh_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base);
vuint16m1_t vloadh_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vloadh_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vloadh_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vloadh_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vloadh_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base);
vuint32m2_t vloadh_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base);
vuint32m4_t vloadh_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base);
vuint32m8_t vloadh_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base);
vuint64m1_t vloadh_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base);
vuint64m2_t vloadh_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base);
vuint64m4_t vloadh_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base);
vuint64m8_t vloadh_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base);
vint32m1_t vloadw_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vloadw_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vloadw_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vloadw_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vloadw_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base);
vint64m2_t vloadw_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base);
vint64m4_t vloadw_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base);
vint64m8_t vloadw_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base);
vuint32m1_t vloadw_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vloadw_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vloadw_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vloadw_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vloadw_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base);
vuint64m2_t vloadw_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base);
vuint64m4_t vloadw_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base);
vuint64m8_t vloadw_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base);
vint8m1_t vload_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vload_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vload_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vload_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vload_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vload_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vload_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vload_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vload_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vload_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vload_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vload_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vload_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base);
vint64m2_t vload_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base);
vint64m4_t vload_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base);
vint64m8_t vload_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base);
vuint8m1_t vload_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vload_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vload_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vload_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vload_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vload_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vload_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vload_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vload_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vload_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vload_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vload_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vload_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base);
vuint64m2_t vload_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base);
vuint64m4_t vload_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base);
vuint64m8_t vload_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base);
vfloat16m1_t vload_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base);
vfloat16m2_t vload_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base);
vfloat16m4_t vload_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base);
vfloat16m8_t vload_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base);
vfloat32m1_t vload_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base);
vfloat32m2_t vload_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base);
vfloat32m4_t vload_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base);
vfloat32m8_t vload_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base);
vfloat64m1_t vload_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base);
vfloat64m2_t vload_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base);
vfloat64m4_t vload_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base);
vfloat64m8_t vload_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base);
```
### [Vector Unit-Stride Store Functions]()

**Prototypes:**
``` C
void vstoreb_i8m1 (int8_t *base, vint8m1_t value);
void vstoreb_i8m2 (int8_t *base, vint8m2_t value);
void vstoreb_i8m4 (int8_t *base, vint8m4_t value);
void vstoreb_i8m8 (int8_t *base, vint8m8_t value);
void vstoreb_i16m1 (int8_t *base, vint16m1_t value);
void vstoreb_i16m2 (int8_t *base, vint16m2_t value);
void vstoreb_i16m4 (int8_t *base, vint16m4_t value);
void vstoreb_i16m8 (int8_t *base, vint16m8_t value);
void vstoreb_i32m1 (int8_t *base, vint32m1_t value);
void vstoreb_i32m2 (int8_t *base, vint32m2_t value);
void vstoreb_i32m4 (int8_t *base, vint32m4_t value);
void vstoreb_i32m8 (int8_t *base, vint32m8_t value);
void vstoreb_i64m1 (int8_t *base, vint64m1_t value);
void vstoreb_i64m2 (int8_t *base, vint64m2_t value);
void vstoreb_i64m4 (int8_t *base, vint64m4_t value);
void vstoreb_i64m8 (int8_t *base, vint64m8_t value);
void vstoreb_u8m1 (uint8_t *base, vuint8m1_t value);
void vstoreb_u8m2 (uint8_t *base, vuint8m2_t value);
void vstoreb_u8m4 (uint8_t *base, vuint8m4_t value);
void vstoreb_u8m8 (uint8_t *base, vuint8m8_t value);
void vstoreb_u16m1 (uint8_t *base, vuint16m1_t value);
void vstoreb_u16m2 (uint8_t *base, vuint16m2_t value);
void vstoreb_u16m4 (uint8_t *base, vuint16m4_t value);
void vstoreb_u16m8 (uint8_t *base, vuint16m8_t value);
void vstoreb_u32m1 (uint8_t *base, vuint32m1_t value);
void vstoreb_u32m2 (uint8_t *base, vuint32m2_t value);
void vstoreb_u32m4 (uint8_t *base, vuint32m4_t value);
void vstoreb_u32m8 (uint8_t *base, vuint32m8_t value);
void vstoreb_u64m1 (uint8_t *base, vuint64m1_t value);
void vstoreb_u64m2 (uint8_t *base, vuint64m2_t value);
void vstoreb_u64m4 (uint8_t *base, vuint64m4_t value);
void vstoreb_u64m8 (uint8_t *base, vuint64m8_t value);
void vstoreh_i16m1 (int16_t *base, vint16m1_t value);
void vstoreh_i16m2 (int16_t *base, vint16m2_t value);
void vstoreh_i16m4 (int16_t *base, vint16m4_t value);
void vstoreh_i16m8 (int16_t *base, vint16m8_t value);
void vstoreh_i32m1 (int16_t *base, vint32m1_t value);
void vstoreh_i32m2 (int16_t *base, vint32m2_t value);
void vstoreh_i32m4 (int16_t *base, vint32m4_t value);
void vstoreh_i32m8 (int16_t *base, vint32m8_t value);
void vstoreh_i64m1 (int16_t *base, vint64m1_t value);
void vstoreh_i64m2 (int16_t *base, vint64m2_t value);
void vstoreh_i64m4 (int16_t *base, vint64m4_t value);
void vstoreh_i64m8 (int16_t *base, vint64m8_t value);
void vstoreh_u16m1 (uint16_t *base, vuint16m1_t value);
void vstoreh_u16m2 (uint16_t *base, vuint16m2_t value);
void vstoreh_u16m4 (uint16_t *base, vuint16m4_t value);
void vstoreh_u16m8 (uint16_t *base, vuint16m8_t value);
void vstoreh_u32m1 (uint16_t *base, vuint32m1_t value);
void vstoreh_u32m2 (uint16_t *base, vuint32m2_t value);
void vstoreh_u32m4 (uint16_t *base, vuint32m4_t value);
void vstoreh_u32m8 (uint16_t *base, vuint32m8_t value);
void vstoreh_u64m1 (uint16_t *base, vuint64m1_t value);
void vstoreh_u64m2 (uint16_t *base, vuint64m2_t value);
void vstoreh_u64m4 (uint16_t *base, vuint64m4_t value);
void vstoreh_u64m8 (uint16_t *base, vuint64m8_t value);
void vstorew_i32m1 (int32_t *base, vint32m1_t value);
void vstorew_i32m2 (int32_t *base, vint32m2_t value);
void vstorew_i32m4 (int32_t *base, vint32m4_t value);
void vstorew_i32m8 (int32_t *base, vint32m8_t value);
void vstorew_i64m1 (int32_t *base, vint64m1_t value);
void vstorew_i64m2 (int32_t *base, vint64m2_t value);
void vstorew_i64m4 (int32_t *base, vint64m4_t value);
void vstorew_i64m8 (int32_t *base, vint64m8_t value);
void vstorew_u32m1 (uint32_t *base, vuint32m1_t value);
void vstorew_u32m2 (uint32_t *base, vuint32m2_t value);
void vstorew_u32m4 (uint32_t *base, vuint32m4_t value);
void vstorew_u32m8 (uint32_t *base, vuint32m8_t value);
void vstorew_u64m1 (uint32_t *base, vuint64m1_t value);
void vstorew_u64m2 (uint32_t *base, vuint64m2_t value);
void vstorew_u64m4 (uint32_t *base, vuint64m4_t value);
void vstorew_u64m8 (uint32_t *base, vuint64m8_t value);
void vstore_i8m1 (int8_t *base, vint8m1_t value);
void vstore_i8m2 (int8_t *base, vint8m2_t value);
void vstore_i8m4 (int8_t *base, vint8m4_t value);
void vstore_i8m8 (int8_t *base, vint8m8_t value);
void vstore_i16m1 (int16_t *base, vint16m1_t value);
void vstore_i16m2 (int16_t *base, vint16m2_t value);
void vstore_i16m4 (int16_t *base, vint16m4_t value);
void vstore_i16m8 (int16_t *base, vint16m8_t value);
void vstore_i32m1 (int32_t *base, vint32m1_t value);
void vstore_i32m2 (int32_t *base, vint32m2_t value);
void vstore_i32m4 (int32_t *base, vint32m4_t value);
void vstore_i32m8 (int32_t *base, vint32m8_t value);
void vstore_i64m1 (int64_t *base, vint64m1_t value);
void vstore_i64m2 (int64_t *base, vint64m2_t value);
void vstore_i64m4 (int64_t *base, vint64m4_t value);
void vstore_i64m8 (int64_t *base, vint64m8_t value);
void vstore_u8m1 (uint8_t *base, vuint8m1_t value);
void vstore_u8m2 (uint8_t *base, vuint8m2_t value);
void vstore_u8m4 (uint8_t *base, vuint8m4_t value);
void vstore_u8m8 (uint8_t *base, vuint8m8_t value);
void vstore_u16m1 (uint16_t *base, vuint16m1_t value);
void vstore_u16m2 (uint16_t *base, vuint16m2_t value);
void vstore_u16m4 (uint16_t *base, vuint16m4_t value);
void vstore_u16m8 (uint16_t *base, vuint16m8_t value);
void vstore_u32m1 (uint32_t *base, vuint32m1_t value);
void vstore_u32m2 (uint32_t *base, vuint32m2_t value);
void vstore_u32m4 (uint32_t *base, vuint32m4_t value);
void vstore_u32m8 (uint32_t *base, vuint32m8_t value);
void vstore_u64m1 (uint64_t *base, vuint64m1_t value);
void vstore_u64m2 (uint64_t *base, vuint64m2_t value);
void vstore_u64m4 (uint64_t *base, vuint64m4_t value);
void vstore_u64m8 (uint64_t *base, vuint64m8_t value);
void vstore_f16m1 (float16_t *base, vfloat16m1_t value);
void vstore_f16m2 (float16_t *base, vfloat16m2_t value);
void vstore_f16m4 (float16_t *base, vfloat16m4_t value);
void vstore_f16m8 (float16_t *base, vfloat16m8_t value);
void vstore_f32m1 (float32_t *base, vfloat32m1_t value);
void vstore_f32m2 (float32_t *base, vfloat32m2_t value);
void vstore_f32m4 (float32_t *base, vfloat32m4_t value);
void vstore_f32m8 (float32_t *base, vfloat32m8_t value);
void vstore_f64m1 (float64_t *base, vfloat64m1_t value);
void vstore_f64m2 (float64_t *base, vfloat64m2_t value);
void vstore_f64m4 (float64_t *base, vfloat64m4_t value);
void vstore_f64m8 (float64_t *base, vfloat64m8_t value);
// masked functions
void vstoreb_i8m1_mask (int8_t *base, vbool8_t mask, vint8m1_t value);
void vstoreb_i8m2_mask (int8_t *base, vbool4_t mask, vint8m2_t value);
void vstoreb_i8m4_mask (int8_t *base, vbool2_t mask, vint8m4_t value);
void vstoreb_i8m8_mask (int8_t *base, vbool1_t mask, vint8m8_t value);
void vstoreb_i16m1_mask (int8_t *base, vbool16_t mask, vint16m1_t value);
void vstoreb_i16m2_mask (int8_t *base, vbool8_t mask, vint16m2_t value);
void vstoreb_i16m4_mask (int8_t *base, vbool4_t mask, vint16m4_t value);
void vstoreb_i16m8_mask (int8_t *base, vbool2_t mask, vint16m8_t value);
void vstoreb_i32m1_mask (int8_t *base, vbool32_t mask, vint32m1_t value);
void vstoreb_i32m2_mask (int8_t *base, vbool16_t mask, vint32m2_t value);
void vstoreb_i32m4_mask (int8_t *base, vbool8_t mask, vint32m4_t value);
void vstoreb_i32m8_mask (int8_t *base, vbool4_t mask, vint32m8_t value);
void vstoreb_i64m1_mask (int8_t *base, vbool64_t mask, vint64m1_t value);
void vstoreb_i64m2_mask (int8_t *base, vbool32_t mask, vint64m2_t value);
void vstoreb_i64m4_mask (int8_t *base, vbool16_t mask, vint64m4_t value);
void vstoreb_i64m8_mask (int8_t *base, vbool8_t mask, vint64m8_t value);
void vstoreb_u8m1_mask (uint8_t *base, vbool8_t mask, vuint8m1_t value);
void vstoreb_u8m2_mask (uint8_t *base, vbool4_t mask, vuint8m2_t value);
void vstoreb_u8m4_mask (uint8_t *base, vbool2_t mask, vuint8m4_t value);
void vstoreb_u8m8_mask (uint8_t *base, vbool1_t mask, vuint8m8_t value);
void vstoreb_u16m1_mask (uint8_t *base, vbool16_t mask, vuint16m1_t value);
void vstoreb_u16m2_mask (uint8_t *base, vbool8_t mask, vuint16m2_t value);
void vstoreb_u16m4_mask (uint8_t *base, vbool4_t mask, vuint16m4_t value);
void vstoreb_u16m8_mask (uint8_t *base, vbool2_t mask, vuint16m8_t value);
void vstoreb_u32m1_mask (uint8_t *base, vbool32_t mask, vuint32m1_t value);
void vstoreb_u32m2_mask (uint8_t *base, vbool16_t mask, vuint32m2_t value);
void vstoreb_u32m4_mask (uint8_t *base, vbool8_t mask, vuint32m4_t value);
void vstoreb_u32m8_mask (uint8_t *base, vbool4_t mask, vuint32m8_t value);
void vstoreb_u64m1_mask (uint8_t *base, vbool64_t mask, vuint64m1_t value);
void vstoreb_u64m2_mask (uint8_t *base, vbool32_t mask, vuint64m2_t value);
void vstoreb_u64m4_mask (uint8_t *base, vbool16_t mask, vuint64m4_t value);
void vstoreb_u64m8_mask (uint8_t *base, vbool8_t mask, vuint64m8_t value);
void vstoreh_i16m1_mask (int16_t *base, vbool16_t mask, vint16m1_t value);
void vstoreh_i16m2_mask (int16_t *base, vbool8_t mask, vint16m2_t value);
void vstoreh_i16m4_mask (int16_t *base, vbool4_t mask, vint16m4_t value);
void vstoreh_i16m8_mask (int16_t *base, vbool2_t mask, vint16m8_t value);
void vstoreh_i32m1_mask (int16_t *base, vbool32_t mask, vint32m1_t value);
void vstoreh_i32m2_mask (int16_t *base, vbool16_t mask, vint32m2_t value);
void vstoreh_i32m4_mask (int16_t *base, vbool8_t mask, vint32m4_t value);
void vstoreh_i32m8_mask (int16_t *base, vbool4_t mask, vint32m8_t value);
void vstoreh_i64m1_mask (int16_t *base, vbool64_t mask, vint64m1_t value);
void vstoreh_i64m2_mask (int16_t *base, vbool32_t mask, vint64m2_t value);
void vstoreh_i64m4_mask (int16_t *base, vbool16_t mask, vint64m4_t value);
void vstoreh_i64m8_mask (int16_t *base, vbool8_t mask, vint64m8_t value);
void vstoreh_u16m1_mask (uint16_t *base, vbool16_t mask, vuint16m1_t value);
void vstoreh_u16m2_mask (uint16_t *base, vbool8_t mask, vuint16m2_t value);
void vstoreh_u16m4_mask (uint16_t *base, vbool4_t mask, vuint16m4_t value);
void vstoreh_u16m8_mask (uint16_t *base, vbool2_t mask, vuint16m8_t value);
void vstoreh_u32m1_mask (uint16_t *base, vbool32_t mask, vuint32m1_t value);
void vstoreh_u32m2_mask (uint16_t *base, vbool16_t mask, vuint32m2_t value);
void vstoreh_u32m4_mask (uint16_t *base, vbool8_t mask, vuint32m4_t value);
void vstoreh_u32m8_mask (uint16_t *base, vbool4_t mask, vuint32m8_t value);
void vstoreh_u64m1_mask (uint16_t *base, vbool64_t mask, vuint64m1_t value);
void vstoreh_u64m2_mask (uint16_t *base, vbool32_t mask, vuint64m2_t value);
void vstoreh_u64m4_mask (uint16_t *base, vbool16_t mask, vuint64m4_t value);
void vstoreh_u64m8_mask (uint16_t *base, vbool8_t mask, vuint64m8_t value);
void vstorew_i32m1_mask (int32_t *base, vbool32_t mask, vint32m1_t value);
void vstorew_i32m2_mask (int32_t *base, vbool16_t mask, vint32m2_t value);
void vstorew_i32m4_mask (int32_t *base, vbool8_t mask, vint32m4_t value);
void vstorew_i32m8_mask (int32_t *base, vbool4_t mask, vint32m8_t value);
void vstorew_i64m1_mask (int32_t *base, vbool64_t mask, vint64m1_t value);
void vstorew_i64m2_mask (int32_t *base, vbool32_t mask, vint64m2_t value);
void vstorew_i64m4_mask (int32_t *base, vbool16_t mask, vint64m4_t value);
void vstorew_i64m8_mask (int32_t *base, vbool8_t mask, vint64m8_t value);
void vstorew_u32m1_mask (uint32_t *base, vbool32_t mask, vuint32m1_t value);
void vstorew_u32m2_mask (uint32_t *base, vbool16_t mask, vuint32m2_t value);
void vstorew_u32m4_mask (uint32_t *base, vbool8_t mask, vuint32m4_t value);
void vstorew_u32m8_mask (uint32_t *base, vbool4_t mask, vuint32m8_t value);
void vstorew_u64m1_mask (uint32_t *base, vbool64_t mask, vuint64m1_t value);
void vstorew_u64m2_mask (uint32_t *base, vbool32_t mask, vuint64m2_t value);
void vstorew_u64m4_mask (uint32_t *base, vbool16_t mask, vuint64m4_t value);
void vstorew_u64m8_mask (uint32_t *base, vbool8_t mask, vuint64m8_t value);
void vstore_i8m1_mask (int8_t *base, vbool8_t mask, vint8m1_t value);
void vstore_i8m2_mask (int8_t *base, vbool4_t mask, vint8m2_t value);
void vstore_i8m4_mask (int8_t *base, vbool2_t mask, vint8m4_t value);
void vstore_i8m8_mask (int8_t *base, vbool1_t mask, vint8m8_t value);
void vstore_i16m1_mask (int16_t *base, vbool16_t mask, vint16m1_t value);
void vstore_i16m2_mask (int16_t *base, vbool8_t mask, vint16m2_t value);
void vstore_i16m4_mask (int16_t *base, vbool4_t mask, vint16m4_t value);
void vstore_i16m8_mask (int16_t *base, vbool2_t mask, vint16m8_t value);
void vstore_i32m1_mask (int32_t *base, vbool32_t mask, vint32m1_t value);
void vstore_i32m2_mask (int32_t *base, vbool16_t mask, vint32m2_t value);
void vstore_i32m4_mask (int32_t *base, vbool8_t mask, vint32m4_t value);
void vstore_i32m8_mask (int32_t *base, vbool4_t mask, vint32m8_t value);
void vstore_i64m1_mask (int64_t *base, vbool64_t mask, vint64m1_t value);
void vstore_i64m2_mask (int64_t *base, vbool32_t mask, vint64m2_t value);
void vstore_i64m4_mask (int64_t *base, vbool16_t mask, vint64m4_t value);
void vstore_i64m8_mask (int64_t *base, vbool8_t mask, vint64m8_t value);
void vstore_u8m1_mask (uint8_t *base, vbool8_t mask, vuint8m1_t value);
void vstore_u8m2_mask (uint8_t *base, vbool4_t mask, vuint8m2_t value);
void vstore_u8m4_mask (uint8_t *base, vbool2_t mask, vuint8m4_t value);
void vstore_u8m8_mask (uint8_t *base, vbool1_t mask, vuint8m8_t value);
void vstore_u16m1_mask (uint16_t *base, vbool16_t mask, vuint16m1_t value);
void vstore_u16m2_mask (uint16_t *base, vbool8_t mask, vuint16m2_t value);
void vstore_u16m4_mask (uint16_t *base, vbool4_t mask, vuint16m4_t value);
void vstore_u16m8_mask (uint16_t *base, vbool2_t mask, vuint16m8_t value);
void vstore_u32m1_mask (uint32_t *base, vbool32_t mask, vuint32m1_t value);
void vstore_u32m2_mask (uint32_t *base, vbool16_t mask, vuint32m2_t value);
void vstore_u32m4_mask (uint32_t *base, vbool8_t mask, vuint32m4_t value);
void vstore_u32m8_mask (uint32_t *base, vbool4_t mask, vuint32m8_t value);
void vstore_u64m1_mask (uint64_t *base, vbool64_t mask, vuint64m1_t value);
void vstore_u64m2_mask (uint64_t *base, vbool32_t mask, vuint64m2_t value);
void vstore_u64m4_mask (uint64_t *base, vbool16_t mask, vuint64m4_t value);
void vstore_u64m8_mask (uint64_t *base, vbool8_t mask, vuint64m8_t value);
void vstore_f16m1_mask (float16_t *base, vbool16_t mask, vfloat16m1_t value);
void vstore_f16m2_mask (float16_t *base, vbool8_t mask, vfloat16m2_t value);
void vstore_f16m4_mask (float16_t *base, vbool4_t mask, vfloat16m4_t value);
void vstore_f16m8_mask (float16_t *base, vbool2_t mask, vfloat16m8_t value);
void vstore_f32m1_mask (float32_t *base, vbool32_t mask, vfloat32m1_t value);
void vstore_f32m2_mask (float32_t *base, vbool16_t mask, vfloat32m2_t value);
void vstore_f32m4_mask (float32_t *base, vbool8_t mask, vfloat32m4_t value);
void vstore_f32m8_mask (float32_t *base, vbool4_t mask, vfloat32m8_t value);
void vstore_f64m1_mask (float64_t *base, vbool64_t mask, vfloat64m1_t value);
void vstore_f64m2_mask (float64_t *base, vbool32_t mask, vfloat64m2_t value);
void vstore_f64m4_mask (float64_t *base, vbool16_t mask, vfloat64m4_t value);
void vstore_f64m8_mask (float64_t *base, vbool8_t mask, vfloat64m8_t value);
```
### [Vector Strided Load Functions]()

**Prototypes:**
``` C
vint8m1_t vloadsb_i8m1 (const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloadsb_i8m2 (const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloadsb_i8m4 (const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloadsb_i8m8 (const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsb_i16m1 (const int8_t *base, ptrdiff_t bstride);
vint16m2_t vloadsb_i16m2 (const int8_t *base, ptrdiff_t bstride);
vint16m4_t vloadsb_i16m4 (const int8_t *base, ptrdiff_t bstride);
vint16m8_t vloadsb_i16m8 (const int8_t *base, ptrdiff_t bstride);
vint32m1_t vloadsb_i32m1 (const int8_t *base, ptrdiff_t bstride);
vint32m2_t vloadsb_i32m2 (const int8_t *base, ptrdiff_t bstride);
vint32m4_t vloadsb_i32m4 (const int8_t *base, ptrdiff_t bstride);
vint32m8_t vloadsb_i32m8 (const int8_t *base, ptrdiff_t bstride);
vint64m1_t vloadsb_i64m1 (const int8_t *base, ptrdiff_t bstride);
vint64m2_t vloadsb_i64m2 (const int8_t *base, ptrdiff_t bstride);
vint64m4_t vloadsb_i64m4 (const int8_t *base, ptrdiff_t bstride);
vint64m8_t vloadsb_i64m8 (const int8_t *base, ptrdiff_t bstride);
vuint8m1_t vloadsb_u8m1 (const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloadsb_u8m2 (const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloadsb_u8m4 (const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloadsb_u8m8 (const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsb_u16m1 (const uint8_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsb_u16m2 (const uint8_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsb_u16m4 (const uint8_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsb_u16m8 (const uint8_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsb_u32m1 (const uint8_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsb_u32m2 (const uint8_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsb_u32m4 (const uint8_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsb_u32m8 (const uint8_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsb_u64m1 (const uint8_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsb_u64m2 (const uint8_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsb_u64m4 (const uint8_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsb_u64m8 (const uint8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsh_i16m1 (const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloadsh_i16m2 (const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloadsh_i16m4 (const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloadsh_i16m8 (const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsh_i32m1 (const int16_t *base, ptrdiff_t bstride);
vint32m2_t vloadsh_i32m2 (const int16_t *base, ptrdiff_t bstride);
vint32m4_t vloadsh_i32m4 (const int16_t *base, ptrdiff_t bstride);
vint32m8_t vloadsh_i32m8 (const int16_t *base, ptrdiff_t bstride);
vint64m1_t vloadsh_i64m1 (const int16_t *base, ptrdiff_t bstride);
vint64m2_t vloadsh_i64m2 (const int16_t *base, ptrdiff_t bstride);
vint64m4_t vloadsh_i64m4 (const int16_t *base, ptrdiff_t bstride);
vint64m8_t vloadsh_i64m8 (const int16_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsh_u16m1 (const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsh_u16m2 (const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsh_u16m4 (const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsh_u16m8 (const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsh_u32m1 (const uint16_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsh_u32m2 (const uint16_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsh_u32m4 (const uint16_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsh_u32m8 (const uint16_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsh_u64m1 (const uint16_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsh_u64m2 (const uint16_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsh_u64m4 (const uint16_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsh_u64m8 (const uint16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsw_i32m1 (const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloadsw_i32m2 (const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloadsw_i32m4 (const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloadsw_i32m8 (const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloadsw_i64m1 (const int32_t *base, ptrdiff_t bstride);
vint64m2_t vloadsw_i64m2 (const int32_t *base, ptrdiff_t bstride);
vint64m4_t vloadsw_i64m4 (const int32_t *base, ptrdiff_t bstride);
vint64m8_t vloadsw_i64m8 (const int32_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsw_u32m1 (const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsw_u32m2 (const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsw_u32m4 (const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsw_u32m8 (const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsw_u64m1 (const uint32_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsw_u64m2 (const uint32_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsw_u64m4 (const uint32_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsw_u64m8 (const uint32_t *base, ptrdiff_t bstride);
vint8m1_t vloads_i8m1 (const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloads_i8m2 (const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloads_i8m4 (const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloads_i8m8 (const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloads_i16m1 (const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloads_i16m2 (const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloads_i16m4 (const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloads_i16m8 (const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloads_i32m1 (const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloads_i32m2 (const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloads_i32m4 (const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloads_i32m8 (const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloads_i64m1 (const int64_t *base, ptrdiff_t bstride);
vint64m2_t vloads_i64m2 (const int64_t *base, ptrdiff_t bstride);
vint64m4_t vloads_i64m4 (const int64_t *base, ptrdiff_t bstride);
vint64m8_t vloads_i64m8 (const int64_t *base, ptrdiff_t bstride);
vuint8m1_t vloads_u8m1 (const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloads_u8m2 (const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloads_u8m4 (const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloads_u8m8 (const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloads_u16m1 (const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloads_u16m2 (const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloads_u16m4 (const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloads_u16m8 (const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloads_u32m1 (const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloads_u32m2 (const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloads_u32m4 (const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloads_u32m8 (const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloads_u64m1 (const uint64_t *base, ptrdiff_t bstride);
vuint64m2_t vloads_u64m2 (const uint64_t *base, ptrdiff_t bstride);
vuint64m4_t vloads_u64m4 (const uint64_t *base, ptrdiff_t bstride);
vuint64m8_t vloads_u64m8 (const uint64_t *base, ptrdiff_t bstride);
vfloat16m1_t vloads_f16m1 (const float16_t *base, ptrdiff_t bstride);
vfloat16m2_t vloads_f16m2 (const float16_t *base, ptrdiff_t bstride);
vfloat16m4_t vloads_f16m4 (const float16_t *base, ptrdiff_t bstride);
vfloat16m8_t vloads_f16m8 (const float16_t *base, ptrdiff_t bstride);
vfloat32m1_t vloads_f32m1 (const float32_t *base, ptrdiff_t bstride);
vfloat32m2_t vloads_f32m2 (const float32_t *base, ptrdiff_t bstride);
vfloat32m4_t vloads_f32m4 (const float32_t *base, ptrdiff_t bstride);
vfloat32m8_t vloads_f32m8 (const float32_t *base, ptrdiff_t bstride);
vfloat64m1_t vloads_f64m1 (const float64_t *base, ptrdiff_t bstride);
vfloat64m2_t vloads_f64m2 (const float64_t *base, ptrdiff_t bstride);
vfloat64m4_t vloads_f64m4 (const float64_t *base, ptrdiff_t bstride);
vfloat64m8_t vloads_f64m8 (const float64_t *base, ptrdiff_t bstride);
// masked functions
vint8m1_t vloadsb_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloadsb_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloadsb_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloadsb_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsb_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m2_t vloadsb_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m4_t vloadsb_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m8_t vloadsb_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m1_t vloadsb_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m2_t vloadsb_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m4_t vloadsb_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m8_t vloadsb_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m1_t vloadsb_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m2_t vloadsb_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m4_t vloadsb_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m8_t vloadsb_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vuint8m1_t vloadsb_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloadsb_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloadsb_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloadsb_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsb_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsb_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsb_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsb_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsb_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsb_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsb_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsb_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsb_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsb_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsb_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsb_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsh_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloadsh_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloadsh_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloadsh_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsh_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m2_t vloadsh_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m4_t vloadsh_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m8_t vloadsh_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m1_t vloadsh_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m2_t vloadsh_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m4_t vloadsh_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m8_t vloadsh_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsh_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsh_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsh_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsh_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsh_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsh_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsh_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsh_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsh_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsh_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsh_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsh_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsw_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloadsw_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloadsw_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloadsw_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloadsw_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m2_t vloadsw_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m4_t vloadsw_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m8_t vloadsw_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsw_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsw_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsw_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsw_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsw_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsw_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsw_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsw_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vint8m1_t vloads_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloads_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloads_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloads_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloads_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloads_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloads_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloads_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloads_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloads_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloads_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloads_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloads_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m2_t vloads_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m4_t vloads_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m8_t vloads_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vuint8m1_t vloads_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloads_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloads_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloads_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloads_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloads_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloads_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloads_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloads_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloads_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloads_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloads_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloads_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m2_t vloads_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m4_t vloads_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m8_t vloads_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vfloat16m1_t vloads_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m2_t vloads_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m4_t vloads_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m8_t vloads_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat32m1_t vloads_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m2_t vloads_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m4_t vloads_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m8_t vloads_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat64m1_t vloads_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m2_t vloads_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m4_t vloads_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m8_t vloads_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, ptrdiff_t bstride);
```
### [Vector Strided Store Functions]()

**Prototypes:**
``` C
void vstoresb_i8m1 (int8_t *base, ptrdiff_t bstride, vint8m1_t value);
void vstoresb_i8m2 (int8_t *base, ptrdiff_t bstride, vint8m2_t value);
void vstoresb_i8m4 (int8_t *base, ptrdiff_t bstride, vint8m4_t value);
void vstoresb_i8m8 (int8_t *base, ptrdiff_t bstride, vint8m8_t value);
void vstoresb_i16m1 (int8_t *base, ptrdiff_t bstride, vint16m1_t value);
void vstoresb_i16m2 (int8_t *base, ptrdiff_t bstride, vint16m2_t value);
void vstoresb_i16m4 (int8_t *base, ptrdiff_t bstride, vint16m4_t value);
void vstoresb_i16m8 (int8_t *base, ptrdiff_t bstride, vint16m8_t value);
void vstoresb_i32m1 (int8_t *base, ptrdiff_t bstride, vint32m1_t value);
void vstoresb_i32m2 (int8_t *base, ptrdiff_t bstride, vint32m2_t value);
void vstoresb_i32m4 (int8_t *base, ptrdiff_t bstride, vint32m4_t value);
void vstoresb_i32m8 (int8_t *base, ptrdiff_t bstride, vint32m8_t value);
void vstoresb_i64m1 (int8_t *base, ptrdiff_t bstride, vint64m1_t value);
void vstoresb_i64m2 (int8_t *base, ptrdiff_t bstride, vint64m2_t value);
void vstoresb_i64m4 (int8_t *base, ptrdiff_t bstride, vint64m4_t value);
void vstoresb_i64m8 (int8_t *base, ptrdiff_t bstride, vint64m8_t value);
void vstoresb_u8m1 (uint8_t *base, ptrdiff_t bstride, vuint8m1_t value);
void vstoresb_u8m2 (uint8_t *base, ptrdiff_t bstride, vuint8m2_t value);
void vstoresb_u8m4 (uint8_t *base, ptrdiff_t bstride, vuint8m4_t value);
void vstoresb_u8m8 (uint8_t *base, ptrdiff_t bstride, vuint8m8_t value);
void vstoresb_u16m1 (uint8_t *base, ptrdiff_t bstride, vuint16m1_t value);
void vstoresb_u16m2 (uint8_t *base, ptrdiff_t bstride, vuint16m2_t value);
void vstoresb_u16m4 (uint8_t *base, ptrdiff_t bstride, vuint16m4_t value);
void vstoresb_u16m8 (uint8_t *base, ptrdiff_t bstride, vuint16m8_t value);
void vstoresb_u32m1 (uint8_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vstoresb_u32m2 (uint8_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vstoresb_u32m4 (uint8_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vstoresb_u32m8 (uint8_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vstoresb_u64m1 (uint8_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vstoresb_u64m2 (uint8_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vstoresb_u64m4 (uint8_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vstoresb_u64m8 (uint8_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vstoresh_i16m1 (int16_t *base, ptrdiff_t bstride, vint16m1_t value);
void vstoresh_i16m2 (int16_t *base, ptrdiff_t bstride, vint16m2_t value);
void vstoresh_i16m4 (int16_t *base, ptrdiff_t bstride, vint16m4_t value);
void vstoresh_i16m8 (int16_t *base, ptrdiff_t bstride, vint16m8_t value);
void vstoresh_i32m1 (int16_t *base, ptrdiff_t bstride, vint32m1_t value);
void vstoresh_i32m2 (int16_t *base, ptrdiff_t bstride, vint32m2_t value);
void vstoresh_i32m4 (int16_t *base, ptrdiff_t bstride, vint32m4_t value);
void vstoresh_i32m8 (int16_t *base, ptrdiff_t bstride, vint32m8_t value);
void vstoresh_i64m1 (int16_t *base, ptrdiff_t bstride, vint64m1_t value);
void vstoresh_i64m2 (int16_t *base, ptrdiff_t bstride, vint64m2_t value);
void vstoresh_i64m4 (int16_t *base, ptrdiff_t bstride, vint64m4_t value);
void vstoresh_i64m8 (int16_t *base, ptrdiff_t bstride, vint64m8_t value);
void vstoresh_u16m1 (uint16_t *base, ptrdiff_t bstride, vuint16m1_t value);
void vstoresh_u16m2 (uint16_t *base, ptrdiff_t bstride, vuint16m2_t value);
void vstoresh_u16m4 (uint16_t *base, ptrdiff_t bstride, vuint16m4_t value);
void vstoresh_u16m8 (uint16_t *base, ptrdiff_t bstride, vuint16m8_t value);
void vstoresh_u32m1 (uint16_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vstoresh_u32m2 (uint16_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vstoresh_u32m4 (uint16_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vstoresh_u32m8 (uint16_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vstoresh_u64m1 (uint16_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vstoresh_u64m2 (uint16_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vstoresh_u64m4 (uint16_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vstoresh_u64m8 (uint16_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vstoresw_i32m1 (int32_t *base, ptrdiff_t bstride, vint32m1_t value);
void vstoresw_i32m2 (int32_t *base, ptrdiff_t bstride, vint32m2_t value);
void vstoresw_i32m4 (int32_t *base, ptrdiff_t bstride, vint32m4_t value);
void vstoresw_i32m8 (int32_t *base, ptrdiff_t bstride, vint32m8_t value);
void vstoresw_i64m1 (int32_t *base, ptrdiff_t bstride, vint64m1_t value);
void vstoresw_i64m2 (int32_t *base, ptrdiff_t bstride, vint64m2_t value);
void vstoresw_i64m4 (int32_t *base, ptrdiff_t bstride, vint64m4_t value);
void vstoresw_i64m8 (int32_t *base, ptrdiff_t bstride, vint64m8_t value);
void vstoresw_u32m1 (uint32_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vstoresw_u32m2 (uint32_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vstoresw_u32m4 (uint32_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vstoresw_u32m8 (uint32_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vstoresw_u64m1 (uint32_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vstoresw_u64m2 (uint32_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vstoresw_u64m4 (uint32_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vstoresw_u64m8 (uint32_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vstores_i8m1 (int8_t *base, ptrdiff_t bstride, vint8m1_t value);
void vstores_i8m2 (int8_t *base, ptrdiff_t bstride, vint8m2_t value);
void vstores_i8m4 (int8_t *base, ptrdiff_t bstride, vint8m4_t value);
void vstores_i8m8 (int8_t *base, ptrdiff_t bstride, vint8m8_t value);
void vstores_i16m1 (int16_t *base, ptrdiff_t bstride, vint16m1_t value);
void vstores_i16m2 (int16_t *base, ptrdiff_t bstride, vint16m2_t value);
void vstores_i16m4 (int16_t *base, ptrdiff_t bstride, vint16m4_t value);
void vstores_i16m8 (int16_t *base, ptrdiff_t bstride, vint16m8_t value);
void vstores_i32m1 (int32_t *base, ptrdiff_t bstride, vint32m1_t value);
void vstores_i32m2 (int32_t *base, ptrdiff_t bstride, vint32m2_t value);
void vstores_i32m4 (int32_t *base, ptrdiff_t bstride, vint32m4_t value);
void vstores_i32m8 (int32_t *base, ptrdiff_t bstride, vint32m8_t value);
void vstores_i64m1 (int64_t *base, ptrdiff_t bstride, vint64m1_t value);
void vstores_i64m2 (int64_t *base, ptrdiff_t bstride, vint64m2_t value);
void vstores_i64m4 (int64_t *base, ptrdiff_t bstride, vint64m4_t value);
void vstores_i64m8 (int64_t *base, ptrdiff_t bstride, vint64m8_t value);
void vstores_u8m1 (uint8_t *base, ptrdiff_t bstride, vuint8m1_t value);
void vstores_u8m2 (uint8_t *base, ptrdiff_t bstride, vuint8m2_t value);
void vstores_u8m4 (uint8_t *base, ptrdiff_t bstride, vuint8m4_t value);
void vstores_u8m8 (uint8_t *base, ptrdiff_t bstride, vuint8m8_t value);
void vstores_u16m1 (uint16_t *base, ptrdiff_t bstride, vuint16m1_t value);
void vstores_u16m2 (uint16_t *base, ptrdiff_t bstride, vuint16m2_t value);
void vstores_u16m4 (uint16_t *base, ptrdiff_t bstride, vuint16m4_t value);
void vstores_u16m8 (uint16_t *base, ptrdiff_t bstride, vuint16m8_t value);
void vstores_u32m1 (uint32_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vstores_u32m2 (uint32_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vstores_u32m4 (uint32_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vstores_u32m8 (uint32_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vstores_u64m1 (uint64_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vstores_u64m2 (uint64_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vstores_u64m4 (uint64_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vstores_u64m8 (uint64_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vstores_f16m1 (float16_t *base, ptrdiff_t bstride, vfloat16m1_t value);
void vstores_f16m2 (float16_t *base, ptrdiff_t bstride, vfloat16m2_t value);
void vstores_f16m4 (float16_t *base, ptrdiff_t bstride, vfloat16m4_t value);
void vstores_f16m8 (float16_t *base, ptrdiff_t bstride, vfloat16m8_t value);
void vstores_f32m1 (float32_t *base, ptrdiff_t bstride, vfloat32m1_t value);
void vstores_f32m2 (float32_t *base, ptrdiff_t bstride, vfloat32m2_t value);
void vstores_f32m4 (float32_t *base, ptrdiff_t bstride, vfloat32m4_t value);
void vstores_f32m8 (float32_t *base, ptrdiff_t bstride, vfloat32m8_t value);
void vstores_f64m1 (float64_t *base, ptrdiff_t bstride, vfloat64m1_t value);
void vstores_f64m2 (float64_t *base, ptrdiff_t bstride, vfloat64m2_t value);
void vstores_f64m4 (float64_t *base, ptrdiff_t bstride, vfloat64m4_t value);
void vstores_f64m8 (float64_t *base, ptrdiff_t bstride, vfloat64m8_t value);
// masked functions
void vstoresb_i8m1_mask (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint8m1_t value);
void vstoresb_i8m2_mask (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint8m2_t value);
void vstoresb_i8m4_mask (int8_t *base, ptrdiff_t bstride, vbool2_t mask, vint8m4_t value);
void vstoresb_i8m8_mask (int8_t *base, ptrdiff_t bstride, vbool1_t mask, vint8m8_t value);
void vstoresb_i16m1_mask (int8_t *base, ptrdiff_t bstride, vbool16_t mask, vint16m1_t value);
void vstoresb_i16m2_mask (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint16m2_t value);
void vstoresb_i16m4_mask (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint16m4_t value);
void vstoresb_i16m8_mask (int8_t *base, ptrdiff_t bstride, vbool2_t mask, vint16m8_t value);
void vstoresb_i32m1_mask (int8_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vstoresb_i32m2_mask (int8_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vstoresb_i32m4_mask (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vstoresb_i32m8_mask (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vstoresb_i64m1_mask (int8_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vstoresb_i64m2_mask (int8_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vstoresb_i64m4_mask (int8_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vstoresb_i64m8_mask (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vstoresb_u8m1_mask (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint8m1_t value);
void vstoresb_u8m2_mask (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint8m2_t value);
void vstoresb_u8m4_mask (uint8_t *base, ptrdiff_t bstride, vbool2_t mask, vuint8m4_t value);
void vstoresb_u8m8_mask (uint8_t *base, ptrdiff_t bstride, vbool1_t mask, vuint8m8_t value);
void vstoresb_u16m1_mask (uint8_t *base, ptrdiff_t bstride, vbool16_t mask, vuint16m1_t value);
void vstoresb_u16m2_mask (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint16m2_t value);
void vstoresb_u16m4_mask (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint16m4_t value);
void vstoresb_u16m8_mask (uint8_t *base, ptrdiff_t bstride, vbool2_t mask, vuint16m8_t value);
void vstoresb_u32m1_mask (uint8_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vstoresb_u32m2_mask (uint8_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vstoresb_u32m4_mask (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vstoresb_u32m8_mask (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vstoresb_u64m1_mask (uint8_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vstoresb_u64m2_mask (uint8_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vstoresb_u64m4_mask (uint8_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vstoresb_u64m8_mask (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vstoresh_i16m1_mask (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint16m1_t value);
void vstoresh_i16m2_mask (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint16m2_t value);
void vstoresh_i16m4_mask (int16_t *base, ptrdiff_t bstride, vbool4_t mask, vint16m4_t value);
void vstoresh_i16m8_mask (int16_t *base, ptrdiff_t bstride, vbool2_t mask, vint16m8_t value);
void vstoresh_i32m1_mask (int16_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vstoresh_i32m2_mask (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vstoresh_i32m4_mask (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vstoresh_i32m8_mask (int16_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vstoresh_i64m1_mask (int16_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vstoresh_i64m2_mask (int16_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vstoresh_i64m4_mask (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vstoresh_i64m8_mask (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vstoresh_u16m1_mask (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint16m1_t value);
void vstoresh_u16m2_mask (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint16m2_t value);
void vstoresh_u16m4_mask (uint16_t *base, ptrdiff_t bstride, vbool4_t mask, vuint16m4_t value);
void vstoresh_u16m8_mask (uint16_t *base, ptrdiff_t bstride, vbool2_t mask, vuint16m8_t value);
void vstoresh_u32m1_mask (uint16_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vstoresh_u32m2_mask (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vstoresh_u32m4_mask (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vstoresh_u32m8_mask (uint16_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vstoresh_u64m1_mask (uint16_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vstoresh_u64m2_mask (uint16_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vstoresh_u64m4_mask (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vstoresh_u64m8_mask (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vstoresw_i32m1_mask (int32_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vstoresw_i32m2_mask (int32_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vstoresw_i32m4_mask (int32_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vstoresw_i32m8_mask (int32_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vstoresw_i64m1_mask (int32_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vstoresw_i64m2_mask (int32_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vstoresw_i64m4_mask (int32_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vstoresw_i64m8_mask (int32_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vstoresw_u32m1_mask (uint32_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vstoresw_u32m2_mask (uint32_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vstoresw_u32m4_mask (uint32_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vstoresw_u32m8_mask (uint32_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vstoresw_u64m1_mask (uint32_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vstoresw_u64m2_mask (uint32_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vstoresw_u64m4_mask (uint32_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vstoresw_u64m8_mask (uint32_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vstores_i8m1_mask (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint8m1_t value);
void vstores_i8m2_mask (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint8m2_t value);
void vstores_i8m4_mask (int8_t *base, ptrdiff_t bstride, vbool2_t mask, vint8m4_t value);
void vstores_i8m8_mask (int8_t *base, ptrdiff_t bstride, vbool1_t mask, vint8m8_t value);
void vstores_i16m1_mask (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint16m1_t value);
void vstores_i16m2_mask (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint16m2_t value);
void vstores_i16m4_mask (int16_t *base, ptrdiff_t bstride, vbool4_t mask, vint16m4_t value);
void vstores_i16m8_mask (int16_t *base, ptrdiff_t bstride, vbool2_t mask, vint16m8_t value);
void vstores_i32m1_mask (int32_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vstores_i32m2_mask (int32_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vstores_i32m4_mask (int32_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vstores_i32m8_mask (int32_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vstores_i64m1_mask (int64_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vstores_i64m2_mask (int64_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vstores_i64m4_mask (int64_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vstores_i64m8_mask (int64_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vstores_u8m1_mask (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint8m1_t value);
void vstores_u8m2_mask (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint8m2_t value);
void vstores_u8m4_mask (uint8_t *base, ptrdiff_t bstride, vbool2_t mask, vuint8m4_t value);
void vstores_u8m8_mask (uint8_t *base, ptrdiff_t bstride, vbool1_t mask, vuint8m8_t value);
void vstores_u16m1_mask (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint16m1_t value);
void vstores_u16m2_mask (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint16m2_t value);
void vstores_u16m4_mask (uint16_t *base, ptrdiff_t bstride, vbool4_t mask, vuint16m4_t value);
void vstores_u16m8_mask (uint16_t *base, ptrdiff_t bstride, vbool2_t mask, vuint16m8_t value);
void vstores_u32m1_mask (uint32_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vstores_u32m2_mask (uint32_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vstores_u32m4_mask (uint32_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vstores_u32m8_mask (uint32_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vstores_u64m1_mask (uint64_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vstores_u64m2_mask (uint64_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vstores_u64m4_mask (uint64_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vstores_u64m8_mask (uint64_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vstores_f16m1_mask (float16_t *base, ptrdiff_t bstride, vbool16_t mask, vfloat16m1_t value);
void vstores_f16m2_mask (float16_t *base, ptrdiff_t bstride, vbool8_t mask, vfloat16m2_t value);
void vstores_f16m4_mask (float16_t *base, ptrdiff_t bstride, vbool4_t mask, vfloat16m4_t value);
void vstores_f16m8_mask (float16_t *base, ptrdiff_t bstride, vbool2_t mask, vfloat16m8_t value);
void vstores_f32m1_mask (float32_t *base, ptrdiff_t bstride, vbool32_t mask, vfloat32m1_t value);
void vstores_f32m2_mask (float32_t *base, ptrdiff_t bstride, vbool16_t mask, vfloat32m2_t value);
void vstores_f32m4_mask (float32_t *base, ptrdiff_t bstride, vbool8_t mask, vfloat32m4_t value);
void vstores_f32m8_mask (float32_t *base, ptrdiff_t bstride, vbool4_t mask, vfloat32m8_t value);
void vstores_f64m1_mask (float64_t *base, ptrdiff_t bstride, vbool64_t mask, vfloat64m1_t value);
void vstores_f64m2_mask (float64_t *base, ptrdiff_t bstride, vbool32_t mask, vfloat64m2_t value);
void vstores_f64m4_mask (float64_t *base, ptrdiff_t bstride, vbool16_t mask, vfloat64m4_t value);
void vstores_f64m8_mask (float64_t *base, ptrdiff_t bstride, vbool8_t mask, vfloat64m8_t value);
```
### [Vector Indexed Load Functions]()

**Prototypes:**
``` C
vint8m1_t vloadxb_i8m1 (const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadxb_i8m2 (const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadxb_i8m4 (const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadxb_i8m8 (const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadxb_i16m1 (const int8_t *base, vuint16m1_t bindex);
vint16m2_t vloadxb_i16m2 (const int8_t *base, vuint16m2_t bindex);
vint16m4_t vloadxb_i16m4 (const int8_t *base, vuint16m4_t bindex);
vint16m8_t vloadxb_i16m8 (const int8_t *base, vuint16m8_t bindex);
vint32m1_t vloadxb_i32m1 (const int8_t *base, vuint32m1_t bindex);
vint32m2_t vloadxb_i32m2 (const int8_t *base, vuint32m2_t bindex);
vint32m4_t vloadxb_i32m4 (const int8_t *base, vuint32m4_t bindex);
vint32m8_t vloadxb_i32m8 (const int8_t *base, vuint32m8_t bindex);
vint64m1_t vloadxb_i64m1 (const int8_t *base, vuint64m1_t bindex);
vint64m2_t vloadxb_i64m2 (const int8_t *base, vuint64m2_t bindex);
vint64m4_t vloadxb_i64m4 (const int8_t *base, vuint64m4_t bindex);
vint64m8_t vloadxb_i64m8 (const int8_t *base, vuint64m8_t bindex);
vuint8m1_t vloadxb_u8m1 (const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadxb_u8m2 (const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadxb_u8m4 (const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadxb_u8m8 (const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadxb_u16m1 (const uint8_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxb_u16m2 (const uint8_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxb_u16m4 (const uint8_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxb_u16m8 (const uint8_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxb_u32m1 (const uint8_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxb_u32m2 (const uint8_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxb_u32m4 (const uint8_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxb_u32m8 (const uint8_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxb_u64m1 (const uint8_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxb_u64m2 (const uint8_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxb_u64m4 (const uint8_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxb_u64m8 (const uint8_t *base, vuint64m8_t bindex);
vint16m1_t vloadxh_i16m1 (const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadxh_i16m2 (const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadxh_i16m4 (const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadxh_i16m8 (const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadxh_i32m1 (const int16_t *base, vuint32m1_t bindex);
vint32m2_t vloadxh_i32m2 (const int16_t *base, vuint32m2_t bindex);
vint32m4_t vloadxh_i32m4 (const int16_t *base, vuint32m4_t bindex);
vint32m8_t vloadxh_i32m8 (const int16_t *base, vuint32m8_t bindex);
vint64m1_t vloadxh_i64m1 (const int16_t *base, vuint64m1_t bindex);
vint64m2_t vloadxh_i64m2 (const int16_t *base, vuint64m2_t bindex);
vint64m4_t vloadxh_i64m4 (const int16_t *base, vuint64m4_t bindex);
vint64m8_t vloadxh_i64m8 (const int16_t *base, vuint64m8_t bindex);
vuint16m1_t vloadxh_u16m1 (const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxh_u16m2 (const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxh_u16m4 (const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxh_u16m8 (const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxh_u32m1 (const uint16_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxh_u32m2 (const uint16_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxh_u32m4 (const uint16_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxh_u32m8 (const uint16_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxh_u64m1 (const uint16_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxh_u64m2 (const uint16_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxh_u64m4 (const uint16_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxh_u64m8 (const uint16_t *base, vuint64m8_t bindex);
vint32m1_t vloadxw_i32m1 (const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadxw_i32m2 (const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadxw_i32m4 (const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadxw_i32m8 (const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadxw_i64m1 (const int32_t *base, vuint64m1_t bindex);
vint64m2_t vloadxw_i64m2 (const int32_t *base, vuint64m2_t bindex);
vint64m4_t vloadxw_i64m4 (const int32_t *base, vuint64m4_t bindex);
vint64m8_t vloadxw_i64m8 (const int32_t *base, vuint64m8_t bindex);
vuint32m1_t vloadxw_u32m1 (const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxw_u32m2 (const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxw_u32m4 (const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxw_u32m8 (const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxw_u64m1 (const uint32_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxw_u64m2 (const uint32_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxw_u64m4 (const uint32_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxw_u64m8 (const uint32_t *base, vuint64m8_t bindex);
vint8m1_t vloadx_i8m1 (const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadx_i8m2 (const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadx_i8m4 (const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadx_i8m8 (const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadx_i16m1 (const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadx_i16m2 (const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadx_i16m4 (const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadx_i16m8 (const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadx_i32m1 (const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadx_i32m2 (const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadx_i32m4 (const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadx_i32m8 (const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadx_i64m1 (const int64_t *base, vuint64m1_t bindex);
vint64m2_t vloadx_i64m2 (const int64_t *base, vuint64m2_t bindex);
vint64m4_t vloadx_i64m4 (const int64_t *base, vuint64m4_t bindex);
vint64m8_t vloadx_i64m8 (const int64_t *base, vuint64m8_t bindex);
vuint8m1_t vloadx_u8m1 (const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadx_u8m2 (const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadx_u8m4 (const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadx_u8m8 (const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadx_u16m1 (const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadx_u16m2 (const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadx_u16m4 (const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadx_u16m8 (const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadx_u32m1 (const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadx_u32m2 (const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadx_u32m4 (const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadx_u32m8 (const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadx_u64m1 (const uint64_t *base, vuint64m1_t bindex);
vuint64m2_t vloadx_u64m2 (const uint64_t *base, vuint64m2_t bindex);
vuint64m4_t vloadx_u64m4 (const uint64_t *base, vuint64m4_t bindex);
vuint64m8_t vloadx_u64m8 (const uint64_t *base, vuint64m8_t bindex);
vfloat16m1_t vloadx_f16m1 (const float16_t *base, vuint16m1_t bindex);
vfloat16m2_t vloadx_f16m2 (const float16_t *base, vuint16m2_t bindex);
vfloat16m4_t vloadx_f16m4 (const float16_t *base, vuint16m4_t bindex);
vfloat16m8_t vloadx_f16m8 (const float16_t *base, vuint16m8_t bindex);
vfloat32m1_t vloadx_f32m1 (const float32_t *base, vuint32m1_t bindex);
vfloat32m2_t vloadx_f32m2 (const float32_t *base, vuint32m2_t bindex);
vfloat32m4_t vloadx_f32m4 (const float32_t *base, vuint32m4_t bindex);
vfloat32m8_t vloadx_f32m8 (const float32_t *base, vuint32m8_t bindex);
vfloat64m1_t vloadx_f64m1 (const float64_t *base, vuint64m1_t bindex);
vfloat64m2_t vloadx_f64m2 (const float64_t *base, vuint64m2_t bindex);
vfloat64m4_t vloadx_f64m4 (const float64_t *base, vuint64m4_t bindex);
vfloat64m8_t vloadx_f64m8 (const float64_t *base, vuint64m8_t bindex);
// masked functions
vint8m1_t vloadxb_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadxb_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadxb_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadxb_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadxb_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base, vuint16m1_t bindex);
vint16m2_t vloadxb_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base, vuint16m2_t bindex);
vint16m4_t vloadxb_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base, vuint16m4_t bindex);
vint16m8_t vloadxb_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base, vuint16m8_t bindex);
vint32m1_t vloadxb_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base, vuint32m1_t bindex);
vint32m2_t vloadxb_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base, vuint32m2_t bindex);
vint32m4_t vloadxb_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base, vuint32m4_t bindex);
vint32m8_t vloadxb_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base, vuint32m8_t bindex);
vint64m1_t vloadxb_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base, vuint64m1_t bindex);
vint64m2_t vloadxb_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base, vuint64m2_t bindex);
vint64m4_t vloadxb_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base, vuint64m4_t bindex);
vint64m8_t vloadxb_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base, vuint64m8_t bindex);
vuint8m1_t vloadxb_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadxb_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadxb_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadxb_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadxb_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxb_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxb_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxb_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxb_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxb_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxb_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxb_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxb_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxb_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxb_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxb_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base, vuint64m8_t bindex);
vint16m1_t vloadxh_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadxh_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadxh_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadxh_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadxh_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base, vuint32m1_t bindex);
vint32m2_t vloadxh_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base, vuint32m2_t bindex);
vint32m4_t vloadxh_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base, vuint32m4_t bindex);
vint32m8_t vloadxh_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base, vuint32m8_t bindex);
vint64m1_t vloadxh_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base, vuint64m1_t bindex);
vint64m2_t vloadxh_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base, vuint64m2_t bindex);
vint64m4_t vloadxh_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base, vuint64m4_t bindex);
vint64m8_t vloadxh_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base, vuint64m8_t bindex);
vuint16m1_t vloadxh_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxh_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxh_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxh_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxh_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxh_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxh_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxh_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxh_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxh_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxh_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxh_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base, vuint64m8_t bindex);
vint32m1_t vloadxw_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadxw_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadxw_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadxw_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadxw_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base, vuint64m1_t bindex);
vint64m2_t vloadxw_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base, vuint64m2_t bindex);
vint64m4_t vloadxw_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base, vuint64m4_t bindex);
vint64m8_t vloadxw_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base, vuint64m8_t bindex);
vuint32m1_t vloadxw_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxw_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxw_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxw_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxw_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxw_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxw_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxw_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base, vuint64m8_t bindex);
vint8m1_t vloadx_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadx_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadx_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadx_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadx_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadx_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadx_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadx_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadx_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadx_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadx_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadx_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadx_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex);
vint64m2_t vloadx_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex);
vint64m4_t vloadx_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex);
vint64m8_t vloadx_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex);
vuint8m1_t vloadx_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadx_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadx_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadx_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadx_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadx_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadx_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadx_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadx_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadx_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadx_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadx_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadx_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex);
vuint64m2_t vloadx_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex);
vuint64m4_t vloadx_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex);
vuint64m8_t vloadx_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex);
vfloat16m1_t vloadx_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex);
vfloat16m2_t vloadx_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex);
vfloat16m4_t vloadx_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex);
vfloat16m8_t vloadx_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex);
vfloat32m1_t vloadx_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex);
vfloat32m2_t vloadx_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex);
vfloat32m4_t vloadx_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex);
vfloat32m8_t vloadx_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex);
vfloat64m1_t vloadx_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex);
vfloat64m2_t vloadx_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex);
vfloat64m4_t vloadx_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex);
vfloat64m8_t vloadx_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex);
```
### [Vector Indexed Store Functions]()

**Prototypes:**
``` C
void vstorexb_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstorexb_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstorexb_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstorexb_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstorexb_i16m1 (int8_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstorexb_i16m2 (int8_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstorexb_i16m4 (int8_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstorexb_i16m8 (int8_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstorexb_i32m1 (int8_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorexb_i32m2 (int8_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorexb_i32m4 (int8_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorexb_i32m8 (int8_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorexb_i64m1 (int8_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorexb_i64m2 (int8_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorexb_i64m4 (int8_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorexb_i64m8 (int8_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorexb_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstorexb_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstorexb_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstorexb_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstorexb_u16m1 (uint8_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstorexb_u16m2 (uint8_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstorexb_u16m4 (uint8_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstorexb_u16m8 (uint8_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstorexb_u32m1 (uint8_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorexb_u32m2 (uint8_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorexb_u32m4 (uint8_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorexb_u32m8 (uint8_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorexb_u64m1 (uint8_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorexb_u64m2 (uint8_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorexb_u64m4 (uint8_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorexb_u64m8 (uint8_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorexh_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstorexh_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstorexh_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstorexh_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstorexh_i32m1 (int16_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorexh_i32m2 (int16_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorexh_i32m4 (int16_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorexh_i32m8 (int16_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorexh_i64m1 (int16_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorexh_i64m2 (int16_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorexh_i64m4 (int16_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorexh_i64m8 (int16_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorexh_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstorexh_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstorexh_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstorexh_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstorexh_u32m1 (uint16_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorexh_u32m2 (uint16_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorexh_u32m4 (uint16_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorexh_u32m8 (uint16_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorexh_u64m1 (uint16_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorexh_u64m2 (uint16_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorexh_u64m4 (uint16_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorexh_u64m8 (uint16_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorexw_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorexw_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorexw_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorexw_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorexw_i64m1 (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorexw_i64m2 (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorexw_i64m4 (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorexw_i64m8 (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorexw_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorexw_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorexw_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorexw_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorexw_u64m1 (uint32_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorexw_u64m2 (uint32_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorexw_u64m4 (uint32_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorexw_u64m8 (uint32_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorex_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstorex_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstorex_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstorex_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstorex_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstorex_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstorex_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstorex_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstorex_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorex_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorex_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorex_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorex_i64m1 (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorex_i64m2 (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorex_i64m4 (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorex_i64m8 (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorex_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstorex_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstorex_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstorex_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstorex_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstorex_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstorex_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstorex_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstorex_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorex_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorex_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorex_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorex_u64m1 (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorex_u64m2 (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorex_u64m4 (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorex_u64m8 (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorex_f16m1 (float16_t *base, vuint16m1_t bindex, vfloat16m1_t value);
void vstorex_f16m2 (float16_t *base, vuint16m2_t bindex, vfloat16m2_t value);
void vstorex_f16m4 (float16_t *base, vuint16m4_t bindex, vfloat16m4_t value);
void vstorex_f16m8 (float16_t *base, vuint16m8_t bindex, vfloat16m8_t value);
void vstorex_f32m1 (float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
void vstorex_f32m2 (float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
void vstorex_f32m4 (float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
void vstorex_f32m8 (float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
void vstorex_f64m1 (float64_t *base, vuint64m1_t bindex, vfloat64m1_t value);
void vstorex_f64m2 (float64_t *base, vuint64m2_t bindex, vfloat64m2_t value);
void vstorex_f64m4 (float64_t *base, vuint64m4_t bindex, vfloat64m4_t value);
void vstorex_f64m8 (float64_t *base, vuint64m8_t bindex, vfloat64m8_t value);
void vstoreuxb_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstoreuxb_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstoreuxb_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstoreuxb_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstoreuxb_i16m1 (int8_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstoreuxb_i16m2 (int8_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstoreuxb_i16m4 (int8_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstoreuxb_i16m8 (int8_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstoreuxb_i32m1 (int8_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreuxb_i32m2 (int8_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreuxb_i32m4 (int8_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreuxb_i32m8 (int8_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreuxb_i64m1 (int8_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreuxb_i64m2 (int8_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreuxb_i64m4 (int8_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreuxb_i64m8 (int8_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreuxb_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstoreuxb_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstoreuxb_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstoreuxb_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstoreuxb_u16m1 (uint8_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstoreuxb_u16m2 (uint8_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstoreuxb_u16m4 (uint8_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstoreuxb_u16m8 (uint8_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstoreuxb_u32m1 (uint8_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreuxb_u32m2 (uint8_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreuxb_u32m4 (uint8_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreuxb_u32m8 (uint8_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreuxb_u64m1 (uint8_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreuxb_u64m2 (uint8_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreuxb_u64m4 (uint8_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreuxb_u64m8 (uint8_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreuxh_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstoreuxh_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstoreuxh_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstoreuxh_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstoreuxh_i32m1 (int16_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreuxh_i32m2 (int16_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreuxh_i32m4 (int16_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreuxh_i32m8 (int16_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreuxh_i64m1 (int16_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreuxh_i64m2 (int16_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreuxh_i64m4 (int16_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreuxh_i64m8 (int16_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreuxh_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstoreuxh_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstoreuxh_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstoreuxh_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstoreuxh_u32m1 (uint16_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreuxh_u32m2 (uint16_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreuxh_u32m4 (uint16_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreuxh_u32m8 (uint16_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreuxh_u64m1 (uint16_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreuxh_u64m2 (uint16_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreuxh_u64m4 (uint16_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreuxh_u64m8 (uint16_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreuxw_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreuxw_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreuxw_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreuxw_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreuxw_i64m1 (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreuxw_i64m2 (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreuxw_i64m4 (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreuxw_i64m8 (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreuxw_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreuxw_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreuxw_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreuxw_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreuxw_u64m1 (uint32_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreuxw_u64m2 (uint32_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreuxw_u64m4 (uint32_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreuxw_u64m8 (uint32_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreux_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstoreux_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstoreux_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstoreux_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstoreux_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstoreux_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstoreux_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstoreux_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstoreux_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreux_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreux_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreux_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreux_i64m1 (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreux_i64m2 (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreux_i64m4 (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreux_i64m8 (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreux_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstoreux_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstoreux_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstoreux_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstoreux_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstoreux_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstoreux_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstoreux_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstoreux_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreux_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreux_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreux_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreux_u64m1 (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreux_u64m2 (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreux_u64m4 (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreux_u64m8 (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreux_f16m1 (float16_t *base, vuint16m1_t bindex, vfloat16m1_t value);
void vstoreux_f16m2 (float16_t *base, vuint16m2_t bindex, vfloat16m2_t value);
void vstoreux_f16m4 (float16_t *base, vuint16m4_t bindex, vfloat16m4_t value);
void vstoreux_f16m8 (float16_t *base, vuint16m8_t bindex, vfloat16m8_t value);
void vstoreux_f32m1 (float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
void vstoreux_f32m2 (float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
void vstoreux_f32m4 (float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
void vstoreux_f32m8 (float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
void vstoreux_f64m1 (float64_t *base, vuint64m1_t bindex, vfloat64m1_t value);
void vstoreux_f64m2 (float64_t *base, vuint64m2_t bindex, vfloat64m2_t value);
void vstoreux_f64m4 (float64_t *base, vuint64m4_t bindex, vfloat64m4_t value);
void vstoreux_f64m8 (float64_t *base, vuint64m8_t bindex, vfloat64m8_t value);
// masked functions
void vstorexb_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstorexb_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstorexb_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstorexb_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstorexb_i16m1_mask (int8_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstorexb_i16m2_mask (int8_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstorexb_i16m4_mask (int8_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstorexb_i16m8_mask (int8_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstorexb_i32m1_mask (int8_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorexb_i32m2_mask (int8_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorexb_i32m4_mask (int8_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorexb_i32m8_mask (int8_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorexb_i64m1_mask (int8_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorexb_i64m2_mask (int8_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorexb_i64m4_mask (int8_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorexb_i64m8_mask (int8_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorexb_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstorexb_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstorexb_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstorexb_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstorexb_u16m1_mask (uint8_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstorexb_u16m2_mask (uint8_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstorexb_u16m4_mask (uint8_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstorexb_u16m8_mask (uint8_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstorexb_u32m1_mask (uint8_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorexb_u32m2_mask (uint8_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorexb_u32m4_mask (uint8_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorexb_u32m8_mask (uint8_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorexb_u64m1_mask (uint8_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorexb_u64m2_mask (uint8_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorexb_u64m4_mask (uint8_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorexb_u64m8_mask (uint8_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorexh_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstorexh_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstorexh_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstorexh_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstorexh_i32m1_mask (int16_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorexh_i32m2_mask (int16_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorexh_i32m4_mask (int16_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorexh_i32m8_mask (int16_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorexh_i64m1_mask (int16_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorexh_i64m2_mask (int16_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorexh_i64m4_mask (int16_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorexh_i64m8_mask (int16_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorexh_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstorexh_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstorexh_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstorexh_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstorexh_u32m1_mask (uint16_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorexh_u32m2_mask (uint16_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorexh_u32m4_mask (uint16_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorexh_u32m8_mask (uint16_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorexh_u64m1_mask (uint16_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorexh_u64m2_mask (uint16_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorexh_u64m4_mask (uint16_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorexh_u64m8_mask (uint16_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorexw_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorexw_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorexw_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorexw_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorexw_i64m1_mask (int32_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorexw_i64m2_mask (int32_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorexw_i64m4_mask (int32_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorexw_i64m8_mask (int32_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorexw_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorexw_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorexw_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorexw_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorexw_u64m1_mask (uint32_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorexw_u64m2_mask (uint32_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorexw_u64m4_mask (uint32_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorexw_u64m8_mask (uint32_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorex_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstorex_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstorex_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstorex_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstorex_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstorex_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstorex_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstorex_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstorex_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorex_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorex_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorex_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorex_i64m1_mask (int64_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorex_i64m2_mask (int64_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorex_i64m4_mask (int64_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorex_i64m8_mask (int64_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorex_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstorex_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstorex_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstorex_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstorex_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstorex_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstorex_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstorex_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstorex_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorex_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorex_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorex_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorex_u64m1_mask (uint64_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorex_u64m2_mask (uint64_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorex_u64m4_mask (uint64_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorex_u64m8_mask (uint64_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorex_f16m1_mask (float16_t *base, vuint16m1_t bindex, vbool16_t mask, vfloat16m1_t value);
void vstorex_f16m2_mask (float16_t *base, vuint16m2_t bindex, vbool8_t mask, vfloat16m2_t value);
void vstorex_f16m4_mask (float16_t *base, vuint16m4_t bindex, vbool4_t mask, vfloat16m4_t value);
void vstorex_f16m8_mask (float16_t *base, vuint16m8_t bindex, vbool2_t mask, vfloat16m8_t value);
void vstorex_f32m1_mask (float32_t *base, vuint32m1_t bindex, vbool32_t mask, vfloat32m1_t value);
void vstorex_f32m2_mask (float32_t *base, vuint32m2_t bindex, vbool16_t mask, vfloat32m2_t value);
void vstorex_f32m4_mask (float32_t *base, vuint32m4_t bindex, vbool8_t mask, vfloat32m4_t value);
void vstorex_f32m8_mask (float32_t *base, vuint32m8_t bindex, vbool4_t mask, vfloat32m8_t value);
void vstorex_f64m1_mask (float64_t *base, vuint64m1_t bindex, vbool64_t mask, vfloat64m1_t value);
void vstorex_f64m2_mask (float64_t *base, vuint64m2_t bindex, vbool32_t mask, vfloat64m2_t value);
void vstorex_f64m4_mask (float64_t *base, vuint64m4_t bindex, vbool16_t mask, vfloat64m4_t value);
void vstorex_f64m8_mask (float64_t *base, vuint64m8_t bindex, vbool8_t mask, vfloat64m8_t value);
void vstoreuxb_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstoreuxb_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstoreuxb_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstoreuxb_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstoreuxb_i16m1_mask (int8_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstoreuxb_i16m2_mask (int8_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstoreuxb_i16m4_mask (int8_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstoreuxb_i16m8_mask (int8_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstoreuxb_i32m1_mask (int8_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreuxb_i32m2_mask (int8_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreuxb_i32m4_mask (int8_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreuxb_i32m8_mask (int8_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreuxb_i64m1_mask (int8_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreuxb_i64m2_mask (int8_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreuxb_i64m4_mask (int8_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreuxb_i64m8_mask (int8_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreuxb_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstoreuxb_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstoreuxb_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstoreuxb_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstoreuxb_u16m1_mask (uint8_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstoreuxb_u16m2_mask (uint8_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstoreuxb_u16m4_mask (uint8_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstoreuxb_u16m8_mask (uint8_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstoreuxb_u32m1_mask (uint8_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreuxb_u32m2_mask (uint8_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreuxb_u32m4_mask (uint8_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreuxb_u32m8_mask (uint8_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreuxb_u64m1_mask (uint8_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreuxb_u64m2_mask (uint8_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreuxb_u64m4_mask (uint8_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreuxb_u64m8_mask (uint8_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreuxh_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstoreuxh_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstoreuxh_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstoreuxh_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstoreuxh_i32m1_mask (int16_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreuxh_i32m2_mask (int16_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreuxh_i32m4_mask (int16_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreuxh_i32m8_mask (int16_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreuxh_i64m1_mask (int16_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreuxh_i64m2_mask (int16_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreuxh_i64m4_mask (int16_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreuxh_i64m8_mask (int16_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreuxh_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstoreuxh_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstoreuxh_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstoreuxh_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstoreuxh_u32m1_mask (uint16_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreuxh_u32m2_mask (uint16_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreuxh_u32m4_mask (uint16_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreuxh_u32m8_mask (uint16_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreuxh_u64m1_mask (uint16_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreuxh_u64m2_mask (uint16_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreuxh_u64m4_mask (uint16_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreuxh_u64m8_mask (uint16_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreuxw_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreuxw_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreuxw_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreuxw_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreuxw_i64m1_mask (int32_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreuxw_i64m2_mask (int32_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreuxw_i64m4_mask (int32_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreuxw_i64m8_mask (int32_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreuxw_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreuxw_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreuxw_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreuxw_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreuxw_u64m1_mask (uint32_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreuxw_u64m2_mask (uint32_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreuxw_u64m4_mask (uint32_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreuxw_u64m8_mask (uint32_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreux_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstoreux_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstoreux_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstoreux_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstoreux_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstoreux_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstoreux_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstoreux_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstoreux_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreux_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreux_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreux_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreux_i64m1_mask (int64_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreux_i64m2_mask (int64_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreux_i64m4_mask (int64_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreux_i64m8_mask (int64_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreux_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstoreux_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstoreux_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstoreux_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstoreux_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstoreux_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstoreux_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstoreux_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstoreux_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreux_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreux_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreux_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreux_u64m1_mask (uint64_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreux_u64m2_mask (uint64_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreux_u64m4_mask (uint64_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreux_u64m8_mask (uint64_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreux_f16m1_mask (float16_t *base, vuint16m1_t bindex, vbool16_t mask, vfloat16m1_t value);
void vstoreux_f16m2_mask (float16_t *base, vuint16m2_t bindex, vbool8_t mask, vfloat16m2_t value);
void vstoreux_f16m4_mask (float16_t *base, vuint16m4_t bindex, vbool4_t mask, vfloat16m4_t value);
void vstoreux_f16m8_mask (float16_t *base, vuint16m8_t bindex, vbool2_t mask, vfloat16m8_t value);
void vstoreux_f32m1_mask (float32_t *base, vuint32m1_t bindex, vbool32_t mask, vfloat32m1_t value);
void vstoreux_f32m2_mask (float32_t *base, vuint32m2_t bindex, vbool16_t mask, vfloat32m2_t value);
void vstoreux_f32m4_mask (float32_t *base, vuint32m4_t bindex, vbool8_t mask, vfloat32m4_t value);
void vstoreux_f32m8_mask (float32_t *base, vuint32m8_t bindex, vbool4_t mask, vfloat32m8_t value);
void vstoreux_f64m1_mask (float64_t *base, vuint64m1_t bindex, vbool64_t mask, vfloat64m1_t value);
void vstoreux_f64m2_mask (float64_t *base, vuint64m2_t bindex, vbool32_t mask, vfloat64m2_t value);
void vstoreux_f64m4_mask (float64_t *base, vuint64m4_t bindex, vbool16_t mask, vfloat64m4_t value);
void vstoreux_f64m8_mask (float64_t *base, vuint64m8_t bindex, vbool8_t mask, vfloat64m8_t value);
```
### [Unit-stride Fault-Only-First Loads Functions]()

**Prototypes:**
``` C
vint8m1_t vloadbff_i8m1 (const int8_t *base);
vint8m2_t vloadbff_i8m2 (const int8_t *base);
vint8m4_t vloadbff_i8m4 (const int8_t *base);
vint8m8_t vloadbff_i8m8 (const int8_t *base);
vint16m1_t vloadbff_i16m1 (const int8_t *base);
vint16m2_t vloadbff_i16m2 (const int8_t *base);
vint16m4_t vloadbff_i16m4 (const int8_t *base);
vint16m8_t vloadbff_i16m8 (const int8_t *base);
vint32m1_t vloadbff_i32m1 (const int8_t *base);
vint32m2_t vloadbff_i32m2 (const int8_t *base);
vint32m4_t vloadbff_i32m4 (const int8_t *base);
vint32m8_t vloadbff_i32m8 (const int8_t *base);
vint64m1_t vloadbff_i64m1 (const int8_t *base);
vint64m2_t vloadbff_i64m2 (const int8_t *base);
vint64m4_t vloadbff_i64m4 (const int8_t *base);
vint64m8_t vloadbff_i64m8 (const int8_t *base);
vuint8m1_t vloadbff_u8m1 (const uint8_t *base);
vuint8m2_t vloadbff_u8m2 (const uint8_t *base);
vuint8m4_t vloadbff_u8m4 (const uint8_t *base);
vuint8m8_t vloadbff_u8m8 (const uint8_t *base);
vuint16m1_t vloadbff_u16m1 (const uint8_t *base);
vuint16m2_t vloadbff_u16m2 (const uint8_t *base);
vuint16m4_t vloadbff_u16m4 (const uint8_t *base);
vuint16m8_t vloadbff_u16m8 (const uint8_t *base);
vuint32m1_t vloadbff_u32m1 (const uint8_t *base);
vuint32m2_t vloadbff_u32m2 (const uint8_t *base);
vuint32m4_t vloadbff_u32m4 (const uint8_t *base);
vuint32m8_t vloadbff_u32m8 (const uint8_t *base);
vuint64m1_t vloadbff_u64m1 (const uint8_t *base);
vuint64m2_t vloadbff_u64m2 (const uint8_t *base);
vuint64m4_t vloadbff_u64m4 (const uint8_t *base);
vuint64m8_t vloadbff_u64m8 (const uint8_t *base);
vint16m1_t vloadhff_i16m1 (const int16_t *base);
vint16m2_t vloadhff_i16m2 (const int16_t *base);
vint16m4_t vloadhff_i16m4 (const int16_t *base);
vint16m8_t vloadhff_i16m8 (const int16_t *base);
vint32m1_t vloadhff_i32m1 (const int16_t *base);
vint32m2_t vloadhff_i32m2 (const int16_t *base);
vint32m4_t vloadhff_i32m4 (const int16_t *base);
vint32m8_t vloadhff_i32m8 (const int16_t *base);
vint64m1_t vloadhff_i64m1 (const int16_t *base);
vint64m2_t vloadhff_i64m2 (const int16_t *base);
vint64m4_t vloadhff_i64m4 (const int16_t *base);
vint64m8_t vloadhff_i64m8 (const int16_t *base);
vuint16m1_t vloadhff_u16m1 (const uint16_t *base);
vuint16m2_t vloadhff_u16m2 (const uint16_t *base);
vuint16m4_t vloadhff_u16m4 (const uint16_t *base);
vuint16m8_t vloadhff_u16m8 (const uint16_t *base);
vuint32m1_t vloadhff_u32m1 (const uint16_t *base);
vuint32m2_t vloadhff_u32m2 (const uint16_t *base);
vuint32m4_t vloadhff_u32m4 (const uint16_t *base);
vuint32m8_t vloadhff_u32m8 (const uint16_t *base);
vuint64m1_t vloadhff_u64m1 (const uint16_t *base);
vuint64m2_t vloadhff_u64m2 (const uint16_t *base);
vuint64m4_t vloadhff_u64m4 (const uint16_t *base);
vuint64m8_t vloadhff_u64m8 (const uint16_t *base);
vint32m1_t vloadwff_i32m1 (const int32_t *base);
vint32m2_t vloadwff_i32m2 (const int32_t *base);
vint32m4_t vloadwff_i32m4 (const int32_t *base);
vint32m8_t vloadwff_i32m8 (const int32_t *base);
vint64m1_t vloadwff_i64m1 (const int32_t *base);
vint64m2_t vloadwff_i64m2 (const int32_t *base);
vint64m4_t vloadwff_i64m4 (const int32_t *base);
vint64m8_t vloadwff_i64m8 (const int32_t *base);
vuint32m1_t vloadwff_u32m1 (const uint32_t *base);
vuint32m2_t vloadwff_u32m2 (const uint32_t *base);
vuint32m4_t vloadwff_u32m4 (const uint32_t *base);
vuint32m8_t vloadwff_u32m8 (const uint32_t *base);
vuint64m1_t vloadwff_u64m1 (const uint32_t *base);
vuint64m2_t vloadwff_u64m2 (const uint32_t *base);
vuint64m4_t vloadwff_u64m4 (const uint32_t *base);
vuint64m8_t vloadwff_u64m8 (const uint32_t *base);
vint8m1_t vloadff_i8m1 (const int8_t *base);
vint8m2_t vloadff_i8m2 (const int8_t *base);
vint8m4_t vloadff_i8m4 (const int8_t *base);
vint8m8_t vloadff_i8m8 (const int8_t *base);
vint16m1_t vloadff_i16m1 (const int16_t *base);
vint16m2_t vloadff_i16m2 (const int16_t *base);
vint16m4_t vloadff_i16m4 (const int16_t *base);
vint16m8_t vloadff_i16m8 (const int16_t *base);
vint32m1_t vloadff_i32m1 (const int32_t *base);
vint32m2_t vloadff_i32m2 (const int32_t *base);
vint32m4_t vloadff_i32m4 (const int32_t *base);
vint32m8_t vloadff_i32m8 (const int32_t *base);
vint64m1_t vloadff_i64m1 (const int64_t *base);
vint64m2_t vloadff_i64m2 (const int64_t *base);
vint64m4_t vloadff_i64m4 (const int64_t *base);
vint64m8_t vloadff_i64m8 (const int64_t *base);
vuint8m1_t vloadff_u8m1 (const uint8_t *base);
vuint8m2_t vloadff_u8m2 (const uint8_t *base);
vuint8m4_t vloadff_u8m4 (const uint8_t *base);
vuint8m8_t vloadff_u8m8 (const uint8_t *base);
vuint16m1_t vloadff_u16m1 (const uint16_t *base);
vuint16m2_t vloadff_u16m2 (const uint16_t *base);
vuint16m4_t vloadff_u16m4 (const uint16_t *base);
vuint16m8_t vloadff_u16m8 (const uint16_t *base);
vuint32m1_t vloadff_u32m1 (const uint32_t *base);
vuint32m2_t vloadff_u32m2 (const uint32_t *base);
vuint32m4_t vloadff_u32m4 (const uint32_t *base);
vuint32m8_t vloadff_u32m8 (const uint32_t *base);
vuint64m1_t vloadff_u64m1 (const uint64_t *base);
vuint64m2_t vloadff_u64m2 (const uint64_t *base);
vuint64m4_t vloadff_u64m4 (const uint64_t *base);
vuint64m8_t vloadff_u64m8 (const uint64_t *base);
vfloat16m1_t vloadff_f16m1 (const float16_t *base);
vfloat16m2_t vloadff_f16m2 (const float16_t *base);
vfloat16m4_t vloadff_f16m4 (const float16_t *base);
vfloat16m8_t vloadff_f16m8 (const float16_t *base);
vfloat32m1_t vloadff_f32m1 (const float32_t *base);
vfloat32m2_t vloadff_f32m2 (const float32_t *base);
vfloat32m4_t vloadff_f32m4 (const float32_t *base);
vfloat32m8_t vloadff_f32m8 (const float32_t *base);
vfloat64m1_t vloadff_f64m1 (const float64_t *base);
vfloat64m2_t vloadff_f64m2 (const float64_t *base);
vfloat64m4_t vloadff_f64m4 (const float64_t *base);
vfloat64m8_t vloadff_f64m8 (const float64_t *base);
// masked functions
vint8m1_t vloadbff_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vloadbff_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vloadbff_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vloadbff_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vloadbff_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base);
vint16m2_t vloadbff_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base);
vint16m4_t vloadbff_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base);
vint16m8_t vloadbff_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base);
vint32m1_t vloadbff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base);
vint32m2_t vloadbff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base);
vint32m4_t vloadbff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base);
vint32m8_t vloadbff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base);
vint64m1_t vloadbff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base);
vint64m2_t vloadbff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base);
vint64m4_t vloadbff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base);
vint64m8_t vloadbff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base);
vuint8m1_t vloadbff_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vloadbff_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vloadbff_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vloadbff_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vloadbff_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base);
vuint16m2_t vloadbff_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base);
vuint16m4_t vloadbff_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base);
vuint16m8_t vloadbff_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base);
vuint32m1_t vloadbff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base);
vuint32m2_t vloadbff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base);
vuint32m4_t vloadbff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base);
vuint32m8_t vloadbff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base);
vuint64m1_t vloadbff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base);
vuint64m2_t vloadbff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base);
vuint64m4_t vloadbff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base);
vuint64m8_t vloadbff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base);
vint16m1_t vloadhff_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vloadhff_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vloadhff_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vloadhff_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vloadhff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base);
vint32m2_t vloadhff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base);
vint32m4_t vloadhff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base);
vint32m8_t vloadhff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base);
vint64m1_t vloadhff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base);
vint64m2_t vloadhff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base);
vint64m4_t vloadhff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base);
vint64m8_t vloadhff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base);
vuint16m1_t vloadhff_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vloadhff_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vloadhff_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vloadhff_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vloadhff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base);
vuint32m2_t vloadhff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base);
vuint32m4_t vloadhff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base);
vuint32m8_t vloadhff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base);
vuint64m1_t vloadhff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base);
vuint64m2_t vloadhff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base);
vuint64m4_t vloadhff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base);
vuint64m8_t vloadhff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base);
vint32m1_t vloadwff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vloadwff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vloadwff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vloadwff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vloadwff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base);
vint64m2_t vloadwff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base);
vint64m4_t vloadwff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base);
vint64m8_t vloadwff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base);
vuint32m1_t vloadwff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vloadwff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vloadwff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vloadwff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vloadwff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base);
vuint64m2_t vloadwff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base);
vuint64m4_t vloadwff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base);
vuint64m8_t vloadwff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base);
vint8m1_t vloadff_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vloadff_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vloadff_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vloadff_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vloadff_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vloadff_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vloadff_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vloadff_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vloadff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vloadff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vloadff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vloadff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vloadff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base);
vint64m2_t vloadff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base);
vint64m4_t vloadff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base);
vint64m8_t vloadff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base);
vuint8m1_t vloadff_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vloadff_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vloadff_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vloadff_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vloadff_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vloadff_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vloadff_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vloadff_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vloadff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vloadff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vloadff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vloadff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vloadff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base);
vuint64m2_t vloadff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base);
vuint64m4_t vloadff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base);
vuint64m8_t vloadff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base);
vfloat16m1_t vloadff_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base);
vfloat16m2_t vloadff_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base);
vfloat16m4_t vloadff_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base);
vfloat16m8_t vloadff_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base);
vfloat32m1_t vloadff_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base);
vfloat32m2_t vloadff_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base);
vfloat32m4_t vloadff_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base);
vfloat32m8_t vloadff_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base);
vfloat64m1_t vloadff_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base);
vfloat64m2_t vloadff_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base);
vfloat64m4_t vloadff_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base);
vfloat64m8_t vloadff_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base);
```
## Vector Integer Arithmetic Functions:

### [Vector Single-Width Integer Add and Subtract Functions]()

**Prototypes:**
``` C
vint8m1_t vadd_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vadd_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vadd_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vadd_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vadd_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vadd_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vadd_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vadd_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vadd_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vadd_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vadd_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vadd_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vadd_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vadd_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vadd_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vadd_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vadd_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vadd_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vadd_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vadd_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vadd_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vadd_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vadd_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vadd_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vadd_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vadd_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vadd_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vadd_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vadd_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vadd_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vadd_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vadd_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vadd_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vadd_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vadd_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vadd_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vadd_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vadd_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vadd_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vadd_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vadd_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vadd_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vadd_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vadd_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vadd_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vadd_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vadd_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vadd_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vadd_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vadd_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vadd_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vadd_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vadd_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vadd_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vadd_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vadd_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vadd_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vadd_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vadd_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vadd_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vadd_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vadd_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vadd_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vadd_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vint8m1_t vsub_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsub_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vsub_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsub_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vsub_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsub_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vsub_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsub_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vsub_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsub_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vsub_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsub_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vsub_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsub_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vsub_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsub_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vsub_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsub_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vsub_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsub_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vsub_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsub_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vsub_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsub_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vsub_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsub_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vsub_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsub_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vsub_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsub_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vsub_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsub_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vsub_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsub_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsub_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsub_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsub_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsub_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsub_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsub_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsub_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsub_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsub_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsub_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsub_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsub_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsub_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsub_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsub_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsub_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsub_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsub_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsub_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsub_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsub_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsub_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsub_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsub_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsub_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsub_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsub_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsub_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsub_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsub_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vint8m1_t vrsub_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vrsub_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vrsub_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vrsub_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vrsub_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vrsub_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vrsub_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vrsub_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vrsub_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vrsub_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vrsub_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vrsub_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vrsub_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vrsub_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vrsub_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vrsub_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vrsub_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrsub_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrsub_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrsub_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrsub_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrsub_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrsub_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrsub_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrsub_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrsub_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrsub_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrsub_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrsub_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrsub_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrsub_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrsub_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vadd_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vadd_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vadd_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vadd_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vadd_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vadd_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vadd_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vadd_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vadd_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vadd_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vadd_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vadd_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vadd_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vadd_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vadd_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vadd_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vadd_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vadd_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vadd_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vadd_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vadd_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vadd_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vadd_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vadd_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vadd_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vadd_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vadd_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vadd_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vadd_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vadd_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vadd_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vadd_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vadd_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vadd_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vadd_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vadd_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vadd_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vadd_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vadd_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vadd_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vadd_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vadd_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vadd_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vadd_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vadd_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vadd_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vadd_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vadd_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vadd_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vadd_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vadd_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vadd_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vadd_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vadd_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vadd_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vadd_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vadd_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vadd_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vadd_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vadd_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vadd_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vadd_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vadd_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vadd_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vsub_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsub_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsub_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsub_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsub_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsub_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsub_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsub_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsub_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsub_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsub_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsub_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsub_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsub_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsub_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsub_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsub_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsub_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsub_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsub_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsub_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsub_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsub_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsub_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsub_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsub_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsub_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsub_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsub_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsub_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsub_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsub_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsub_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsub_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsub_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsub_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsub_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsub_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsub_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsub_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsub_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsub_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsub_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsub_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsub_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsub_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsub_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsub_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsub_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsub_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsub_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsub_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsub_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsub_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsub_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsub_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsub_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsub_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsub_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsub_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsub_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsub_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsub_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsub_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vrsub_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vrsub_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vrsub_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vrsub_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vrsub_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vrsub_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vrsub_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vrsub_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vrsub_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vrsub_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vrsub_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vrsub_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vrsub_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vrsub_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vrsub_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vrsub_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vrsub_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrsub_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrsub_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrsub_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrsub_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrsub_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrsub_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrsub_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrsub_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrsub_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrsub_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrsub_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrsub_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrsub_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrsub_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrsub_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Widening Integer Add/Subtract Functions]()

**Prototypes:**
``` C
vint16m2_t vwadd_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwadd_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint16m2_t vwadd_wv_i8m1 (vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwadd_ws_i8m1 (vint16m2_t op1, int8_t op2);
vint16m4_t vwadd_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwadd_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint16m4_t vwadd_wv_i8m2 (vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwadd_ws_i8m2 (vint16m4_t op1, int8_t op2);
vint16m8_t vwadd_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwadd_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint16m8_t vwadd_wv_i8m4 (vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwadd_ws_i8m4 (vint16m8_t op1, int8_t op2);
vint32m2_t vwadd_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwadd_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint32m2_t vwadd_wv_i16m1 (vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwadd_ws_i16m1 (vint32m2_t op1, int16_t op2);
vint32m4_t vwadd_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwadd_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint32m4_t vwadd_wv_i16m2 (vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwadd_ws_i16m2 (vint32m4_t op1, int16_t op2);
vint32m8_t vwadd_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwadd_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint32m8_t vwadd_wv_i16m4 (vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwadd_ws_i16m4 (vint32m8_t op1, int16_t op2);
vint64m2_t vwadd_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwadd_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint64m2_t vwadd_wv_i32m1 (vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwadd_ws_i32m1 (vint64m2_t op1, int32_t op2);
vint64m4_t vwadd_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwadd_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint64m4_t vwadd_wv_i32m2 (vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwadd_ws_i32m2 (vint64m4_t op1, int32_t op2);
vint64m8_t vwadd_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwadd_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint64m8_t vwadd_wv_i32m4 (vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwadd_ws_i32m4 (vint64m8_t op1, int32_t op2);
vuint16m2_t vwadd_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwadd_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwadd_wv_u8m1 (vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwadd_ws_u8m1 (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwadd_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwadd_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwadd_wv_u8m2 (vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwadd_ws_u8m2 (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwadd_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwadd_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwadd_wv_u8m4 (vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwadd_ws_u8m4 (vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwadd_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwadd_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwadd_wv_u16m1 (vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwadd_ws_u16m1 (vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwadd_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwadd_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwadd_wv_u16m2 (vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwadd_ws_u16m2 (vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwadd_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwadd_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwadd_wv_u16m4 (vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwadd_ws_u16m4 (vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwadd_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwadd_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwadd_wv_u32m1 (vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwadd_ws_u32m1 (vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwadd_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwadd_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwadd_wv_u32m2 (vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwadd_ws_u32m2 (vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwadd_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwadd_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwadd_wv_u32m4 (vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwadd_ws_u32m4 (vuint64m8_t op1, uint32_t op2);
vint16m2_t vwsub_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwsub_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint16m2_t vwsub_wv_i8m1 (vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwsub_ws_i8m1 (vint16m2_t op1, int8_t op2);
vint16m4_t vwsub_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwsub_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint16m4_t vwsub_wv_i8m2 (vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwsub_ws_i8m2 (vint16m4_t op1, int8_t op2);
vint16m8_t vwsub_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwsub_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint16m8_t vwsub_wv_i8m4 (vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwsub_ws_i8m4 (vint16m8_t op1, int8_t op2);
vint32m2_t vwsub_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwsub_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint32m2_t vwsub_wv_i16m1 (vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwsub_ws_i16m1 (vint32m2_t op1, int16_t op2);
vint32m4_t vwsub_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwsub_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint32m4_t vwsub_wv_i16m2 (vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwsub_ws_i16m2 (vint32m4_t op1, int16_t op2);
vint32m8_t vwsub_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwsub_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint32m8_t vwsub_wv_i16m4 (vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwsub_ws_i16m4 (vint32m8_t op1, int16_t op2);
vint64m2_t vwsub_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwsub_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint64m2_t vwsub_wv_i32m1 (vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwsub_ws_i32m1 (vint64m2_t op1, int32_t op2);
vint64m4_t vwsub_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwsub_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint64m4_t vwsub_wv_i32m2 (vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwsub_ws_i32m2 (vint64m4_t op1, int32_t op2);
vint64m8_t vwsub_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwsub_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint64m8_t vwsub_wv_i32m4 (vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwsub_ws_i32m4 (vint64m8_t op1, int32_t op2);
vuint16m2_t vwsub_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwsub_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwsub_wv_u8m1 (vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwsub_ws_u8m1 (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwsub_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwsub_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwsub_wv_u8m2 (vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwsub_ws_u8m2 (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwsub_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwsub_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwsub_wv_u8m4 (vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwsub_ws_u8m4 (vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwsub_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwsub_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwsub_wv_u16m1 (vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwsub_ws_u16m1 (vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwsub_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwsub_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwsub_wv_u16m2 (vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwsub_ws_u16m2 (vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwsub_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwsub_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwsub_wv_u16m4 (vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwsub_ws_u16m4 (vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwsub_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwsub_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwsub_wv_u32m1 (vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwsub_ws_u32m1 (vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwsub_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwsub_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwsub_wv_u32m2 (vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwsub_ws_u32m2 (vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwsub_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwsub_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwsub_wv_u32m4 (vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwsub_ws_u32m4 (vuint64m8_t op1, uint32_t op2);
// masked functions
vint16m2_t vwadd_vv_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwadd_vs_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m2_t vwadd_wv_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwadd_ws_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2);
vint16m4_t vwadd_vv_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwadd_vs_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m4_t vwadd_wv_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwadd_ws_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2);
vint16m8_t vwadd_vv_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwadd_vs_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint16m8_t vwadd_wv_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwadd_ws_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2);
vint32m2_t vwadd_vv_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwadd_vs_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m2_t vwadd_wv_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwadd_ws_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2);
vint32m4_t vwadd_vv_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwadd_vs_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m4_t vwadd_wv_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwadd_ws_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2);
vint32m8_t vwadd_vv_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwadd_vs_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint32m8_t vwadd_wv_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwadd_ws_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2);
vint64m2_t vwadd_vv_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwadd_vs_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m2_t vwadd_wv_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwadd_ws_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2);
vint64m4_t vwadd_vv_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwadd_vs_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m4_t vwadd_wv_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwadd_ws_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2);
vint64m8_t vwadd_vv_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwadd_vs_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vint64m8_t vwadd_wv_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwadd_ws_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2);
vuint16m2_t vwadd_vv_u8m1_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwadd_vs_u8m1_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwadd_wv_u8m1_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwadd_ws_u8m1_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwadd_vv_u8m2_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwadd_vs_u8m2_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwadd_wv_u8m2_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwadd_ws_u8m2_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwadd_vv_u8m4_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwadd_vs_u8m4_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwadd_wv_u8m4_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwadd_ws_u8m4_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwadd_vv_u16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwadd_vs_u16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwadd_wv_u16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwadd_ws_u16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwadd_vv_u16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwadd_vs_u16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwadd_wv_u16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwadd_ws_u16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwadd_vv_u16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwadd_vs_u16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwadd_wv_u16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwadd_ws_u16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwadd_vv_u32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwadd_vs_u32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwadd_wv_u32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwadd_ws_u32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwadd_vv_u32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwadd_vs_u32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwadd_wv_u32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwadd_ws_u32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwadd_vv_u32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwadd_vs_u32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwadd_wv_u32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwadd_ws_u32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2);
vint16m2_t vwsub_vv_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwsub_vs_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m2_t vwsub_wv_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwsub_ws_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2);
vint16m4_t vwsub_vv_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwsub_vs_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m4_t vwsub_wv_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwsub_ws_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2);
vint16m8_t vwsub_vv_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwsub_vs_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint16m8_t vwsub_wv_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwsub_ws_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2);
vint32m2_t vwsub_vv_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwsub_vs_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m2_t vwsub_wv_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwsub_ws_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2);
vint32m4_t vwsub_vv_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwsub_vs_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m4_t vwsub_wv_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwsub_ws_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2);
vint32m8_t vwsub_vv_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwsub_vs_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint32m8_t vwsub_wv_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwsub_ws_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2);
vint64m2_t vwsub_vv_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwsub_vs_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m2_t vwsub_wv_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwsub_ws_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2);
vint64m4_t vwsub_vv_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwsub_vs_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m4_t vwsub_wv_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwsub_ws_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2);
vint64m8_t vwsub_vv_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwsub_vs_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vint64m8_t vwsub_wv_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwsub_ws_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2);
vuint16m2_t vwsub_vv_u8m1_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwsub_vs_u8m1_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwsub_wv_u8m1_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwsub_ws_u8m1_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwsub_vv_u8m2_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwsub_vs_u8m2_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwsub_wv_u8m2_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwsub_ws_u8m2_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwsub_vv_u8m4_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwsub_vs_u8m4_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwsub_wv_u8m4_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwsub_ws_u8m4_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwsub_vv_u16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwsub_vs_u16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwsub_wv_u16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwsub_ws_u16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwsub_vv_u16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwsub_vs_u16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwsub_wv_u16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwsub_ws_u16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwsub_vv_u16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwsub_vs_u16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwsub_wv_u16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwsub_ws_u16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwsub_vv_u32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwsub_vs_u32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwsub_wv_u32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwsub_ws_u32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwsub_vv_u32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwsub_vs_u32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwsub_wv_u32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwsub_ws_u32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwsub_vv_u32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwsub_vs_u32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwsub_wv_u32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwsub_ws_u32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2);
```
### [Vector Integer Add-with-Carry / Subtract-with-Borrow Functions]()

**Prototypes:**
``` C
vint8m1_t vadc_vvm_i8m1 (vint8m1_t op1, vint8m1_t op2, vbool8_t carryin);
vint8m1_t vadc_vsm_i8m1 (vint8m1_t op1, int8_t op2, vbool8_t carryin);
vint8m2_t vadc_vvm_i8m2 (vint8m2_t op1, vint8m2_t op2, vbool4_t carryin);
vint8m2_t vadc_vsm_i8m2 (vint8m2_t op1, int8_t op2, vbool4_t carryin);
vint8m4_t vadc_vvm_i8m4 (vint8m4_t op1, vint8m4_t op2, vbool2_t carryin);
vint8m4_t vadc_vsm_i8m4 (vint8m4_t op1, int8_t op2, vbool2_t carryin);
vint8m8_t vadc_vvm_i8m8 (vint8m8_t op1, vint8m8_t op2, vbool1_t carryin);
vint8m8_t vadc_vsm_i8m8 (vint8m8_t op1, int8_t op2, vbool1_t carryin);
vint16m1_t vadc_vvm_i16m1 (vint16m1_t op1, vint16m1_t op2, vbool16_t carryin);
vint16m1_t vadc_vsm_i16m1 (vint16m1_t op1, int16_t op2, vbool16_t carryin);
vint16m2_t vadc_vvm_i16m2 (vint16m2_t op1, vint16m2_t op2, vbool8_t carryin);
vint16m2_t vadc_vsm_i16m2 (vint16m2_t op1, int16_t op2, vbool8_t carryin);
vint16m4_t vadc_vvm_i16m4 (vint16m4_t op1, vint16m4_t op2, vbool4_t carryin);
vint16m4_t vadc_vsm_i16m4 (vint16m4_t op1, int16_t op2, vbool4_t carryin);
vint16m8_t vadc_vvm_i16m8 (vint16m8_t op1, vint16m8_t op2, vbool2_t carryin);
vint16m8_t vadc_vsm_i16m8 (vint16m8_t op1, int16_t op2, vbool2_t carryin);
vint32m1_t vadc_vvm_i32m1 (vint32m1_t op1, vint32m1_t op2, vbool32_t carryin);
vint32m1_t vadc_vsm_i32m1 (vint32m1_t op1, int32_t op2, vbool32_t carryin);
vint32m2_t vadc_vvm_i32m2 (vint32m2_t op1, vint32m2_t op2, vbool16_t carryin);
vint32m2_t vadc_vsm_i32m2 (vint32m2_t op1, int32_t op2, vbool16_t carryin);
vint32m4_t vadc_vvm_i32m4 (vint32m4_t op1, vint32m4_t op2, vbool8_t carryin);
vint32m4_t vadc_vsm_i32m4 (vint32m4_t op1, int32_t op2, vbool8_t carryin);
vint32m8_t vadc_vvm_i32m8 (vint32m8_t op1, vint32m8_t op2, vbool4_t carryin);
vint32m8_t vadc_vsm_i32m8 (vint32m8_t op1, int32_t op2, vbool4_t carryin);
vint64m1_t vadc_vvm_i64m1 (vint64m1_t op1, vint64m1_t op2, vbool64_t carryin);
vint64m1_t vadc_vsm_i64m1 (vint64m1_t op1, int64_t op2, vbool64_t carryin);
vint64m2_t vadc_vvm_i64m2 (vint64m2_t op1, vint64m2_t op2, vbool32_t carryin);
vint64m2_t vadc_vsm_i64m2 (vint64m2_t op1, int64_t op2, vbool32_t carryin);
vint64m4_t vadc_vvm_i64m4 (vint64m4_t op1, vint64m4_t op2, vbool16_t carryin);
vint64m4_t vadc_vsm_i64m4 (vint64m4_t op1, int64_t op2, vbool16_t carryin);
vint64m8_t vadc_vvm_i64m8 (vint64m8_t op1, vint64m8_t op2, vbool8_t carryin);
vint64m8_t vadc_vsm_i64m8 (vint64m8_t op1, int64_t op2, vbool8_t carryin);
vuint8m1_t vadc_vvm_u8m1 (vuint8m1_t op1, vuint8m1_t op2, vbool8_t carryin);
vuint8m1_t vadc_vsm_u8m1 (vuint8m1_t op1, uint8_t op2, vbool8_t carryin);
vuint8m2_t vadc_vvm_u8m2 (vuint8m2_t op1, vuint8m2_t op2, vbool4_t carryin);
vuint8m2_t vadc_vsm_u8m2 (vuint8m2_t op1, uint8_t op2, vbool4_t carryin);
vuint8m4_t vadc_vvm_u8m4 (vuint8m4_t op1, vuint8m4_t op2, vbool2_t carryin);
vuint8m4_t vadc_vsm_u8m4 (vuint8m4_t op1, uint8_t op2, vbool2_t carryin);
vuint8m8_t vadc_vvm_u8m8 (vuint8m8_t op1, vuint8m8_t op2, vbool1_t carryin);
vuint8m8_t vadc_vsm_u8m8 (vuint8m8_t op1, uint8_t op2, vbool1_t carryin);
vuint16m1_t vadc_vvm_u16m1 (vuint16m1_t op1, vuint16m1_t op2, vbool16_t carryin);
vuint16m1_t vadc_vsm_u16m1 (vuint16m1_t op1, uint16_t op2, vbool16_t carryin);
vuint16m2_t vadc_vvm_u16m2 (vuint16m2_t op1, vuint16m2_t op2, vbool8_t carryin);
vuint16m2_t vadc_vsm_u16m2 (vuint16m2_t op1, uint16_t op2, vbool8_t carryin);
vuint16m4_t vadc_vvm_u16m4 (vuint16m4_t op1, vuint16m4_t op2, vbool4_t carryin);
vuint16m4_t vadc_vsm_u16m4 (vuint16m4_t op1, uint16_t op2, vbool4_t carryin);
vuint16m8_t vadc_vvm_u16m8 (vuint16m8_t op1, vuint16m8_t op2, vbool2_t carryin);
vuint16m8_t vadc_vsm_u16m8 (vuint16m8_t op1, uint16_t op2, vbool2_t carryin);
vuint32m1_t vadc_vvm_u32m1 (vuint32m1_t op1, vuint32m1_t op2, vbool32_t carryin);
vuint32m1_t vadc_vsm_u32m1 (vuint32m1_t op1, uint32_t op2, vbool32_t carryin);
vuint32m2_t vadc_vvm_u32m2 (vuint32m2_t op1, vuint32m2_t op2, vbool16_t carryin);
vuint32m2_t vadc_vsm_u32m2 (vuint32m2_t op1, uint32_t op2, vbool16_t carryin);
vuint32m4_t vadc_vvm_u32m4 (vuint32m4_t op1, vuint32m4_t op2, vbool8_t carryin);
vuint32m4_t vadc_vsm_u32m4 (vuint32m4_t op1, uint32_t op2, vbool8_t carryin);
vuint32m8_t vadc_vvm_u32m8 (vuint32m8_t op1, vuint32m8_t op2, vbool4_t carryin);
vuint32m8_t vadc_vsm_u32m8 (vuint32m8_t op1, uint32_t op2, vbool4_t carryin);
vuint64m1_t vadc_vvm_u64m1 (vuint64m1_t op1, vuint64m1_t op2, vbool64_t carryin);
vuint64m1_t vadc_vsm_u64m1 (vuint64m1_t op1, uint64_t op2, vbool64_t carryin);
vuint64m2_t vadc_vvm_u64m2 (vuint64m2_t op1, vuint64m2_t op2, vbool32_t carryin);
vuint64m2_t vadc_vsm_u64m2 (vuint64m2_t op1, uint64_t op2, vbool32_t carryin);
vuint64m4_t vadc_vvm_u64m4 (vuint64m4_t op1, vuint64m4_t op2, vbool16_t carryin);
vuint64m4_t vadc_vsm_u64m4 (vuint64m4_t op1, uint64_t op2, vbool16_t carryin);
vuint64m8_t vadc_vvm_u64m8 (vuint64m8_t op1, vuint64m8_t op2, vbool8_t carryin);
vuint64m8_t vadc_vsm_u64m8 (vuint64m8_t op1, uint64_t op2, vbool8_t carryin);
vbool8_t vmadc_vvm_i8m1 (vint8m1_t op1, vint8m1_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm_i8m1 (vint8m1_t op1, int8_t op2, vbool8_t carryin);
vbool8_t vmadc_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmadc_vs_i8m1 (vint8m1_t op1, int8_t op2);
vbool4_t vmadc_vvm_i8m2 (vint8m2_t op1, vint8m2_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm_i8m2 (vint8m2_t op1, int8_t op2, vbool4_t carryin);
vbool4_t vmadc_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmadc_vs_i8m2 (vint8m2_t op1, int8_t op2);
vbool2_t vmadc_vvm_i8m4 (vint8m4_t op1, vint8m4_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm_i8m4 (vint8m4_t op1, int8_t op2, vbool2_t carryin);
vbool2_t vmadc_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmadc_vs_i8m4 (vint8m4_t op1, int8_t op2);
vbool1_t vmadc_vvm_i8m8 (vint8m8_t op1, vint8m8_t op2, vbool1_t carryin);
vbool1_t vmadc_vsm_i8m8 (vint8m8_t op1, int8_t op2, vbool1_t carryin);
vbool1_t vmadc_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmadc_vs_i8m8 (vint8m8_t op1, int8_t op2);
vbool16_t vmadc_vvm_i16m1 (vint16m1_t op1, vint16m1_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm_i16m1 (vint16m1_t op1, int16_t op2, vbool16_t carryin);
vbool16_t vmadc_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmadc_vs_i16m1 (vint16m1_t op1, int16_t op2);
vbool8_t vmadc_vvm_i16m2 (vint16m2_t op1, vint16m2_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm_i16m2 (vint16m2_t op1, int16_t op2, vbool8_t carryin);
vbool8_t vmadc_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmadc_vs_i16m2 (vint16m2_t op1, int16_t op2);
vbool4_t vmadc_vvm_i16m4 (vint16m4_t op1, vint16m4_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm_i16m4 (vint16m4_t op1, int16_t op2, vbool4_t carryin);
vbool4_t vmadc_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmadc_vs_i16m4 (vint16m4_t op1, int16_t op2);
vbool2_t vmadc_vvm_i16m8 (vint16m8_t op1, vint16m8_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm_i16m8 (vint16m8_t op1, int16_t op2, vbool2_t carryin);
vbool2_t vmadc_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmadc_vs_i16m8 (vint16m8_t op1, int16_t op2);
vbool32_t vmadc_vvm_i32m1 (vint32m1_t op1, vint32m1_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm_i32m1 (vint32m1_t op1, int32_t op2, vbool32_t carryin);
vbool32_t vmadc_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmadc_vs_i32m1 (vint32m1_t op1, int32_t op2);
vbool16_t vmadc_vvm_i32m2 (vint32m2_t op1, vint32m2_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm_i32m2 (vint32m2_t op1, int32_t op2, vbool16_t carryin);
vbool16_t vmadc_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmadc_vs_i32m2 (vint32m2_t op1, int32_t op2);
vbool8_t vmadc_vvm_i32m4 (vint32m4_t op1, vint32m4_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm_i32m4 (vint32m4_t op1, int32_t op2, vbool8_t carryin);
vbool8_t vmadc_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmadc_vs_i32m4 (vint32m4_t op1, int32_t op2);
vbool4_t vmadc_vvm_i32m8 (vint32m8_t op1, vint32m8_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm_i32m8 (vint32m8_t op1, int32_t op2, vbool4_t carryin);
vbool4_t vmadc_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmadc_vs_i32m8 (vint32m8_t op1, int32_t op2);
vbool64_t vmadc_vvm_i64m1 (vint64m1_t op1, vint64m1_t op2, vbool64_t carryin);
vbool64_t vmadc_vsm_i64m1 (vint64m1_t op1, int64_t op2, vbool64_t carryin);
vbool64_t vmadc_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmadc_vs_i64m1 (vint64m1_t op1, int64_t op2);
vbool32_t vmadc_vvm_i64m2 (vint64m2_t op1, vint64m2_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm_i64m2 (vint64m2_t op1, int64_t op2, vbool32_t carryin);
vbool32_t vmadc_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmadc_vs_i64m2 (vint64m2_t op1, int64_t op2);
vbool16_t vmadc_vvm_i64m4 (vint64m4_t op1, vint64m4_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm_i64m4 (vint64m4_t op1, int64_t op2, vbool16_t carryin);
vbool16_t vmadc_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmadc_vs_i64m4 (vint64m4_t op1, int64_t op2);
vbool8_t vmadc_vvm_i64m8 (vint64m8_t op1, vint64m8_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm_i64m8 (vint64m8_t op1, int64_t op2, vbool8_t carryin);
vbool8_t vmadc_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmadc_vs_i64m8 (vint64m8_t op1, int64_t op2);
vbool8_t vmadc_vvm_u8m1 (vuint8m1_t op1, vuint8m1_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm_u8m1 (vuint8m1_t op1, uint8_t op2, vbool8_t carryin);
vbool8_t vmadc_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmadc_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vbool4_t vmadc_vvm_u8m2 (vuint8m2_t op1, vuint8m2_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm_u8m2 (vuint8m2_t op1, uint8_t op2, vbool4_t carryin);
vbool4_t vmadc_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmadc_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vbool2_t vmadc_vvm_u8m4 (vuint8m4_t op1, vuint8m4_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm_u8m4 (vuint8m4_t op1, uint8_t op2, vbool2_t carryin);
vbool2_t vmadc_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmadc_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vbool1_t vmadc_vvm_u8m8 (vuint8m8_t op1, vuint8m8_t op2, vbool1_t carryin);
vbool1_t vmadc_vsm_u8m8 (vuint8m8_t op1, uint8_t op2, vbool1_t carryin);
vbool1_t vmadc_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmadc_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vbool16_t vmadc_vvm_u16m1 (vuint16m1_t op1, vuint16m1_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm_u16m1 (vuint16m1_t op1, uint16_t op2, vbool16_t carryin);
vbool16_t vmadc_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmadc_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vbool8_t vmadc_vvm_u16m2 (vuint16m2_t op1, vuint16m2_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm_u16m2 (vuint16m2_t op1, uint16_t op2, vbool8_t carryin);
vbool8_t vmadc_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmadc_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vbool4_t vmadc_vvm_u16m4 (vuint16m4_t op1, vuint16m4_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm_u16m4 (vuint16m4_t op1, uint16_t op2, vbool4_t carryin);
vbool4_t vmadc_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmadc_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vbool2_t vmadc_vvm_u16m8 (vuint16m8_t op1, vuint16m8_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm_u16m8 (vuint16m8_t op1, uint16_t op2, vbool2_t carryin);
vbool2_t vmadc_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmadc_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vbool32_t vmadc_vvm_u32m1 (vuint32m1_t op1, vuint32m1_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm_u32m1 (vuint32m1_t op1, uint32_t op2, vbool32_t carryin);
vbool32_t vmadc_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmadc_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vbool16_t vmadc_vvm_u32m2 (vuint32m2_t op1, vuint32m2_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm_u32m2 (vuint32m2_t op1, uint32_t op2, vbool16_t carryin);
vbool16_t vmadc_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmadc_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vbool8_t vmadc_vvm_u32m4 (vuint32m4_t op1, vuint32m4_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm_u32m4 (vuint32m4_t op1, uint32_t op2, vbool8_t carryin);
vbool8_t vmadc_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmadc_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vbool4_t vmadc_vvm_u32m8 (vuint32m8_t op1, vuint32m8_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm_u32m8 (vuint32m8_t op1, uint32_t op2, vbool4_t carryin);
vbool4_t vmadc_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmadc_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vbool64_t vmadc_vvm_u64m1 (vuint64m1_t op1, vuint64m1_t op2, vbool64_t carryin);
vbool64_t vmadc_vsm_u64m1 (vuint64m1_t op1, uint64_t op2, vbool64_t carryin);
vbool64_t vmadc_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmadc_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vbool32_t vmadc_vvm_u64m2 (vuint64m2_t op1, vuint64m2_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm_u64m2 (vuint64m2_t op1, uint64_t op2, vbool32_t carryin);
vbool32_t vmadc_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmadc_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vbool16_t vmadc_vvm_u64m4 (vuint64m4_t op1, vuint64m4_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm_u64m4 (vuint64m4_t op1, uint64_t op2, vbool16_t carryin);
vbool16_t vmadc_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmadc_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vbool8_t vmadc_vvm_u64m8 (vuint64m8_t op1, vuint64m8_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm_u64m8 (vuint64m8_t op1, uint64_t op2, vbool8_t carryin);
vbool8_t vmadc_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmadc_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vint8m1_t vsbc_vvm_i8m1 (vint8m1_t op1, vint8m1_t op2, vbool8_t borrowin);
vint8m1_t vsbc_vsm_i8m1 (vint8m1_t op1, int8_t op2, vbool8_t borrowin);
vint8m2_t vsbc_vvm_i8m2 (vint8m2_t op1, vint8m2_t op2, vbool4_t borrowin);
vint8m2_t vsbc_vsm_i8m2 (vint8m2_t op1, int8_t op2, vbool4_t borrowin);
vint8m4_t vsbc_vvm_i8m4 (vint8m4_t op1, vint8m4_t op2, vbool2_t borrowin);
vint8m4_t vsbc_vsm_i8m4 (vint8m4_t op1, int8_t op2, vbool2_t borrowin);
vint8m8_t vsbc_vvm_i8m8 (vint8m8_t op1, vint8m8_t op2, vbool1_t borrowin);
vint8m8_t vsbc_vsm_i8m8 (vint8m8_t op1, int8_t op2, vbool1_t borrowin);
vint16m1_t vsbc_vvm_i16m1 (vint16m1_t op1, vint16m1_t op2, vbool16_t borrowin);
vint16m1_t vsbc_vsm_i16m1 (vint16m1_t op1, int16_t op2, vbool16_t borrowin);
vint16m2_t vsbc_vvm_i16m2 (vint16m2_t op1, vint16m2_t op2, vbool8_t borrowin);
vint16m2_t vsbc_vsm_i16m2 (vint16m2_t op1, int16_t op2, vbool8_t borrowin);
vint16m4_t vsbc_vvm_i16m4 (vint16m4_t op1, vint16m4_t op2, vbool4_t borrowin);
vint16m4_t vsbc_vsm_i16m4 (vint16m4_t op1, int16_t op2, vbool4_t borrowin);
vint16m8_t vsbc_vvm_i16m8 (vint16m8_t op1, vint16m8_t op2, vbool2_t borrowin);
vint16m8_t vsbc_vsm_i16m8 (vint16m8_t op1, int16_t op2, vbool2_t borrowin);
vint32m1_t vsbc_vvm_i32m1 (vint32m1_t op1, vint32m1_t op2, vbool32_t borrowin);
vint32m1_t vsbc_vsm_i32m1 (vint32m1_t op1, int32_t op2, vbool32_t borrowin);
vint32m2_t vsbc_vvm_i32m2 (vint32m2_t op1, vint32m2_t op2, vbool16_t borrowin);
vint32m2_t vsbc_vsm_i32m2 (vint32m2_t op1, int32_t op2, vbool16_t borrowin);
vint32m4_t vsbc_vvm_i32m4 (vint32m4_t op1, vint32m4_t op2, vbool8_t borrowin);
vint32m4_t vsbc_vsm_i32m4 (vint32m4_t op1, int32_t op2, vbool8_t borrowin);
vint32m8_t vsbc_vvm_i32m8 (vint32m8_t op1, vint32m8_t op2, vbool4_t borrowin);
vint32m8_t vsbc_vsm_i32m8 (vint32m8_t op1, int32_t op2, vbool4_t borrowin);
vint64m1_t vsbc_vvm_i64m1 (vint64m1_t op1, vint64m1_t op2, vbool64_t borrowin);
vint64m1_t vsbc_vsm_i64m1 (vint64m1_t op1, int64_t op2, vbool64_t borrowin);
vint64m2_t vsbc_vvm_i64m2 (vint64m2_t op1, vint64m2_t op2, vbool32_t borrowin);
vint64m2_t vsbc_vsm_i64m2 (vint64m2_t op1, int64_t op2, vbool32_t borrowin);
vint64m4_t vsbc_vvm_i64m4 (vint64m4_t op1, vint64m4_t op2, vbool16_t borrowin);
vint64m4_t vsbc_vsm_i64m4 (vint64m4_t op1, int64_t op2, vbool16_t borrowin);
vint64m8_t vsbc_vvm_i64m8 (vint64m8_t op1, vint64m8_t op2, vbool8_t borrowin);
vint64m8_t vsbc_vsm_i64m8 (vint64m8_t op1, int64_t op2, vbool8_t borrowin);
vuint8m1_t vsbc_vvm_u8m1 (vuint8m1_t op1, vuint8m1_t op2, vbool8_t borrowin);
vuint8m1_t vsbc_vsm_u8m1 (vuint8m1_t op1, uint8_t op2, vbool8_t borrowin);
vuint8m2_t vsbc_vvm_u8m2 (vuint8m2_t op1, vuint8m2_t op2, vbool4_t borrowin);
vuint8m2_t vsbc_vsm_u8m2 (vuint8m2_t op1, uint8_t op2, vbool4_t borrowin);
vuint8m4_t vsbc_vvm_u8m4 (vuint8m4_t op1, vuint8m4_t op2, vbool2_t borrowin);
vuint8m4_t vsbc_vsm_u8m4 (vuint8m4_t op1, uint8_t op2, vbool2_t borrowin);
vuint8m8_t vsbc_vvm_u8m8 (vuint8m8_t op1, vuint8m8_t op2, vbool1_t borrowin);
vuint8m8_t vsbc_vsm_u8m8 (vuint8m8_t op1, uint8_t op2, vbool1_t borrowin);
vuint16m1_t vsbc_vvm_u16m1 (vuint16m1_t op1, vuint16m1_t op2, vbool16_t borrowin);
vuint16m1_t vsbc_vsm_u16m1 (vuint16m1_t op1, uint16_t op2, vbool16_t borrowin);
vuint16m2_t vsbc_vvm_u16m2 (vuint16m2_t op1, vuint16m2_t op2, vbool8_t borrowin);
vuint16m2_t vsbc_vsm_u16m2 (vuint16m2_t op1, uint16_t op2, vbool8_t borrowin);
vuint16m4_t vsbc_vvm_u16m4 (vuint16m4_t op1, vuint16m4_t op2, vbool4_t borrowin);
vuint16m4_t vsbc_vsm_u16m4 (vuint16m4_t op1, uint16_t op2, vbool4_t borrowin);
vuint16m8_t vsbc_vvm_u16m8 (vuint16m8_t op1, vuint16m8_t op2, vbool2_t borrowin);
vuint16m8_t vsbc_vsm_u16m8 (vuint16m8_t op1, uint16_t op2, vbool2_t borrowin);
vuint32m1_t vsbc_vvm_u32m1 (vuint32m1_t op1, vuint32m1_t op2, vbool32_t borrowin);
vuint32m1_t vsbc_vsm_u32m1 (vuint32m1_t op1, uint32_t op2, vbool32_t borrowin);
vuint32m2_t vsbc_vvm_u32m2 (vuint32m2_t op1, vuint32m2_t op2, vbool16_t borrowin);
vuint32m2_t vsbc_vsm_u32m2 (vuint32m2_t op1, uint32_t op2, vbool16_t borrowin);
vuint32m4_t vsbc_vvm_u32m4 (vuint32m4_t op1, vuint32m4_t op2, vbool8_t borrowin);
vuint32m4_t vsbc_vsm_u32m4 (vuint32m4_t op1, uint32_t op2, vbool8_t borrowin);
vuint32m8_t vsbc_vvm_u32m8 (vuint32m8_t op1, vuint32m8_t op2, vbool4_t borrowin);
vuint32m8_t vsbc_vsm_u32m8 (vuint32m8_t op1, uint32_t op2, vbool4_t borrowin);
vuint64m1_t vsbc_vvm_u64m1 (vuint64m1_t op1, vuint64m1_t op2, vbool64_t borrowin);
vuint64m1_t vsbc_vsm_u64m1 (vuint64m1_t op1, uint64_t op2, vbool64_t borrowin);
vuint64m2_t vsbc_vvm_u64m2 (vuint64m2_t op1, vuint64m2_t op2, vbool32_t borrowin);
vuint64m2_t vsbc_vsm_u64m2 (vuint64m2_t op1, uint64_t op2, vbool32_t borrowin);
vuint64m4_t vsbc_vvm_u64m4 (vuint64m4_t op1, vuint64m4_t op2, vbool16_t borrowin);
vuint64m4_t vsbc_vsm_u64m4 (vuint64m4_t op1, uint64_t op2, vbool16_t borrowin);
vuint64m8_t vsbc_vvm_u64m8 (vuint64m8_t op1, vuint64m8_t op2, vbool8_t borrowin);
vuint64m8_t vsbc_vsm_u64m8 (vuint64m8_t op1, uint64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vvm_i8m1 (vint8m1_t op1, vint8m1_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm_i8m1 (vint8m1_t op1, int8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsbc_vs_i8m1 (vint8m1_t op1, int8_t op2);
vbool4_t vmsbc_vvm_i8m2 (vint8m2_t op1, vint8m2_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm_i8m2 (vint8m2_t op1, int8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsbc_vs_i8m2 (vint8m2_t op1, int8_t op2);
vbool2_t vmsbc_vvm_i8m4 (vint8m4_t op1, vint8m4_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm_i8m4 (vint8m4_t op1, int8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsbc_vs_i8m4 (vint8m4_t op1, int8_t op2);
vbool1_t vmsbc_vvm_i8m8 (vint8m8_t op1, vint8m8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vsm_i8m8 (vint8m8_t op1, int8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsbc_vs_i8m8 (vint8m8_t op1, int8_t op2);
vbool16_t vmsbc_vvm_i16m1 (vint16m1_t op1, vint16m1_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm_i16m1 (vint16m1_t op1, int16_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsbc_vs_i16m1 (vint16m1_t op1, int16_t op2);
vbool8_t vmsbc_vvm_i16m2 (vint16m2_t op1, vint16m2_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm_i16m2 (vint16m2_t op1, int16_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsbc_vs_i16m2 (vint16m2_t op1, int16_t op2);
vbool4_t vmsbc_vvm_i16m4 (vint16m4_t op1, vint16m4_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm_i16m4 (vint16m4_t op1, int16_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsbc_vs_i16m4 (vint16m4_t op1, int16_t op2);
vbool2_t vmsbc_vvm_i16m8 (vint16m8_t op1, vint16m8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm_i16m8 (vint16m8_t op1, int16_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsbc_vs_i16m8 (vint16m8_t op1, int16_t op2);
vbool32_t vmsbc_vvm_i32m1 (vint32m1_t op1, vint32m1_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm_i32m1 (vint32m1_t op1, int32_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsbc_vs_i32m1 (vint32m1_t op1, int32_t op2);
vbool16_t vmsbc_vvm_i32m2 (vint32m2_t op1, vint32m2_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm_i32m2 (vint32m2_t op1, int32_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsbc_vs_i32m2 (vint32m2_t op1, int32_t op2);
vbool8_t vmsbc_vvm_i32m4 (vint32m4_t op1, vint32m4_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm_i32m4 (vint32m4_t op1, int32_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsbc_vs_i32m4 (vint32m4_t op1, int32_t op2);
vbool4_t vmsbc_vvm_i32m8 (vint32m8_t op1, vint32m8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm_i32m8 (vint32m8_t op1, int32_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsbc_vs_i32m8 (vint32m8_t op1, int32_t op2);
vbool64_t vmsbc_vvm_i64m1 (vint64m1_t op1, vint64m1_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vsm_i64m1 (vint64m1_t op1, int64_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsbc_vs_i64m1 (vint64m1_t op1, int64_t op2);
vbool32_t vmsbc_vvm_i64m2 (vint64m2_t op1, vint64m2_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm_i64m2 (vint64m2_t op1, int64_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsbc_vs_i64m2 (vint64m2_t op1, int64_t op2);
vbool16_t vmsbc_vvm_i64m4 (vint64m4_t op1, vint64m4_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm_i64m4 (vint64m4_t op1, int64_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsbc_vs_i64m4 (vint64m4_t op1, int64_t op2);
vbool8_t vmsbc_vvm_i64m8 (vint64m8_t op1, vint64m8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm_i64m8 (vint64m8_t op1, int64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsbc_vs_i64m8 (vint64m8_t op1, int64_t op2);
vbool8_t vmsbc_vvm_u8m1 (vuint8m1_t op1, vuint8m1_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm_u8m1 (vuint8m1_t op1, uint8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsbc_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vbool4_t vmsbc_vvm_u8m2 (vuint8m2_t op1, vuint8m2_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm_u8m2 (vuint8m2_t op1, uint8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsbc_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vbool2_t vmsbc_vvm_u8m4 (vuint8m4_t op1, vuint8m4_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm_u8m4 (vuint8m4_t op1, uint8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsbc_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vbool1_t vmsbc_vvm_u8m8 (vuint8m8_t op1, vuint8m8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vsm_u8m8 (vuint8m8_t op1, uint8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsbc_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vbool16_t vmsbc_vvm_u16m1 (vuint16m1_t op1, vuint16m1_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm_u16m1 (vuint16m1_t op1, uint16_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsbc_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vbool8_t vmsbc_vvm_u16m2 (vuint16m2_t op1, vuint16m2_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm_u16m2 (vuint16m2_t op1, uint16_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsbc_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vbool4_t vmsbc_vvm_u16m4 (vuint16m4_t op1, vuint16m4_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm_u16m4 (vuint16m4_t op1, uint16_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsbc_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vbool2_t vmsbc_vvm_u16m8 (vuint16m8_t op1, vuint16m8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm_u16m8 (vuint16m8_t op1, uint16_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsbc_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vbool32_t vmsbc_vvm_u32m1 (vuint32m1_t op1, vuint32m1_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm_u32m1 (vuint32m1_t op1, uint32_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsbc_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vbool16_t vmsbc_vvm_u32m2 (vuint32m2_t op1, vuint32m2_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm_u32m2 (vuint32m2_t op1, uint32_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsbc_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vbool8_t vmsbc_vvm_u32m4 (vuint32m4_t op1, vuint32m4_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm_u32m4 (vuint32m4_t op1, uint32_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsbc_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vbool4_t vmsbc_vvm_u32m8 (vuint32m8_t op1, vuint32m8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm_u32m8 (vuint32m8_t op1, uint32_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsbc_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vbool64_t vmsbc_vvm_u64m1 (vuint64m1_t op1, vuint64m1_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vsm_u64m1 (vuint64m1_t op1, uint64_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsbc_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vbool32_t vmsbc_vvm_u64m2 (vuint64m2_t op1, vuint64m2_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm_u64m2 (vuint64m2_t op1, uint64_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsbc_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vbool16_t vmsbc_vvm_u64m4 (vuint64m4_t op1, vuint64m4_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm_u64m4 (vuint64m4_t op1, uint64_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsbc_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vbool8_t vmsbc_vvm_u64m8 (vuint64m8_t op1, vuint64m8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm_u64m8 (vuint64m8_t op1, uint64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsbc_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
```
### [Vector Bitwise Logical Functions]()

**Prototypes:**
``` C
vuint8m1_t vand_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vand_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vand_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vand_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vand_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vand_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vand_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vand_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vand_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vand_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vand_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vand_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vand_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vand_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vand_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vand_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vand_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vand_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vand_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vand_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vand_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vand_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vand_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vand_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vand_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vand_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vand_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vand_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vand_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vand_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vand_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vand_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vuint8m1_t vor_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vor_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vor_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vor_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vor_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vor_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vor_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vor_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vor_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vor_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vor_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vor_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vor_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vor_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vor_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vor_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vor_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vor_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vor_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vor_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vor_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vor_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vor_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vor_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vor_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vor_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vor_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vor_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vor_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vor_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vor_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vor_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vuint8m1_t vxor_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vxor_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vxor_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vxor_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vxor_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vxor_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vxor_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vxor_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vxor_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vxor_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vxor_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vxor_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vxor_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vxor_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vxor_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vxor_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vxor_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vxor_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vxor_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vxor_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vxor_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vxor_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vxor_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vxor_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vxor_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vxor_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vxor_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vxor_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vxor_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vxor_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vxor_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vxor_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
// masked functions
vuint8m1_t vand_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vand_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vand_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vand_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vand_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vand_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vand_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vand_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vand_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vand_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vand_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vand_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vand_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vand_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vand_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vand_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vand_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vand_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vand_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vand_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vand_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vand_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vand_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vand_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vand_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vand_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vand_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vand_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vand_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vand_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vand_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vand_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vuint8m1_t vor_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vor_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vor_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vor_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vor_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vor_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vor_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vor_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vor_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vor_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vor_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vor_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vor_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vor_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vor_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vor_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vor_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vor_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vor_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vor_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vor_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vor_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vor_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vor_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vor_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vor_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vor_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vor_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vor_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vor_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vor_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vor_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vuint8m1_t vxor_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vxor_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vxor_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vxor_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vxor_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vxor_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vxor_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vxor_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vxor_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vxor_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vxor_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vxor_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vxor_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vxor_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vxor_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vxor_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vxor_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vxor_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vxor_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vxor_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vxor_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vxor_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vxor_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vxor_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vxor_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vxor_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vxor_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vxor_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vxor_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vxor_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vxor_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vxor_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Bit Shift Functions]()

**Prototypes:**
``` C
vuint8m1_t vsll_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsll_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsll_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsll_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsll_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsll_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsll_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsll_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsll_vv_u16m1 (vuint16m1_t op1, vuint8m1_t op2);
vuint16m1_t vsll_vs_u16m1 (vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsll_vv_u16m2 (vuint16m2_t op1, vuint8m2_t op2);
vuint16m2_t vsll_vs_u16m2 (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsll_vv_u16m4 (vuint16m4_t op1, vuint8m4_t op2);
vuint16m4_t vsll_vs_u16m4 (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsll_vv_u16m8 (vuint16m8_t op1, vuint8m8_t op2);
vuint16m8_t vsll_vs_u16m8 (vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsll_vv_u32m1 (vuint32m1_t op1, vuint8m1_t op2);
vuint32m1_t vsll_vs_u32m1 (vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsll_vv_u32m2 (vuint32m2_t op1, vuint8m2_t op2);
vuint32m2_t vsll_vs_u32m2 (vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsll_vv_u32m4 (vuint32m4_t op1, vuint8m4_t op2);
vuint32m4_t vsll_vs_u32m4 (vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsll_vv_u32m8 (vuint32m8_t op1, vuint8m8_t op2);
vuint32m8_t vsll_vs_u32m8 (vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsll_vv_u64m1 (vuint64m1_t op1, vuint8m1_t op2);
vuint64m1_t vsll_vs_u64m1 (vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsll_vv_u64m2 (vuint64m2_t op1, vuint8m2_t op2);
vuint64m2_t vsll_vs_u64m2 (vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsll_vv_u64m4 (vuint64m4_t op1, vuint8m4_t op2);
vuint64m4_t vsll_vs_u64m4 (vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsll_vv_u64m8 (vuint64m8_t op1, vuint8m8_t op2);
vuint64m8_t vsll_vs_u64m8 (vuint64m8_t op1, uint8_t op2);
vuint8m1_t vsrl_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsrl_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsrl_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsrl_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsrl_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsrl_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsrl_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsrl_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsrl_vv_u16m1 (vuint16m1_t op1, vuint8m1_t op2);
vuint16m1_t vsrl_vs_u16m1 (vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsrl_vv_u16m2 (vuint16m2_t op1, vuint8m2_t op2);
vuint16m2_t vsrl_vs_u16m2 (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsrl_vv_u16m4 (vuint16m4_t op1, vuint8m4_t op2);
vuint16m4_t vsrl_vs_u16m4 (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsrl_vv_u16m8 (vuint16m8_t op1, vuint8m8_t op2);
vuint16m8_t vsrl_vs_u16m8 (vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsrl_vv_u32m1 (vuint32m1_t op1, vuint8m1_t op2);
vuint32m1_t vsrl_vs_u32m1 (vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsrl_vv_u32m2 (vuint32m2_t op1, vuint8m2_t op2);
vuint32m2_t vsrl_vs_u32m2 (vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsrl_vv_u32m4 (vuint32m4_t op1, vuint8m4_t op2);
vuint32m4_t vsrl_vs_u32m4 (vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsrl_vv_u32m8 (vuint32m8_t op1, vuint8m8_t op2);
vuint32m8_t vsrl_vs_u32m8 (vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsrl_vv_u64m1 (vuint64m1_t op1, vuint8m1_t op2);
vuint64m1_t vsrl_vs_u64m1 (vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsrl_vv_u64m2 (vuint64m2_t op1, vuint8m2_t op2);
vuint64m2_t vsrl_vs_u64m2 (vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsrl_vv_u64m4 (vuint64m4_t op1, vuint8m4_t op2);
vuint64m4_t vsrl_vs_u64m4 (vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsrl_vv_u64m8 (vuint64m8_t op1, vuint8m8_t op2);
vuint64m8_t vsrl_vs_u64m8 (vuint64m8_t op1, uint8_t op2);
vint8m1_t vsra_vv_i8m1 (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vsra_vs_i8m1 (vint8m1_t op1, uint8_t op2);
vint8m2_t vsra_vv_i8m2 (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vsra_vs_i8m2 (vint8m2_t op1, uint8_t op2);
vint8m4_t vsra_vv_i8m4 (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vsra_vs_i8m4 (vint8m4_t op1, uint8_t op2);
vint8m8_t vsra_vv_i8m8 (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vsra_vs_i8m8 (vint8m8_t op1, uint8_t op2);
vint16m1_t vsra_vv_i16m1 (vint16m1_t op1, vuint8m1_t op2);
vint16m1_t vsra_vs_i16m1 (vint16m1_t op1, uint8_t op2);
vint16m2_t vsra_vv_i16m2 (vint16m2_t op1, vuint8m2_t op2);
vint16m2_t vsra_vs_i16m2 (vint16m2_t op1, uint8_t op2);
vint16m4_t vsra_vv_i16m4 (vint16m4_t op1, vuint8m4_t op2);
vint16m4_t vsra_vs_i16m4 (vint16m4_t op1, uint8_t op2);
vint16m8_t vsra_vv_i16m8 (vint16m8_t op1, vuint8m8_t op2);
vint16m8_t vsra_vs_i16m8 (vint16m8_t op1, uint8_t op2);
vint32m1_t vsra_vv_i32m1 (vint32m1_t op1, vuint8m1_t op2);
vint32m1_t vsra_vs_i32m1 (vint32m1_t op1, uint8_t op2);
vint32m2_t vsra_vv_i32m2 (vint32m2_t op1, vuint8m2_t op2);
vint32m2_t vsra_vs_i32m2 (vint32m2_t op1, uint8_t op2);
vint32m4_t vsra_vv_i32m4 (vint32m4_t op1, vuint8m4_t op2);
vint32m4_t vsra_vs_i32m4 (vint32m4_t op1, uint8_t op2);
vint32m8_t vsra_vv_i32m8 (vint32m8_t op1, vuint8m8_t op2);
vint32m8_t vsra_vs_i32m8 (vint32m8_t op1, uint8_t op2);
vint64m1_t vsra_vv_i64m1 (vint64m1_t op1, vuint8m1_t op2);
vint64m1_t vsra_vs_i64m1 (vint64m1_t op1, uint8_t op2);
vint64m2_t vsra_vv_i64m2 (vint64m2_t op1, vuint8m2_t op2);
vint64m2_t vsra_vs_i64m2 (vint64m2_t op1, uint8_t op2);
vint64m4_t vsra_vv_i64m4 (vint64m4_t op1, vuint8m4_t op2);
vint64m4_t vsra_vs_i64m4 (vint64m4_t op1, uint8_t op2);
vint64m8_t vsra_vv_i64m8 (vint64m8_t op1, vuint8m8_t op2);
vint64m8_t vsra_vs_i64m8 (vint64m8_t op1, uint8_t op2);
// masked functions
vuint8m1_t vsll_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsll_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsll_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsll_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsll_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsll_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsll_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsll_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsll_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint8m1_t op2);
vuint16m1_t vsll_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsll_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m2_t op2);
vuint16m2_t vsll_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsll_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m4_t op2);
vuint16m4_t vsll_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsll_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m8_t op2);
vuint16m8_t vsll_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsll_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint8m1_t op2);
vuint32m1_t vsll_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsll_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint8m2_t op2);
vuint32m2_t vsll_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsll_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint8m4_t op2);
vuint32m4_t vsll_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsll_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint8m8_t op2);
vuint32m8_t vsll_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsll_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint8m1_t op2);
vuint64m1_t vsll_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsll_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint8m2_t op2);
vuint64m2_t vsll_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsll_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint8m4_t op2);
vuint64m4_t vsll_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsll_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint8m8_t op2);
vuint64m8_t vsll_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint8_t op2);
vuint8m1_t vsrl_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsrl_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsrl_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsrl_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsrl_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsrl_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsrl_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsrl_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsrl_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint8m1_t op2);
vuint16m1_t vsrl_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsrl_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m2_t op2);
vuint16m2_t vsrl_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsrl_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m4_t op2);
vuint16m4_t vsrl_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsrl_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m8_t op2);
vuint16m8_t vsrl_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsrl_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint8m1_t op2);
vuint32m1_t vsrl_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsrl_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint8m2_t op2);
vuint32m2_t vsrl_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsrl_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint8m4_t op2);
vuint32m4_t vsrl_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsrl_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint8m8_t op2);
vuint32m8_t vsrl_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsrl_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint8m1_t op2);
vuint64m1_t vsrl_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsrl_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint8m2_t op2);
vuint64m2_t vsrl_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsrl_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint8m4_t op2);
vuint64m4_t vsrl_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsrl_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint8m8_t op2);
vuint64m8_t vsrl_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint8_t op2);
vint8m1_t vsra_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vsra_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vsra_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vsra_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vsra_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vsra_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vsra_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vsra_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vsra_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint8m1_t op2);
vint16m1_t vsra_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint8_t op2);
vint16m2_t vsra_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint8m2_t op2);
vint16m2_t vsra_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint8_t op2);
vint16m4_t vsra_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint8m4_t op2);
vint16m4_t vsra_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint8_t op2);
vint16m8_t vsra_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint8m8_t op2);
vint16m8_t vsra_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint8_t op2);
vint32m1_t vsra_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint8m1_t op2);
vint32m1_t vsra_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint8_t op2);
vint32m2_t vsra_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint8m2_t op2);
vint32m2_t vsra_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint8_t op2);
vint32m4_t vsra_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint8m4_t op2);
vint32m4_t vsra_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint8_t op2);
vint32m8_t vsra_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint8m8_t op2);
vint32m8_t vsra_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint8_t op2);
vint64m1_t vsra_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint8m1_t op2);
vint64m1_t vsra_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint8_t op2);
vint64m2_t vsra_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint8m2_t op2);
vint64m2_t vsra_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint8_t op2);
vint64m4_t vsra_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint8m4_t op2);
vint64m4_t vsra_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint8_t op2);
vint64m8_t vsra_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint8m8_t op2);
vint64m8_t vsra_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint8_t op2);
```
### [Vector Narrowing Integer Right Shift Functions]()

**Prototypes:**
``` C
vuint8m1_t vnsrl_wv_u16m2 (vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnsrl_ws_u16m2 (vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnsrl_wv_u16m4 (vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnsrl_ws_u16m4 (vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnsrl_wv_u16m8 (vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnsrl_ws_u16m8 (vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnsrl_wv_u32m2 (vuint32m2_t op1, vuint8m1_t op2);
vuint16m1_t vnsrl_ws_u32m2 (vuint32m2_t op1, uint8_t op2);
vuint16m2_t vnsrl_wv_u32m4 (vuint32m4_t op1, vuint8m2_t op2);
vuint16m2_t vnsrl_ws_u32m4 (vuint32m4_t op1, uint8_t op2);
vuint16m4_t vnsrl_wv_u32m8 (vuint32m8_t op1, vuint8m4_t op2);
vuint16m4_t vnsrl_ws_u32m8 (vuint32m8_t op1, uint8_t op2);
vuint32m1_t vnsrl_wv_u64m2 (vuint64m2_t op1, vuint8m1_t op2);
vuint32m1_t vnsrl_ws_u64m2 (vuint64m2_t op1, uint8_t op2);
vuint32m2_t vnsrl_wv_u64m4 (vuint64m4_t op1, vuint8m2_t op2);
vuint32m2_t vnsrl_ws_u64m4 (vuint64m4_t op1, uint8_t op2);
vuint32m4_t vnsrl_wv_u64m8 (vuint64m8_t op1, vuint8m4_t op2);
vuint32m4_t vnsrl_ws_u64m8 (vuint64m8_t op1, uint8_t op2);
vint8m1_t vnsra_wv_i16m2 (vint16m2_t op1, vuint8m1_t op2);
vint8m1_t vnsra_ws_i16m2 (vint16m2_t op1, uint8_t op2);
vint8m2_t vnsra_wv_i16m4 (vint16m4_t op1, vuint8m2_t op2);
vint8m2_t vnsra_ws_i16m4 (vint16m4_t op1, uint8_t op2);
vint8m4_t vnsra_wv_i16m8 (vint16m8_t op1, vuint8m4_t op2);
vint8m4_t vnsra_ws_i16m8 (vint16m8_t op1, uint8_t op2);
vint16m1_t vnsra_wv_i32m2 (vint32m2_t op1, vuint8m1_t op2);
vint16m1_t vnsra_ws_i32m2 (vint32m2_t op1, uint8_t op2);
vint16m2_t vnsra_wv_i32m4 (vint32m4_t op1, vuint8m2_t op2);
vint16m2_t vnsra_ws_i32m4 (vint32m4_t op1, uint8_t op2);
vint16m4_t vnsra_wv_i32m8 (vint32m8_t op1, vuint8m4_t op2);
vint16m4_t vnsra_ws_i32m8 (vint32m8_t op1, uint8_t op2);
vint32m1_t vnsra_wv_i64m2 (vint64m2_t op1, vuint8m1_t op2);
vint32m1_t vnsra_ws_i64m2 (vint64m2_t op1, uint8_t op2);
vint32m2_t vnsra_wv_i64m4 (vint64m4_t op1, vuint8m2_t op2);
vint32m2_t vnsra_ws_i64m4 (vint64m4_t op1, uint8_t op2);
vint32m4_t vnsra_wv_i64m8 (vint64m8_t op1, vuint8m4_t op2);
vint32m4_t vnsra_ws_i64m8 (vint64m8_t op1, uint8_t op2);
// masked functions
vuint8m1_t vnsrl_wv_u16m2_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnsrl_ws_u16m2_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnsrl_wv_u16m4_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnsrl_ws_u16m4_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnsrl_wv_u16m8_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnsrl_ws_u16m8_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnsrl_wv_u32m2_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint8m1_t op2);
vuint16m1_t vnsrl_ws_u32m2_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint16m2_t vnsrl_wv_u32m4_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint8m2_t op2);
vuint16m2_t vnsrl_ws_u32m4_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint16m4_t vnsrl_wv_u32m8_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint8m4_t op2);
vuint16m4_t vnsrl_ws_u32m8_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint32m1_t vnsrl_wv_u64m2_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint8m1_t op2);
vuint32m1_t vnsrl_ws_u64m2_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint32m2_t vnsrl_wv_u64m4_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint8m2_t op2);
vuint32m2_t vnsrl_ws_u64m4_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint32m4_t vnsrl_wv_u64m8_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint8m4_t op2);
vuint32m4_t vnsrl_ws_u64m8_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, uint8_t op2);
vint8m1_t vnsra_wv_i16m2_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t op2);
vint8m1_t vnsra_ws_i16m2_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, uint8_t op2);
vint8m2_t vnsra_wv_i16m4_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t op2);
vint8m2_t vnsra_ws_i16m4_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, uint8_t op2);
vint8m4_t vnsra_wv_i16m8_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t op2);
vint8m4_t vnsra_ws_i16m8_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, uint8_t op2);
vint16m1_t vnsra_wv_i32m2_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint8m1_t op2);
vint16m1_t vnsra_ws_i32m2_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, uint8_t op2);
vint16m2_t vnsra_wv_i32m4_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint8m2_t op2);
vint16m2_t vnsra_ws_i32m4_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, uint8_t op2);
vint16m4_t vnsra_wv_i32m8_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint8m4_t op2);
vint16m4_t vnsra_ws_i32m8_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, uint8_t op2);
vint32m1_t vnsra_wv_i64m2_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint8m1_t op2);
vint32m1_t vnsra_ws_i64m2_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, uint8_t op2);
vint32m2_t vnsra_wv_i64m4_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint8m2_t op2);
vint32m2_t vnsra_ws_i64m4_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, uint8_t op2);
vint32m4_t vnsra_wv_i64m8_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint8m4_t op2);
vint32m4_t vnsra_ws_i64m8_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, uint8_t op2);
```
### [Vector Integer Comparison Functions]()

**Prototypes:**
``` C
vbool8_t vseteq_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vbool8_t vseteq_vs_i8m1 (vint8m1_t op1, int8_t op2);
vbool4_t vseteq_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vbool4_t vseteq_vs_i8m2 (vint8m2_t op1, int8_t op2);
vbool2_t vseteq_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vbool2_t vseteq_vs_i8m4 (vint8m4_t op1, int8_t op2);
vbool1_t vseteq_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vbool1_t vseteq_vs_i8m8 (vint8m8_t op1, int8_t op2);
vbool16_t vseteq_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vbool16_t vseteq_vs_i16m1 (vint16m1_t op1, int16_t op2);
vbool8_t vseteq_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vbool8_t vseteq_vs_i16m2 (vint16m2_t op1, int16_t op2);
vbool4_t vseteq_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vbool4_t vseteq_vs_i16m4 (vint16m4_t op1, int16_t op2);
vbool2_t vseteq_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vbool2_t vseteq_vs_i16m8 (vint16m8_t op1, int16_t op2);
vbool32_t vseteq_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vbool32_t vseteq_vs_i32m1 (vint32m1_t op1, int32_t op2);
vbool16_t vseteq_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vbool16_t vseteq_vs_i32m2 (vint32m2_t op1, int32_t op2);
vbool8_t vseteq_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vbool8_t vseteq_vs_i32m4 (vint32m4_t op1, int32_t op2);
vbool4_t vseteq_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vbool4_t vseteq_vs_i32m8 (vint32m8_t op1, int32_t op2);
vbool64_t vseteq_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vbool64_t vseteq_vs_i64m1 (vint64m1_t op1, int64_t op2);
vbool32_t vseteq_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vbool32_t vseteq_vs_i64m2 (vint64m2_t op1, int64_t op2);
vbool16_t vseteq_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vbool16_t vseteq_vs_i64m4 (vint64m4_t op1, int64_t op2);
vbool8_t vseteq_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vbool8_t vseteq_vs_i64m8 (vint64m8_t op1, int64_t op2);
vbool8_t vseteq_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vseteq_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vbool4_t vseteq_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vseteq_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vbool2_t vseteq_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vseteq_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vbool1_t vseteq_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vseteq_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vbool16_t vseteq_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vseteq_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vbool8_t vseteq_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vseteq_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vbool4_t vseteq_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vseteq_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vbool2_t vseteq_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vseteq_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vbool32_t vseteq_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vseteq_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vbool16_t vseteq_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vseteq_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vbool8_t vseteq_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vseteq_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vbool4_t vseteq_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vseteq_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vbool64_t vseteq_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vseteq_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vbool32_t vseteq_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vseteq_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vbool16_t vseteq_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vseteq_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vbool8_t vseteq_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vseteq_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetne_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetne_vs_i8m1 (vint8m1_t op1, int8_t op2);
vbool4_t vsetne_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetne_vs_i8m2 (vint8m2_t op1, int8_t op2);
vbool2_t vsetne_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetne_vs_i8m4 (vint8m4_t op1, int8_t op2);
vbool1_t vsetne_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetne_vs_i8m8 (vint8m8_t op1, int8_t op2);
vbool16_t vsetne_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetne_vs_i16m1 (vint16m1_t op1, int16_t op2);
vbool8_t vsetne_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetne_vs_i16m2 (vint16m2_t op1, int16_t op2);
vbool4_t vsetne_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetne_vs_i16m4 (vint16m4_t op1, int16_t op2);
vbool2_t vsetne_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetne_vs_i16m8 (vint16m8_t op1, int16_t op2);
vbool32_t vsetne_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetne_vs_i32m1 (vint32m1_t op1, int32_t op2);
vbool16_t vsetne_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetne_vs_i32m2 (vint32m2_t op1, int32_t op2);
vbool8_t vsetne_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetne_vs_i32m4 (vint32m4_t op1, int32_t op2);
vbool4_t vsetne_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetne_vs_i32m8 (vint32m8_t op1, int32_t op2);
vbool64_t vsetne_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetne_vs_i64m1 (vint64m1_t op1, int64_t op2);
vbool32_t vsetne_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetne_vs_i64m2 (vint64m2_t op1, int64_t op2);
vbool16_t vsetne_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetne_vs_i64m4 (vint64m4_t op1, int64_t op2);
vbool8_t vsetne_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetne_vs_i64m8 (vint64m8_t op1, int64_t op2);
vbool8_t vsetne_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetne_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetne_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetne_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetne_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetne_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetne_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetne_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetne_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetne_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetne_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetne_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetne_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetne_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetne_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetne_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetne_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetne_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetne_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetne_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetne_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetne_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetne_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetne_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetne_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetne_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetne_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetne_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetne_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetne_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetne_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetne_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetlt_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetlt_vs_i8m1 (vint8m1_t op1, int8_t op2);
vbool4_t vsetlt_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetlt_vs_i8m2 (vint8m2_t op1, int8_t op2);
vbool2_t vsetlt_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetlt_vs_i8m4 (vint8m4_t op1, int8_t op2);
vbool1_t vsetlt_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetlt_vs_i8m8 (vint8m8_t op1, int8_t op2);
vbool16_t vsetlt_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetlt_vs_i16m1 (vint16m1_t op1, int16_t op2);
vbool8_t vsetlt_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetlt_vs_i16m2 (vint16m2_t op1, int16_t op2);
vbool4_t vsetlt_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetlt_vs_i16m4 (vint16m4_t op1, int16_t op2);
vbool2_t vsetlt_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetlt_vs_i16m8 (vint16m8_t op1, int16_t op2);
vbool32_t vsetlt_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetlt_vs_i32m1 (vint32m1_t op1, int32_t op2);
vbool16_t vsetlt_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetlt_vs_i32m2 (vint32m2_t op1, int32_t op2);
vbool8_t vsetlt_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetlt_vs_i32m4 (vint32m4_t op1, int32_t op2);
vbool4_t vsetlt_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetlt_vs_i32m8 (vint32m8_t op1, int32_t op2);
vbool64_t vsetlt_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetlt_vs_i64m1 (vint64m1_t op1, int64_t op2);
vbool32_t vsetlt_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetlt_vs_i64m2 (vint64m2_t op1, int64_t op2);
vbool16_t vsetlt_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetlt_vs_i64m4 (vint64m4_t op1, int64_t op2);
vbool8_t vsetlt_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetlt_vs_i64m8 (vint64m8_t op1, int64_t op2);
vbool8_t vsetlt_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetlt_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetlt_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetlt_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetlt_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetlt_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetlt_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetlt_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetlt_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetlt_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetlt_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetlt_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetlt_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetlt_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetlt_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetlt_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetlt_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetlt_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetlt_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetlt_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetlt_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetlt_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetlt_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetlt_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetlt_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetlt_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetlt_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetlt_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetlt_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetlt_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetlt_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetlt_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetle_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetle_vs_i8m1 (vint8m1_t op1, int8_t op2);
vbool4_t vsetle_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetle_vs_i8m2 (vint8m2_t op1, int8_t op2);
vbool2_t vsetle_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetle_vs_i8m4 (vint8m4_t op1, int8_t op2);
vbool1_t vsetle_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetle_vs_i8m8 (vint8m8_t op1, int8_t op2);
vbool16_t vsetle_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetle_vs_i16m1 (vint16m1_t op1, int16_t op2);
vbool8_t vsetle_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetle_vs_i16m2 (vint16m2_t op1, int16_t op2);
vbool4_t vsetle_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetle_vs_i16m4 (vint16m4_t op1, int16_t op2);
vbool2_t vsetle_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetle_vs_i16m8 (vint16m8_t op1, int16_t op2);
vbool32_t vsetle_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetle_vs_i32m1 (vint32m1_t op1, int32_t op2);
vbool16_t vsetle_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetle_vs_i32m2 (vint32m2_t op1, int32_t op2);
vbool8_t vsetle_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetle_vs_i32m4 (vint32m4_t op1, int32_t op2);
vbool4_t vsetle_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetle_vs_i32m8 (vint32m8_t op1, int32_t op2);
vbool64_t vsetle_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetle_vs_i64m1 (vint64m1_t op1, int64_t op2);
vbool32_t vsetle_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetle_vs_i64m2 (vint64m2_t op1, int64_t op2);
vbool16_t vsetle_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetle_vs_i64m4 (vint64m4_t op1, int64_t op2);
vbool8_t vsetle_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetle_vs_i64m8 (vint64m8_t op1, int64_t op2);
vbool8_t vsetle_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetle_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetle_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetle_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetle_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetle_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetle_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetle_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetle_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetle_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetle_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetle_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetle_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetle_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetle_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetle_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetle_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetle_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetle_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetle_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetle_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetle_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetle_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetle_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetle_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetle_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetle_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetle_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetle_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetle_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetle_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetle_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetgt_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetgt_vs_i8m1 (vint8m1_t op1, int8_t op2);
vbool4_t vsetgt_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetgt_vs_i8m2 (vint8m2_t op1, int8_t op2);
vbool2_t vsetgt_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetgt_vs_i8m4 (vint8m4_t op1, int8_t op2);
vbool1_t vsetgt_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetgt_vs_i8m8 (vint8m8_t op1, int8_t op2);
vbool16_t vsetgt_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetgt_vs_i16m1 (vint16m1_t op1, int16_t op2);
vbool8_t vsetgt_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetgt_vs_i16m2 (vint16m2_t op1, int16_t op2);
vbool4_t vsetgt_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetgt_vs_i16m4 (vint16m4_t op1, int16_t op2);
vbool2_t vsetgt_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetgt_vs_i16m8 (vint16m8_t op1, int16_t op2);
vbool32_t vsetgt_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetgt_vs_i32m1 (vint32m1_t op1, int32_t op2);
vbool16_t vsetgt_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetgt_vs_i32m2 (vint32m2_t op1, int32_t op2);
vbool8_t vsetgt_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetgt_vs_i32m4 (vint32m4_t op1, int32_t op2);
vbool4_t vsetgt_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetgt_vs_i32m8 (vint32m8_t op1, int32_t op2);
vbool64_t vsetgt_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetgt_vs_i64m1 (vint64m1_t op1, int64_t op2);
vbool32_t vsetgt_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetgt_vs_i64m2 (vint64m2_t op1, int64_t op2);
vbool16_t vsetgt_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetgt_vs_i64m4 (vint64m4_t op1, int64_t op2);
vbool8_t vsetgt_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetgt_vs_i64m8 (vint64m8_t op1, int64_t op2);
vbool8_t vsetgt_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetgt_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetgt_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetgt_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetgt_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetgt_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetgt_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetgt_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetgt_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetgt_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetgt_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetgt_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetgt_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetgt_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetgt_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetgt_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetgt_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetgt_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetgt_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetgt_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetgt_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetgt_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetgt_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetgt_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetgt_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetgt_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetgt_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetgt_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetgt_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetgt_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetgt_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetgt_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetge_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetge_vs_i8m1 (vint8m1_t op1, int8_t op2);
vbool4_t vsetge_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetge_vs_i8m2 (vint8m2_t op1, int8_t op2);
vbool2_t vsetge_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetge_vs_i8m4 (vint8m4_t op1, int8_t op2);
vbool1_t vsetge_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetge_vs_i8m8 (vint8m8_t op1, int8_t op2);
vbool16_t vsetge_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetge_vs_i16m1 (vint16m1_t op1, int16_t op2);
vbool8_t vsetge_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetge_vs_i16m2 (vint16m2_t op1, int16_t op2);
vbool4_t vsetge_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetge_vs_i16m4 (vint16m4_t op1, int16_t op2);
vbool2_t vsetge_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetge_vs_i16m8 (vint16m8_t op1, int16_t op2);
vbool32_t vsetge_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetge_vs_i32m1 (vint32m1_t op1, int32_t op2);
vbool16_t vsetge_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetge_vs_i32m2 (vint32m2_t op1, int32_t op2);
vbool8_t vsetge_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetge_vs_i32m4 (vint32m4_t op1, int32_t op2);
vbool4_t vsetge_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetge_vs_i32m8 (vint32m8_t op1, int32_t op2);
vbool64_t vsetge_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetge_vs_i64m1 (vint64m1_t op1, int64_t op2);
vbool32_t vsetge_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetge_vs_i64m2 (vint64m2_t op1, int64_t op2);
vbool16_t vsetge_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetge_vs_i64m4 (vint64m4_t op1, int64_t op2);
vbool8_t vsetge_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetge_vs_i64m8 (vint64m8_t op1, int64_t op2);
vbool8_t vsetge_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetge_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetge_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetge_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetge_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetge_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetge_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetge_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetge_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetge_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetge_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetge_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetge_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetge_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetge_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetge_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetge_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetge_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetge_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetge_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetge_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetge_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetge_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetge_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetge_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetge_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetge_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetge_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetge_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetge_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetge_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetge_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
// masked functions
vbool8_t vseteq_vv_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vseteq_vs_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vseteq_vv_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vseteq_vs_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vseteq_vv_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vseteq_vs_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vseteq_vv_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vseteq_vs_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vseteq_vv_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vseteq_vs_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vseteq_vv_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vseteq_vs_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vseteq_vv_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vseteq_vs_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vseteq_vv_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vseteq_vs_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vseteq_vv_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vseteq_vs_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vseteq_vv_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vseteq_vs_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vseteq_vv_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vseteq_vs_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vseteq_vv_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vseteq_vs_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vseteq_vv_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vseteq_vs_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vseteq_vv_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vseteq_vs_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vseteq_vv_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vseteq_vs_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vseteq_vv_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vseteq_vs_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vseteq_vv_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vseteq_vs_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vseteq_vv_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vseteq_vs_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vseteq_vv_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vseteq_vs_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vseteq_vv_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vseteq_vs_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vseteq_vv_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vseteq_vs_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vseteq_vv_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vseteq_vs_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vseteq_vv_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vseteq_vs_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vseteq_vv_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vseteq_vs_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vseteq_vv_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vseteq_vs_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vseteq_vv_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vseteq_vs_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vseteq_vv_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vseteq_vs_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vseteq_vv_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vseteq_vs_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vseteq_vv_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vseteq_vs_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vseteq_vv_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vseteq_vs_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vseteq_vv_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vseteq_vs_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vseteq_vv_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vseteq_vs_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetne_vv_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetne_vs_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetne_vv_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetne_vs_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetne_vv_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetne_vs_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetne_vv_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetne_vs_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetne_vv_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetne_vs_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetne_vv_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetne_vs_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetne_vv_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetne_vs_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetne_vv_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetne_vs_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetne_vv_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetne_vs_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetne_vv_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetne_vs_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetne_vv_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetne_vs_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetne_vv_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetne_vs_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetne_vv_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetne_vs_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetne_vv_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetne_vs_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetne_vv_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetne_vs_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetne_vv_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetne_vs_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetne_vv_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetne_vs_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetne_vv_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetne_vs_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetne_vv_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetne_vs_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetne_vv_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetne_vs_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetne_vv_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetne_vs_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetne_vv_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetne_vs_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetne_vv_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetne_vs_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetne_vv_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetne_vs_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetne_vv_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetne_vs_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetne_vv_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetne_vs_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetne_vv_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetne_vs_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetne_vv_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetne_vs_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetne_vv_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetne_vs_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetne_vv_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetne_vs_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetne_vv_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetne_vs_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetne_vv_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetne_vs_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetlt_vv_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetlt_vs_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetlt_vv_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetlt_vs_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetlt_vv_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetlt_vs_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetlt_vv_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetlt_vs_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetlt_vv_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetlt_vs_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetlt_vv_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetlt_vs_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetlt_vv_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetlt_vs_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetlt_vv_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetlt_vs_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetlt_vv_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetlt_vs_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetlt_vv_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetlt_vs_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetlt_vv_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetlt_vs_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetlt_vv_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetlt_vs_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetlt_vv_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetlt_vs_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetlt_vv_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetlt_vs_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetlt_vv_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetlt_vs_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetlt_vv_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetlt_vs_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetlt_vv_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetlt_vs_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetlt_vv_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetlt_vs_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetlt_vv_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetlt_vs_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetlt_vv_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetlt_vs_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetlt_vv_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetlt_vs_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetlt_vv_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetlt_vs_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetlt_vv_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetlt_vs_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetlt_vv_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetlt_vs_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetlt_vv_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetlt_vs_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetlt_vv_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetlt_vs_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetlt_vv_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetlt_vs_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetlt_vv_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetlt_vs_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetlt_vv_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetlt_vs_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetlt_vv_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetlt_vs_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetlt_vv_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetlt_vs_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetlt_vv_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetlt_vs_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetle_vv_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetle_vs_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetle_vv_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetle_vs_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetle_vv_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetle_vs_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetle_vv_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetle_vs_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetle_vv_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetle_vs_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetle_vv_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetle_vs_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetle_vv_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetle_vs_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetle_vv_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetle_vs_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetle_vv_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetle_vs_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetle_vv_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetle_vs_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetle_vv_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetle_vs_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetle_vv_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetle_vs_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetle_vv_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetle_vs_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetle_vv_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetle_vs_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetle_vv_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetle_vs_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetle_vv_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetle_vs_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetle_vv_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetle_vs_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetle_vv_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetle_vs_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetle_vv_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetle_vs_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetle_vv_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetle_vs_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetle_vv_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetle_vs_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetle_vv_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetle_vs_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetle_vv_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetle_vs_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetle_vv_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetle_vs_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetle_vv_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetle_vs_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetle_vv_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetle_vs_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetle_vv_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetle_vs_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetle_vv_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetle_vs_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetle_vv_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetle_vs_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetle_vv_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetle_vs_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetle_vv_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetle_vs_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetle_vv_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetle_vs_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetgt_vv_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetgt_vs_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetgt_vv_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetgt_vs_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetgt_vv_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetgt_vs_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetgt_vv_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetgt_vs_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetgt_vv_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetgt_vs_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetgt_vv_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetgt_vs_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetgt_vv_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetgt_vs_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetgt_vv_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetgt_vs_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetgt_vv_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetgt_vs_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetgt_vv_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetgt_vs_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetgt_vv_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetgt_vs_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetgt_vv_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetgt_vs_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetgt_vv_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetgt_vs_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetgt_vv_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetgt_vs_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetgt_vv_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetgt_vs_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetgt_vv_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetgt_vs_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetgt_vv_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetgt_vs_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetgt_vv_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetgt_vs_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetgt_vv_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetgt_vs_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetgt_vv_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetgt_vs_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetgt_vv_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetgt_vs_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetgt_vv_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetgt_vs_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetgt_vv_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetgt_vs_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetgt_vv_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetgt_vs_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetgt_vv_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetgt_vs_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetgt_vv_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetgt_vs_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetgt_vv_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetgt_vs_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetgt_vv_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetgt_vs_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetgt_vv_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetgt_vs_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetgt_vv_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetgt_vs_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetgt_vv_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetgt_vs_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetgt_vv_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetgt_vs_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetge_vv_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetge_vs_i8m1_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetge_vv_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetge_vs_i8m2_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetge_vv_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetge_vs_i8m4_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetge_vv_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetge_vs_i8m8_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetge_vv_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetge_vs_i16m1_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetge_vv_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetge_vs_i16m2_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetge_vv_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetge_vs_i16m4_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetge_vv_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetge_vs_i16m8_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetge_vv_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetge_vs_i32m1_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetge_vv_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetge_vs_i32m2_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetge_vv_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetge_vs_i32m4_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetge_vv_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetge_vs_i32m8_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetge_vv_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetge_vs_i64m1_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetge_vv_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetge_vs_i64m2_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetge_vv_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetge_vs_i64m4_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetge_vv_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetge_vs_i64m8_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetge_vv_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetge_vs_u8m1_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetge_vv_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetge_vs_u8m2_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetge_vv_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetge_vs_u8m4_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetge_vv_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetge_vs_u8m8_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetge_vv_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetge_vs_u16m1_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetge_vv_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetge_vs_u16m2_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetge_vv_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetge_vs_u16m4_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetge_vv_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetge_vs_u16m8_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetge_vv_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetge_vs_u32m1_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetge_vv_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetge_vs_u32m2_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetge_vv_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetge_vs_u32m4_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetge_vv_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetge_vs_u32m8_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetge_vv_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetge_vs_u64m1_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetge_vv_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetge_vs_u64m2_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetge_vv_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetge_vs_u64m4_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetge_vv_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetge_vs_u64m8_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Integer Min/Max Functions]()

**Prototypes:**
``` C
vint8m1_t vmin_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmin_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vmin_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmin_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vmin_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmin_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vmin_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmin_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vmin_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmin_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vmin_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmin_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vmin_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmin_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vmin_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmin_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vmin_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmin_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vmin_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmin_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vmin_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmin_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vmin_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmin_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vmin_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmin_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vmin_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmin_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vmin_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmin_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vmin_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmin_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vmin_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmin_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmin_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmin_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmin_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmin_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmin_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmin_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmin_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmin_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmin_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmin_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmin_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmin_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmin_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmin_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmin_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmin_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmin_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmin_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmin_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmin_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmin_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmin_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmin_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmin_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmin_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmin_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmin_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmin_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmin_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmin_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmax_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmax_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vmax_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmax_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vmax_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmax_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vmax_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmax_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vmax_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmax_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vmax_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmax_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vmax_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmax_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vmax_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmax_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vmax_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmax_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vmax_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmax_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vmax_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmax_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vmax_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmax_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vmax_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmax_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vmax_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmax_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vmax_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmax_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vmax_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmax_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vmax_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmax_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmax_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmax_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmax_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmax_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmax_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmax_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmax_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmax_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmax_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmax_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmax_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmax_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmax_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmax_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmax_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmax_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmax_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmax_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmax_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmax_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmax_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmax_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmax_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmax_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmax_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmax_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmax_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmax_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmax_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmax_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vmin_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmin_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmin_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmin_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmin_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmin_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmin_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmin_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmin_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmin_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmin_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmin_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmin_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmin_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmin_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmin_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmin_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmin_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmin_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmin_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmin_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmin_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmin_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmin_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmin_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmin_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmin_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmin_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmin_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmin_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmin_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmin_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmin_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmin_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmin_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmin_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmin_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmin_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmin_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmin_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmin_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmin_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmin_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmin_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmin_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmin_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmin_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmin_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmin_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmin_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmin_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmin_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmin_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmin_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmin_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmin_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmin_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmin_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmin_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmin_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmin_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmin_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmin_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmin_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmax_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmax_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmax_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmax_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmax_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmax_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmax_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmax_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmax_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmax_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmax_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmax_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmax_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmax_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmax_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmax_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmax_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmax_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmax_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmax_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmax_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmax_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmax_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmax_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmax_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmax_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmax_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmax_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmax_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmax_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmax_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmax_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmax_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmax_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmax_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmax_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmax_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmax_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmax_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmax_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmax_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmax_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmax_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmax_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmax_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmax_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmax_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmax_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmax_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmax_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmax_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmax_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmax_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmax_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmax_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmax_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmax_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmax_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmax_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmax_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmax_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmax_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmax_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmax_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Integer Multiply Functions]()

**Prototypes:**
``` C
vint8m1_t vmul_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmul_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vmul_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmul_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vmul_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmul_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vmul_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmul_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vmul_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmul_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vmul_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmul_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vmul_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmul_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vmul_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmul_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vmul_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmul_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vmul_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmul_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vmul_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmul_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vmul_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmul_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vmul_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmul_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vmul_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmul_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vmul_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmul_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vmul_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmul_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vmul_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmul_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmul_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmul_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmul_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmul_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmul_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmul_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmul_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmul_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmul_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmul_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmul_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmul_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmul_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmul_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmul_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmul_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmul_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmul_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmul_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmul_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmul_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmul_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmul_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmul_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmul_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmul_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmul_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmul_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmul_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmul_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulh_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmulh_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vmulh_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmulh_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vmulh_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmulh_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vmulh_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmulh_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vmulh_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmulh_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vmulh_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmulh_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vmulh_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmulh_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vmulh_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmulh_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vmulh_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmulh_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vmulh_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmulh_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vmulh_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmulh_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vmulh_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmulh_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vmulh_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmulh_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vmulh_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmulh_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vmulh_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmulh_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vmulh_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmulh_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vmulh_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmulh_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmulh_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmulh_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmulh_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmulh_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmulh_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmulh_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmulh_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmulh_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmulh_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmulh_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmulh_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmulh_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmulh_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmulh_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmulh_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmulh_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmulh_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmulh_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmulh_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmulh_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmulh_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmulh_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmulh_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmulh_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmulh_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmulh_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmulh_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmulh_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmulh_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmulh_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulhsu_vv_i8m1 (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmulhsu_vs_i8m1 (vint8m1_t op1, uint8_t op2);
vint8m2_t vmulhsu_vv_i8m2 (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmulhsu_vs_i8m2 (vint8m2_t op1, uint8_t op2);
vint8m4_t vmulhsu_vv_i8m4 (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmulhsu_vs_i8m4 (vint8m4_t op1, uint8_t op2);
vint8m8_t vmulhsu_vv_i8m8 (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmulhsu_vs_i8m8 (vint8m8_t op1, uint8_t op2);
vint16m1_t vmulhsu_vv_i16m1 (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmulhsu_vs_i16m1 (vint16m1_t op1, uint16_t op2);
vint16m2_t vmulhsu_vv_i16m2 (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmulhsu_vs_i16m2 (vint16m2_t op1, uint16_t op2);
vint16m4_t vmulhsu_vv_i16m4 (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmulhsu_vs_i16m4 (vint16m4_t op1, uint16_t op2);
vint16m8_t vmulhsu_vv_i16m8 (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmulhsu_vs_i16m8 (vint16m8_t op1, uint16_t op2);
vint32m1_t vmulhsu_vv_i32m1 (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmulhsu_vs_i32m1 (vint32m1_t op1, uint32_t op2);
vint32m2_t vmulhsu_vv_i32m2 (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmulhsu_vs_i32m2 (vint32m2_t op1, uint32_t op2);
vint32m4_t vmulhsu_vv_i32m4 (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmulhsu_vs_i32m4 (vint32m4_t op1, uint32_t op2);
vint32m8_t vmulhsu_vv_i32m8 (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmulhsu_vs_i32m8 (vint32m8_t op1, uint32_t op2);
vint64m1_t vmulhsu_vv_i64m1 (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmulhsu_vs_i64m1 (vint64m1_t op1, uint64_t op2);
vint64m2_t vmulhsu_vv_i64m2 (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmulhsu_vs_i64m2 (vint64m2_t op1, uint64_t op2);
vint64m4_t vmulhsu_vv_i64m4 (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmulhsu_vs_i64m4 (vint64m4_t op1, uint64_t op2);
vint64m8_t vmulhsu_vv_i64m8 (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmulhsu_vs_i64m8 (vint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vmul_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmul_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmul_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmul_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmul_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmul_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmul_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmul_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmul_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmul_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmul_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmul_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmul_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmul_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmul_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmul_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmul_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmul_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmul_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmul_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmul_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmul_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmul_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmul_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmul_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmul_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmul_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmul_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmul_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmul_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmul_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmul_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmul_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmul_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmul_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmul_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmul_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmul_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmul_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmul_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmul_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmul_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmul_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmul_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmul_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmul_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmul_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmul_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmul_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmul_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmul_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmul_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmul_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmul_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmul_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmul_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmul_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmul_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmul_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmul_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmul_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmul_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmul_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmul_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulh_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmulh_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmulh_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmulh_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmulh_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmulh_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmulh_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmulh_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmulh_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmulh_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmulh_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmulh_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmulh_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmulh_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmulh_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmulh_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmulh_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmulh_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmulh_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmulh_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmulh_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmulh_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmulh_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmulh_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmulh_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmulh_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmulh_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmulh_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmulh_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmulh_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmulh_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmulh_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmulh_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmulh_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmulh_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmulh_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmulh_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmulh_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmulh_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmulh_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmulh_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmulh_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmulh_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmulh_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmulh_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmulh_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmulh_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmulh_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmulh_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmulh_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmulh_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmulh_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmulh_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmulh_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmulh_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmulh_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmulh_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmulh_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmulh_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmulh_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmulh_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmulh_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmulh_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmulh_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulhsu_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmulhsu_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vmulhsu_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmulhsu_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vmulhsu_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmulhsu_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vmulhsu_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmulhsu_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vmulhsu_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmulhsu_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2);
vint16m2_t vmulhsu_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmulhsu_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2);
vint16m4_t vmulhsu_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmulhsu_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2);
vint16m8_t vmulhsu_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmulhsu_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2);
vint32m1_t vmulhsu_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmulhsu_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2);
vint32m2_t vmulhsu_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmulhsu_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2);
vint32m4_t vmulhsu_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmulhsu_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2);
vint32m8_t vmulhsu_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmulhsu_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2);
vint64m1_t vmulhsu_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmulhsu_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2);
vint64m2_t vmulhsu_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmulhsu_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2);
vint64m4_t vmulhsu_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmulhsu_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2);
vint64m8_t vmulhsu_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmulhsu_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2);
```
### [Vector Integer Divide Functions]()

**Prototypes:**
``` C
vint8m1_t vdiv_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vdiv_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vdiv_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vdiv_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vdiv_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vdiv_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vdiv_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vdiv_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vdiv_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vdiv_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vdiv_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vdiv_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vdiv_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vdiv_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vdiv_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vdiv_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vdiv_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vdiv_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vdiv_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vdiv_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vdiv_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vdiv_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vdiv_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vdiv_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vdiv_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vdiv_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vdiv_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vdiv_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vdiv_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vdiv_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vdiv_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vdiv_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vdiv_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vdiv_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vdiv_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vdiv_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vdiv_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vdiv_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vdiv_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vdiv_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vdiv_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vdiv_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vdiv_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vdiv_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vdiv_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vdiv_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vdiv_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vdiv_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vdiv_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vdiv_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vdiv_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vdiv_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vdiv_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vdiv_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vdiv_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vdiv_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vdiv_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vdiv_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vdiv_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vdiv_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vdiv_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vdiv_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vdiv_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vdiv_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vint8m1_t vrem_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vrem_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vrem_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vrem_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vrem_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vrem_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vrem_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vrem_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vrem_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vrem_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vrem_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vrem_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vrem_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vrem_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vrem_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vrem_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vrem_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vrem_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vrem_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vrem_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vrem_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vrem_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vrem_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vrem_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vrem_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vrem_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vrem_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vrem_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vrem_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vrem_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vrem_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vrem_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vrem_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrem_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrem_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrem_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrem_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrem_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrem_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrem_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrem_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrem_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrem_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrem_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrem_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrem_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrem_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrem_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrem_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrem_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrem_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrem_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrem_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrem_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrem_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrem_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrem_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrem_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrem_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrem_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrem_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrem_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrem_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrem_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vdiv_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vdiv_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vdiv_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vdiv_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vdiv_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vdiv_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vdiv_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vdiv_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vdiv_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vdiv_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vdiv_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vdiv_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vdiv_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vdiv_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vdiv_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vdiv_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vdiv_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vdiv_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vdiv_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vdiv_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vdiv_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vdiv_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vdiv_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vdiv_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vdiv_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vdiv_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vdiv_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vdiv_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vdiv_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vdiv_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vdiv_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vdiv_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vdiv_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vdiv_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vdiv_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vdiv_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vdiv_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vdiv_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vdiv_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vdiv_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vdiv_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vdiv_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vdiv_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vdiv_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vdiv_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vdiv_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vdiv_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vdiv_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vdiv_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vdiv_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vdiv_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vdiv_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vdiv_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vdiv_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vdiv_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vdiv_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vdiv_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vdiv_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vdiv_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vdiv_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vdiv_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vdiv_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vdiv_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vdiv_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vrem_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vrem_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vrem_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vrem_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vrem_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vrem_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vrem_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vrem_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vrem_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vrem_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vrem_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vrem_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vrem_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vrem_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vrem_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vrem_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vrem_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vrem_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vrem_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vrem_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vrem_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vrem_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vrem_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vrem_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vrem_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vrem_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vrem_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vrem_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vrem_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vrem_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vrem_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vrem_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vrem_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrem_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrem_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrem_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrem_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrem_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrem_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrem_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrem_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrem_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrem_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrem_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrem_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrem_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrem_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrem_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrem_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrem_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrem_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrem_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrem_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrem_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrem_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrem_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrem_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrem_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrem_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrem_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrem_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrem_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrem_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrem_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Widening Integer Multiply Functions]()

**Prototypes:**
``` C
vint16m2_t vwmul_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmul_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint16m4_t vwmul_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmul_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint16m8_t vwmul_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmul_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint32m2_t vwmul_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmul_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint32m4_t vwmul_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmul_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint32m8_t vwmul_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmul_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint64m2_t vwmul_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmul_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint64m4_t vwmul_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmul_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint64m8_t vwmul_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmul_vs_i32m4 (vint32m4_t op1, int32_t op2);
vuint16m2_t vwmul_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmul_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint16m4_t vwmul_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmul_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint16m8_t vwmul_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmul_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint32m2_t vwmul_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmul_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint32m4_t vwmul_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmul_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint32m8_t vwmul_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmul_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint64m2_t vwmul_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmul_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint64m4_t vwmul_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmul_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint64m8_t vwmul_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmul_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vint16m2_t vwmulsu_vv_i8m1 (vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmulsu_vs_i8m1 (vint8m1_t op1, uint8_t op2);
vint16m4_t vwmulsu_vv_i8m2 (vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmulsu_vs_i8m2 (vint8m2_t op1, uint8_t op2);
vint16m8_t vwmulsu_vv_i8m4 (vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmulsu_vs_i8m4 (vint8m4_t op1, uint8_t op2);
vint32m2_t vwmulsu_vv_i16m1 (vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmulsu_vs_i16m1 (vint16m1_t op1, uint16_t op2);
vint32m4_t vwmulsu_vv_i16m2 (vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmulsu_vs_i16m2 (vint16m2_t op1, uint16_t op2);
vint32m8_t vwmulsu_vv_i16m4 (vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmulsu_vs_i16m4 (vint16m4_t op1, uint16_t op2);
vint64m2_t vwmulsu_vv_i32m1 (vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmulsu_vs_i32m1 (vint32m1_t op1, uint32_t op2);
vint64m4_t vwmulsu_vv_i32m2 (vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmulsu_vs_i32m2 (vint32m2_t op1, uint32_t op2);
vint64m8_t vwmulsu_vv_i32m4 (vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmulsu_vs_i32m4 (vint32m4_t op1, uint32_t op2);
// masked functions
vint16m2_t vwmul_vv_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmul_vs_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m4_t vwmul_vv_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmul_vs_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m8_t vwmul_vv_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmul_vs_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint32m2_t vwmul_vv_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmul_vs_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m4_t vwmul_vv_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmul_vs_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m8_t vwmul_vv_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmul_vs_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint64m2_t vwmul_vv_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmul_vs_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m4_t vwmul_vv_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmul_vs_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m8_t vwmul_vv_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmul_vs_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vuint16m2_t vwmul_vv_u8m1_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmul_vs_u8m1_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m4_t vwmul_vv_u8m2_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmul_vs_u8m2_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m8_t vwmul_vv_u8m4_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmul_vs_u8m4_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint32m2_t vwmul_vv_u16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmul_vs_u16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m4_t vwmul_vv_u16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmul_vs_u16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m8_t vwmul_vv_u16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmul_vs_u16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint64m2_t vwmul_vv_u32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmul_vs_u32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m4_t vwmul_vv_u32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmul_vs_u32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m8_t vwmul_vv_u32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmul_vs_u32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vint16m2_t vwmulsu_vv_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmulsu_vs_i8m1_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, uint8_t op2);
vint16m4_t vwmulsu_vv_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmulsu_vs_i8m2_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, uint8_t op2);
vint16m8_t vwmulsu_vv_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmulsu_vs_i8m4_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, uint8_t op2);
vint32m2_t vwmulsu_vv_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmulsu_vs_i16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, uint16_t op2);
vint32m4_t vwmulsu_vv_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmulsu_vs_i16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, uint16_t op2);
vint32m8_t vwmulsu_vv_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmulsu_vs_i16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, uint16_t op2);
vint64m2_t vwmulsu_vv_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmulsu_vs_i32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, uint32_t op2);
vint64m4_t vwmulsu_vv_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmulsu_vs_i32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, uint32_t op2);
vint64m8_t vwmulsu_vv_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmulsu_vs_i32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, uint32_t op2);
```
### [Vector Single-Width Integer Multiply-Add Functions]()

**Prototypes:**
``` C
vint8m1_t vmacc_vv_i8m1 (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmacc_sv_i8m1 (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmacc_vv_i8m2 (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmacc_sv_i8m2 (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmacc_vv_i8m4 (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmacc_sv_i8m4 (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmacc_vv_i8m8 (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmacc_sv_i8m8 (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmacc_vv_i16m1 (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmacc_sv_i16m1 (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmacc_vv_i16m2 (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmacc_sv_i16m2 (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmacc_vv_i16m4 (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmacc_sv_i16m4 (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmacc_vv_i16m8 (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmacc_sv_i16m8 (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmacc_vv_i32m1 (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmacc_sv_i32m1 (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmacc_vv_i32m2 (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmacc_sv_i32m2 (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmacc_vv_i32m4 (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmacc_sv_i32m4 (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmacc_vv_i32m8 (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmacc_sv_i32m8 (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmacc_vv_i64m1 (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmacc_sv_i64m1 (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmacc_vv_i64m2 (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmacc_sv_i64m2 (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmacc_vv_i64m4 (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmacc_sv_i64m4 (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmacc_vv_i64m8 (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmacc_sv_i64m8 (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmacc_vv_u8m1 (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmacc_sv_u8m1 (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmacc_vv_u8m2 (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmacc_sv_u8m2 (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmacc_vv_u8m4 (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmacc_sv_u8m4 (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmacc_vv_u8m8 (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmacc_sv_u8m8 (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmacc_vv_u16m1 (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmacc_sv_u16m1 (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmacc_vv_u16m2 (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmacc_sv_u16m2 (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmacc_vv_u16m4 (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmacc_sv_u16m4 (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmacc_vv_u16m8 (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmacc_sv_u16m8 (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmacc_vv_u32m1 (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmacc_sv_u32m1 (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmacc_vv_u32m2 (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmacc_sv_u32m2 (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmacc_vv_u32m4 (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmacc_sv_u32m4 (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmacc_vv_u32m8 (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmacc_sv_u32m8 (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmacc_vv_u64m1 (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmacc_sv_u64m1 (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmacc_vv_u64m2 (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmacc_sv_u64m2 (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmacc_vv_u64m4 (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmacc_sv_u64m4 (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmacc_vv_u64m8 (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmacc_sv_u64m8 (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsac_vv_i8m1 (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsac_sv_i8m1 (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsac_vv_i8m2 (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsac_sv_i8m2 (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsac_vv_i8m4 (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsac_sv_i8m4 (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsac_vv_i8m8 (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsac_sv_i8m8 (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsac_vv_i16m1 (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsac_sv_i16m1 (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsac_vv_i16m2 (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsac_sv_i16m2 (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsac_vv_i16m4 (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsac_sv_i16m4 (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsac_vv_i16m8 (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsac_sv_i16m8 (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsac_vv_i32m1 (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsac_sv_i32m1 (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsac_vv_i32m2 (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsac_sv_i32m2 (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsac_vv_i32m4 (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsac_sv_i32m4 (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsac_vv_i32m8 (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsac_sv_i32m8 (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsac_vv_i64m1 (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsac_sv_i64m1 (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsac_vv_i64m2 (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsac_sv_i64m2 (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsac_vv_i64m4 (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsac_sv_i64m4 (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsac_vv_i64m8 (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsac_sv_i64m8 (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsac_vv_u8m1 (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsac_sv_u8m1 (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsac_vv_u8m2 (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsac_sv_u8m2 (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsac_vv_u8m4 (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsac_sv_u8m4 (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsac_vv_u8m8 (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsac_sv_u8m8 (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsac_vv_u16m1 (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsac_sv_u16m1 (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsac_vv_u16m2 (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsac_sv_u16m2 (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsac_vv_u16m4 (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsac_sv_u16m4 (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsac_vv_u16m8 (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsac_sv_u16m8 (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsac_vv_u32m1 (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsac_sv_u32m1 (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsac_vv_u32m2 (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsac_sv_u32m2 (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsac_vv_u32m4 (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsac_sv_u32m4 (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsac_vv_u32m8 (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsac_sv_u32m8 (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsac_vv_u64m1 (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsac_sv_u64m1 (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsac_vv_u64m2 (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsac_sv_u64m2 (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsac_vv_u64m4 (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsac_sv_u64m4 (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsac_vv_u64m8 (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsac_sv_u64m8 (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vmadd_vv_i8m1 (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmadd_sv_i8m1 (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmadd_vv_i8m2 (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmadd_sv_i8m2 (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmadd_vv_i8m4 (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmadd_sv_i8m4 (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmadd_vv_i8m8 (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmadd_sv_i8m8 (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmadd_vv_i16m1 (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmadd_sv_i16m1 (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmadd_vv_i16m2 (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmadd_sv_i16m2 (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmadd_vv_i16m4 (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmadd_sv_i16m4 (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmadd_vv_i16m8 (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmadd_sv_i16m8 (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmadd_vv_i32m1 (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmadd_sv_i32m1 (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmadd_vv_i32m2 (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmadd_sv_i32m2 (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmadd_vv_i32m4 (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmadd_sv_i32m4 (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmadd_vv_i32m8 (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmadd_sv_i32m8 (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmadd_vv_i64m1 (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmadd_sv_i64m1 (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmadd_vv_i64m2 (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmadd_sv_i64m2 (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmadd_vv_i64m4 (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmadd_sv_i64m4 (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmadd_vv_i64m8 (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmadd_sv_i64m8 (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmadd_vv_u8m1 (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmadd_sv_u8m1 (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmadd_vv_u8m2 (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmadd_sv_u8m2 (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmadd_vv_u8m4 (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmadd_sv_u8m4 (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmadd_vv_u8m8 (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmadd_sv_u8m8 (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmadd_vv_u16m1 (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmadd_sv_u16m1 (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmadd_vv_u16m2 (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmadd_sv_u16m2 (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmadd_vv_u16m4 (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmadd_sv_u16m4 (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmadd_vv_u16m8 (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmadd_sv_u16m8 (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmadd_vv_u32m1 (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmadd_sv_u32m1 (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmadd_vv_u32m2 (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmadd_sv_u32m2 (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmadd_vv_u32m4 (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmadd_sv_u32m4 (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmadd_vv_u32m8 (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmadd_sv_u32m8 (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmadd_vv_u64m1 (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmadd_sv_u64m1 (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmadd_vv_u64m2 (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmadd_sv_u64m2 (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmadd_vv_u64m4 (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmadd_sv_u64m4 (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmadd_vv_u64m8 (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmadd_sv_u64m8 (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsub_vv_i8m1 (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsub_sv_i8m1 (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsub_vv_i8m2 (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsub_sv_i8m2 (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsub_vv_i8m4 (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsub_sv_i8m4 (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsub_vv_i8m8 (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsub_sv_i8m8 (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsub_vv_i16m1 (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsub_sv_i16m1 (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsub_vv_i16m2 (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsub_sv_i16m2 (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsub_vv_i16m4 (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsub_sv_i16m4 (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsub_vv_i16m8 (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsub_sv_i16m8 (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsub_vv_i32m1 (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsub_sv_i32m1 (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsub_vv_i32m2 (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsub_sv_i32m2 (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsub_vv_i32m4 (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsub_sv_i32m4 (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsub_vv_i32m8 (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsub_sv_i32m8 (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsub_vv_i64m1 (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsub_sv_i64m1 (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsub_vv_i64m2 (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsub_sv_i64m2 (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsub_vv_i64m4 (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsub_sv_i64m4 (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsub_vv_i64m8 (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsub_sv_i64m8 (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsub_vv_u8m1 (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsub_sv_u8m1 (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsub_vv_u8m2 (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsub_sv_u8m2 (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsub_vv_u8m4 (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsub_sv_u8m4 (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsub_vv_u8m8 (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsub_sv_u8m8 (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsub_vv_u16m1 (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsub_sv_u16m1 (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsub_vv_u16m2 (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsub_sv_u16m2 (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsub_vv_u16m4 (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsub_sv_u16m4 (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsub_vv_u16m8 (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsub_sv_u16m8 (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsub_vv_u32m1 (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsub_sv_u32m1 (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsub_vv_u32m2 (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsub_sv_u32m2 (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsub_vv_u32m4 (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsub_sv_u32m4 (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsub_vv_u32m8 (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsub_sv_u32m8 (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsub_vv_u64m1 (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsub_sv_u64m1 (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsub_vv_u64m2 (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsub_sv_u64m2 (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsub_vv_u64m4 (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsub_sv_u64m4 (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsub_vv_u64m8 (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsub_sv_u64m8 (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
// masked functions
vint8m1_t vmacc_vv_i8m1_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmacc_sv_i8m1_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmacc_vv_i8m2_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmacc_sv_i8m2_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmacc_vv_i8m4_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmacc_sv_i8m4_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmacc_vv_i8m8_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmacc_sv_i8m8_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmacc_vv_i16m1_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmacc_sv_i16m1_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmacc_vv_i16m2_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmacc_sv_i16m2_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmacc_vv_i16m4_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmacc_sv_i16m4_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmacc_vv_i16m8_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmacc_sv_i16m8_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmacc_vv_i32m1_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmacc_sv_i32m1_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmacc_vv_i32m2_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmacc_sv_i32m2_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmacc_vv_i32m4_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmacc_sv_i32m4_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmacc_vv_i32m8_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmacc_sv_i32m8_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmacc_vv_i64m1_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmacc_sv_i64m1_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmacc_vv_i64m2_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmacc_sv_i64m2_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmacc_vv_i64m4_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmacc_sv_i64m4_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmacc_vv_i64m8_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmacc_sv_i64m8_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmacc_vv_u8m1_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmacc_sv_u8m1_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmacc_vv_u8m2_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmacc_sv_u8m2_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmacc_vv_u8m4_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmacc_sv_u8m4_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmacc_vv_u8m8_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmacc_sv_u8m8_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmacc_vv_u16m1_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmacc_sv_u16m1_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmacc_vv_u16m2_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmacc_sv_u16m2_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmacc_vv_u16m4_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmacc_sv_u16m4_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmacc_vv_u16m8_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmacc_sv_u16m8_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmacc_vv_u32m1_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmacc_sv_u32m1_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmacc_vv_u32m2_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmacc_sv_u32m2_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmacc_vv_u32m4_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmacc_sv_u32m4_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmacc_vv_u32m8_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmacc_sv_u32m8_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmacc_vv_u64m1_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmacc_sv_u64m1_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmacc_vv_u64m2_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmacc_sv_u64m2_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmacc_vv_u64m4_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmacc_sv_u64m4_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmacc_vv_u64m8_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmacc_sv_u64m8_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsac_vv_i8m1_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsac_sv_i8m1_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsac_vv_i8m2_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsac_sv_i8m2_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsac_vv_i8m4_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsac_sv_i8m4_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsac_vv_i8m8_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsac_sv_i8m8_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsac_vv_i16m1_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsac_sv_i16m1_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsac_vv_i16m2_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsac_sv_i16m2_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsac_vv_i16m4_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsac_sv_i16m4_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsac_vv_i16m8_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsac_sv_i16m8_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsac_vv_i32m1_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsac_sv_i32m1_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsac_vv_i32m2_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsac_sv_i32m2_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsac_vv_i32m4_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsac_sv_i32m4_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsac_vv_i32m8_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsac_sv_i32m8_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsac_vv_i64m1_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsac_sv_i64m1_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsac_vv_i64m2_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsac_sv_i64m2_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsac_vv_i64m4_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsac_sv_i64m4_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsac_vv_i64m8_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsac_sv_i64m8_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsac_vv_u8m1_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsac_sv_u8m1_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsac_vv_u8m2_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsac_sv_u8m2_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsac_vv_u8m4_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsac_sv_u8m4_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsac_vv_u8m8_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsac_sv_u8m8_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsac_vv_u16m1_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsac_sv_u16m1_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsac_vv_u16m2_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsac_sv_u16m2_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsac_vv_u16m4_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsac_sv_u16m4_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsac_vv_u16m8_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsac_sv_u16m8_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsac_vv_u32m1_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsac_sv_u32m1_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsac_vv_u32m2_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsac_sv_u32m2_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsac_vv_u32m4_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsac_sv_u32m4_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsac_vv_u32m8_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsac_sv_u32m8_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsac_vv_u64m1_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsac_sv_u64m1_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsac_vv_u64m2_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsac_sv_u64m2_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsac_vv_u64m4_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsac_sv_u64m4_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsac_vv_u64m8_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsac_sv_u64m8_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vmadd_vv_i8m1_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmadd_sv_i8m1_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmadd_vv_i8m2_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmadd_sv_i8m2_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmadd_vv_i8m4_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmadd_sv_i8m4_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmadd_vv_i8m8_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmadd_sv_i8m8_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmadd_vv_i16m1_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmadd_sv_i16m1_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmadd_vv_i16m2_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmadd_sv_i16m2_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmadd_vv_i16m4_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmadd_sv_i16m4_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmadd_vv_i16m8_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmadd_sv_i16m8_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmadd_vv_i32m1_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmadd_sv_i32m1_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmadd_vv_i32m2_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmadd_sv_i32m2_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmadd_vv_i32m4_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmadd_sv_i32m4_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmadd_vv_i32m8_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmadd_sv_i32m8_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmadd_vv_i64m1_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmadd_sv_i64m1_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmadd_vv_i64m2_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmadd_sv_i64m2_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmadd_vv_i64m4_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmadd_sv_i64m4_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmadd_vv_i64m8_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmadd_sv_i64m8_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmadd_vv_u8m1_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmadd_sv_u8m1_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmadd_vv_u8m2_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmadd_sv_u8m2_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmadd_vv_u8m4_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmadd_sv_u8m4_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmadd_vv_u8m8_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmadd_sv_u8m8_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmadd_vv_u16m1_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmadd_sv_u16m1_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmadd_vv_u16m2_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmadd_sv_u16m2_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmadd_vv_u16m4_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmadd_sv_u16m4_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmadd_vv_u16m8_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmadd_sv_u16m8_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmadd_vv_u32m1_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmadd_sv_u32m1_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmadd_vv_u32m2_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmadd_sv_u32m2_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmadd_vv_u32m4_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmadd_sv_u32m4_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmadd_vv_u32m8_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmadd_sv_u32m8_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmadd_vv_u64m1_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmadd_sv_u64m1_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmadd_vv_u64m2_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmadd_sv_u64m2_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmadd_vv_u64m4_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmadd_sv_u64m4_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmadd_vv_u64m8_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmadd_sv_u64m8_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsub_vv_i8m1_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsub_sv_i8m1_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsub_vv_i8m2_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsub_sv_i8m2_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsub_vv_i8m4_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsub_sv_i8m4_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsub_vv_i8m8_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsub_sv_i8m8_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsub_vv_i16m1_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsub_sv_i16m1_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsub_vv_i16m2_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsub_sv_i16m2_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsub_vv_i16m4_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsub_sv_i16m4_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsub_vv_i16m8_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsub_sv_i16m8_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsub_vv_i32m1_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsub_sv_i32m1_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsub_vv_i32m2_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsub_sv_i32m2_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsub_vv_i32m4_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsub_sv_i32m4_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsub_vv_i32m8_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsub_sv_i32m8_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsub_vv_i64m1_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsub_sv_i64m1_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsub_vv_i64m2_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsub_sv_i64m2_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsub_vv_i64m4_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsub_sv_i64m4_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsub_vv_i64m8_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsub_sv_i64m8_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsub_vv_u8m1_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsub_sv_u8m1_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsub_vv_u8m2_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsub_sv_u8m2_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsub_vv_u8m4_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsub_sv_u8m4_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsub_vv_u8m8_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsub_sv_u8m8_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsub_vv_u16m1_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsub_sv_u16m1_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsub_vv_u16m2_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsub_sv_u16m2_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsub_vv_u16m4_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsub_sv_u16m4_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsub_vv_u16m8_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsub_sv_u16m8_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsub_vv_u32m1_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsub_sv_u32m1_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsub_vv_u32m2_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsub_sv_u32m2_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsub_vv_u32m4_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsub_sv_u32m4_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsub_vv_u32m8_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsub_sv_u32m8_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsub_vv_u64m1_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsub_sv_u64m1_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsub_vv_u64m2_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsub_sv_u64m2_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsub_vv_u64m4_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsub_sv_u64m4_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsub_vv_u64m8_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsub_sv_u64m8_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
```
### [Vector Widening Integer Multiply-Add Functions]()

**Prototypes:**
``` C
vint16m2_t vwmacc_vv_i8m1 (vint16m2_t acc, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmacc_sv_i8m1 (vint16m2_t acc, int8_t op1, vint8m1_t op2);
vint16m4_t vwmacc_vv_i8m2 (vint16m4_t acc, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmacc_sv_i8m2 (vint16m4_t acc, int8_t op1, vint8m2_t op2);
vint16m8_t vwmacc_vv_i8m4 (vint16m8_t acc, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmacc_sv_i8m4 (vint16m8_t acc, int8_t op1, vint8m4_t op2);
vint32m2_t vwmacc_vv_i16m1 (vint32m2_t acc, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmacc_sv_i16m1 (vint32m2_t acc, int16_t op1, vint16m1_t op2);
vint32m4_t vwmacc_vv_i16m2 (vint32m4_t acc, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmacc_sv_i16m2 (vint32m4_t acc, int16_t op1, vint16m2_t op2);
vint32m8_t vwmacc_vv_i16m4 (vint32m8_t acc, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmacc_sv_i16m4 (vint32m8_t acc, int16_t op1, vint16m4_t op2);
vint64m2_t vwmacc_vv_i32m1 (vint64m2_t acc, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmacc_sv_i32m1 (vint64m2_t acc, int32_t op1, vint32m1_t op2);
vint64m4_t vwmacc_vv_i32m2 (vint64m4_t acc, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmacc_sv_i32m2 (vint64m4_t acc, int32_t op1, vint32m2_t op2);
vint64m8_t vwmacc_vv_i32m4 (vint64m8_t acc, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmacc_sv_i32m4 (vint64m8_t acc, int32_t op1, vint32m4_t op2);
vuint16m2_t vwmacc_vv_u8m1 (vuint16m2_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmacc_sv_u8m1 (vuint16m2_t acc, uint8_t op1, vuint8m1_t op2);
vuint16m4_t vwmacc_vv_u8m2 (vuint16m4_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmacc_sv_u8m2 (vuint16m4_t acc, uint8_t op1, vuint8m2_t op2);
vuint16m8_t vwmacc_vv_u8m4 (vuint16m8_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmacc_sv_u8m4 (vuint16m8_t acc, uint8_t op1, vuint8m4_t op2);
vuint32m2_t vwmacc_vv_u16m1 (vuint32m2_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmacc_sv_u16m1 (vuint32m2_t acc, uint16_t op1, vuint16m1_t op2);
vuint32m4_t vwmacc_vv_u16m2 (vuint32m4_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmacc_sv_u16m2 (vuint32m4_t acc, uint16_t op1, vuint16m2_t op2);
vuint32m8_t vwmacc_vv_u16m4 (vuint32m8_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmacc_sv_u16m4 (vuint32m8_t acc, uint16_t op1, vuint16m4_t op2);
vuint64m2_t vwmacc_vv_u32m1 (vuint64m2_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmacc_sv_u32m1 (vuint64m2_t acc, uint32_t op1, vuint32m1_t op2);
vuint64m4_t vwmacc_vv_u32m2 (vuint64m4_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmacc_sv_u32m2 (vuint64m4_t acc, uint32_t op1, vuint32m2_t op2);
vuint64m8_t vwmacc_vv_u32m4 (vuint64m8_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmacc_sv_u32m4 (vuint64m8_t acc, uint32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccsu_vv_i8m1 (vint16m2_t acc, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmaccsu_sv_i8m1 (vint16m2_t acc, int8_t op1, vuint8m1_t op2);
vint16m4_t vwmaccsu_vv_i8m2 (vint16m4_t acc, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmaccsu_sv_i8m2 (vint16m4_t acc, int8_t op1, vuint8m2_t op2);
vint16m8_t vwmaccsu_vv_i8m4 (vint16m8_t acc, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmaccsu_sv_i8m4 (vint16m8_t acc, int8_t op1, vuint8m4_t op2);
vint32m2_t vwmaccsu_vv_i16m1 (vint32m2_t acc, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmaccsu_sv_i16m1 (vint32m2_t acc, int16_t op1, vuint16m1_t op2);
vint32m4_t vwmaccsu_vv_i16m2 (vint32m4_t acc, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmaccsu_sv_i16m2 (vint32m4_t acc, int16_t op1, vuint16m2_t op2);
vint32m8_t vwmaccsu_vv_i16m4 (vint32m8_t acc, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmaccsu_sv_i16m4 (vint32m8_t acc, int16_t op1, vuint16m4_t op2);
vint64m2_t vwmaccsu_vv_i32m1 (vint64m2_t acc, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmaccsu_sv_i32m1 (vint64m2_t acc, int32_t op1, vuint32m1_t op2);
vint64m4_t vwmaccsu_vv_i32m2 (vint64m4_t acc, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmaccsu_sv_i32m2 (vint64m4_t acc, int32_t op1, vuint32m2_t op2);
vint64m8_t vwmaccsu_vv_i32m4 (vint64m8_t acc, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmaccsu_sv_i32m4 (vint64m8_t acc, int32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccus_sv_i8m1 (vint16m2_t acc, uint8_t op1, vint8m1_t op2);
vint16m4_t vwmaccus_sv_i8m2 (vint16m4_t acc, uint8_t op1, vint8m2_t op2);
vint16m8_t vwmaccus_sv_i8m4 (vint16m8_t acc, uint8_t op1, vint8m4_t op2);
vint32m2_t vwmaccus_sv_i16m1 (vint32m2_t acc, uint16_t op1, vint16m1_t op2);
vint32m4_t vwmaccus_sv_i16m2 (vint32m4_t acc, uint16_t op1, vint16m2_t op2);
vint32m8_t vwmaccus_sv_i16m4 (vint32m8_t acc, uint16_t op1, vint16m4_t op2);
vint64m2_t vwmaccus_sv_i32m1 (vint64m2_t acc, uint32_t op1, vint32m1_t op2);
vint64m4_t vwmaccus_sv_i32m2 (vint64m4_t acc, uint32_t op1, vint32m2_t op2);
vint64m8_t vwmaccus_sv_i32m4 (vint64m8_t acc, uint32_t op1, vint32m4_t op2);
// masked functions
vint16m2_t vwmacc_vv_i8m1_mask (vbool8_t mask, vint16m2_t acc, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmacc_sv_i8m1_mask (vbool8_t mask, vint16m2_t acc, int8_t op1, vint8m1_t op2);
vint16m4_t vwmacc_vv_i8m2_mask (vbool4_t mask, vint16m4_t acc, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmacc_sv_i8m2_mask (vbool4_t mask, vint16m4_t acc, int8_t op1, vint8m2_t op2);
vint16m8_t vwmacc_vv_i8m4_mask (vbool2_t mask, vint16m8_t acc, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmacc_sv_i8m4_mask (vbool2_t mask, vint16m8_t acc, int8_t op1, vint8m4_t op2);
vint32m2_t vwmacc_vv_i16m1_mask (vbool16_t mask, vint32m2_t acc, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmacc_sv_i16m1_mask (vbool16_t mask, vint32m2_t acc, int16_t op1, vint16m1_t op2);
vint32m4_t vwmacc_vv_i16m2_mask (vbool8_t mask, vint32m4_t acc, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmacc_sv_i16m2_mask (vbool8_t mask, vint32m4_t acc, int16_t op1, vint16m2_t op2);
vint32m8_t vwmacc_vv_i16m4_mask (vbool4_t mask, vint32m8_t acc, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmacc_sv_i16m4_mask (vbool4_t mask, vint32m8_t acc, int16_t op1, vint16m4_t op2);
vint64m2_t vwmacc_vv_i32m1_mask (vbool32_t mask, vint64m2_t acc, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmacc_sv_i32m1_mask (vbool32_t mask, vint64m2_t acc, int32_t op1, vint32m1_t op2);
vint64m4_t vwmacc_vv_i32m2_mask (vbool16_t mask, vint64m4_t acc, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmacc_sv_i32m2_mask (vbool16_t mask, vint64m4_t acc, int32_t op1, vint32m2_t op2);
vint64m8_t vwmacc_vv_i32m4_mask (vbool8_t mask, vint64m8_t acc, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmacc_sv_i32m4_mask (vbool8_t mask, vint64m8_t acc, int32_t op1, vint32m4_t op2);
vuint16m2_t vwmacc_vv_u8m1_mask (vbool8_t mask, vuint16m2_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmacc_sv_u8m1_mask (vbool8_t mask, vuint16m2_t acc, uint8_t op1, vuint8m1_t op2);
vuint16m4_t vwmacc_vv_u8m2_mask (vbool4_t mask, vuint16m4_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmacc_sv_u8m2_mask (vbool4_t mask, vuint16m4_t acc, uint8_t op1, vuint8m2_t op2);
vuint16m8_t vwmacc_vv_u8m4_mask (vbool2_t mask, vuint16m8_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmacc_sv_u8m4_mask (vbool2_t mask, vuint16m8_t acc, uint8_t op1, vuint8m4_t op2);
vuint32m2_t vwmacc_vv_u16m1_mask (vbool16_t mask, vuint32m2_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmacc_sv_u16m1_mask (vbool16_t mask, vuint32m2_t acc, uint16_t op1, vuint16m1_t op2);
vuint32m4_t vwmacc_vv_u16m2_mask (vbool8_t mask, vuint32m4_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmacc_sv_u16m2_mask (vbool8_t mask, vuint32m4_t acc, uint16_t op1, vuint16m2_t op2);
vuint32m8_t vwmacc_vv_u16m4_mask (vbool4_t mask, vuint32m8_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmacc_sv_u16m4_mask (vbool4_t mask, vuint32m8_t acc, uint16_t op1, vuint16m4_t op2);
vuint64m2_t vwmacc_vv_u32m1_mask (vbool32_t mask, vuint64m2_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmacc_sv_u32m1_mask (vbool32_t mask, vuint64m2_t acc, uint32_t op1, vuint32m1_t op2);
vuint64m4_t vwmacc_vv_u32m2_mask (vbool16_t mask, vuint64m4_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmacc_sv_u32m2_mask (vbool16_t mask, vuint64m4_t acc, uint32_t op1, vuint32m2_t op2);
vuint64m8_t vwmacc_vv_u32m4_mask (vbool8_t mask, vuint64m8_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmacc_sv_u32m4_mask (vbool8_t mask, vuint64m8_t acc, uint32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccsu_vv_i8m1_mask (vbool8_t mask, vint16m2_t acc, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmaccsu_sv_i8m1_mask (vbool8_t mask, vint16m2_t acc, int8_t op1, vuint8m1_t op2);
vint16m4_t vwmaccsu_vv_i8m2_mask (vbool4_t mask, vint16m4_t acc, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmaccsu_sv_i8m2_mask (vbool4_t mask, vint16m4_t acc, int8_t op1, vuint8m2_t op2);
vint16m8_t vwmaccsu_vv_i8m4_mask (vbool2_t mask, vint16m8_t acc, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmaccsu_sv_i8m4_mask (vbool2_t mask, vint16m8_t acc, int8_t op1, vuint8m4_t op2);
vint32m2_t vwmaccsu_vv_i16m1_mask (vbool16_t mask, vint32m2_t acc, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmaccsu_sv_i16m1_mask (vbool16_t mask, vint32m2_t acc, int16_t op1, vuint16m1_t op2);
vint32m4_t vwmaccsu_vv_i16m2_mask (vbool8_t mask, vint32m4_t acc, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmaccsu_sv_i16m2_mask (vbool8_t mask, vint32m4_t acc, int16_t op1, vuint16m2_t op2);
vint32m8_t vwmaccsu_vv_i16m4_mask (vbool4_t mask, vint32m8_t acc, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmaccsu_sv_i16m4_mask (vbool4_t mask, vint32m8_t acc, int16_t op1, vuint16m4_t op2);
vint64m2_t vwmaccsu_vv_i32m1_mask (vbool32_t mask, vint64m2_t acc, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmaccsu_sv_i32m1_mask (vbool32_t mask, vint64m2_t acc, int32_t op1, vuint32m1_t op2);
vint64m4_t vwmaccsu_vv_i32m2_mask (vbool16_t mask, vint64m4_t acc, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmaccsu_sv_i32m2_mask (vbool16_t mask, vint64m4_t acc, int32_t op1, vuint32m2_t op2);
vint64m8_t vwmaccsu_vv_i32m4_mask (vbool8_t mask, vint64m8_t acc, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmaccsu_sv_i32m4_mask (vbool8_t mask, vint64m8_t acc, int32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccus_sv_i8m1_mask (vbool8_t mask, vint16m2_t acc, uint8_t op1, vint8m1_t op2);
vint16m4_t vwmaccus_sv_i8m2_mask (vbool4_t mask, vint16m4_t acc, uint8_t op1, vint8m2_t op2);
vint16m8_t vwmaccus_sv_i8m4_mask (vbool2_t mask, vint16m8_t acc, uint8_t op1, vint8m4_t op2);
vint32m2_t vwmaccus_sv_i16m1_mask (vbool16_t mask, vint32m2_t acc, uint16_t op1, vint16m1_t op2);
vint32m4_t vwmaccus_sv_i16m2_mask (vbool8_t mask, vint32m4_t acc, uint16_t op1, vint16m2_t op2);
vint32m8_t vwmaccus_sv_i16m4_mask (vbool4_t mask, vint32m8_t acc, uint16_t op1, vint16m4_t op2);
vint64m2_t vwmaccus_sv_i32m1_mask (vbool32_t mask, vint64m2_t acc, uint32_t op1, vint32m1_t op2);
vint64m4_t vwmaccus_sv_i32m2_mask (vbool16_t mask, vint64m4_t acc, uint32_t op1, vint32m2_t op2);
vint64m8_t vwmaccus_sv_i32m4_mask (vbool8_t mask, vint64m8_t acc, uint32_t op1, vint32m4_t op2);
```
### [Vector Quad-Widening Integer Multiply-Add Functions]()

**Prototypes:**
``` C
vint32m4_t vqmacc_vv_i8m1 (vint32m4_t acc, vint8m1_t op1, vint8m1_t op2);
vint32m4_t vqmacc_sv_i8m1 (vint32m4_t acc, int8_t op1, vint8m1_t op2);
vint32m8_t vqmacc_vv_i8m2 (vint32m8_t acc, vint8m2_t op1, vint8m2_t op2);
vint32m8_t vqmacc_sv_i8m2 (vint32m8_t acc, int8_t op1, vint8m2_t op2);
vint64m4_t vqmacc_vv_i16m1 (vint64m4_t acc, vint16m1_t op1, vint16m1_t op2);
vint64m4_t vqmacc_sv_i16m1 (vint64m4_t acc, int16_t op1, vint16m1_t op2);
vint64m8_t vqmacc_vv_i16m2 (vint64m8_t acc, vint16m2_t op1, vint16m2_t op2);
vint64m8_t vqmacc_sv_i16m2 (vint64m8_t acc, int16_t op1, vint16m2_t op2);
vuint32m4_t vqmacc_vv_u8m1 (vuint32m4_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint32m4_t vqmacc_sv_u8m1 (vuint32m4_t acc, uint8_t op1, vuint8m1_t op2);
vuint32m8_t vqmacc_vv_u8m2 (vuint32m8_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint32m8_t vqmacc_sv_u8m2 (vuint32m8_t acc, uint8_t op1, vuint8m2_t op2);
vuint64m4_t vqmacc_vv_u16m1 (vuint64m4_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint64m4_t vqmacc_sv_u16m1 (vuint64m4_t acc, uint16_t op1, vuint16m1_t op2);
vuint64m8_t vqmacc_vv_u16m2 (vuint64m8_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint64m8_t vqmacc_sv_u16m2 (vuint64m8_t acc, uint16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccsu_vv_i8m1 (vint32m4_t acc, vint8m1_t op1, vuint8m1_t op2);
vint32m4_t vqmaccsu_sv_i8m1 (vint32m4_t acc, int8_t op1, vuint8m1_t op2);
vint32m8_t vqmaccsu_vv_i8m2 (vint32m8_t acc, vint8m2_t op1, vuint8m2_t op2);
vint32m8_t vqmaccsu_sv_i8m2 (vint32m8_t acc, int8_t op1, vuint8m2_t op2);
vint64m4_t vqmaccsu_vv_i16m1 (vint64m4_t acc, vint16m1_t op1, vuint16m1_t op2);
vint64m4_t vqmaccsu_sv_i16m1 (vint64m4_t acc, int16_t op1, vuint16m1_t op2);
vint64m8_t vqmaccsu_vv_i16m2 (vint64m8_t acc, vint16m2_t op1, vuint16m2_t op2);
vint64m8_t vqmaccsu_sv_i16m2 (vint64m8_t acc, int16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccus_sv_i8m1 (vint32m4_t acc, uint8_t op1, vint8m1_t op2);
vint32m8_t vqmaccus_sv_i8m2 (vint32m8_t acc, uint8_t op1, vint8m2_t op2);
vint64m4_t vqmaccus_sv_i16m1 (vint64m4_t acc, uint16_t op1, vint16m1_t op2);
vint64m8_t vqmaccus_sv_i16m2 (vint64m8_t acc, uint16_t op1, vint16m2_t op2);
// masked functions
vint32m4_t vqmacc_vv_i8m1_mask (vbool8_t mask, vint32m4_t acc, vint8m1_t op1, vint8m1_t op2);
vint32m4_t vqmacc_sv_i8m1_mask (vbool8_t mask, vint32m4_t acc, int8_t op1, vint8m1_t op2);
vint32m8_t vqmacc_vv_i8m2_mask (vbool4_t mask, vint32m8_t acc, vint8m2_t op1, vint8m2_t op2);
vint32m8_t vqmacc_sv_i8m2_mask (vbool4_t mask, vint32m8_t acc, int8_t op1, vint8m2_t op2);
vint64m4_t vqmacc_vv_i16m1_mask (vbool16_t mask, vint64m4_t acc, vint16m1_t op1, vint16m1_t op2);
vint64m4_t vqmacc_sv_i16m1_mask (vbool16_t mask, vint64m4_t acc, int16_t op1, vint16m1_t op2);
vint64m8_t vqmacc_vv_i16m2_mask (vbool8_t mask, vint64m8_t acc, vint16m2_t op1, vint16m2_t op2);
vint64m8_t vqmacc_sv_i16m2_mask (vbool8_t mask, vint64m8_t acc, int16_t op1, vint16m2_t op2);
vuint32m4_t vqmacc_vv_u8m1_mask (vbool8_t mask, vuint32m4_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint32m4_t vqmacc_sv_u8m1_mask (vbool8_t mask, vuint32m4_t acc, uint8_t op1, vuint8m1_t op2);
vuint32m8_t vqmacc_vv_u8m2_mask (vbool4_t mask, vuint32m8_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint32m8_t vqmacc_sv_u8m2_mask (vbool4_t mask, vuint32m8_t acc, uint8_t op1, vuint8m2_t op2);
vuint64m4_t vqmacc_vv_u16m1_mask (vbool16_t mask, vuint64m4_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint64m4_t vqmacc_sv_u16m1_mask (vbool16_t mask, vuint64m4_t acc, uint16_t op1, vuint16m1_t op2);
vuint64m8_t vqmacc_vv_u16m2_mask (vbool8_t mask, vuint64m8_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint64m8_t vqmacc_sv_u16m2_mask (vbool8_t mask, vuint64m8_t acc, uint16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccsu_vv_i8m1_mask (vbool8_t mask, vint32m4_t acc, vint8m1_t op1, vuint8m1_t op2);
vint32m4_t vqmaccsu_sv_i8m1_mask (vbool8_t mask, vint32m4_t acc, int8_t op1, vuint8m1_t op2);
vint32m8_t vqmaccsu_vv_i8m2_mask (vbool4_t mask, vint32m8_t acc, vint8m2_t op1, vuint8m2_t op2);
vint32m8_t vqmaccsu_sv_i8m2_mask (vbool4_t mask, vint32m8_t acc, int8_t op1, vuint8m2_t op2);
vint64m4_t vqmaccsu_vv_i16m1_mask (vbool16_t mask, vint64m4_t acc, vint16m1_t op1, vuint16m1_t op2);
vint64m4_t vqmaccsu_sv_i16m1_mask (vbool16_t mask, vint64m4_t acc, int16_t op1, vuint16m1_t op2);
vint64m8_t vqmaccsu_vv_i16m2_mask (vbool8_t mask, vint64m8_t acc, vint16m2_t op1, vuint16m2_t op2);
vint64m8_t vqmaccsu_sv_i16m2_mask (vbool8_t mask, vint64m8_t acc, int16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccus_sv_i8m1_mask (vbool8_t mask, vint32m4_t acc, uint8_t op1, vint8m1_t op2);
vint32m8_t vqmaccus_sv_i8m2_mask (vbool4_t mask, vint32m8_t acc, uint8_t op1, vint8m2_t op2);
vint64m4_t vqmaccus_sv_i16m1_mask (vbool16_t mask, vint64m4_t acc, uint16_t op1, vint16m1_t op2);
vint64m8_t vqmaccus_sv_i16m2_mask (vbool8_t mask, vint64m8_t acc, uint16_t op1, vint16m2_t op2);
```
### [Vector Integer Merge Functions]()

**Prototypes:**
``` C
vint8m1_t vmerge_vv_i8m1_mask (vbool8_t mask, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmerge_vs_i8m1_mask (vbool8_t mask, vint8m1_t op1, int8_t op2);
vint8m2_t vmerge_vv_i8m2_mask (vbool4_t mask, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmerge_vs_i8m2_mask (vbool4_t mask, vint8m2_t op1, int8_t op2);
vint8m4_t vmerge_vv_i8m4_mask (vbool2_t mask, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmerge_vs_i8m4_mask (vbool2_t mask, vint8m4_t op1, int8_t op2);
vint8m8_t vmerge_vv_i8m8_mask (vbool1_t mask, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmerge_vs_i8m8_mask (vbool1_t mask, vint8m8_t op1, int8_t op2);
vint16m1_t vmerge_vv_i16m1_mask (vbool16_t mask, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmerge_vs_i16m1_mask (vbool16_t mask, vint16m1_t op1, int16_t op2);
vint16m2_t vmerge_vv_i16m2_mask (vbool8_t mask, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmerge_vs_i16m2_mask (vbool8_t mask, vint16m2_t op1, int16_t op2);
vint16m4_t vmerge_vv_i16m4_mask (vbool4_t mask, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmerge_vs_i16m4_mask (vbool4_t mask, vint16m4_t op1, int16_t op2);
vint16m8_t vmerge_vv_i16m8_mask (vbool2_t mask, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmerge_vs_i16m8_mask (vbool2_t mask, vint16m8_t op1, int16_t op2);
vint32m1_t vmerge_vv_i32m1_mask (vbool32_t mask, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmerge_vs_i32m1_mask (vbool32_t mask, vint32m1_t op1, int32_t op2);
vint32m2_t vmerge_vv_i32m2_mask (vbool16_t mask, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmerge_vs_i32m2_mask (vbool16_t mask, vint32m2_t op1, int32_t op2);
vint32m4_t vmerge_vv_i32m4_mask (vbool8_t mask, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmerge_vs_i32m4_mask (vbool8_t mask, vint32m4_t op1, int32_t op2);
vint32m8_t vmerge_vv_i32m8_mask (vbool4_t mask, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmerge_vs_i32m8_mask (vbool4_t mask, vint32m8_t op1, int32_t op2);
vint64m1_t vmerge_vv_i64m1_mask (vbool64_t mask, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmerge_vs_i64m1_mask (vbool64_t mask, vint64m1_t op1, int64_t op2);
vint64m2_t vmerge_vv_i64m2_mask (vbool32_t mask, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmerge_vs_i64m2_mask (vbool32_t mask, vint64m2_t op1, int64_t op2);
vint64m4_t vmerge_vv_i64m4_mask (vbool16_t mask, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmerge_vs_i64m4_mask (vbool16_t mask, vint64m4_t op1, int64_t op2);
vint64m8_t vmerge_vv_i64m8_mask (vbool8_t mask, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmerge_vs_i64m8_mask (vbool8_t mask, vint64m8_t op1, int64_t op2);
vuint8m1_t vmerge_vv_u8m1_mask (vbool8_t mask, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmerge_vs_u8m1_mask (vbool8_t mask, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmerge_vv_u8m2_mask (vbool4_t mask, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmerge_vs_u8m2_mask (vbool4_t mask, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmerge_vv_u8m4_mask (vbool2_t mask, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmerge_vs_u8m4_mask (vbool2_t mask, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmerge_vv_u8m8_mask (vbool1_t mask, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmerge_vs_u8m8_mask (vbool1_t mask, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmerge_vv_u16m1_mask (vbool16_t mask, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmerge_vs_u16m1_mask (vbool16_t mask, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmerge_vv_u16m2_mask (vbool8_t mask, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmerge_vs_u16m2_mask (vbool8_t mask, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmerge_vv_u16m4_mask (vbool4_t mask, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmerge_vs_u16m4_mask (vbool4_t mask, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmerge_vv_u16m8_mask (vbool2_t mask, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmerge_vs_u16m8_mask (vbool2_t mask, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmerge_vv_u32m1_mask (vbool32_t mask, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmerge_vs_u32m1_mask (vbool32_t mask, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmerge_vv_u32m2_mask (vbool16_t mask, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmerge_vs_u32m2_mask (vbool16_t mask, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmerge_vv_u32m4_mask (vbool8_t mask, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmerge_vs_u32m4_mask (vbool8_t mask, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmerge_vv_u32m8_mask (vbool4_t mask, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmerge_vs_u32m8_mask (vbool4_t mask, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmerge_vv_u64m1_mask (vbool64_t mask, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmerge_vs_u64m1_mask (vbool64_t mask, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmerge_vv_u64m2_mask (vbool32_t mask, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmerge_vs_u64m2_mask (vbool32_t mask, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmerge_vv_u64m4_mask (vbool16_t mask, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmerge_vs_u64m4_mask (vbool16_t mask, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmerge_vv_u64m8_mask (vbool8_t mask, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmerge_vs_u64m8_mask (vbool8_t mask, vuint64m8_t op1, uint64_t op2);
```
### [Vector Integer Move Functions]()

**Prototypes:**
``` C
vint8m1_t vcopy_v_i8m1 (vint8m1_t src);
vint8m1_t vsplat_s_i8m1 (int8_t src);
vint8m2_t vcopy_v_i8m2 (vint8m2_t src);
vint8m2_t vsplat_s_i8m2 (int8_t src);
vint8m4_t vcopy_v_i8m4 (vint8m4_t src);
vint8m4_t vsplat_s_i8m4 (int8_t src);
vint8m8_t vcopy_v_i8m8 (vint8m8_t src);
vint8m8_t vsplat_s_i8m8 (int8_t src);
vint16m1_t vcopy_v_i16m1 (vint16m1_t src);
vint16m1_t vsplat_s_i16m1 (int16_t src);
vint16m2_t vcopy_v_i16m2 (vint16m2_t src);
vint16m2_t vsplat_s_i16m2 (int16_t src);
vint16m4_t vcopy_v_i16m4 (vint16m4_t src);
vint16m4_t vsplat_s_i16m4 (int16_t src);
vint16m8_t vcopy_v_i16m8 (vint16m8_t src);
vint16m8_t vsplat_s_i16m8 (int16_t src);
vint32m1_t vcopy_v_i32m1 (vint32m1_t src);
vint32m1_t vsplat_s_i32m1 (int32_t src);
vint32m2_t vcopy_v_i32m2 (vint32m2_t src);
vint32m2_t vsplat_s_i32m2 (int32_t src);
vint32m4_t vcopy_v_i32m4 (vint32m4_t src);
vint32m4_t vsplat_s_i32m4 (int32_t src);
vint32m8_t vcopy_v_i32m8 (vint32m8_t src);
vint32m8_t vsplat_s_i32m8 (int32_t src);
vint64m1_t vcopy_v_i64m1 (vint64m1_t src);
vint64m1_t vsplat_s_i64m1 (int64_t src);
vint64m2_t vcopy_v_i64m2 (vint64m2_t src);
vint64m2_t vsplat_s_i64m2 (int64_t src);
vint64m4_t vcopy_v_i64m4 (vint64m4_t src);
vint64m4_t vsplat_s_i64m4 (int64_t src);
vint64m8_t vcopy_v_i64m8 (vint64m8_t src);
vint64m8_t vsplat_s_i64m8 (int64_t src);
vuint8m1_t vcopy_v_u8m1 (vuint8m1_t src);
vuint8m1_t vsplat_s_u8m1 (uint8_t src);
vuint8m2_t vcopy_v_u8m2 (vuint8m2_t src);
vuint8m2_t vsplat_s_u8m2 (uint8_t src);
vuint8m4_t vcopy_v_u8m4 (vuint8m4_t src);
vuint8m4_t vsplat_s_u8m4 (uint8_t src);
vuint8m8_t vcopy_v_u8m8 (vuint8m8_t src);
vuint8m8_t vsplat_s_u8m8 (uint8_t src);
vuint16m1_t vcopy_v_u16m1 (vuint16m1_t src);
vuint16m1_t vsplat_s_u16m1 (uint16_t src);
vuint16m2_t vcopy_v_u16m2 (vuint16m2_t src);
vuint16m2_t vsplat_s_u16m2 (uint16_t src);
vuint16m4_t vcopy_v_u16m4 (vuint16m4_t src);
vuint16m4_t vsplat_s_u16m4 (uint16_t src);
vuint16m8_t vcopy_v_u16m8 (vuint16m8_t src);
vuint16m8_t vsplat_s_u16m8 (uint16_t src);
vuint32m1_t vcopy_v_u32m1 (vuint32m1_t src);
vuint32m1_t vsplat_s_u32m1 (uint32_t src);
vuint32m2_t vcopy_v_u32m2 (vuint32m2_t src);
vuint32m2_t vsplat_s_u32m2 (uint32_t src);
vuint32m4_t vcopy_v_u32m4 (vuint32m4_t src);
vuint32m4_t vsplat_s_u32m4 (uint32_t src);
vuint32m8_t vcopy_v_u32m8 (vuint32m8_t src);
vuint32m8_t vsplat_s_u32m8 (uint32_t src);
vuint64m1_t vcopy_v_u64m1 (vuint64m1_t src);
vuint64m1_t vsplat_s_u64m1 (uint64_t src);
vuint64m2_t vcopy_v_u64m2 (vuint64m2_t src);
vuint64m2_t vsplat_s_u64m2 (uint64_t src);
vuint64m4_t vcopy_v_u64m4 (vuint64m4_t src);
vuint64m4_t vsplat_s_u64m4 (uint64_t src);
vuint64m8_t vcopy_v_u64m8 (vuint64m8_t src);
vuint64m8_t vsplat_s_u64m8 (uint64_t src);
```
## Vector Fixed-Point Arithmetic Functions:

### [Vector Single-Width Saturating Add and Subtract Functions]()

**Prototypes:**
``` C
vint8m1_t vsadd_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsadd_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vsadd_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsadd_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vsadd_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsadd_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vsadd_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsadd_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vsadd_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsadd_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vsadd_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsadd_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vsadd_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsadd_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vsadd_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsadd_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vsadd_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsadd_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vsadd_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsadd_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vsadd_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsadd_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vsadd_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsadd_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vsadd_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsadd_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vsadd_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsadd_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vsadd_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsadd_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vsadd_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsadd_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vsadd_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsadd_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsadd_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsadd_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsadd_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsadd_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsadd_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsadd_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsadd_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsadd_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsadd_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsadd_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsadd_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsadd_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsadd_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsadd_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsadd_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsadd_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsadd_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsadd_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsadd_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsadd_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsadd_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsadd_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsadd_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsadd_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsadd_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsadd_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsadd_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsadd_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsadd_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsadd_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vint8m1_t vssub_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssub_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vssub_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssub_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vssub_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssub_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vssub_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssub_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vssub_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssub_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vssub_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssub_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vssub_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssub_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vssub_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssub_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vssub_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssub_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vssub_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssub_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vssub_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssub_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vssub_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssub_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vssub_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssub_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vssub_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssub_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vssub_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssub_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vssub_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssub_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vssub_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssub_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssub_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssub_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssub_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssub_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssub_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssub_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssub_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssub_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssub_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssub_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssub_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssub_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssub_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssub_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssub_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssub_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssub_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssub_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssub_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssub_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssub_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssub_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssub_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssub_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssub_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssub_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssub_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssub_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssub_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssub_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vsadd_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsadd_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsadd_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsadd_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsadd_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsadd_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsadd_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsadd_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsadd_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsadd_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsadd_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsadd_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsadd_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsadd_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsadd_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsadd_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsadd_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsadd_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsadd_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsadd_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsadd_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsadd_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsadd_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsadd_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsadd_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsadd_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsadd_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsadd_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsadd_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsadd_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsadd_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsadd_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsadd_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsadd_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsadd_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsadd_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsadd_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsadd_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsadd_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsadd_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsadd_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsadd_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsadd_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsadd_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsadd_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsadd_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsadd_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsadd_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsadd_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsadd_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsadd_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsadd_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsadd_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsadd_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsadd_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsadd_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsadd_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsadd_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsadd_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsadd_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsadd_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsadd_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsadd_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsadd_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vssub_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssub_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vssub_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssub_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vssub_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssub_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vssub_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssub_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vssub_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssub_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vssub_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssub_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vssub_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssub_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vssub_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssub_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vssub_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssub_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vssub_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssub_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vssub_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssub_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vssub_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssub_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vssub_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssub_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vssub_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssub_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vssub_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssub_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vssub_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssub_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vssub_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssub_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssub_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssub_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssub_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssub_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssub_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssub_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssub_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssub_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssub_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssub_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssub_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssub_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssub_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssub_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssub_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssub_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssub_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssub_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssub_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssub_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssub_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssub_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssub_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssub_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssub_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssub_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssub_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssub_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssub_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssub_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Averaging Add and Subtract Functions]()

**Prototypes:**
``` C
vint8m1_t vaadd_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vaadd_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vaadd_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vaadd_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vaadd_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vaadd_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vaadd_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vaadd_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vaadd_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vaadd_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vaadd_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vaadd_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vaadd_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vaadd_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vaadd_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vaadd_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vaadd_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vaadd_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vaadd_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vaadd_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vaadd_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vaadd_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vaadd_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vaadd_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vaadd_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vaadd_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vaadd_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vaadd_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vaadd_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vaadd_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vaadd_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vaadd_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vaadd_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vaadd_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vaadd_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vaadd_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vaadd_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vaadd_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vaadd_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vaadd_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vaadd_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vaadd_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vaadd_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vaadd_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vaadd_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vaadd_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vaadd_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vaadd_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vaadd_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vaadd_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vaadd_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vaadd_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vaadd_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vaadd_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vaadd_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vaadd_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vaadd_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vaadd_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vaadd_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vaadd_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vaadd_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vaadd_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vaadd_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vaadd_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vint8m1_t vasub_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vasub_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vasub_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vasub_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vasub_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vasub_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vasub_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vasub_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vasub_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vasub_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vasub_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vasub_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vasub_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vasub_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vasub_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vasub_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vasub_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vasub_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vasub_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vasub_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vasub_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vasub_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vasub_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vasub_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vasub_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vasub_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vasub_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vasub_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vasub_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vasub_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vasub_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vasub_vs_i64m8 (vint64m8_t op1, int64_t op2);
vuint8m1_t vasub_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vasub_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vasub_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vasub_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vasub_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vasub_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vasub_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vasub_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vasub_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vasub_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vasub_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vasub_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vasub_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vasub_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vasub_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vasub_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vasub_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vasub_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vasub_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vasub_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vasub_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vasub_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vasub_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vasub_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vasub_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vasub_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vasub_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vasub_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vasub_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vasub_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vasub_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vasub_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vaadd_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vaadd_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vaadd_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vaadd_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vaadd_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vaadd_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vaadd_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vaadd_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vaadd_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vaadd_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vaadd_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vaadd_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vaadd_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vaadd_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vaadd_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vaadd_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vaadd_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vaadd_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vaadd_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vaadd_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vaadd_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vaadd_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vaadd_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vaadd_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vaadd_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vaadd_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vaadd_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vaadd_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vaadd_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vaadd_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vaadd_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vaadd_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vaadd_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vaadd_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vaadd_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vaadd_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vaadd_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vaadd_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vaadd_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vaadd_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vaadd_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vaadd_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vaadd_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vaadd_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vaadd_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vaadd_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vaadd_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vaadd_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vaadd_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vaadd_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vaadd_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vaadd_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vaadd_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vaadd_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vaadd_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vaadd_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vaadd_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vaadd_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vaadd_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vaadd_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vaadd_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vaadd_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vaadd_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vaadd_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vasub_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vasub_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vasub_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vasub_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vasub_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vasub_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vasub_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vasub_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vasub_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vasub_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vasub_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vasub_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vasub_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vasub_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vasub_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vasub_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vasub_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vasub_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vasub_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vasub_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vasub_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vasub_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vasub_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vasub_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vasub_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vasub_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vasub_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vasub_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vasub_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vasub_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vasub_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vasub_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vasub_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vasub_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vasub_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vasub_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vasub_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vasub_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vasub_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vasub_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vasub_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vasub_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vasub_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vasub_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vasub_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vasub_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vasub_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vasub_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vasub_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vasub_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vasub_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vasub_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vasub_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vasub_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vasub_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vasub_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vasub_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vasub_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vasub_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vasub_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vasub_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vasub_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vasub_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vasub_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Fractional Multiply with Rounding and Saturation Functions]()

**Prototypes:**
``` C
vint8m1_t vsmul_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsmul_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vsmul_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsmul_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vsmul_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsmul_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vsmul_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsmul_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vsmul_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsmul_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vsmul_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsmul_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vsmul_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsmul_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vsmul_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsmul_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vsmul_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsmul_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vsmul_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsmul_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vsmul_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsmul_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vsmul_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsmul_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vsmul_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsmul_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vsmul_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsmul_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vsmul_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsmul_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vsmul_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsmul_vs_i64m8 (vint64m8_t op1, int64_t op2);
// masked functions
vint8m1_t vsmul_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsmul_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsmul_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsmul_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsmul_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsmul_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsmul_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsmul_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsmul_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsmul_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsmul_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsmul_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsmul_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsmul_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsmul_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsmul_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsmul_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsmul_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsmul_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsmul_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsmul_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsmul_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsmul_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsmul_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsmul_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsmul_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsmul_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsmul_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsmul_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsmul_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsmul_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsmul_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
```
### [Vector Single-Width Scaling Shift Functions]()

**Prototypes:**
``` C
vuint8m1_t vssrl_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssrl_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssrl_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssrl_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssrl_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssrl_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssrl_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssrl_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssrl_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssrl_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssrl_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssrl_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssrl_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssrl_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssrl_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssrl_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssrl_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssrl_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssrl_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssrl_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssrl_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssrl_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssrl_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssrl_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssrl_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssrl_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssrl_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssrl_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssrl_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssrl_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssrl_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssrl_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vint8m1_t vssra_vv_i8m1 (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssra_vs_i8m1 (vint8m1_t op1, int8_t op2);
vint8m2_t vssra_vv_i8m2 (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssra_vs_i8m2 (vint8m2_t op1, int8_t op2);
vint8m4_t vssra_vv_i8m4 (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssra_vs_i8m4 (vint8m4_t op1, int8_t op2);
vint8m8_t vssra_vv_i8m8 (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssra_vs_i8m8 (vint8m8_t op1, int8_t op2);
vint16m1_t vssra_vv_i16m1 (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssra_vs_i16m1 (vint16m1_t op1, int16_t op2);
vint16m2_t vssra_vv_i16m2 (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssra_vs_i16m2 (vint16m2_t op1, int16_t op2);
vint16m4_t vssra_vv_i16m4 (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssra_vs_i16m4 (vint16m4_t op1, int16_t op2);
vint16m8_t vssra_vv_i16m8 (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssra_vs_i16m8 (vint16m8_t op1, int16_t op2);
vint32m1_t vssra_vv_i32m1 (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssra_vs_i32m1 (vint32m1_t op1, int32_t op2);
vint32m2_t vssra_vv_i32m2 (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssra_vs_i32m2 (vint32m2_t op1, int32_t op2);
vint32m4_t vssra_vv_i32m4 (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssra_vs_i32m4 (vint32m4_t op1, int32_t op2);
vint32m8_t vssra_vv_i32m8 (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssra_vs_i32m8 (vint32m8_t op1, int32_t op2);
vint64m1_t vssra_vv_i64m1 (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssra_vs_i64m1 (vint64m1_t op1, int64_t op2);
vint64m2_t vssra_vv_i64m2 (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssra_vs_i64m2 (vint64m2_t op1, int64_t op2);
vint64m4_t vssra_vv_i64m4 (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssra_vs_i64m4 (vint64m4_t op1, int64_t op2);
vint64m8_t vssra_vv_i64m8 (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssra_vs_i64m8 (vint64m8_t op1, int64_t op2);
// masked functions
vuint8m1_t vssrl_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssrl_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssrl_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssrl_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssrl_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssrl_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssrl_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssrl_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssrl_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssrl_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssrl_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssrl_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssrl_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssrl_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssrl_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssrl_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssrl_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssrl_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssrl_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssrl_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssrl_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssrl_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssrl_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssrl_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssrl_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssrl_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssrl_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssrl_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssrl_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssrl_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssrl_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssrl_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vssra_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssra_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vssra_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssra_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vssra_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssra_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vssra_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssra_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vssra_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssra_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vssra_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssra_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vssra_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssra_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vssra_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssra_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vssra_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssra_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vssra_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssra_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vssra_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssra_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vssra_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssra_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vssra_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssra_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vssra_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssra_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vssra_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssra_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vssra_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssra_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
```
### [Vector Narrowing Fixed-Point Clip Functions]()

**Prototypes:**
``` C
vint8m1_t vnclip_wv_i16m2 (vint16m2_t op1, vint8m1_t op2);
vint8m1_t vnclip_ws_i16m2 (vint16m2_t op1, int8_t op2);
vint8m2_t vnclip_wv_i16m4 (vint16m4_t op1, vint8m2_t op2);
vint8m2_t vnclip_ws_i16m4 (vint16m4_t op1, int8_t op2);
vint8m4_t vnclip_wv_i16m8 (vint16m8_t op1, vint8m4_t op2);
vint8m4_t vnclip_ws_i16m8 (vint16m8_t op1, int8_t op2);
vint16m1_t vnclip_wv_i32m2 (vint32m2_t op1, vint16m1_t op2);
vint16m1_t vnclip_ws_i32m2 (vint32m2_t op1, int16_t op2);
vint16m2_t vnclip_wv_i32m4 (vint32m4_t op1, vint16m2_t op2);
vint16m2_t vnclip_ws_i32m4 (vint32m4_t op1, int16_t op2);
vint16m4_t vnclip_wv_i32m8 (vint32m8_t op1, vint16m4_t op2);
vint16m4_t vnclip_ws_i32m8 (vint32m8_t op1, int16_t op2);
vint32m1_t vnclip_wv_i64m2 (vint64m2_t op1, vint32m1_t op2);
vint32m1_t vnclip_ws_i64m2 (vint64m2_t op1, int32_t op2);
vint32m2_t vnclip_wv_i64m4 (vint64m4_t op1, vint32m2_t op2);
vint32m2_t vnclip_ws_i64m4 (vint64m4_t op1, int32_t op2);
vint32m4_t vnclip_wv_i64m8 (vint64m8_t op1, vint32m4_t op2);
vint32m4_t vnclip_ws_i64m8 (vint64m8_t op1, int32_t op2);
vuint8m1_t vnclip_wv_u16m2 (vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnclip_ws_u16m2 (vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnclip_wv_u16m4 (vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnclip_ws_u16m4 (vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnclip_wv_u16m8 (vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnclip_ws_u16m8 (vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnclip_wv_u32m2 (vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnclip_ws_u32m2 (vuint32m2_t op1, uint16_t op2);
vuint16m2_t vnclip_wv_u32m4 (vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnclip_ws_u32m4 (vuint32m4_t op1, uint16_t op2);
vuint16m4_t vnclip_wv_u32m8 (vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnclip_ws_u32m8 (vuint32m8_t op1, uint16_t op2);
vuint32m1_t vnclip_wv_u64m2 (vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnclip_ws_u64m2 (vuint64m2_t op1, uint32_t op2);
vuint32m2_t vnclip_wv_u64m4 (vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnclip_ws_u64m4 (vuint64m4_t op1, uint32_t op2);
vuint32m4_t vnclip_wv_u64m8 (vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnclip_ws_u64m8 (vuint64m8_t op1, uint32_t op2);
// masked functions
vint8m1_t vnclip_wv_i16m2_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint8m1_t vnclip_ws_i16m2_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, int8_t op2);
vint8m2_t vnclip_wv_i16m4_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint8m2_t vnclip_ws_i16m4_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, int8_t op2);
vint8m4_t vnclip_wv_i16m8_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint8m4_t vnclip_ws_i16m8_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, int8_t op2);
vint16m1_t vnclip_wv_i32m2_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint16m1_t vnclip_ws_i32m2_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, int16_t op2);
vint16m2_t vnclip_wv_i32m4_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint16m2_t vnclip_ws_i32m4_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, int16_t op2);
vint16m4_t vnclip_wv_i32m8_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint16m4_t vnclip_ws_i32m8_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, int16_t op2);
vint32m1_t vnclip_wv_i64m2_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint32m1_t vnclip_ws_i64m2_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, int32_t op2);
vint32m2_t vnclip_wv_i64m4_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint32m2_t vnclip_ws_i64m4_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, int32_t op2);
vint32m4_t vnclip_wv_i64m8_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint32m4_t vnclip_ws_i64m8_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, int32_t op2);
vuint8m1_t vnclip_wv_u16m2_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnclip_ws_u16m2_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnclip_wv_u16m4_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnclip_ws_u16m4_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnclip_wv_u16m8_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnclip_ws_u16m8_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnclip_wv_u32m2_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnclip_ws_u32m2_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint16m2_t vnclip_wv_u32m4_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnclip_ws_u32m4_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint16m4_t vnclip_wv_u32m8_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnclip_ws_u32m8_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint32m1_t vnclip_wv_u64m2_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnclip_ws_u64m2_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint32m2_t vnclip_wv_u64m4_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnclip_ws_u64m4_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint32m4_t vnclip_wv_u64m8_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnclip_ws_u64m8_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, uint32_t op2);
```
## Vector floating-Point Functions:

### [Vector Single-Width Floating-Point Add/Subtract Functions]()

**Prototypes:**
``` C
vfloat16m1_t vadd_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vadd_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vadd_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vadd_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vadd_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vadd_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vadd_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vadd_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vadd_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vadd_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vadd_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vadd_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vadd_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vadd_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vadd_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vadd_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vadd_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vadd_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vadd_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vadd_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vadd_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vadd_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vadd_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vadd_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsub_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsub_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsub_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsub_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsub_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsub_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsub_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsub_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsub_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsub_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsub_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsub_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsub_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsub_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsub_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsub_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsub_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsub_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsub_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsub_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsub_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsub_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsub_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsub_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrsub_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrsub_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrsub_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrsub_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrsub_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrsub_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrsub_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrsub_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrsub_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrsub_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrsub_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrsub_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vadd_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vadd_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vadd_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vadd_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vadd_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vadd_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vadd_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vadd_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vadd_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vadd_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vadd_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vadd_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vadd_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vadd_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vadd_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vadd_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vadd_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vadd_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vadd_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vadd_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vadd_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vadd_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vadd_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vadd_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsub_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsub_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsub_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsub_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsub_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsub_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsub_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsub_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsub_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsub_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsub_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsub_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsub_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsub_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsub_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsub_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsub_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsub_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsub_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsub_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsub_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsub_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsub_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsub_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrsub_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrsub_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrsub_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrsub_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrsub_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrsub_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrsub_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrsub_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrsub_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrsub_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrsub_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrsub_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Widening Floating-Point Add/Subtract Functions]()

**Prototypes:**
``` C
vfloat32m2_t vwadd_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwadd_wv_f16m1 (vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd_ws_f16m1 (vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwadd_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwadd_wv_f16m2 (vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd_ws_f16m2 (vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwadd_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwadd_wv_f16m4 (vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd_ws_f16m4 (vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwadd_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwadd_wv_f32m1 (vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd_ws_f32m1 (vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwadd_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwadd_wv_f32m2 (vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd_ws_f32m2 (vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwadd_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwadd_wv_f32m4 (vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd_ws_f32m4 (vfloat64m8_t op1, float32_t op2);
vfloat32m2_t vwsub_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwsub_wv_f16m1 (vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub_ws_f16m1 (vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwsub_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwsub_wv_f16m2 (vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub_ws_f16m2 (vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwsub_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwsub_wv_f16m4 (vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub_ws_f16m4 (vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwsub_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwsub_wv_f32m1 (vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub_ws_f32m1 (vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwsub_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwsub_wv_f32m2 (vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub_ws_f32m2 (vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwsub_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwsub_wv_f32m4 (vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub_ws_f32m4 (vfloat64m8_t op1, float32_t op2);
// masked functions
vfloat32m2_t vwadd_vv_f16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd_vs_f16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwadd_wv_f16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd_ws_f16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwadd_vv_f16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd_vs_f16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwadd_wv_f16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd_ws_f16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwadd_vv_f16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd_vs_f16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwadd_wv_f16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd_ws_f16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwadd_vv_f32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd_vs_f32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwadd_wv_f32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd_ws_f32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwadd_vv_f32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd_vs_f32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwadd_wv_f32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd_ws_f32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwadd_vv_f32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd_vs_f32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwadd_wv_f32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd_ws_f32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2);
vfloat32m2_t vwsub_vv_f16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub_vs_f16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwsub_wv_f16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub_ws_f16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwsub_vv_f16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub_vs_f16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwsub_wv_f16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub_ws_f16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwsub_vv_f16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub_vs_f16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwsub_wv_f16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub_ws_f16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwsub_vv_f32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub_vs_f32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwsub_wv_f32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub_ws_f32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwsub_vv_f32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub_vs_f32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwsub_wv_f32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub_ws_f32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwsub_vv_f32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub_vs_f32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwsub_wv_f32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub_ws_f32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2);
```
### [Vector Single-Width Floating-Point Multiply/Divide Functions]()

**Prototypes:**
``` C
vfloat16m1_t vmul_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmul_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmul_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmul_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmul_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmul_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmul_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmul_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmul_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmul_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmul_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmul_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmul_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmul_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmul_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmul_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmul_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmul_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmul_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmul_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmul_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmul_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmul_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmul_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vdiv_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vdiv_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vdiv_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vdiv_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vdiv_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vdiv_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vdiv_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vdiv_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vdiv_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vdiv_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vdiv_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vdiv_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vdiv_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vdiv_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vdiv_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vdiv_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vdiv_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vdiv_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vdiv_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vdiv_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vdiv_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vdiv_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vdiv_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vdiv_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrdiv_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrdiv_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrdiv_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrdiv_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrdiv_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrdiv_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrdiv_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrdiv_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrdiv_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrdiv_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrdiv_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrdiv_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vmul_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmul_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmul_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmul_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmul_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmul_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmul_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmul_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmul_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmul_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmul_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmul_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmul_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmul_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmul_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmul_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmul_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmul_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmul_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmul_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmul_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmul_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmul_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmul_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vdiv_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vdiv_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vdiv_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vdiv_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vdiv_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vdiv_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vdiv_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vdiv_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vdiv_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vdiv_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vdiv_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vdiv_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vdiv_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vdiv_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vdiv_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vdiv_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vdiv_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vdiv_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vdiv_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vdiv_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vdiv_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vdiv_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vdiv_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vdiv_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrdiv_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrdiv_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrdiv_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrdiv_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrdiv_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrdiv_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrdiv_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrdiv_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrdiv_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrdiv_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrdiv_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrdiv_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Widening Floating-Point Multiply Functions]()

**Prototypes:**
``` C
vfloat32m2_t vwmul_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmul_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat32m4_t vwmul_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmul_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat32m8_t vwmul_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmul_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat64m2_t vwmul_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmul_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat64m4_t vwmul_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmul_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat64m8_t vwmul_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmul_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
// masked functions
vfloat32m2_t vwmul_vv_f16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmul_vs_f16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m4_t vwmul_vv_f16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmul_vs_f16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m8_t vwmul_vv_f16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmul_vs_f16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat64m2_t vwmul_vv_f32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmul_vs_f32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m4_t vwmul_vv_f32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmul_vs_f32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m8_t vwmul_vv_f32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmul_vs_f32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
```
### [Vector Single-Width Floating-Point Fused Multiply-Add Functions]()

**Prototypes:**
``` C
vfloat16m1_t vmacc_vv_f16m1 (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmacc_sv_f16m1 (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmacc_vv_f16m2 (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmacc_sv_f16m2 (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmacc_vv_f16m4 (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmacc_sv_f16m4 (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmacc_vv_f16m8 (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmacc_sv_f16m8 (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmacc_vv_f32m1 (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmacc_sv_f32m1 (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmacc_vv_f32m2 (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmacc_sv_f32m2 (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmacc_vv_f32m4 (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmacc_sv_f32m4 (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmacc_vv_f32m8 (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmacc_sv_f32m8 (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmacc_vv_f64m1 (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmacc_sv_f64m1 (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmacc_vv_f64m2 (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmacc_sv_f64m2 (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmacc_vv_f64m4 (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmacc_sv_f64m4 (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmacc_vv_f64m8 (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmacc_sv_f64m8 (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmacc_vv_f16m1 (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmacc_sv_f16m1 (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmacc_vv_f16m2 (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmacc_sv_f16m2 (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmacc_vv_f16m4 (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmacc_sv_f16m4 (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmacc_vv_f16m8 (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmacc_sv_f16m8 (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmacc_vv_f32m1 (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmacc_sv_f32m1 (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmacc_vv_f32m2 (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmacc_sv_f32m2 (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmacc_vv_f32m4 (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmacc_sv_f32m4 (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmacc_vv_f32m8 (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmacc_sv_f32m8 (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmacc_vv_f64m1 (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmacc_sv_f64m1 (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmacc_vv_f64m2 (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmacc_sv_f64m2 (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmacc_vv_f64m4 (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmacc_sv_f64m4 (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmacc_vv_f64m8 (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmacc_sv_f64m8 (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsac_vv_f16m1 (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsac_sv_f16m1 (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsac_vv_f16m2 (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsac_sv_f16m2 (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsac_vv_f16m4 (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsac_sv_f16m4 (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsac_vv_f16m8 (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsac_sv_f16m8 (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsac_vv_f32m1 (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsac_sv_f32m1 (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsac_vv_f32m2 (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsac_sv_f32m2 (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsac_vv_f32m4 (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsac_sv_f32m4 (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsac_vv_f32m8 (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsac_sv_f32m8 (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsac_vv_f64m1 (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsac_sv_f64m1 (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsac_vv_f64m2 (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsac_sv_f64m2 (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsac_vv_f64m4 (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsac_sv_f64m4 (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsac_vv_f64m8 (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsac_sv_f64m8 (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsac_vv_f16m1 (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsac_sv_f16m1 (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsac_vv_f16m2 (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsac_sv_f16m2 (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsac_vv_f16m4 (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsac_sv_f16m4 (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsac_vv_f16m8 (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsac_sv_f16m8 (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsac_vv_f32m1 (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsac_sv_f32m1 (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsac_vv_f32m2 (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsac_sv_f32m2 (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsac_vv_f32m4 (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsac_sv_f32m4 (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsac_vv_f32m8 (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsac_sv_f32m8 (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsac_vv_f64m1 (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsac_sv_f64m1 (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsac_vv_f64m2 (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsac_sv_f64m2 (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsac_vv_f64m4 (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsac_sv_f64m4 (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsac_vv_f64m8 (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsac_sv_f64m8 (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmadd_vv_f16m1 (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmadd_sv_f16m1 (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmadd_vv_f16m2 (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmadd_sv_f16m2 (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmadd_vv_f16m4 (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmadd_sv_f16m4 (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmadd_vv_f16m8 (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmadd_sv_f16m8 (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmadd_vv_f32m1 (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmadd_sv_f32m1 (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmadd_vv_f32m2 (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmadd_sv_f32m2 (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmadd_vv_f32m4 (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmadd_sv_f32m4 (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmadd_vv_f32m8 (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmadd_sv_f32m8 (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmadd_vv_f64m1 (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmadd_sv_f64m1 (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmadd_vv_f64m2 (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmadd_sv_f64m2 (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmadd_vv_f64m4 (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmadd_sv_f64m4 (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmadd_vv_f64m8 (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmadd_sv_f64m8 (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmadd_vv_f16m1 (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmadd_sv_f16m1 (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmadd_vv_f16m2 (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmadd_sv_f16m2 (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmadd_vv_f16m4 (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmadd_sv_f16m4 (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmadd_vv_f16m8 (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmadd_sv_f16m8 (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmadd_vv_f32m1 (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmadd_sv_f32m1 (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmadd_vv_f32m2 (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmadd_sv_f32m2 (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmadd_vv_f32m4 (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmadd_sv_f32m4 (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmadd_vv_f32m8 (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmadd_sv_f32m8 (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmadd_vv_f64m1 (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmadd_sv_f64m1 (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmadd_vv_f64m2 (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmadd_sv_f64m2 (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmadd_vv_f64m4 (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmadd_sv_f64m4 (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmadd_vv_f64m8 (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmadd_sv_f64m8 (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsub_vv_f16m1 (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsub_sv_f16m1 (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsub_vv_f16m2 (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsub_sv_f16m2 (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsub_vv_f16m4 (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsub_sv_f16m4 (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsub_vv_f16m8 (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsub_sv_f16m8 (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsub_vv_f32m1 (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsub_sv_f32m1 (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsub_vv_f32m2 (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsub_sv_f32m2 (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsub_vv_f32m4 (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsub_sv_f32m4 (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsub_vv_f32m8 (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsub_sv_f32m8 (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsub_vv_f64m1 (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsub_sv_f64m1 (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsub_vv_f64m2 (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsub_sv_f64m2 (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsub_vv_f64m4 (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsub_sv_f64m4 (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsub_vv_f64m8 (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsub_sv_f64m8 (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsub_vv_f16m1 (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsub_sv_f16m1 (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsub_vv_f16m2 (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsub_sv_f16m2 (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsub_vv_f16m4 (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsub_sv_f16m4 (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsub_vv_f16m8 (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsub_sv_f16m8 (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsub_vv_f32m1 (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsub_sv_f32m1 (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsub_vv_f32m2 (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsub_sv_f32m2 (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsub_vv_f32m4 (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsub_sv_f32m4 (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsub_vv_f32m8 (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsub_sv_f32m8 (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsub_vv_f64m1 (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsub_sv_f64m1 (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsub_vv_f64m2 (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsub_sv_f64m2 (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsub_vv_f64m4 (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsub_sv_f64m4 (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsub_vv_f64m8 (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsub_sv_f64m8 (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
// masked functions
vfloat16m1_t vmacc_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmacc_sv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmacc_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmacc_sv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmacc_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmacc_sv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmacc_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmacc_sv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmacc_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmacc_sv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmacc_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmacc_sv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmacc_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmacc_sv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmacc_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmacc_sv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmacc_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmacc_sv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmacc_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmacc_sv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmacc_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmacc_sv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmacc_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmacc_sv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmacc_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmacc_sv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmacc_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmacc_sv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmacc_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmacc_sv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmacc_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmacc_sv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmacc_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmacc_sv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmacc_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmacc_sv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmacc_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmacc_sv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmacc_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmacc_sv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmacc_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmacc_sv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmacc_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmacc_sv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmacc_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmacc_sv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmacc_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmacc_sv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsac_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsac_sv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsac_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsac_sv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsac_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsac_sv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsac_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsac_sv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsac_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsac_sv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsac_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsac_sv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsac_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsac_sv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsac_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsac_sv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsac_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsac_sv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsac_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsac_sv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsac_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsac_sv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsac_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsac_sv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsac_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsac_sv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsac_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsac_sv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsac_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsac_sv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsac_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsac_sv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsac_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsac_sv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsac_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsac_sv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsac_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsac_sv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsac_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsac_sv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsac_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsac_sv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsac_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsac_sv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsac_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsac_sv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsac_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsac_sv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmadd_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmadd_sv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmadd_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmadd_sv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmadd_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmadd_sv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmadd_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmadd_sv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmadd_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmadd_sv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmadd_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmadd_sv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmadd_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmadd_sv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmadd_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmadd_sv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmadd_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmadd_sv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmadd_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmadd_sv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmadd_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmadd_sv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmadd_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmadd_sv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmadd_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmadd_sv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmadd_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmadd_sv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmadd_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmadd_sv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmadd_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmadd_sv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmadd_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmadd_sv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmadd_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmadd_sv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmadd_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmadd_sv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmadd_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmadd_sv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmadd_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmadd_sv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmadd_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmadd_sv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmadd_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmadd_sv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmadd_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmadd_sv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsub_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsub_sv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsub_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsub_sv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsub_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsub_sv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsub_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsub_sv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsub_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsub_sv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsub_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsub_sv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsub_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsub_sv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsub_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsub_sv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsub_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsub_sv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsub_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsub_sv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsub_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsub_sv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsub_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsub_sv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsub_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsub_sv_f16m1_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsub_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsub_sv_f16m2_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsub_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsub_sv_f16m4_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsub_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsub_sv_f16m8_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsub_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsub_sv_f32m1_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsub_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsub_sv_f32m2_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsub_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsub_sv_f32m4_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsub_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsub_sv_f32m8_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsub_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsub_sv_f64m1_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsub_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsub_sv_f64m2_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsub_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsub_sv_f64m4_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsub_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsub_sv_f64m8_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
```
### [Vector Widening Floating-Point Fused Multiply-Add Functions]()

**Prototypes:**
``` C
vfloat32m2_t vwmacc_vv_f16m1 (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmacc_sv_f16m1 (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmacc_vv_f16m2 (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmacc_sv_f16m2 (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmacc_vv_f16m4 (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmacc_sv_f16m4 (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmacc_vv_f32m1 (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmacc_sv_f32m1 (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmacc_vv_f32m2 (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmacc_sv_f32m2 (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmacc_vv_f32m4 (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmacc_sv_f32m4 (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmacc_vv_f16m1 (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmacc_sv_f16m1 (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmacc_vv_f16m2 (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmacc_sv_f16m2 (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmacc_vv_f16m4 (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmacc_sv_f16m4 (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmacc_vv_f32m1 (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmacc_sv_f32m1 (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmacc_vv_f32m2 (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmacc_sv_f32m2 (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmacc_vv_f32m4 (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmacc_sv_f32m4 (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwmsac_vv_f16m1 (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmsac_sv_f16m1 (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmsac_vv_f16m2 (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmsac_sv_f16m2 (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmsac_vv_f16m4 (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmsac_sv_f16m4 (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmsac_vv_f32m1 (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmsac_sv_f32m1 (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmsac_vv_f32m2 (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmsac_sv_f32m2 (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmsac_vv_f32m4 (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmsac_sv_f32m4 (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmsac_vv_f16m1 (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmsac_sv_f16m1 (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmsac_vv_f16m2 (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmsac_sv_f16m2 (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmsac_vv_f16m4 (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmsac_sv_f16m4 (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmsac_vv_f32m1 (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmsac_sv_f32m1 (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmsac_vv_f32m2 (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmsac_sv_f32m2 (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmsac_vv_f32m4 (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmsac_sv_f32m4 (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
// masked functions
vfloat32m2_t vwmacc_vv_f16m1_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmacc_sv_f16m1_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmacc_vv_f16m2_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmacc_sv_f16m2_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmacc_vv_f16m4_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmacc_sv_f16m4_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmacc_vv_f32m1_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmacc_sv_f32m1_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmacc_vv_f32m2_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmacc_sv_f32m2_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmacc_vv_f32m4_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmacc_sv_f32m4_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmacc_vv_f16m1_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmacc_sv_f16m1_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmacc_vv_f16m2_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmacc_sv_f16m2_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmacc_vv_f16m4_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmacc_sv_f16m4_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmacc_vv_f32m1_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmacc_sv_f32m1_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmacc_vv_f32m2_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmacc_sv_f32m2_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmacc_vv_f32m4_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmacc_sv_f32m4_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwmsac_vv_f16m1_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmsac_sv_f16m1_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmsac_vv_f16m2_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmsac_sv_f16m2_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmsac_vv_f16m4_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmsac_sv_f16m4_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmsac_vv_f32m1_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmsac_sv_f32m1_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmsac_vv_f32m2_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmsac_sv_f32m2_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmsac_vv_f32m4_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmsac_sv_f32m4_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmsac_vv_f16m1_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmsac_sv_f16m1_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmsac_vv_f16m2_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmsac_sv_f16m2_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmsac_vv_f16m4_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmsac_sv_f16m4_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmsac_vv_f32m1_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmsac_sv_f32m1_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmsac_vv_f32m2_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmsac_sv_f32m2_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmsac_vv_f32m4_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmsac_sv_f32m4_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
```
### [Vector Floating-Point Square-Root Functions]()

**Prototypes:**
``` C
vfloat16m1_t vsqrt_v_f16m1 (vfloat16m1_t op1);
vfloat16m2_t vsqrt_v_f16m2 (vfloat16m2_t op1);
vfloat16m4_t vsqrt_v_f16m4 (vfloat16m4_t op1);
vfloat16m8_t vsqrt_v_f16m8 (vfloat16m8_t op1);
vfloat32m1_t vsqrt_v_f32m1 (vfloat32m1_t op1);
vfloat32m2_t vsqrt_v_f32m2 (vfloat32m2_t op1);
vfloat32m4_t vsqrt_v_f32m4 (vfloat32m4_t op1);
vfloat32m8_t vsqrt_v_f32m8 (vfloat32m8_t op1);
vfloat64m1_t vsqrt_v_f64m1 (vfloat64m1_t op1);
vfloat64m2_t vsqrt_v_f64m2 (vfloat64m2_t op1);
vfloat64m4_t vsqrt_v_f64m4 (vfloat64m4_t op1);
vfloat64m8_t vsqrt_v_f64m8 (vfloat64m8_t op1);
// masked functions
vfloat16m1_t vsqrt_v_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1);
vfloat16m2_t vsqrt_v_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1);
vfloat16m4_t vsqrt_v_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1);
vfloat16m8_t vsqrt_v_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1);
vfloat32m1_t vsqrt_v_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1);
vfloat32m2_t vsqrt_v_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1);
vfloat32m4_t vsqrt_v_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1);
vfloat32m8_t vsqrt_v_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1);
vfloat64m1_t vsqrt_v_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1);
vfloat64m2_t vsqrt_v_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1);
vfloat64m4_t vsqrt_v_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1);
vfloat64m8_t vsqrt_v_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1);
```
### [Vector Floating-Point MIN/MAX Functions]()

**Prototypes:**
``` C
vfloat16m1_t vmin_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmin_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmin_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmin_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmin_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmin_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmin_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmin_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmin_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmin_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmin_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmin_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmin_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmin_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmin_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmin_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmin_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmin_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmin_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmin_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmin_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmin_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmin_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmin_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vmax_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmax_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmax_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmax_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmax_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmax_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmax_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmax_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmax_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmax_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmax_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmax_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmax_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmax_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmax_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmax_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmax_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmax_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmax_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmax_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmax_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmax_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmax_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmax_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vmin_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmin_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmin_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmin_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmin_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmin_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmin_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmin_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmin_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmin_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmin_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmin_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmin_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmin_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmin_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmin_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmin_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmin_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmin_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmin_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmin_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmin_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmin_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmin_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vmax_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmax_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmax_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmax_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmax_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmax_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmax_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmax_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmax_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmax_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmax_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmax_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmax_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmax_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmax_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmax_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmax_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmax_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmax_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmax_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmax_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmax_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmax_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmax_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Sign-Injection Functions]()

**Prototypes:**
``` C
vfloat16m1_t vsgnj_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnj_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnj_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnj_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnj_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnj_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnj_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnj_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnj_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnj_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnj_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnj_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnj_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnj_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnj_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnj_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnj_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnj_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnj_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnj_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnj_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnj_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnj_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnj_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjn_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjn_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjn_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjn_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjn_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjn_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjn_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjn_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjn_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjn_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjn_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjn_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjn_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjn_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjn_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjn_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjn_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjn_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjn_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjn_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjn_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjn_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjn_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjn_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjx_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjx_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjx_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjx_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjx_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjx_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjx_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjx_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjx_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjx_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjx_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjx_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjx_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjx_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjx_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjx_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjx_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjx_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjx_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjx_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjx_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjx_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjx_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjx_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vsgnj_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnj_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnj_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnj_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnj_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnj_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnj_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnj_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnj_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnj_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnj_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnj_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnj_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnj_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnj_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnj_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnj_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnj_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnj_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnj_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnj_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnj_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnj_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnj_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjn_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjn_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjn_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjn_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjn_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjn_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjn_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjn_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjn_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjn_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjn_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjn_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjn_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjn_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjn_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjn_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjn_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjn_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjn_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjn_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjn_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjn_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjn_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjn_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjx_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjx_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjx_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjx_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjx_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjx_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjx_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjx_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjx_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjx_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjx_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjx_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjx_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjx_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjx_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjx_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjx_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjx_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjx_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjx_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjx_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjx_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjx_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjx_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Compare Functions]()

**Prototypes:**
``` C
vbool16_t vseteq_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vseteq_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vbool8_t vseteq_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vseteq_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vbool4_t vseteq_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vseteq_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vbool2_t vseteq_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vseteq_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vbool32_t vseteq_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vseteq_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vbool16_t vseteq_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vseteq_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vbool8_t vseteq_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vseteq_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vbool4_t vseteq_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vseteq_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vbool64_t vseteq_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vseteq_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vbool32_t vseteq_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vseteq_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vbool16_t vseteq_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vseteq_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vbool8_t vseteq_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vseteq_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetne_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetne_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetne_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetne_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetne_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetne_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetne_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetne_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetne_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetne_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetne_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetne_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetne_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetne_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetne_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetne_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetne_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetne_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetne_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetne_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetne_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetne_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetne_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetne_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetlt_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetlt_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetlt_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetlt_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetlt_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetlt_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetlt_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetlt_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetlt_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetlt_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetlt_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetlt_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetlt_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetlt_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetlt_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetlt_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetlt_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetlt_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetlt_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetlt_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetlt_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetlt_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetlt_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetlt_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetle_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetle_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetle_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetle_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetle_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetle_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetle_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetle_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetle_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetle_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetle_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetle_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetle_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetle_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetle_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetle_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetle_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetle_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetle_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetle_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetle_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetle_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetle_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetle_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetgt_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetgt_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetgt_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetgt_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetgt_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetgt_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetgt_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetgt_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetgt_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetgt_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetgt_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetgt_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetgt_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetgt_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetgt_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetgt_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetgt_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetgt_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetgt_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetgt_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetgt_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetgt_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetgt_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetgt_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetge_vv_f16m1 (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetge_vs_f16m1 (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetge_vv_f16m2 (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetge_vs_f16m2 (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetge_vv_f16m4 (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetge_vs_f16m4 (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetge_vv_f16m8 (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetge_vs_f16m8 (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetge_vv_f32m1 (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetge_vs_f32m1 (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetge_vv_f32m2 (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetge_vs_f32m2 (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetge_vv_f32m4 (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetge_vs_f32m4 (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetge_vv_f32m8 (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetge_vs_f32m8 (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetge_vv_f64m1 (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetge_vs_f64m1 (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetge_vv_f64m2 (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetge_vs_f64m2 (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetge_vv_f64m4 (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetge_vs_f64m4 (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetge_vv_f64m8 (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetge_vs_f64m8 (vfloat64m8_t op1, float64_t op2);
// masked functions
vbool16_t vseteq_vv_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vseteq_vs_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vseteq_vv_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vseteq_vs_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vseteq_vv_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vseteq_vs_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vseteq_vv_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vseteq_vs_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vseteq_vv_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vseteq_vs_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vseteq_vv_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vseteq_vs_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vseteq_vv_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vseteq_vs_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vseteq_vv_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vseteq_vs_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vseteq_vv_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vseteq_vs_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vseteq_vv_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vseteq_vs_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vseteq_vv_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vseteq_vs_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vseteq_vv_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vseteq_vs_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetne_vv_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetne_vs_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetne_vv_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetne_vs_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetne_vv_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetne_vs_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetne_vv_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetne_vs_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetne_vv_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetne_vs_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetne_vv_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetne_vs_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetne_vv_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetne_vs_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetne_vv_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetne_vs_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetne_vv_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetne_vs_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetne_vv_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetne_vs_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetne_vv_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetne_vs_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetne_vv_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetne_vs_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetlt_vv_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetlt_vs_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetlt_vv_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetlt_vs_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetlt_vv_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetlt_vs_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetlt_vv_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetlt_vs_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetlt_vv_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetlt_vs_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetlt_vv_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetlt_vs_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetlt_vv_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetlt_vs_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetlt_vv_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetlt_vs_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetlt_vv_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetlt_vs_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetlt_vv_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetlt_vs_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetlt_vv_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetlt_vs_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetlt_vv_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetlt_vs_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetle_vv_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetle_vs_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetle_vv_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetle_vs_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetle_vv_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetle_vs_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetle_vv_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetle_vs_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetle_vv_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetle_vs_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetle_vv_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetle_vs_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetle_vv_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetle_vs_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetle_vv_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetle_vs_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetle_vv_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetle_vs_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetle_vv_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetle_vs_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetle_vv_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetle_vs_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetle_vv_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetle_vs_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetgt_vv_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetgt_vs_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetgt_vv_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetgt_vs_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetgt_vv_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetgt_vs_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetgt_vv_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetgt_vs_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetgt_vv_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetgt_vs_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetgt_vv_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetgt_vs_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetgt_vv_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetgt_vs_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetgt_vv_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetgt_vs_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetgt_vv_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetgt_vs_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetgt_vv_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetgt_vs_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetgt_vv_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetgt_vs_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetgt_vv_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetgt_vs_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetge_vv_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetge_vs_f16m1_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetge_vv_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetge_vs_f16m2_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetge_vv_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetge_vs_f16m4_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetge_vv_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetge_vs_f16m8_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetge_vv_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetge_vs_f32m1_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetge_vv_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetge_vs_f32m2_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetge_vv_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetge_vs_f32m4_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetge_vv_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetge_vs_f32m8_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetge_vv_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetge_vs_f64m1_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetge_vv_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetge_vs_f64m2_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetge_vv_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetge_vs_f64m4_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetge_vv_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetge_vs_f64m8_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Classify Functions]()

**Prototypes:**
``` C
vuint16m1_t vclass_v_f16m1 (vfloat16m1_t op1);
vuint16m2_t vclass_v_f16m2 (vfloat16m2_t op1);
vuint16m4_t vclass_v_f16m4 (vfloat16m4_t op1);
vuint16m8_t vclass_v_f16m8 (vfloat16m8_t op1);
vuint32m1_t vclass_v_f32m1 (vfloat32m1_t op1);
vuint32m2_t vclass_v_f32m2 (vfloat32m2_t op1);
vuint32m4_t vclass_v_f32m4 (vfloat32m4_t op1);
vuint32m8_t vclass_v_f32m8 (vfloat32m8_t op1);
vuint64m1_t vclass_v_f64m1 (vfloat64m1_t op1);
vuint64m2_t vclass_v_f64m2 (vfloat64m2_t op1);
vuint64m4_t vclass_v_f64m4 (vfloat64m4_t op1);
vuint64m8_t vclass_v_f64m8 (vfloat64m8_t op1);
// masked functions
vuint16m1_t vclass_v_f16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t op1);
vuint16m2_t vclass_v_f16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t op1);
vuint16m4_t vclass_v_f16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t op1);
vuint16m8_t vclass_v_f16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t op1);
vuint32m1_t vclass_v_f32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t op1);
vuint32m2_t vclass_v_f32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t op1);
vuint32m4_t vclass_v_f32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t op1);
vuint32m8_t vclass_v_f32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t op1);
vuint64m1_t vclass_v_f64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t op1);
vuint64m2_t vclass_v_f64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t op1);
vuint64m4_t vclass_v_f64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t op1);
vuint64m8_t vclass_v_f64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t op1);
```
### [Vector Floating-Point Merge Functions]()

**Prototypes:**
``` C
vfloat16m1_t vmerge_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmerge_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmerge_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmerge_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmerge_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmerge_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmerge_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmerge_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmerge_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmerge_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmerge_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmerge_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Move Functions]()

**Prototypes:**
``` C
vfloat16m1_t vsplat_s_f16m1 (float16_t src);
vfloat16m2_t vsplat_s_f16m2 (float16_t src);
vfloat16m4_t vsplat_s_f16m4 (float16_t src);
vfloat16m8_t vsplat_s_f16m8 (float16_t src);
vfloat32m1_t vsplat_s_f32m1 (float32_t src);
vfloat32m2_t vsplat_s_f32m2 (float32_t src);
vfloat32m4_t vsplat_s_f32m4 (float32_t src);
vfloat32m8_t vsplat_s_f32m8 (float32_t src);
vfloat64m1_t vsplat_s_f64m1 (float64_t src);
vfloat64m2_t vsplat_s_f64m2 (float64_t src);
vfloat64m4_t vsplat_s_f64m4 (float64_t src);
vfloat64m8_t vsplat_s_f64m8 (float64_t src);
```
### [Single-Width Floating-Point/Integer Type-Convert Functions]()

**Prototypes:**
``` C
vint16m1_t vcvt_i16_f16_v_16m1 (vfloat16m1_t src);
vint16m2_t vcvt_i16_f16_v_16m2 (vfloat16m2_t src);
vint16m4_t vcvt_i16_f16_v_16m4 (vfloat16m4_t src);
vint16m8_t vcvt_i16_f16_v_16m8 (vfloat16m8_t src);
vuint16m1_t vcvt_u16_f16_v_16m1 (vfloat16m1_t src);
vuint16m2_t vcvt_u16_f16_v_16m2 (vfloat16m2_t src);
vuint16m4_t vcvt_u16_f16_v_16m4 (vfloat16m4_t src);
vuint16m8_t vcvt_u16_f16_v_16m8 (vfloat16m8_t src);
vfloat16m1_t vcvt_f16_i16_v_16m1 (vint16m1_t src);
vfloat16m2_t vcvt_f16_i16_v_16m2 (vint16m2_t src);
vfloat16m4_t vcvt_f16_i16_v_16m4 (vint16m4_t src);
vfloat16m8_t vcvt_f16_i16_v_16m8 (vint16m8_t src);
vfloat16m1_t vcvt_f16_u16_v_16m1 (vuint16m1_t src);
vfloat16m2_t vcvt_f16_u16_v_16m2 (vuint16m2_t src);
vfloat16m4_t vcvt_f16_u16_v_16m4 (vuint16m4_t src);
vfloat16m8_t vcvt_f16_u16_v_16m8 (vuint16m8_t src);
vint32m1_t vcvt_i32_f32_v_32m1 (vfloat32m1_t src);
vint32m2_t vcvt_i32_f32_v_32m2 (vfloat32m2_t src);
vint32m4_t vcvt_i32_f32_v_32m4 (vfloat32m4_t src);
vint32m8_t vcvt_i32_f32_v_32m8 (vfloat32m8_t src);
vuint32m1_t vcvt_u32_f32_v_32m1 (vfloat32m1_t src);
vuint32m2_t vcvt_u32_f32_v_32m2 (vfloat32m2_t src);
vuint32m4_t vcvt_u32_f32_v_32m4 (vfloat32m4_t src);
vuint32m8_t vcvt_u32_f32_v_32m8 (vfloat32m8_t src);
vfloat32m1_t vcvt_f32_i32_v_32m1 (vint32m1_t src);
vfloat32m2_t vcvt_f32_i32_v_32m2 (vint32m2_t src);
vfloat32m4_t vcvt_f32_i32_v_32m4 (vint32m4_t src);
vfloat32m8_t vcvt_f32_i32_v_32m8 (vint32m8_t src);
vfloat32m1_t vcvt_f32_u32_v_32m1 (vuint32m1_t src);
vfloat32m2_t vcvt_f32_u32_v_32m2 (vuint32m2_t src);
vfloat32m4_t vcvt_f32_u32_v_32m4 (vuint32m4_t src);
vfloat32m8_t vcvt_f32_u32_v_32m8 (vuint32m8_t src);
vint64m1_t vcvt_i64_f64_v_64m1 (vfloat64m1_t src);
vint64m2_t vcvt_i64_f64_v_64m2 (vfloat64m2_t src);
vint64m4_t vcvt_i64_f64_v_64m4 (vfloat64m4_t src);
vint64m8_t vcvt_i64_f64_v_64m8 (vfloat64m8_t src);
vuint64m1_t vcvt_u64_f64_v_64m1 (vfloat64m1_t src);
vuint64m2_t vcvt_u64_f64_v_64m2 (vfloat64m2_t src);
vuint64m4_t vcvt_u64_f64_v_64m4 (vfloat64m4_t src);
vuint64m8_t vcvt_u64_f64_v_64m8 (vfloat64m8_t src);
vfloat64m1_t vcvt_f64_i64_v_64m1 (vint64m1_t src);
vfloat64m2_t vcvt_f64_i64_v_64m2 (vint64m2_t src);
vfloat64m4_t vcvt_f64_i64_v_64m4 (vint64m4_t src);
vfloat64m8_t vcvt_f64_i64_v_64m8 (vint64m8_t src);
vfloat64m1_t vcvt_f64_u64_v_64m1 (vuint64m1_t src);
vfloat64m2_t vcvt_f64_u64_v_64m2 (vuint64m2_t src);
vfloat64m4_t vcvt_f64_u64_v_64m4 (vuint64m4_t src);
vfloat64m8_t vcvt_f64_u64_v_64m8 (vuint64m8_t src);
// masked functions
vint16m1_t vcvt_i16_f16_v_16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src);
vint16m2_t vcvt_i16_f16_v_16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src);
vint16m4_t vcvt_i16_f16_v_16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src);
vint16m8_t vcvt_i16_f16_v_16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src);
vuint16m1_t vcvt_u16_f16_v_16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src);
vuint16m2_t vcvt_u16_f16_v_16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src);
vuint16m4_t vcvt_u16_f16_v_16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src);
vuint16m8_t vcvt_u16_f16_v_16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src);
vfloat16m1_t vcvt_f16_i16_v_16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vint16m1_t src);
vfloat16m2_t vcvt_f16_i16_v_16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vint16m2_t src);
vfloat16m4_t vcvt_f16_i16_v_16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vint16m4_t src);
vfloat16m8_t vcvt_f16_i16_v_16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vint16m8_t src);
vfloat16m1_t vcvt_f16_u16_v_16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vuint16m1_t src);
vfloat16m2_t vcvt_f16_u16_v_16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vuint16m2_t src);
vfloat16m4_t vcvt_f16_u16_v_16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vuint16m4_t src);
vfloat16m8_t vcvt_f16_u16_v_16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vuint16m8_t src);
vint32m1_t vcvt_i32_f32_v_32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src);
vint32m2_t vcvt_i32_f32_v_32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src);
vint32m4_t vcvt_i32_f32_v_32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src);
vint32m8_t vcvt_i32_f32_v_32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src);
vuint32m1_t vcvt_u32_f32_v_32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src);
vuint32m2_t vcvt_u32_f32_v_32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src);
vuint32m4_t vcvt_u32_f32_v_32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src);
vuint32m8_t vcvt_u32_f32_v_32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src);
vfloat32m1_t vcvt_f32_i32_v_32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vint32m1_t src);
vfloat32m2_t vcvt_f32_i32_v_32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vint32m2_t src);
vfloat32m4_t vcvt_f32_i32_v_32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vint32m4_t src);
vfloat32m8_t vcvt_f32_i32_v_32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vint32m8_t src);
vfloat32m1_t vcvt_f32_u32_v_32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vuint32m1_t src);
vfloat32m2_t vcvt_f32_u32_v_32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vuint32m2_t src);
vfloat32m4_t vcvt_f32_u32_v_32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vuint32m4_t src);
vfloat32m8_t vcvt_f32_u32_v_32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vuint32m8_t src);
vint64m1_t vcvt_i64_f64_v_64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src);
vint64m2_t vcvt_i64_f64_v_64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src);
vint64m4_t vcvt_i64_f64_v_64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src);
vint64m8_t vcvt_i64_f64_v_64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src);
vuint64m1_t vcvt_u64_f64_v_64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src);
vuint64m2_t vcvt_u64_f64_v_64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src);
vuint64m4_t vcvt_u64_f64_v_64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src);
vuint64m8_t vcvt_u64_f64_v_64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src);
vfloat64m1_t vcvt_f64_i64_v_64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vint64m1_t src);
vfloat64m2_t vcvt_f64_i64_v_64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vint64m2_t src);
vfloat64m4_t vcvt_f64_i64_v_64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vint64m4_t src);
vfloat64m8_t vcvt_f64_i64_v_64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vint64m8_t src);
vfloat64m1_t vcvt_f64_u64_v_64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vuint64m1_t src);
vfloat64m2_t vcvt_f64_u64_v_64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vuint64m2_t src);
vfloat64m4_t vcvt_f64_u64_v_64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vuint64m4_t src);
vfloat64m8_t vcvt_f64_u64_v_64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vuint64m8_t src);
```
### [Widening Floating-Point/Integer Type-Convert Functions]()

**Prototypes:**
``` C
vint32m2_t vcvt_i32_f16_v_16m1 (vfloat16m1_t src);
vint32m4_t vcvt_i32_f16_v_16m2 (vfloat16m2_t src);
vint32m8_t vcvt_i32_f16_v_16m4 (vfloat16m4_t src);
vint32m2_t vcvt_i32_i16_v_16m1 (vint16m1_t src);
vint32m4_t vcvt_i32_i16_v_16m2 (vint16m2_t src);
vint32m8_t vcvt_i32_i16_v_16m4 (vint16m4_t src);
vuint32m2_t vcvt_u32_u16_v_16m1 (vuint16m1_t src);
vuint32m4_t vcvt_u32_u16_v_16m2 (vuint16m2_t src);
vuint32m8_t vcvt_u32_u16_v_16m4 (vuint16m4_t src);
vuint32m2_t vcvt_u32_f16_v_16m1 (vfloat16m1_t src);
vuint32m4_t vcvt_u32_f16_v_16m2 (vfloat16m2_t src);
vuint32m8_t vcvt_u32_f16_v_16m4 (vfloat16m4_t src);
vfloat32m2_t vcvt_f32_i16_v_16m1 (vint16m1_t src);
vfloat32m4_t vcvt_f32_i16_v_16m2 (vint16m2_t src);
vfloat32m8_t vcvt_f32_i16_v_16m4 (vint16m4_t src);
vfloat32m2_t vcvt_f32_u16_v_16m1 (vuint16m1_t src);
vfloat32m4_t vcvt_f32_u16_v_16m2 (vuint16m2_t src);
vfloat32m8_t vcvt_f32_u16_v_16m4 (vuint16m4_t src);
vfloat32m2_t vcvt_f32_f16_v_16m1 (vfloat16m1_t src);
vfloat32m4_t vcvt_f32_f16_v_16m2 (vfloat16m2_t src);
vfloat32m8_t vcvt_f32_f16_v_16m4 (vfloat16m4_t src);
vint64m2_t vcvt_i64_f32_v_32m1 (vfloat32m1_t src);
vint64m4_t vcvt_i64_f32_v_32m2 (vfloat32m2_t src);
vint64m8_t vcvt_i64_f32_v_32m4 (vfloat32m4_t src);
vint64m2_t vcvt_i64_i32_v_32m1 (vint32m1_t src);
vint64m4_t vcvt_i64_i32_v_32m2 (vint32m2_t src);
vint64m8_t vcvt_i64_i32_v_32m4 (vint32m4_t src);
vuint64m2_t vcvt_u64_u32_v_32m1 (vuint32m1_t src);
vuint64m4_t vcvt_u64_u32_v_32m2 (vuint32m2_t src);
vuint64m8_t vcvt_u64_u32_v_32m4 (vuint32m4_t src);
vuint64m2_t vcvt_u64_f32_v_32m1 (vfloat32m1_t src);
vuint64m4_t vcvt_u64_f32_v_32m2 (vfloat32m2_t src);
vuint64m8_t vcvt_u64_f32_v_32m4 (vfloat32m4_t src);
vfloat64m2_t vcvt_f64_i32_v_32m1 (vint32m1_t src);
vfloat64m4_t vcvt_f64_i32_v_32m2 (vint32m2_t src);
vfloat64m8_t vcvt_f64_i32_v_32m4 (vint32m4_t src);
vfloat64m2_t vcvt_f64_u32_v_32m1 (vuint32m1_t src);
vfloat64m4_t vcvt_f64_u32_v_32m2 (vuint32m2_t src);
vfloat64m8_t vcvt_f64_u32_v_32m4 (vuint32m4_t src);
vfloat64m2_t vcvt_f64_f32_v_32m1 (vfloat32m1_t src);
vfloat64m4_t vcvt_f64_f32_v_32m2 (vfloat32m2_t src);
vfloat64m8_t vcvt_f64_f32_v_32m4 (vfloat32m4_t src);
// masked functions
vint32m2_t vcvt_i32_f16_v_16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src);
vint32m4_t vcvt_i32_f16_v_16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src);
vint32m8_t vcvt_i32_f16_v_16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src);
vint32m2_t vcvt_i32_i16_v_16m1_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t src);
vint32m4_t vcvt_i32_i16_v_16m2_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t src);
vint32m8_t vcvt_i32_i16_v_16m4_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t src);
vuint32m2_t vcvt_u32_u16_v_16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t src);
vuint32m4_t vcvt_u32_u16_v_16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t src);
vuint32m8_t vcvt_u32_u16_v_16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t src);
vuint32m2_t vcvt_u32_f16_v_16m1_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src);
vuint32m4_t vcvt_u32_f16_v_16m2_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src);
vuint32m8_t vcvt_u32_f16_v_16m4_mask (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src);
vfloat32m2_t vcvt_f32_i16_v_16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vint16m1_t src);
vfloat32m4_t vcvt_f32_i16_v_16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vint16m2_t src);
vfloat32m8_t vcvt_f32_i16_v_16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vint16m4_t src);
vfloat32m2_t vcvt_f32_u16_v_16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vuint16m1_t src);
vfloat32m4_t vcvt_f32_u16_v_16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vuint16m2_t src);
vfloat32m8_t vcvt_f32_u16_v_16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vuint16m4_t src);
vfloat32m2_t vcvt_f32_f16_v_16m1_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t src);
vfloat32m4_t vcvt_f32_f16_v_16m2_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t src);
vfloat32m8_t vcvt_f32_f16_v_16m4_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t src);
vint64m2_t vcvt_i64_f32_v_32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src);
vint64m4_t vcvt_i64_f32_v_32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src);
vint64m8_t vcvt_i64_f32_v_32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src);
vint64m2_t vcvt_i64_i32_v_32m1_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t src);
vint64m4_t vcvt_i64_i32_v_32m2_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t src);
vint64m8_t vcvt_i64_i32_v_32m4_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t src);
vuint64m2_t vcvt_u64_u32_v_32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t src);
vuint64m4_t vcvt_u64_u32_v_32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t src);
vuint64m8_t vcvt_u64_u32_v_32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t src);
vuint64m2_t vcvt_u64_f32_v_32m1_mask (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src);
vuint64m4_t vcvt_u64_f32_v_32m2_mask (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src);
vuint64m8_t vcvt_u64_f32_v_32m4_mask (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src);
vfloat64m2_t vcvt_f64_i32_v_32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vint32m1_t src);
vfloat64m4_t vcvt_f64_i32_v_32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vint32m2_t src);
vfloat64m8_t vcvt_f64_i32_v_32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vint32m4_t src);
vfloat64m2_t vcvt_f64_u32_v_32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vuint32m1_t src);
vfloat64m4_t vcvt_f64_u32_v_32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vuint32m2_t src);
vfloat64m8_t vcvt_f64_u32_v_32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vuint32m4_t src);
vfloat64m2_t vcvt_f64_f32_v_32m1_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t src);
vfloat64m4_t vcvt_f64_f32_v_32m2_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t src);
vfloat64m8_t vcvt_f64_f32_v_32m4_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t src);
```
### [Narrowing Floating-Point/Integer Type-Convert Functions]()

**Prototypes:**
``` C
vint16m1_t vcvt_i16_f32_v_32m2 (vfloat32m2_t src);
vint16m2_t vcvt_i16_f32_v_32m4 (vfloat32m4_t src);
vint16m4_t vcvt_i16_f32_v_32m8 (vfloat32m8_t src);
vuint16m1_t vcvt_u16_f32_v_32m2 (vfloat32m2_t src);
vuint16m2_t vcvt_u16_f32_v_32m4 (vfloat32m4_t src);
vuint16m4_t vcvt_u16_f32_v_32m8 (vfloat32m8_t src);
vfloat16m1_t vcvt_f16_i32_v_32m2 (vint32m2_t src);
vfloat16m2_t vcvt_f16_i32_v_32m4 (vint32m4_t src);
vfloat16m4_t vcvt_f16_i32_v_32m8 (vint32m8_t src);
vfloat16m1_t vcvt_f16_u32_v_32m2 (vuint32m2_t src);
vfloat16m2_t vcvt_f16_u32_v_32m4 (vuint32m4_t src);
vfloat16m4_t vcvt_f16_u32_v_32m8 (vuint32m8_t src);
vfloat16m1_t vcvt_f16_f32_v_32m2 (vfloat32m2_t src);
vfloat16m1_t vcvt_rod_f16_f32_v_32m2 (vfloat32m2_t src);
vfloat16m2_t vcvt_f16_f32_v_32m4 (vfloat32m4_t src);
vfloat16m2_t vcvt_rod_f16_f32_v_32m4 (vfloat32m4_t src);
vfloat16m4_t vcvt_f16_f32_v_32m8 (vfloat32m8_t src);
vfloat16m4_t vcvt_rod_f16_f32_v_32m8 (vfloat32m8_t src);
vint32m1_t vcvt_i32_f64_v_64m2 (vfloat64m2_t src);
vint32m2_t vcvt_i32_f64_v_64m4 (vfloat64m4_t src);
vint32m4_t vcvt_i32_f64_v_64m8 (vfloat64m8_t src);
vuint32m1_t vcvt_u32_f64_v_64m2 (vfloat64m2_t src);
vuint32m2_t vcvt_u32_f64_v_64m4 (vfloat64m4_t src);
vuint32m4_t vcvt_u32_f64_v_64m8 (vfloat64m8_t src);
vfloat32m1_t vcvt_f32_i64_v_64m2 (vint64m2_t src);
vfloat32m2_t vcvt_f32_i64_v_64m4 (vint64m4_t src);
vfloat32m4_t vcvt_f32_i64_v_64m8 (vint64m8_t src);
vfloat32m1_t vcvt_f32_u64_v_64m2 (vuint64m2_t src);
vfloat32m2_t vcvt_f32_u64_v_64m4 (vuint64m4_t src);
vfloat32m4_t vcvt_f32_u64_v_64m8 (vuint64m8_t src);
vfloat32m1_t vcvt_f32_f64_v_64m2 (vfloat64m2_t src);
vfloat32m1_t vcvt_rod_f32_f64_v_64m2 (vfloat64m2_t src);
vfloat32m2_t vcvt_f32_f64_v_64m4 (vfloat64m4_t src);
vfloat32m2_t vcvt_rod_f32_f64_v_64m4 (vfloat64m4_t src);
vfloat32m4_t vcvt_f32_f64_v_64m8 (vfloat64m8_t src);
vfloat32m4_t vcvt_rod_f32_f64_v_64m8 (vfloat64m8_t src);
// masked functions
vint16m1_t vcvt_i16_f32_v_32m2_mask (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src);
vint16m2_t vcvt_i16_f32_v_32m4_mask (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src);
vint16m4_t vcvt_i16_f32_v_32m8_mask (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src);
vuint16m1_t vcvt_u16_f32_v_32m2_mask (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src);
vuint16m2_t vcvt_u16_f32_v_32m4_mask (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src);
vuint16m4_t vcvt_u16_f32_v_32m8_mask (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src);
vfloat16m1_t vcvt_f16_i32_v_32m2_mask (vbool16_t mask, vfloat16m1_t maskedoff, vint32m2_t src);
vfloat16m2_t vcvt_f16_i32_v_32m4_mask (vbool8_t mask, vfloat16m2_t maskedoff, vint32m4_t src);
vfloat16m4_t vcvt_f16_i32_v_32m8_mask (vbool4_t mask, vfloat16m4_t maskedoff, vint32m8_t src);
vfloat16m1_t vcvt_f16_u32_v_32m2_mask (vbool16_t mask, vfloat16m1_t maskedoff, vuint32m2_t src);
vfloat16m2_t vcvt_f16_u32_v_32m4_mask (vbool8_t mask, vfloat16m2_t maskedoff, vuint32m4_t src);
vfloat16m4_t vcvt_f16_u32_v_32m8_mask (vbool4_t mask, vfloat16m4_t maskedoff, vuint32m8_t src);
vfloat16m1_t vcvt_f16_f32_v_32m2_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src);
vfloat16m1_t vcvt_rod_f16_f32_v_32m2_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src);
vfloat16m2_t vcvt_f16_f32_v_32m4_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src);
vfloat16m2_t vcvt_rod_f16_f32_v_32m4_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src);
vfloat16m4_t vcvt_f16_f32_v_32m8_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src);
vfloat16m4_t vcvt_rod_f16_f32_v_32m8_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src);
vint32m1_t vcvt_i32_f64_v_64m2_mask (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src);
vint32m2_t vcvt_i32_f64_v_64m4_mask (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src);
vint32m4_t vcvt_i32_f64_v_64m8_mask (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src);
vuint32m1_t vcvt_u32_f64_v_64m2_mask (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src);
vuint32m2_t vcvt_u32_f64_v_64m4_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src);
vuint32m4_t vcvt_u32_f64_v_64m8_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src);
vfloat32m1_t vcvt_f32_i64_v_64m2_mask (vbool32_t mask, vfloat32m1_t maskedoff, vint64m2_t src);
vfloat32m2_t vcvt_f32_i64_v_64m4_mask (vbool16_t mask, vfloat32m2_t maskedoff, vint64m4_t src);
vfloat32m4_t vcvt_f32_i64_v_64m8_mask (vbool8_t mask, vfloat32m4_t maskedoff, vint64m8_t src);
vfloat32m1_t vcvt_f32_u64_v_64m2_mask (vbool32_t mask, vfloat32m1_t maskedoff, vuint64m2_t src);
vfloat32m2_t vcvt_f32_u64_v_64m4_mask (vbool16_t mask, vfloat32m2_t maskedoff, vuint64m4_t src);
vfloat32m4_t vcvt_f32_u64_v_64m8_mask (vbool8_t mask, vfloat32m4_t maskedoff, vuint64m8_t src);
vfloat32m1_t vcvt_f32_f64_v_64m2_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src);
vfloat32m1_t vcvt_rod_f32_f64_v_64m2_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src);
vfloat32m2_t vcvt_f32_f64_v_64m4_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src);
vfloat32m2_t vcvt_rod_f32_f64_v_64m4_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src);
vfloat32m4_t vcvt_f32_f64_v_64m8_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src);
vfloat32m4_t vcvt_rod_f32_f64_v_64m8_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src);
```
## Vector Reduction Functions:

### [Vector Single-Width Integer Reduction Functions]()

**Prototypes:**
``` C
vint8m1_t vredsum_vs_i8m1 (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredsum_vs_i8m2 (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredsum_vs_i8m4 (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredsum_vs_i8m8 (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredsum_vs_i16m1 (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredsum_vs_i16m2 (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredsum_vs_i16m4 (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredsum_vs_i16m8 (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredsum_vs_i32m1 (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredsum_vs_i32m2 (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredsum_vs_i32m4 (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredsum_vs_i32m8 (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredsum_vs_i64m1 (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredsum_vs_i64m2 (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredsum_vs_i64m4 (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredsum_vs_i64m8 (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredsum_vs_u8m1 (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_vs_u8m2 (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_vs_u8m4 (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_vs_u8m8 (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredsum_vs_u16m1 (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_vs_u16m2 (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_vs_u16m4 (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_vs_u16m8 (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredsum_vs_u32m1 (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_vs_u32m2 (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_vs_u32m4 (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_vs_u32m8 (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredsum_vs_u64m1 (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_vs_u64m2 (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_vs_u64m4 (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_vs_u64m8 (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmax_vs_i8m1 (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmax_vs_i8m2 (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmax_vs_i8m4 (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmax_vs_i8m8 (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmax_vs_i16m1 (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmax_vs_i16m2 (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmax_vs_i16m4 (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmax_vs_i16m8 (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmax_vs_i32m1 (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmax_vs_i32m2 (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmax_vs_i32m4 (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmax_vs_i32m8 (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmax_vs_i64m1 (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmax_vs_i64m2 (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmax_vs_i64m4 (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmax_vs_i64m8 (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmax_vs_u8m1 (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_vs_u8m2 (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_vs_u8m4 (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_vs_u8m8 (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmax_vs_u16m1 (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_vs_u16m2 (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_vs_u16m4 (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_vs_u16m8 (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmax_vs_u32m1 (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_vs_u32m2 (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_vs_u32m4 (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_vs_u32m8 (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmax_vs_u64m1 (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_vs_u64m2 (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_vs_u64m4 (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_vs_u64m8 (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmin_vs_i8m1 (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmin_vs_i8m2 (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmin_vs_i8m4 (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmin_vs_i8m8 (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmin_vs_i16m1 (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmin_vs_i16m2 (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmin_vs_i16m4 (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmin_vs_i16m8 (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmin_vs_i32m1 (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmin_vs_i32m2 (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmin_vs_i32m4 (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmin_vs_i32m8 (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmin_vs_i64m1 (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmin_vs_i64m2 (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmin_vs_i64m4 (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmin_vs_i64m8 (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmin_vs_u8m1 (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_vs_u8m2 (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_vs_u8m4 (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_vs_u8m8 (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmin_vs_u16m1 (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_vs_u16m2 (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_vs_u16m4 (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_vs_u16m8 (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmin_vs_u32m1 (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_vs_u32m2 (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_vs_u32m4 (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_vs_u32m8 (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmin_vs_u64m1 (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_vs_u64m2 (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_vs_u64m4 (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_vs_u64m8 (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredand_vs_i8m1 (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredand_vs_i8m2 (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredand_vs_i8m4 (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredand_vs_i8m8 (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredand_vs_i16m1 (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredand_vs_i16m2 (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredand_vs_i16m4 (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredand_vs_i16m8 (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredand_vs_i32m1 (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredand_vs_i32m2 (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredand_vs_i32m4 (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredand_vs_i32m8 (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredand_vs_i64m1 (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredand_vs_i64m2 (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredand_vs_i64m4 (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredand_vs_i64m8 (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredand_vs_u8m1 (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_vs_u8m2 (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_vs_u8m4 (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_vs_u8m8 (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredand_vs_u16m1 (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_vs_u16m2 (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_vs_u16m4 (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_vs_u16m8 (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredand_vs_u32m1 (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_vs_u32m2 (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_vs_u32m4 (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_vs_u32m8 (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredand_vs_u64m1 (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_vs_u64m2 (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_vs_u64m4 (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_vs_u64m8 (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredor_vs_i8m1 (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredor_vs_i8m2 (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredor_vs_i8m4 (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredor_vs_i8m8 (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredor_vs_i16m1 (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredor_vs_i16m2 (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredor_vs_i16m4 (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredor_vs_i16m8 (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredor_vs_i32m1 (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredor_vs_i32m2 (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredor_vs_i32m4 (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredor_vs_i32m8 (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredor_vs_i64m1 (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredor_vs_i64m2 (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredor_vs_i64m4 (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredor_vs_i64m8 (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredor_vs_u8m1 (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_vs_u8m2 (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_vs_u8m4 (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_vs_u8m8 (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredor_vs_u16m1 (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_vs_u16m2 (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_vs_u16m4 (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_vs_u16m8 (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredor_vs_u32m1 (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_vs_u32m2 (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_vs_u32m4 (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_vs_u32m8 (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredor_vs_u64m1 (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_vs_u64m2 (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_vs_u64m4 (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_vs_u64m8 (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredxor_vs_i8m1 (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredxor_vs_i8m2 (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredxor_vs_i8m4 (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredxor_vs_i8m8 (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredxor_vs_i16m1 (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredxor_vs_i16m2 (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredxor_vs_i16m4 (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredxor_vs_i16m8 (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredxor_vs_i32m1 (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredxor_vs_i32m2 (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredxor_vs_i32m4 (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredxor_vs_i32m8 (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredxor_vs_i64m1 (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredxor_vs_i64m2 (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredxor_vs_i64m4 (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredxor_vs_i64m8 (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredxor_vs_u8m1 (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_vs_u8m2 (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_vs_u8m4 (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_vs_u8m8 (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredxor_vs_u16m1 (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_vs_u16m2 (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_vs_u16m4 (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_vs_u16m8 (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredxor_vs_u32m1 (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_vs_u32m2 (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_vs_u32m4 (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_vs_u32m8 (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredxor_vs_u64m1 (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_vs_u64m2 (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_vs_u64m4 (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_vs_u64m8 (vuint64m8_t vector, vuint64m1_t scalar);
// masked functions
vint8m1_t vredsum_vs_i8m1_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredsum_vs_i8m2_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredsum_vs_i8m4_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredsum_vs_i8m8_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredsum_vs_i16m1_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredsum_vs_i16m2_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredsum_vs_i16m4_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredsum_vs_i16m8_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredsum_vs_i32m1_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredsum_vs_i32m2_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredsum_vs_i32m4_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredsum_vs_i32m8_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredsum_vs_i64m1_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredsum_vs_i64m2_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredsum_vs_i64m4_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredsum_vs_i64m8_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredsum_vs_u8m1_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_vs_u8m2_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_vs_u8m4_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_vs_u8m8_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredsum_vs_u16m1_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_vs_u16m2_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_vs_u16m4_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_vs_u16m8_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredsum_vs_u32m1_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_vs_u32m2_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_vs_u32m4_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_vs_u32m8_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredsum_vs_u64m1_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_vs_u64m2_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_vs_u64m4_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_vs_u64m8_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmax_vs_i8m1_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmax_vs_i8m2_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmax_vs_i8m4_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmax_vs_i8m8_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmax_vs_i16m1_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmax_vs_i16m2_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmax_vs_i16m4_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmax_vs_i16m8_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmax_vs_i32m1_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmax_vs_i32m2_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmax_vs_i32m4_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmax_vs_i32m8_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmax_vs_i64m1_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmax_vs_i64m2_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmax_vs_i64m4_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmax_vs_i64m8_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmax_vs_u8m1_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_vs_u8m2_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_vs_u8m4_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_vs_u8m8_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmax_vs_u16m1_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_vs_u16m2_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_vs_u16m4_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_vs_u16m8_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmax_vs_u32m1_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_vs_u32m2_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_vs_u32m4_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_vs_u32m8_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmax_vs_u64m1_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_vs_u64m2_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_vs_u64m4_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_vs_u64m8_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmin_vs_i8m1_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmin_vs_i8m2_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmin_vs_i8m4_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmin_vs_i8m8_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmin_vs_i16m1_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmin_vs_i16m2_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmin_vs_i16m4_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmin_vs_i16m8_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmin_vs_i32m1_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmin_vs_i32m2_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmin_vs_i32m4_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmin_vs_i32m8_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmin_vs_i64m1_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmin_vs_i64m2_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmin_vs_i64m4_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmin_vs_i64m8_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmin_vs_u8m1_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_vs_u8m2_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_vs_u8m4_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_vs_u8m8_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmin_vs_u16m1_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_vs_u16m2_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_vs_u16m4_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_vs_u16m8_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmin_vs_u32m1_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_vs_u32m2_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_vs_u32m4_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_vs_u32m8_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmin_vs_u64m1_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_vs_u64m2_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_vs_u64m4_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_vs_u64m8_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredand_vs_i8m1_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredand_vs_i8m2_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredand_vs_i8m4_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredand_vs_i8m8_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredand_vs_i16m1_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredand_vs_i16m2_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredand_vs_i16m4_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredand_vs_i16m8_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredand_vs_i32m1_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredand_vs_i32m2_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredand_vs_i32m4_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredand_vs_i32m8_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredand_vs_i64m1_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredand_vs_i64m2_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredand_vs_i64m4_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredand_vs_i64m8_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredand_vs_u8m1_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_vs_u8m2_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_vs_u8m4_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_vs_u8m8_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredand_vs_u16m1_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_vs_u16m2_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_vs_u16m4_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_vs_u16m8_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredand_vs_u32m1_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_vs_u32m2_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_vs_u32m4_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_vs_u32m8_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredand_vs_u64m1_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_vs_u64m2_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_vs_u64m4_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_vs_u64m8_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredor_vs_i8m1_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredor_vs_i8m2_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredor_vs_i8m4_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredor_vs_i8m8_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredor_vs_i16m1_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredor_vs_i16m2_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredor_vs_i16m4_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredor_vs_i16m8_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredor_vs_i32m1_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredor_vs_i32m2_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredor_vs_i32m4_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredor_vs_i32m8_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredor_vs_i64m1_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredor_vs_i64m2_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredor_vs_i64m4_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredor_vs_i64m8_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredor_vs_u8m1_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_vs_u8m2_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_vs_u8m4_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_vs_u8m8_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredor_vs_u16m1_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_vs_u16m2_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_vs_u16m4_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_vs_u16m8_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredor_vs_u32m1_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_vs_u32m2_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_vs_u32m4_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_vs_u32m8_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredor_vs_u64m1_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_vs_u64m2_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_vs_u64m4_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_vs_u64m8_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredxor_vs_i8m1_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredxor_vs_i8m2_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredxor_vs_i8m4_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredxor_vs_i8m8_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredxor_vs_i16m1_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredxor_vs_i16m2_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredxor_vs_i16m4_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredxor_vs_i16m8_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredxor_vs_i32m1_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredxor_vs_i32m2_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredxor_vs_i32m4_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredxor_vs_i32m8_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredxor_vs_i64m1_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredxor_vs_i64m2_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredxor_vs_i64m4_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredxor_vs_i64m8_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredxor_vs_u8m1_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_vs_u8m2_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_vs_u8m4_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_vs_u8m8_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredxor_vs_u16m1_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_vs_u16m2_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_vs_u16m4_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_vs_u16m8_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredxor_vs_u32m1_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_vs_u32m2_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_vs_u32m4_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_vs_u32m8_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredxor_vs_u64m1_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_vs_u64m2_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_vs_u64m4_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_vs_u64m8_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
```
### [Vector Widening Integer Reduction Functions]()https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#152-vector-widening-integer-reduction-instructions):

**Prototypes:**
``` C
vint16m1_t vwredsum_vs_i8m1 (vint8m1_t vector, vint16m1_t scalar);
vint16m1_t vwredsum_vs_i8m2 (vint8m2_t vector, vint16m1_t scalar);
vint16m1_t vwredsum_vs_i8m4 (vint8m4_t vector, vint16m1_t scalar);
vint32m1_t vwredsum_vs_i16m1 (vint16m1_t vector, vint32m1_t scalar);
vint32m1_t vwredsum_vs_i16m2 (vint16m2_t vector, vint32m1_t scalar);
vint32m1_t vwredsum_vs_i16m4 (vint16m4_t vector, vint32m1_t scalar);
vint64m1_t vwredsum_vs_i32m1 (vint32m1_t vector, vint64m1_t scalar);
vint64m1_t vwredsum_vs_i32m2 (vint32m2_t vector, vint64m1_t scalar);
vint64m1_t vwredsum_vs_i32m4 (vint32m4_t vector, vint64m1_t scalar);
vuint16m1_t vwredsum_vs_u8m1 (vuint8m1_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum_vs_u8m2 (vuint8m2_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum_vs_u8m4 (vuint8m4_t vector, vuint16m1_t scalar);
vuint32m1_t vwredsum_vs_u16m1 (vuint16m1_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum_vs_u16m2 (vuint16m2_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum_vs_u16m4 (vuint16m4_t vector, vuint32m1_t scalar);
vuint64m1_t vwredsum_vs_u32m1 (vuint32m1_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum_vs_u32m2 (vuint32m2_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum_vs_u32m4 (vuint32m4_t vector, vuint64m1_t scalar);
// masked functions
vint16m1_t vwredsum_vs_i8m1_mask (vbool8_t mask, vint8m1_t vector, vint16m1_t scalar);
vint16m1_t vwredsum_vs_i8m2_mask (vbool4_t mask, vint8m2_t vector, vint16m1_t scalar);
vint16m1_t vwredsum_vs_i8m4_mask (vbool2_t mask, vint8m4_t vector, vint16m1_t scalar);
vint32m1_t vwredsum_vs_i16m1_mask (vbool16_t mask, vint16m1_t vector, vint32m1_t scalar);
vint32m1_t vwredsum_vs_i16m2_mask (vbool8_t mask, vint16m2_t vector, vint32m1_t scalar);
vint32m1_t vwredsum_vs_i16m4_mask (vbool4_t mask, vint16m4_t vector, vint32m1_t scalar);
vint64m1_t vwredsum_vs_i32m1_mask (vbool32_t mask, vint32m1_t vector, vint64m1_t scalar);
vint64m1_t vwredsum_vs_i32m2_mask (vbool16_t mask, vint32m2_t vector, vint64m1_t scalar);
vint64m1_t vwredsum_vs_i32m4_mask (vbool8_t mask, vint32m4_t vector, vint64m1_t scalar);
vuint16m1_t vwredsum_vs_u8m1_mask (vbool8_t mask, vuint8m1_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum_vs_u8m2_mask (vbool4_t mask, vuint8m2_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum_vs_u8m4_mask (vbool2_t mask, vuint8m4_t vector, vuint16m1_t scalar);
vuint32m1_t vwredsum_vs_u16m1_mask (vbool16_t mask, vuint16m1_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum_vs_u16m2_mask (vbool8_t mask, vuint16m2_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum_vs_u16m4_mask (vbool4_t mask, vuint16m4_t vector, vuint32m1_t scalar);
vuint64m1_t vwredsum_vs_u32m1_mask (vbool32_t mask, vuint32m1_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum_vs_u32m2_mask (vbool16_t mask, vuint32m2_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum_vs_u32m4_mask (vbool8_t mask, vuint32m4_t vector, vuint64m1_t scalar);
```
### [Vector Single-Width Floating-Point Reduction Functions]()

**Prototypes:**
``` C
vfloat16m1_t vredosum_vs_f16m1 (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum_vs_f16m2 (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum_vs_f16m4 (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum_vs_f16m8 (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredosum_vs_f32m1 (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum_vs_f32m2 (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum_vs_f32m4 (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum_vs_f32m8 (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredosum_vs_f64m1 (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum_vs_f64m2 (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum_vs_f64m4 (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum_vs_f64m8 (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredsum_vs_f16m1 (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum_vs_f16m2 (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum_vs_f16m4 (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum_vs_f16m8 (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredsum_vs_f32m1 (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum_vs_f32m2 (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum_vs_f32m4 (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum_vs_f32m8 (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredsum_vs_f64m1 (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum_vs_f64m2 (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum_vs_f64m4 (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum_vs_f64m8 (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmax_vs_f16m1 (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax_vs_f16m2 (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax_vs_f16m4 (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax_vs_f16m8 (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmax_vs_f32m1 (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax_vs_f32m2 (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax_vs_f32m4 (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax_vs_f32m8 (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmax_vs_f64m1 (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax_vs_f64m2 (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax_vs_f64m4 (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax_vs_f64m8 (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmin_vs_f16m1 (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin_vs_f16m2 (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin_vs_f16m4 (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin_vs_f16m8 (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmin_vs_f32m1 (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin_vs_f32m2 (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin_vs_f32m4 (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin_vs_f32m8 (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmin_vs_f64m1 (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin_vs_f64m2 (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin_vs_f64m4 (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin_vs_f64m8 (vfloat64m8_t vector, vfloat64m1_t scalar);
// masked functions
vfloat16m1_t vredosum_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredosum_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredosum_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredsum_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredsum_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredsum_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmax_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmax_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmax_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmin_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmin_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmin_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
```
### [Vector Widening Floating-Point Reduction Functions]()

**Prototypes:**
``` C
vfloat32m1_t vwredosum_vs_f16m1 (vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum_vs_f16m2 (vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum_vs_f16m4 (vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredosum_vs_f32m1 (vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum_vs_f32m2 (vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum_vs_f32m4 (vfloat32m4_t vector, vfloat64m1_t scalar);
vfloat32m1_t vwredsum_vs_f16m1 (vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum_vs_f16m2 (vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum_vs_f16m4 (vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredsum_vs_f32m1 (vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum_vs_f32m2 (vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum_vs_f32m4 (vfloat32m4_t vector, vfloat64m1_t scalar);
// masked functions
vfloat32m1_t vwredosum_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredosum_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t vector, vfloat64m1_t scalar);
vfloat32m1_t vwredsum_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredsum_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t vector, vfloat64m1_t scalar);
```
## Vector Mask Functions:

### [Vector Mask-Register Logical Functions]()

**Prototypes:**
``` C
vbool1_t vand_mm_b1 (vbool1_t op1, vbool1_t op2);
vbool2_t vand_mm_b2 (vbool2_t op1, vbool2_t op2);
vbool4_t vand_mm_b4 (vbool4_t op1, vbool4_t op2);
vbool8_t vand_mm_b8 (vbool8_t op1, vbool8_t op2);
vbool16_t vand_mm_b16 (vbool16_t op1, vbool16_t op2);
vbool32_t vand_mm_b32 (vbool32_t op1, vbool32_t op2);
vbool64_t vand_mm_b64 (vbool64_t op1, vbool64_t op2);
vbool1_t vnand_mm_b1 (vbool1_t op1, vbool1_t op2);
vbool2_t vnand_mm_b2 (vbool2_t op1, vbool2_t op2);
vbool4_t vnand_mm_b4 (vbool4_t op1, vbool4_t op2);
vbool8_t vnand_mm_b8 (vbool8_t op1, vbool8_t op2);
vbool16_t vnand_mm_b16 (vbool16_t op1, vbool16_t op2);
vbool32_t vnand_mm_b32 (vbool32_t op1, vbool32_t op2);
vbool64_t vnand_mm_b64 (vbool64_t op1, vbool64_t op2);
vbool1_t vandnot_mm_b1 (vbool1_t op1, vbool1_t op2);
vbool2_t vandnot_mm_b2 (vbool2_t op1, vbool2_t op2);
vbool4_t vandnot_mm_b4 (vbool4_t op1, vbool4_t op2);
vbool8_t vandnot_mm_b8 (vbool8_t op1, vbool8_t op2);
vbool16_t vandnot_mm_b16 (vbool16_t op1, vbool16_t op2);
vbool32_t vandnot_mm_b32 (vbool32_t op1, vbool32_t op2);
vbool64_t vandnot_mm_b64 (vbool64_t op1, vbool64_t op2);
vbool1_t vxor_mm_b1 (vbool1_t op1, vbool1_t op2);
vbool2_t vxor_mm_b2 (vbool2_t op1, vbool2_t op2);
vbool4_t vxor_mm_b4 (vbool4_t op1, vbool4_t op2);
vbool8_t vxor_mm_b8 (vbool8_t op1, vbool8_t op2);
vbool16_t vxor_mm_b16 (vbool16_t op1, vbool16_t op2);
vbool32_t vxor_mm_b32 (vbool32_t op1, vbool32_t op2);
vbool64_t vxor_mm_b64 (vbool64_t op1, vbool64_t op2);
vbool1_t vor_mm_b1 (vbool1_t op1, vbool1_t op2);
vbool2_t vor_mm_b2 (vbool2_t op1, vbool2_t op2);
vbool4_t vor_mm_b4 (vbool4_t op1, vbool4_t op2);
vbool8_t vor_mm_b8 (vbool8_t op1, vbool8_t op2);
vbool16_t vor_mm_b16 (vbool16_t op1, vbool16_t op2);
vbool32_t vor_mm_b32 (vbool32_t op1, vbool32_t op2);
vbool64_t vor_mm_b64 (vbool64_t op1, vbool64_t op2);
vbool1_t vnor_mm_b1 (vbool1_t op1, vbool1_t op2);
vbool2_t vnor_mm_b2 (vbool2_t op1, vbool2_t op2);
vbool4_t vnor_mm_b4 (vbool4_t op1, vbool4_t op2);
vbool8_t vnor_mm_b8 (vbool8_t op1, vbool8_t op2);
vbool16_t vnor_mm_b16 (vbool16_t op1, vbool16_t op2);
vbool32_t vnor_mm_b32 (vbool32_t op1, vbool32_t op2);
vbool64_t vnor_mm_b64 (vbool64_t op1, vbool64_t op2);
vbool1_t vornot_mm_b1 (vbool1_t op1, vbool1_t op2);
vbool2_t vornot_mm_b2 (vbool2_t op1, vbool2_t op2);
vbool4_t vornot_mm_b4 (vbool4_t op1, vbool4_t op2);
vbool8_t vornot_mm_b8 (vbool8_t op1, vbool8_t op2);
vbool16_t vornot_mm_b16 (vbool16_t op1, vbool16_t op2);
vbool32_t vornot_mm_b32 (vbool32_t op1, vbool32_t op2);
vbool64_t vornot_mm_b64 (vbool64_t op1, vbool64_t op2);
vbool1_t vxnor_mm_b1 (vbool1_t op1, vbool1_t op2);
vbool2_t vxnor_mm_b2 (vbool2_t op1, vbool2_t op2);
vbool4_t vxnor_mm_b4 (vbool4_t op1, vbool4_t op2);
vbool8_t vxnor_mm_b8 (vbool8_t op1, vbool8_t op2);
vbool16_t vxnor_mm_b16 (vbool16_t op1, vbool16_t op2);
vbool32_t vxnor_mm_b32 (vbool32_t op1, vbool32_t op2);
vbool64_t vxnor_mm_b64 (vbool64_t op1, vbool64_t op2);
vbool1_t vcpy_m_b1 (vbool1_t op1);
vbool2_t vcpy_m_b2 (vbool2_t op1);
vbool4_t vcpy_m_b4 (vbool4_t op1);
vbool8_t vcpy_m_b8 (vbool8_t op1);
vbool16_t vcpy_m_b16 (vbool16_t op1);
vbool32_t vcpy_m_b32 (vbool32_t op1);
vbool64_t vcpy_m_b64 (vbool64_t op1);
vbool1_t vclr_b1 ();
vbool2_t vclr_b2 ();
vbool4_t vclr_b4 ();
vbool8_t vclr_b8 ();
vbool16_t vclr_b16 ();
vbool32_t vclr_b32 ();
vbool64_t vclr_b64 ();
vbool1_t vset_b1 ();
vbool2_t vset_b2 ();
vbool4_t vset_b4 ();
vbool8_t vset_b8 ();
vbool16_t vset_b16 ();
vbool32_t vset_b32 ();
vbool64_t vset_b64 ();
vbool1_t vnot_m_b1 (vbool1_t op1);
vbool2_t vnot_m_b2 (vbool2_t op1);
vbool4_t vnot_m_b4 (vbool4_t op1);
vbool8_t vnot_m_b8 (vbool8_t op1);
vbool16_t vnot_m_b16 (vbool16_t op1);
vbool32_t vnot_m_b32 (vbool32_t op1);
vbool64_t vnot_m_b64 (vbool64_t op1);
```
### [Vector mask population count Functions]()

**Prototypes:**
``` C
unsigned long vpopc_m_b1 (vbool1_t op1);
unsigned long vpopc_m_b2 (vbool2_t op1);
unsigned long vpopc_m_b4 (vbool4_t op1);
unsigned long vpopc_m_b8 (vbool8_t op1);
unsigned long vpopc_m_b16 (vbool16_t op1);
unsigned long vpopc_m_b32 (vbool32_t op1);
unsigned long vpopc_m_b64 (vbool64_t op1);
// masked functions
unsigned long vpopc_m_b1_mask (vbool1_t mask, vbool1_t op1);
unsigned long vpopc_m_b2_mask (vbool2_t mask, vbool2_t op1);
unsigned long vpopc_m_b4_mask (vbool4_t mask, vbool4_t op1);
unsigned long vpopc_m_b8_mask (vbool8_t mask, vbool8_t op1);
unsigned long vpopc_m_b16_mask (vbool16_t mask, vbool16_t op1);
unsigned long vpopc_m_b32_mask (vbool32_t mask, vbool32_t op1);
unsigned long vpopc_m_b64_mask (vbool64_t mask, vbool64_t op1);
```
### [Find-first-set mask bit Functions]()

**Prototypes:**
``` C
long vfirst_m_b1 (vbool1_t op1);
long vfirst_m_b2 (vbool2_t op1);
long vfirst_m_b4 (vbool4_t op1);
long vfirst_m_b8 (vbool8_t op1);
long vfirst_m_b16 (vbool16_t op1);
long vfirst_m_b32 (vbool32_t op1);
long vfirst_m_b64 (vbool64_t op1);
// masked functions
long vfirst_m_b1_mask (vbool1_t mask, vbool1_t op1);
long vfirst_m_b2_mask (vbool2_t mask, vbool2_t op1);
long vfirst_m_b4_mask (vbool4_t mask, vbool4_t op1);
long vfirst_m_b8_mask (vbool8_t mask, vbool8_t op1);
long vfirst_m_b16_mask (vbool16_t mask, vbool16_t op1);
long vfirst_m_b32_mask (vbool32_t mask, vbool32_t op1);
long vfirst_m_b64_mask (vbool64_t mask, vbool64_t op1);
```
### [Set-before-first mask bit Functions]()

**Prototypes:**
``` C
vbool1_t vsbf_m_b1 (vbool1_t op1);
vbool2_t vsbf_m_b2 (vbool2_t op1);
vbool4_t vsbf_m_b4 (vbool4_t op1);
vbool8_t vsbf_m_b8 (vbool8_t op1);
vbool16_t vsbf_m_b16 (vbool16_t op1);
vbool32_t vsbf_m_b32 (vbool32_t op1);
vbool64_t vsbf_m_b64 (vbool64_t op1);
// masked functions
vbool1_t vsbf_m_b1_mask (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vsbf_m_b2_mask (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vsbf_m_b4_mask (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vsbf_m_b8_mask (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vsbf_m_b16_mask (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vsbf_m_b32_mask (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vsbf_m_b64_mask (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### [Set-including-first mask bit Functions]()

**Prototypes:**
``` C
vbool1_t vsif_m_b1 (vbool1_t op1);
vbool2_t vsif_m_b2 (vbool2_t op1);
vbool4_t vsif_m_b4 (vbool4_t op1);
vbool8_t vsif_m_b8 (vbool8_t op1);
vbool16_t vsif_m_b16 (vbool16_t op1);
vbool32_t vsif_m_b32 (vbool32_t op1);
vbool64_t vsif_m_b64 (vbool64_t op1);
// masked functions
vbool1_t vsif_m_b1_mask (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vsif_m_b2_mask (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vsif_m_b4_mask (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vsif_m_b8_mask (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vsif_m_b16_mask (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vsif_m_b32_mask (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vsif_m_b64_mask (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### [Set-only-first mask bit Functions]()

**Prototypes:**
``` C
vbool1_t vsof_m_b1 (vbool1_t op1);
vbool2_t vsof_m_b2 (vbool2_t op1);
vbool4_t vsof_m_b4 (vbool4_t op1);
vbool8_t vsof_m_b8 (vbool8_t op1);
vbool16_t vsof_m_b16 (vbool16_t op1);
vbool32_t vsof_m_b32 (vbool32_t op1);
vbool64_t vsof_m_b64 (vbool64_t op1);
// masked functions
vbool1_t vsof_m_b1_mask (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vsof_m_b2_mask (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vsof_m_b4_mask (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vsof_m_b8_mask (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vsof_m_b16_mask (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vsof_m_b32_mask (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vsof_m_b64_mask (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### [Vector Iota Functions]()

**Prototypes:**
``` C
vuint8m1_t viota_m_8m1 (vbool8_t op1);
vuint8m2_t viota_m_8m2 (vbool4_t op1);
vuint8m4_t viota_m_8m4 (vbool2_t op1);
vuint8m8_t viota_m_8m8 (vbool1_t op1);
vuint16m1_t viota_m_16m1 (vbool16_t op1);
vuint16m2_t viota_m_16m2 (vbool8_t op1);
vuint16m4_t viota_m_16m4 (vbool4_t op1);
vuint16m8_t viota_m_16m8 (vbool2_t op1);
vuint32m1_t viota_m_32m1 (vbool32_t op1);
vuint32m2_t viota_m_32m2 (vbool16_t op1);
vuint32m4_t viota_m_32m4 (vbool8_t op1);
vuint32m8_t viota_m_32m8 (vbool4_t op1);
vuint64m1_t viota_m_64m1 (vbool64_t op1);
vuint64m2_t viota_m_64m2 (vbool32_t op1);
vuint64m4_t viota_m_64m4 (vbool16_t op1);
vuint64m8_t viota_m_64m8 (vbool8_t op1);
// masked functions
vuint8m1_t viota_m_8m1_mask (vbool8_t mask, vbool8_t op1);
vuint8m2_t viota_m_8m2_mask (vbool4_t mask, vbool4_t op1);
vuint8m4_t viota_m_8m4_mask (vbool2_t mask, vbool2_t op1);
vuint8m8_t viota_m_8m8_mask (vbool1_t mask, vbool1_t op1);
vuint16m1_t viota_m_16m1_mask (vbool16_t mask, vbool16_t op1);
vuint16m2_t viota_m_16m2_mask (vbool8_t mask, vbool8_t op1);
vuint16m4_t viota_m_16m4_mask (vbool4_t mask, vbool4_t op1);
vuint16m8_t viota_m_16m8_mask (vbool2_t mask, vbool2_t op1);
vuint32m1_t viota_m_32m1_mask (vbool32_t mask, vbool32_t op1);
vuint32m2_t viota_m_32m2_mask (vbool16_t mask, vbool16_t op1);
vuint32m4_t viota_m_32m4_mask (vbool8_t mask, vbool8_t op1);
vuint32m8_t viota_m_32m8_mask (vbool4_t mask, vbool4_t op1);
vuint64m1_t viota_m_64m1_mask (vbool64_t mask, vbool64_t op1);
vuint64m2_t viota_m_64m2_mask (vbool32_t mask, vbool32_t op1);
vuint64m4_t viota_m_64m4_mask (vbool16_t mask, vbool16_t op1);
vuint64m8_t viota_m_64m8_mask (vbool8_t mask, vbool8_t op1);
```
### [Vector Element Index Functions]()

**Prototypes:**
``` C
vuint8m1_t vid_8m1 ();
vuint8m2_t vid_8m2 ();
vuint8m4_t vid_8m4 ();
vuint8m8_t vid_8m8 ();
vuint16m1_t vid_16m1 ();
vuint16m2_t vid_16m2 ();
vuint16m4_t vid_16m4 ();
vuint16m8_t vid_16m8 ();
vuint32m1_t vid_32m1 ();
vuint32m2_t vid_32m2 ();
vuint32m4_t vid_32m4 ();
vuint32m8_t vid_32m8 ();
vuint64m1_t vid_64m1 ();
vuint64m2_t vid_64m2 ();
vuint64m4_t vid_64m4 ();
vuint64m8_t vid_64m8 ();
// masked functions
vuint8m1_t vid_8m1_mask (vbool8_t mask, vuint8m1_t maskedoff);
vuint8m2_t vid_8m2_mask (vbool4_t mask, vuint8m2_t maskedoff);
vuint8m4_t vid_8m4_mask (vbool2_t mask, vuint8m4_t maskedoff);
vuint8m8_t vid_8m8_mask (vbool1_t mask, vuint8m8_t maskedoff);
vuint16m1_t vid_16m1_mask (vbool16_t mask, vuint16m1_t maskedoff);
vuint16m2_t vid_16m2_mask (vbool8_t mask, vuint16m2_t maskedoff);
vuint16m4_t vid_16m4_mask (vbool4_t mask, vuint16m4_t maskedoff);
vuint16m8_t vid_16m8_mask (vbool2_t mask, vuint16m8_t maskedoff);
vuint32m1_t vid_32m1_mask (vbool32_t mask, vuint32m1_t maskedoff);
vuint32m2_t vid_32m2_mask (vbool16_t mask, vuint32m2_t maskedoff);
vuint32m4_t vid_32m4_mask (vbool8_t mask, vuint32m4_t maskedoff);
vuint32m8_t vid_32m8_mask (vbool4_t mask, vuint32m8_t maskedoff);
vuint64m1_t vid_64m1_mask (vbool64_t mask, vuint64m1_t maskedoff);
vuint64m2_t vid_64m2_mask (vbool32_t mask, vuint64m2_t maskedoff);
vuint64m4_t vid_64m4_mask (vbool16_t mask, vuint64m4_t maskedoff);
vuint64m8_t vid_64m8_mask (vbool8_t mask, vuint64m8_t maskedoff);
```
## Vector Permutation Functions:

### [Integer and Floating-Point Scalar Move Functions]()

**Prototypes:**
``` C
int8_t vmv_v_i8m1 (vint8m1_t src);
vint8m1_t vmv_s_i8m1 (vint8m1_t dst, int8_t src);
int8_t vmv_v_i8m2 (vint8m2_t src);
vint8m2_t vmv_s_i8m2 (vint8m2_t dst, int8_t src);
int8_t vmv_v_i8m4 (vint8m4_t src);
vint8m4_t vmv_s_i8m4 (vint8m4_t dst, int8_t src);
int8_t vmv_v_i8m8 (vint8m8_t src);
vint8m8_t vmv_s_i8m8 (vint8m8_t dst, int8_t src);
int16_t vmv_v_i16m1 (vint16m1_t src);
vint16m1_t vmv_s_i16m1 (vint16m1_t dst, int16_t src);
int16_t vmv_v_i16m2 (vint16m2_t src);
vint16m2_t vmv_s_i16m2 (vint16m2_t dst, int16_t src);
int16_t vmv_v_i16m4 (vint16m4_t src);
vint16m4_t vmv_s_i16m4 (vint16m4_t dst, int16_t src);
int16_t vmv_v_i16m8 (vint16m8_t src);
vint16m8_t vmv_s_i16m8 (vint16m8_t dst, int16_t src);
int32_t vmv_v_i32m1 (vint32m1_t src);
vint32m1_t vmv_s_i32m1 (vint32m1_t dst, int32_t src);
int32_t vmv_v_i32m2 (vint32m2_t src);
vint32m2_t vmv_s_i32m2 (vint32m2_t dst, int32_t src);
int32_t vmv_v_i32m4 (vint32m4_t src);
vint32m4_t vmv_s_i32m4 (vint32m4_t dst, int32_t src);
int32_t vmv_v_i32m8 (vint32m8_t src);
vint32m8_t vmv_s_i32m8 (vint32m8_t dst, int32_t src);
int64_t vmv_v_i64m1 (vint64m1_t src);
vint64m1_t vmv_s_i64m1 (vint64m1_t dst, int64_t src);
int64_t vmv_v_i64m2 (vint64m2_t src);
vint64m2_t vmv_s_i64m2 (vint64m2_t dst, int64_t src);
int64_t vmv_v_i64m4 (vint64m4_t src);
vint64m4_t vmv_s_i64m4 (vint64m4_t dst, int64_t src);
int64_t vmv_v_i64m8 (vint64m8_t src);
vint64m8_t vmv_s_i64m8 (vint64m8_t dst, int64_t src);
uint8_t vmv_v_u8m1 (vuint8m1_t src);
vuint8m1_t vmv_s_u8m1 (vuint8m1_t dst, uint8_t src);
uint8_t vmv_v_u8m2 (vuint8m2_t src);
vuint8m2_t vmv_s_u8m2 (vuint8m2_t dst, uint8_t src);
uint8_t vmv_v_u8m4 (vuint8m4_t src);
vuint8m4_t vmv_s_u8m4 (vuint8m4_t dst, uint8_t src);
uint8_t vmv_v_u8m8 (vuint8m8_t src);
vuint8m8_t vmv_s_u8m8 (vuint8m8_t dst, uint8_t src);
uint16_t vmv_v_u16m1 (vuint16m1_t src);
vuint16m1_t vmv_s_u16m1 (vuint16m1_t dst, uint16_t src);
uint16_t vmv_v_u16m2 (vuint16m2_t src);
vuint16m2_t vmv_s_u16m2 (vuint16m2_t dst, uint16_t src);
uint16_t vmv_v_u16m4 (vuint16m4_t src);
vuint16m4_t vmv_s_u16m4 (vuint16m4_t dst, uint16_t src);
uint16_t vmv_v_u16m8 (vuint16m8_t src);
vuint16m8_t vmv_s_u16m8 (vuint16m8_t dst, uint16_t src);
uint32_t vmv_v_u32m1 (vuint32m1_t src);
vuint32m1_t vmv_s_u32m1 (vuint32m1_t dst, uint32_t src);
uint32_t vmv_v_u32m2 (vuint32m2_t src);
vuint32m2_t vmv_s_u32m2 (vuint32m2_t dst, uint32_t src);
uint32_t vmv_v_u32m4 (vuint32m4_t src);
vuint32m4_t vmv_s_u32m4 (vuint32m4_t dst, uint32_t src);
uint32_t vmv_v_u32m8 (vuint32m8_t src);
vuint32m8_t vmv_s_u32m8 (vuint32m8_t dst, uint32_t src);
uint64_t vmv_v_u64m1 (vuint64m1_t src);
vuint64m1_t vmv_s_u64m1 (vuint64m1_t dst, uint64_t src);
uint64_t vmv_v_u64m2 (vuint64m2_t src);
vuint64m2_t vmv_s_u64m2 (vuint64m2_t dst, uint64_t src);
uint64_t vmv_v_u64m4 (vuint64m4_t src);
vuint64m4_t vmv_s_u64m4 (vuint64m4_t dst, uint64_t src);
uint64_t vmv_v_u64m8 (vuint64m8_t src);
vuint64m8_t vmv_s_u64m8 (vuint64m8_t dst, uint64_t src);
float16_t vmv_v_f16m1 (vfloat16m1_t src);
vfloat16m1_t vmv_s_f16m1 (vfloat16m1_t dst, float16_t src);
float16_t vmv_v_f16m2 (vfloat16m2_t src);
vfloat16m2_t vmv_s_f16m2 (vfloat16m2_t dst, float16_t src);
float16_t vmv_v_f16m4 (vfloat16m4_t src);
vfloat16m4_t vmv_s_f16m4 (vfloat16m4_t dst, float16_t src);
float16_t vmv_v_f16m8 (vfloat16m8_t src);
vfloat16m8_t vmv_s_f16m8 (vfloat16m8_t dst, float16_t src);
float32_t vmv_v_f32m1 (vfloat32m1_t src);
vfloat32m1_t vmv_s_f32m1 (vfloat32m1_t dst, float32_t src);
float32_t vmv_v_f32m2 (vfloat32m2_t src);
vfloat32m2_t vmv_s_f32m2 (vfloat32m2_t dst, float32_t src);
float32_t vmv_v_f32m4 (vfloat32m4_t src);
vfloat32m4_t vmv_s_f32m4 (vfloat32m4_t dst, float32_t src);
float32_t vmv_v_f32m8 (vfloat32m8_t src);
vfloat32m8_t vmv_s_f32m8 (vfloat32m8_t dst, float32_t src);
float64_t vmv_v_f64m1 (vfloat64m1_t src);
vfloat64m1_t vmv_s_f64m1 (vfloat64m1_t dst, float64_t src);
float64_t vmv_v_f64m2 (vfloat64m2_t src);
vfloat64m2_t vmv_s_f64m2 (vfloat64m2_t dst, float64_t src);
float64_t vmv_v_f64m4 (vfloat64m4_t src);
vfloat64m4_t vmv_s_f64m4 (vfloat64m4_t dst, float64_t src);
float64_t vmv_v_f64m8 (vfloat64m8_t src);
vfloat64m8_t vmv_s_f64m8 (vfloat64m8_t dst, float64_t src);
```
### [Vector Slideup and Slidedown Functions]()

**Prototypes:**
``` C
vint8m1_t vslideup_vs_i8m1 (vint8m1_t src, size_t offset);
vint8m2_t vslideup_vs_i8m2 (vint8m2_t src, size_t offset);
vint8m4_t vslideup_vs_i8m4 (vint8m4_t src, size_t offset);
vint8m8_t vslideup_vs_i8m8 (vint8m8_t src, size_t offset);
vint16m1_t vslideup_vs_i16m1 (vint16m1_t src, size_t offset);
vint16m2_t vslideup_vs_i16m2 (vint16m2_t src, size_t offset);
vint16m4_t vslideup_vs_i16m4 (vint16m4_t src, size_t offset);
vint16m8_t vslideup_vs_i16m8 (vint16m8_t src, size_t offset);
vint32m1_t vslideup_vs_i32m1 (vint32m1_t src, size_t offset);
vint32m2_t vslideup_vs_i32m2 (vint32m2_t src, size_t offset);
vint32m4_t vslideup_vs_i32m4 (vint32m4_t src, size_t offset);
vint32m8_t vslideup_vs_i32m8 (vint32m8_t src, size_t offset);
vint64m1_t vslideup_vs_i64m1 (vint64m1_t src, size_t offset);
vint64m2_t vslideup_vs_i64m2 (vint64m2_t src, size_t offset);
vint64m4_t vslideup_vs_i64m4 (vint64m4_t src, size_t offset);
vint64m8_t vslideup_vs_i64m8 (vint64m8_t src, size_t offset);
vuint8m1_t vslideup_vs_u8m1 (vuint8m1_t src, size_t offset);
vuint8m2_t vslideup_vs_u8m2 (vuint8m2_t src, size_t offset);
vuint8m4_t vslideup_vs_u8m4 (vuint8m4_t src, size_t offset);
vuint8m8_t vslideup_vs_u8m8 (vuint8m8_t src, size_t offset);
vuint16m1_t vslideup_vs_u16m1 (vuint16m1_t src, size_t offset);
vuint16m2_t vslideup_vs_u16m2 (vuint16m2_t src, size_t offset);
vuint16m4_t vslideup_vs_u16m4 (vuint16m4_t src, size_t offset);
vuint16m8_t vslideup_vs_u16m8 (vuint16m8_t src, size_t offset);
vuint32m1_t vslideup_vs_u32m1 (vuint32m1_t src, size_t offset);
vuint32m2_t vslideup_vs_u32m2 (vuint32m2_t src, size_t offset);
vuint32m4_t vslideup_vs_u32m4 (vuint32m4_t src, size_t offset);
vuint32m8_t vslideup_vs_u32m8 (vuint32m8_t src, size_t offset);
vuint64m1_t vslideup_vs_u64m1 (vuint64m1_t src, size_t offset);
vuint64m2_t vslideup_vs_u64m2 (vuint64m2_t src, size_t offset);
vuint64m4_t vslideup_vs_u64m4 (vuint64m4_t src, size_t offset);
vuint64m8_t vslideup_vs_u64m8 (vuint64m8_t src, size_t offset);
vfloat16m1_t vslideup_vs_f16m1 (vfloat16m1_t src, size_t offset);
vfloat16m2_t vslideup_vs_f16m2 (vfloat16m2_t src, size_t offset);
vfloat16m4_t vslideup_vs_f16m4 (vfloat16m4_t src, size_t offset);
vfloat16m8_t vslideup_vs_f16m8 (vfloat16m8_t src, size_t offset);
vfloat32m1_t vslideup_vs_f32m1 (vfloat32m1_t src, size_t offset);
vfloat32m2_t vslideup_vs_f32m2 (vfloat32m2_t src, size_t offset);
vfloat32m4_t vslideup_vs_f32m4 (vfloat32m4_t src, size_t offset);
vfloat32m8_t vslideup_vs_f32m8 (vfloat32m8_t src, size_t offset);
vfloat64m1_t vslideup_vs_f64m1 (vfloat64m1_t src, size_t offset);
vfloat64m2_t vslideup_vs_f64m2 (vfloat64m2_t src, size_t offset);
vfloat64m4_t vslideup_vs_f64m4 (vfloat64m4_t src, size_t offset);
vfloat64m8_t vslideup_vs_f64m8 (vfloat64m8_t src, size_t offset);
vint8m1_t vslidedown_vs_i8m1 (vint8m1_t src, size_t offset);
vint8m2_t vslidedown_vs_i8m2 (vint8m2_t src, size_t offset);
vint8m4_t vslidedown_vs_i8m4 (vint8m4_t src, size_t offset);
vint8m8_t vslidedown_vs_i8m8 (vint8m8_t src, size_t offset);
vint16m1_t vslidedown_vs_i16m1 (vint16m1_t src, size_t offset);
vint16m2_t vslidedown_vs_i16m2 (vint16m2_t src, size_t offset);
vint16m4_t vslidedown_vs_i16m4 (vint16m4_t src, size_t offset);
vint16m8_t vslidedown_vs_i16m8 (vint16m8_t src, size_t offset);
vint32m1_t vslidedown_vs_i32m1 (vint32m1_t src, size_t offset);
vint32m2_t vslidedown_vs_i32m2 (vint32m2_t src, size_t offset);
vint32m4_t vslidedown_vs_i32m4 (vint32m4_t src, size_t offset);
vint32m8_t vslidedown_vs_i32m8 (vint32m8_t src, size_t offset);
vint64m1_t vslidedown_vs_i64m1 (vint64m1_t src, size_t offset);
vint64m2_t vslidedown_vs_i64m2 (vint64m2_t src, size_t offset);
vint64m4_t vslidedown_vs_i64m4 (vint64m4_t src, size_t offset);
vint64m8_t vslidedown_vs_i64m8 (vint64m8_t src, size_t offset);
vuint8m1_t vslidedown_vs_u8m1 (vuint8m1_t src, size_t offset);
vuint8m2_t vslidedown_vs_u8m2 (vuint8m2_t src, size_t offset);
vuint8m4_t vslidedown_vs_u8m4 (vuint8m4_t src, size_t offset);
vuint8m8_t vslidedown_vs_u8m8 (vuint8m8_t src, size_t offset);
vuint16m1_t vslidedown_vs_u16m1 (vuint16m1_t src, size_t offset);
vuint16m2_t vslidedown_vs_u16m2 (vuint16m2_t src, size_t offset);
vuint16m4_t vslidedown_vs_u16m4 (vuint16m4_t src, size_t offset);
vuint16m8_t vslidedown_vs_u16m8 (vuint16m8_t src, size_t offset);
vuint32m1_t vslidedown_vs_u32m1 (vuint32m1_t src, size_t offset);
vuint32m2_t vslidedown_vs_u32m2 (vuint32m2_t src, size_t offset);
vuint32m4_t vslidedown_vs_u32m4 (vuint32m4_t src, size_t offset);
vuint32m8_t vslidedown_vs_u32m8 (vuint32m8_t src, size_t offset);
vuint64m1_t vslidedown_vs_u64m1 (vuint64m1_t src, size_t offset);
vuint64m2_t vslidedown_vs_u64m2 (vuint64m2_t src, size_t offset);
vuint64m4_t vslidedown_vs_u64m4 (vuint64m4_t src, size_t offset);
vuint64m8_t vslidedown_vs_u64m8 (vuint64m8_t src, size_t offset);
vfloat16m1_t vslidedown_vs_f16m1 (vfloat16m1_t src, size_t offset);
vfloat16m2_t vslidedown_vs_f16m2 (vfloat16m2_t src, size_t offset);
vfloat16m4_t vslidedown_vs_f16m4 (vfloat16m4_t src, size_t offset);
vfloat16m8_t vslidedown_vs_f16m8 (vfloat16m8_t src, size_t offset);
vfloat32m1_t vslidedown_vs_f32m1 (vfloat32m1_t src, size_t offset);
vfloat32m2_t vslidedown_vs_f32m2 (vfloat32m2_t src, size_t offset);
vfloat32m4_t vslidedown_vs_f32m4 (vfloat32m4_t src, size_t offset);
vfloat32m8_t vslidedown_vs_f32m8 (vfloat32m8_t src, size_t offset);
vfloat64m1_t vslidedown_vs_f64m1 (vfloat64m1_t src, size_t offset);
vfloat64m2_t vslidedown_vs_f64m2 (vfloat64m2_t src, size_t offset);
vfloat64m4_t vslidedown_vs_f64m4 (vfloat64m4_t src, size_t offset);
vfloat64m8_t vslidedown_vs_f64m8 (vfloat64m8_t src, size_t offset);
// masked functions
vint8m1_t vslideup_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset);
vint8m2_t vslideup_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset);
vint8m4_t vslideup_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset);
vint8m8_t vslideup_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset);
vint16m1_t vslideup_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset);
vint16m2_t vslideup_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset);
vint16m4_t vslideup_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset);
vint16m8_t vslideup_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset);
vint32m1_t vslideup_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset);
vint32m2_t vslideup_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset);
vint32m4_t vslideup_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset);
vint32m8_t vslideup_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset);
vint64m1_t vslideup_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset);
vint64m2_t vslideup_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset);
vint64m4_t vslideup_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset);
vint64m8_t vslideup_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset);
vuint8m1_t vslideup_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset);
vuint8m2_t vslideup_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset);
vuint8m4_t vslideup_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset);
vuint8m8_t vslideup_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset);
vuint16m1_t vslideup_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset);
vuint16m2_t vslideup_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset);
vuint16m4_t vslideup_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset);
vuint16m8_t vslideup_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset);
vuint32m1_t vslideup_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset);
vuint32m2_t vslideup_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset);
vuint32m4_t vslideup_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset);
vuint32m8_t vslideup_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset);
vuint64m1_t vslideup_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset);
vuint64m2_t vslideup_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset);
vuint64m4_t vslideup_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset);
vuint64m8_t vslideup_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset);
vfloat16m1_t vslideup_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset);
vfloat16m2_t vslideup_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset);
vfloat16m4_t vslideup_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset);
vfloat16m8_t vslideup_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset);
vfloat32m1_t vslideup_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset);
vfloat32m2_t vslideup_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset);
vfloat32m4_t vslideup_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset);
vfloat32m8_t vslideup_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset);
vfloat64m1_t vslideup_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset);
vfloat64m2_t vslideup_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset);
vfloat64m4_t vslideup_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset);
vfloat64m8_t vslideup_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset);
vint8m1_t vslidedown_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset);
vint8m2_t vslidedown_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset);
vint8m4_t vslidedown_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset);
vint8m8_t vslidedown_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset);
vint16m1_t vslidedown_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset);
vint16m2_t vslidedown_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset);
vint16m4_t vslidedown_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset);
vint16m8_t vslidedown_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset);
vint32m1_t vslidedown_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset);
vint32m2_t vslidedown_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset);
vint32m4_t vslidedown_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset);
vint32m8_t vslidedown_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset);
vint64m1_t vslidedown_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset);
vint64m2_t vslidedown_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset);
vint64m4_t vslidedown_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset);
vint64m8_t vslidedown_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset);
vuint8m1_t vslidedown_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset);
vuint8m2_t vslidedown_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset);
vuint8m4_t vslidedown_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset);
vuint8m8_t vslidedown_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset);
vuint16m1_t vslidedown_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset);
vuint16m2_t vslidedown_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset);
vuint16m4_t vslidedown_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset);
vuint16m8_t vslidedown_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset);
vuint32m1_t vslidedown_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset);
vuint32m2_t vslidedown_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset);
vuint32m4_t vslidedown_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset);
vuint32m8_t vslidedown_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset);
vuint64m1_t vslidedown_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset);
vuint64m2_t vslidedown_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset);
vuint64m4_t vslidedown_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset);
vuint64m8_t vslidedown_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset);
vfloat16m1_t vslidedown_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset);
vfloat16m2_t vslidedown_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset);
vfloat16m4_t vslidedown_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset);
vfloat16m8_t vslidedown_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset);
vfloat32m1_t vslidedown_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset);
vfloat32m2_t vslidedown_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset);
vfloat32m4_t vslidedown_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset);
vfloat32m8_t vslidedown_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset);
vfloat64m1_t vslidedown_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset);
vfloat64m2_t vslidedown_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset);
vfloat64m4_t vslidedown_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset);
vfloat64m8_t vslidedown_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset);
```
### [Vector Slide1up and Slide1down Functions]()

**Prototypes:**
``` C
vint8m1_t vslide1up_vs_i8m1 (vint8m1_t src, long value);
vint8m2_t vslide1up_vs_i8m2 (vint8m2_t src, long value);
vint8m4_t vslide1up_vs_i8m4 (vint8m4_t src, long value);
vint8m8_t vslide1up_vs_i8m8 (vint8m8_t src, long value);
vint16m1_t vslide1up_vs_i16m1 (vint16m1_t src, long value);
vint16m2_t vslide1up_vs_i16m2 (vint16m2_t src, long value);
vint16m4_t vslide1up_vs_i16m4 (vint16m4_t src, long value);
vint16m8_t vslide1up_vs_i16m8 (vint16m8_t src, long value);
vint32m1_t vslide1up_vs_i32m1 (vint32m1_t src, long value);
vint32m2_t vslide1up_vs_i32m2 (vint32m2_t src, long value);
vint32m4_t vslide1up_vs_i32m4 (vint32m4_t src, long value);
vint32m8_t vslide1up_vs_i32m8 (vint32m8_t src, long value);
vint64m1_t vslide1up_vs_i64m1 (vint64m1_t src, long value);
vint64m2_t vslide1up_vs_i64m2 (vint64m2_t src, long value);
vint64m4_t vslide1up_vs_i64m4 (vint64m4_t src, long value);
vint64m8_t vslide1up_vs_i64m8 (vint64m8_t src, long value);
vuint8m1_t vslide1up_vs_u8m1 (vuint8m1_t src, long value);
vuint8m2_t vslide1up_vs_u8m2 (vuint8m2_t src, long value);
vuint8m4_t vslide1up_vs_u8m4 (vuint8m4_t src, long value);
vuint8m8_t vslide1up_vs_u8m8 (vuint8m8_t src, long value);
vuint16m1_t vslide1up_vs_u16m1 (vuint16m1_t src, long value);
vuint16m2_t vslide1up_vs_u16m2 (vuint16m2_t src, long value);
vuint16m4_t vslide1up_vs_u16m4 (vuint16m4_t src, long value);
vuint16m8_t vslide1up_vs_u16m8 (vuint16m8_t src, long value);
vuint32m1_t vslide1up_vs_u32m1 (vuint32m1_t src, long value);
vuint32m2_t vslide1up_vs_u32m2 (vuint32m2_t src, long value);
vuint32m4_t vslide1up_vs_u32m4 (vuint32m4_t src, long value);
vuint32m8_t vslide1up_vs_u32m8 (vuint32m8_t src, long value);
vuint64m1_t vslide1up_vs_u64m1 (vuint64m1_t src, long value);
vuint64m2_t vslide1up_vs_u64m2 (vuint64m2_t src, long value);
vuint64m4_t vslide1up_vs_u64m4 (vuint64m4_t src, long value);
vuint64m8_t vslide1up_vs_u64m8 (vuint64m8_t src, long value);
vint8m1_t vslide1down_vs_i8m1 (vint8m1_t src, long value);
vint8m2_t vslide1down_vs_i8m2 (vint8m2_t src, long value);
vint8m4_t vslide1down_vs_i8m4 (vint8m4_t src, long value);
vint8m8_t vslide1down_vs_i8m8 (vint8m8_t src, long value);
vint16m1_t vslide1down_vs_i16m1 (vint16m1_t src, long value);
vint16m2_t vslide1down_vs_i16m2 (vint16m2_t src, long value);
vint16m4_t vslide1down_vs_i16m4 (vint16m4_t src, long value);
vint16m8_t vslide1down_vs_i16m8 (vint16m8_t src, long value);
vint32m1_t vslide1down_vs_i32m1 (vint32m1_t src, long value);
vint32m2_t vslide1down_vs_i32m2 (vint32m2_t src, long value);
vint32m4_t vslide1down_vs_i32m4 (vint32m4_t src, long value);
vint32m8_t vslide1down_vs_i32m8 (vint32m8_t src, long value);
vint64m1_t vslide1down_vs_i64m1 (vint64m1_t src, long value);
vint64m2_t vslide1down_vs_i64m2 (vint64m2_t src, long value);
vint64m4_t vslide1down_vs_i64m4 (vint64m4_t src, long value);
vint64m8_t vslide1down_vs_i64m8 (vint64m8_t src, long value);
vuint8m1_t vslide1down_vs_u8m1 (vuint8m1_t src, long value);
vuint8m2_t vslide1down_vs_u8m2 (vuint8m2_t src, long value);
vuint8m4_t vslide1down_vs_u8m4 (vuint8m4_t src, long value);
vuint8m8_t vslide1down_vs_u8m8 (vuint8m8_t src, long value);
vuint16m1_t vslide1down_vs_u16m1 (vuint16m1_t src, long value);
vuint16m2_t vslide1down_vs_u16m2 (vuint16m2_t src, long value);
vuint16m4_t vslide1down_vs_u16m4 (vuint16m4_t src, long value);
vuint16m8_t vslide1down_vs_u16m8 (vuint16m8_t src, long value);
vuint32m1_t vslide1down_vs_u32m1 (vuint32m1_t src, long value);
vuint32m2_t vslide1down_vs_u32m2 (vuint32m2_t src, long value);
vuint32m4_t vslide1down_vs_u32m4 (vuint32m4_t src, long value);
vuint32m8_t vslide1down_vs_u32m8 (vuint32m8_t src, long value);
vuint64m1_t vslide1down_vs_u64m1 (vuint64m1_t src, long value);
vuint64m2_t vslide1down_vs_u64m2 (vuint64m2_t src, long value);
vuint64m4_t vslide1down_vs_u64m4 (vuint64m4_t src, long value);
vuint64m8_t vslide1down_vs_u64m8 (vuint64m8_t src, long value);
// masked functions
vint8m1_t vslide1up_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, long value);
vint8m2_t vslide1up_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, long value);
vint8m4_t vslide1up_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, long value);
vint8m8_t vslide1up_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, long value);
vint16m1_t vslide1up_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, long value);
vint16m2_t vslide1up_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, long value);
vint16m4_t vslide1up_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, long value);
vint16m8_t vslide1up_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, long value);
vint32m1_t vslide1up_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, long value);
vint32m2_t vslide1up_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, long value);
vint32m4_t vslide1up_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, long value);
vint32m8_t vslide1up_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, long value);
vint64m1_t vslide1up_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, long value);
vint64m2_t vslide1up_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, long value);
vint64m4_t vslide1up_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, long value);
vint64m8_t vslide1up_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, long value);
vuint8m1_t vslide1up_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, long value);
vuint8m2_t vslide1up_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, long value);
vuint8m4_t vslide1up_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, long value);
vuint8m8_t vslide1up_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, long value);
vuint16m1_t vslide1up_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, long value);
vuint16m2_t vslide1up_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, long value);
vuint16m4_t vslide1up_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, long value);
vuint16m8_t vslide1up_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, long value);
vuint32m1_t vslide1up_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, long value);
vuint32m2_t vslide1up_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, long value);
vuint32m4_t vslide1up_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, long value);
vuint32m8_t vslide1up_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, long value);
vuint64m1_t vslide1up_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, long value);
vuint64m2_t vslide1up_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, long value);
vuint64m4_t vslide1up_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, long value);
vuint64m8_t vslide1up_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, long value);
vint8m1_t vslide1down_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, long value);
vint8m2_t vslide1down_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, long value);
vint8m4_t vslide1down_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, long value);
vint8m8_t vslide1down_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, long value);
vint16m1_t vslide1down_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, long value);
vint16m2_t vslide1down_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, long value);
vint16m4_t vslide1down_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, long value);
vint16m8_t vslide1down_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, long value);
vint32m1_t vslide1down_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, long value);
vint32m2_t vslide1down_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, long value);
vint32m4_t vslide1down_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, long value);
vint32m8_t vslide1down_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, long value);
vint64m1_t vslide1down_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, long value);
vint64m2_t vslide1down_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, long value);
vint64m4_t vslide1down_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, long value);
vint64m8_t vslide1down_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, long value);
vuint8m1_t vslide1down_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, long value);
vuint8m2_t vslide1down_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, long value);
vuint8m4_t vslide1down_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, long value);
vuint8m8_t vslide1down_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, long value);
vuint16m1_t vslide1down_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, long value);
vuint16m2_t vslide1down_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, long value);
vuint16m4_t vslide1down_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, long value);
vuint16m8_t vslide1down_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, long value);
vuint32m1_t vslide1down_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, long value);
vuint32m2_t vslide1down_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, long value);
vuint32m4_t vslide1down_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, long value);
vuint32m8_t vslide1down_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, long value);
vuint64m1_t vslide1down_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, long value);
vuint64m2_t vslide1down_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, long value);
vuint64m4_t vslide1down_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, long value);
vuint64m8_t vslide1down_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, long value);
```
### [Vector Register Gather Functions]()

**Prototypes:**
``` C
vint8m1_t vrgather_vv_i8m1 (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vrgather_vs_i8m1 (vint8m1_t op1, uint8_t op2);
vint8m2_t vrgather_vv_i8m2 (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vrgather_vs_i8m2 (vint8m2_t op1, uint8_t op2);
vint8m4_t vrgather_vv_i8m4 (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vrgather_vs_i8m4 (vint8m4_t op1, uint8_t op2);
vint8m8_t vrgather_vv_i8m8 (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vrgather_vs_i8m8 (vint8m8_t op1, uint8_t op2);
vint16m1_t vrgather_vv_i16m1 (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vrgather_vs_i16m1 (vint16m1_t op1, uint16_t op2);
vint16m2_t vrgather_vv_i16m2 (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vrgather_vs_i16m2 (vint16m2_t op1, uint16_t op2);
vint16m4_t vrgather_vv_i16m4 (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vrgather_vs_i16m4 (vint16m4_t op1, uint16_t op2);
vint16m8_t vrgather_vv_i16m8 (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vrgather_vs_i16m8 (vint16m8_t op1, uint16_t op2);
vint32m1_t vrgather_vv_i32m1 (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vrgather_vs_i32m1 (vint32m1_t op1, uint32_t op2);
vint32m2_t vrgather_vv_i32m2 (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vrgather_vs_i32m2 (vint32m2_t op1, uint32_t op2);
vint32m4_t vrgather_vv_i32m4 (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vrgather_vs_i32m4 (vint32m4_t op1, uint32_t op2);
vint32m8_t vrgather_vv_i32m8 (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vrgather_vs_i32m8 (vint32m8_t op1, uint32_t op2);
vint64m1_t vrgather_vv_i64m1 (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vrgather_vs_i64m1 (vint64m1_t op1, uint64_t op2);
vint64m2_t vrgather_vv_i64m2 (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vrgather_vs_i64m2 (vint64m2_t op1, uint64_t op2);
vint64m4_t vrgather_vv_i64m4 (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vrgather_vs_i64m4 (vint64m4_t op1, uint64_t op2);
vint64m8_t vrgather_vv_i64m8 (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vrgather_vs_i64m8 (vint64m8_t op1, uint64_t op2);
vuint8m1_t vrgather_vv_u8m1 (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrgather_vs_u8m1 (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrgather_vv_u8m2 (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrgather_vs_u8m2 (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrgather_vv_u8m4 (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrgather_vs_u8m4 (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrgather_vv_u8m8 (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrgather_vs_u8m8 (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrgather_vv_u16m1 (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrgather_vs_u16m1 (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrgather_vv_u16m2 (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrgather_vs_u16m2 (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrgather_vv_u16m4 (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrgather_vs_u16m4 (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrgather_vv_u16m8 (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrgather_vs_u16m8 (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrgather_vv_u32m1 (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrgather_vs_u32m1 (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrgather_vv_u32m2 (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrgather_vs_u32m2 (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrgather_vv_u32m4 (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrgather_vs_u32m4 (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrgather_vv_u32m8 (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrgather_vs_u32m8 (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrgather_vv_u64m1 (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrgather_vs_u64m1 (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrgather_vv_u64m2 (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrgather_vs_u64m2 (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrgather_vv_u64m4 (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrgather_vs_u64m4 (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrgather_vv_u64m8 (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrgather_vs_u64m8 (vuint64m8_t op1, uint64_t op2);
vfloat16m1_t vrgather_vv_f16m1 (vfloat16m1_t op1, vuint16m1_t op2);
vfloat16m1_t vrgather_vs_f16m1 (vfloat16m1_t op1, uint16_t op2);
vfloat16m2_t vrgather_vv_f16m2 (vfloat16m2_t op1, vuint16m2_t op2);
vfloat16m2_t vrgather_vs_f16m2 (vfloat16m2_t op1, uint16_t op2);
vfloat16m4_t vrgather_vv_f16m4 (vfloat16m4_t op1, vuint16m4_t op2);
vfloat16m4_t vrgather_vs_f16m4 (vfloat16m4_t op1, uint16_t op2);
vfloat16m8_t vrgather_vv_f16m8 (vfloat16m8_t op1, vuint16m8_t op2);
vfloat16m8_t vrgather_vs_f16m8 (vfloat16m8_t op1, uint16_t op2);
vfloat32m1_t vrgather_vv_f32m1 (vfloat32m1_t op1, vuint32m1_t op2);
vfloat32m1_t vrgather_vs_f32m1 (vfloat32m1_t op1, uint32_t op2);
vfloat32m2_t vrgather_vv_f32m2 (vfloat32m2_t op1, vuint32m2_t op2);
vfloat32m2_t vrgather_vs_f32m2 (vfloat32m2_t op1, uint32_t op2);
vfloat32m4_t vrgather_vv_f32m4 (vfloat32m4_t op1, vuint32m4_t op2);
vfloat32m4_t vrgather_vs_f32m4 (vfloat32m4_t op1, uint32_t op2);
vfloat32m8_t vrgather_vv_f32m8 (vfloat32m8_t op1, vuint32m8_t op2);
vfloat32m8_t vrgather_vs_f32m8 (vfloat32m8_t op1, uint32_t op2);
vfloat64m1_t vrgather_vv_f64m1 (vfloat64m1_t op1, vuint64m1_t op2);
vfloat64m1_t vrgather_vs_f64m1 (vfloat64m1_t op1, uint64_t op2);
vfloat64m2_t vrgather_vv_f64m2 (vfloat64m2_t op1, vuint64m2_t op2);
vfloat64m2_t vrgather_vs_f64m2 (vfloat64m2_t op1, uint64_t op2);
vfloat64m4_t vrgather_vv_f64m4 (vfloat64m4_t op1, vuint64m4_t op2);
vfloat64m4_t vrgather_vs_f64m4 (vfloat64m4_t op1, uint64_t op2);
vfloat64m8_t vrgather_vv_f64m8 (vfloat64m8_t op1, vuint64m8_t op2);
vfloat64m8_t vrgather_vs_f64m8 (vfloat64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vrgather_vv_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vrgather_vs_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vrgather_vv_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vrgather_vs_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vrgather_vv_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vrgather_vs_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vrgather_vv_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vrgather_vs_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vrgather_vv_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vrgather_vs_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2);
vint16m2_t vrgather_vv_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vrgather_vs_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2);
vint16m4_t vrgather_vv_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vrgather_vs_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2);
vint16m8_t vrgather_vv_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vrgather_vs_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2);
vint32m1_t vrgather_vv_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vrgather_vs_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2);
vint32m2_t vrgather_vv_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vrgather_vs_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2);
vint32m4_t vrgather_vv_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vrgather_vs_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2);
vint32m8_t vrgather_vv_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vrgather_vs_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2);
vint64m1_t vrgather_vv_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vrgather_vs_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2);
vint64m2_t vrgather_vv_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vrgather_vs_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2);
vint64m4_t vrgather_vv_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vrgather_vs_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2);
vint64m8_t vrgather_vv_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vrgather_vs_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2);
vuint8m1_t vrgather_vv_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrgather_vs_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrgather_vv_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrgather_vs_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrgather_vv_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrgather_vs_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrgather_vv_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrgather_vs_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrgather_vv_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrgather_vs_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrgather_vv_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrgather_vs_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrgather_vv_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrgather_vs_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrgather_vv_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrgather_vs_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrgather_vv_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrgather_vs_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrgather_vv_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrgather_vs_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrgather_vv_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrgather_vs_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrgather_vv_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrgather_vs_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrgather_vv_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrgather_vs_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrgather_vv_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrgather_vs_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrgather_vv_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrgather_vs_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrgather_vv_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrgather_vs_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vfloat16m1_t vrgather_vv_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t op2);
vfloat16m1_t vrgather_vs_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, uint16_t op2);
vfloat16m2_t vrgather_vv_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t op2);
vfloat16m2_t vrgather_vs_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, uint16_t op2);
vfloat16m4_t vrgather_vv_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t op2);
vfloat16m4_t vrgather_vs_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, uint16_t op2);
vfloat16m8_t vrgather_vv_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t op2);
vfloat16m8_t vrgather_vs_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, uint16_t op2);
vfloat32m1_t vrgather_vv_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint32m1_t op2);
vfloat32m1_t vrgather_vs_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, uint32_t op2);
vfloat32m2_t vrgather_vv_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint32m2_t op2);
vfloat32m2_t vrgather_vs_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, uint32_t op2);
vfloat32m4_t vrgather_vv_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint32m4_t op2);
vfloat32m4_t vrgather_vs_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, uint32_t op2);
vfloat32m8_t vrgather_vv_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint32m8_t op2);
vfloat32m8_t vrgather_vs_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, uint32_t op2);
vfloat64m1_t vrgather_vv_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint64m1_t op2);
vfloat64m1_t vrgather_vs_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, uint64_t op2);
vfloat64m2_t vrgather_vv_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint64m2_t op2);
vfloat64m2_t vrgather_vs_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, uint64_t op2);
vfloat64m4_t vrgather_vv_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint64m4_t op2);
vfloat64m4_t vrgather_vs_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, uint64_t op2);
vfloat64m8_t vrgather_vv_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint64m8_t op2);
vfloat64m8_t vrgather_vs_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, uint64_t op2);
```
### [Vector Compress Functions]()

**Prototypes:**
``` C
vint8m1_t vcompress_vm_i8m1 (vint8m1_t src, vbool8_t mask);
vint8m2_t vcompress_vm_i8m2 (vint8m2_t src, vbool4_t mask);
vint8m4_t vcompress_vm_i8m4 (vint8m4_t src, vbool2_t mask);
vint8m8_t vcompress_vm_i8m8 (vint8m8_t src, vbool1_t mask);
vint16m1_t vcompress_vm_i16m1 (vint16m1_t src, vbool16_t mask);
vint16m2_t vcompress_vm_i16m2 (vint16m2_t src, vbool8_t mask);
vint16m4_t vcompress_vm_i16m4 (vint16m4_t src, vbool4_t mask);
vint16m8_t vcompress_vm_i16m8 (vint16m8_t src, vbool2_t mask);
vint32m1_t vcompress_vm_i32m1 (vint32m1_t src, vbool32_t mask);
vint32m2_t vcompress_vm_i32m2 (vint32m2_t src, vbool16_t mask);
vint32m4_t vcompress_vm_i32m4 (vint32m4_t src, vbool8_t mask);
vint32m8_t vcompress_vm_i32m8 (vint32m8_t src, vbool4_t mask);
vint64m1_t vcompress_vm_i64m1 (vint64m1_t src, vbool64_t mask);
vint64m2_t vcompress_vm_i64m2 (vint64m2_t src, vbool32_t mask);
vint64m4_t vcompress_vm_i64m4 (vint64m4_t src, vbool16_t mask);
vint64m8_t vcompress_vm_i64m8 (vint64m8_t src, vbool8_t mask);
vuint8m1_t vcompress_vm_u8m1 (vuint8m1_t src, vbool8_t mask);
vuint8m2_t vcompress_vm_u8m2 (vuint8m2_t src, vbool4_t mask);
vuint8m4_t vcompress_vm_u8m4 (vuint8m4_t src, vbool2_t mask);
vuint8m8_t vcompress_vm_u8m8 (vuint8m8_t src, vbool1_t mask);
vuint16m1_t vcompress_vm_u16m1 (vuint16m1_t src, vbool16_t mask);
vuint16m2_t vcompress_vm_u16m2 (vuint16m2_t src, vbool8_t mask);
vuint16m4_t vcompress_vm_u16m4 (vuint16m4_t src, vbool4_t mask);
vuint16m8_t vcompress_vm_u16m8 (vuint16m8_t src, vbool2_t mask);
vuint32m1_t vcompress_vm_u32m1 (vuint32m1_t src, vbool32_t mask);
vuint32m2_t vcompress_vm_u32m2 (vuint32m2_t src, vbool16_t mask);
vuint32m4_t vcompress_vm_u32m4 (vuint32m4_t src, vbool8_t mask);
vuint32m8_t vcompress_vm_u32m8 (vuint32m8_t src, vbool4_t mask);
vuint64m1_t vcompress_vm_u64m1 (vuint64m1_t src, vbool64_t mask);
vuint64m2_t vcompress_vm_u64m2 (vuint64m2_t src, vbool32_t mask);
vuint64m4_t vcompress_vm_u64m4 (vuint64m4_t src, vbool16_t mask);
vuint64m8_t vcompress_vm_u64m8 (vuint64m8_t src, vbool8_t mask);
vfloat16m1_t vcompress_vm_f16m1 (vfloat16m1_t src, vbool16_t mask);
vfloat16m2_t vcompress_vm_f16m2 (vfloat16m2_t src, vbool8_t mask);
vfloat16m4_t vcompress_vm_f16m4 (vfloat16m4_t src, vbool4_t mask);
vfloat16m8_t vcompress_vm_f16m8 (vfloat16m8_t src, vbool2_t mask);
vfloat32m1_t vcompress_vm_f32m1 (vfloat32m1_t src, vbool32_t mask);
vfloat32m2_t vcompress_vm_f32m2 (vfloat32m2_t src, vbool16_t mask);
vfloat32m4_t vcompress_vm_f32m4 (vfloat32m4_t src, vbool8_t mask);
vfloat32m8_t vcompress_vm_f32m8 (vfloat32m8_t src, vbool4_t mask);
vfloat64m1_t vcompress_vm_f64m1 (vfloat64m1_t src, vbool64_t mask);
vfloat64m2_t vcompress_vm_f64m2 (vfloat64m2_t src, vbool32_t mask);
vfloat64m4_t vcompress_vm_f64m4 (vfloat64m4_t src, vbool16_t mask);
vfloat64m8_t vcompress_vm_f64m8 (vfloat64m8_t src, vbool8_t mask);
```
## Miscellaneous Vector Functions:

### [Reinterpret Cast Conversion Functions]()

**Prototypes:**
``` C
vuint8m1_t vreinterpret_u8_i8_v_8m1 (vint8m1_t src);
vuint8m2_t vreinterpret_u8_i8_v_8m2 (vint8m2_t src);
vuint8m4_t vreinterpret_u8_i8_v_8m4 (vint8m4_t src);
vuint8m8_t vreinterpret_u8_i8_v_8m8 (vint8m8_t src);
vint8m1_t vreinterpret_i8_u8_v_8m1 (vuint8m1_t src);
vint8m2_t vreinterpret_i8_u8_v_8m2 (vuint8m2_t src);
vint8m4_t vreinterpret_i8_u8_v_8m4 (vuint8m4_t src);
vint8m8_t vreinterpret_i8_u8_v_8m8 (vuint8m8_t src);
vuint16m1_t vreinterpret_u16_i16_v_16m1 (vint16m1_t src);
vuint16m2_t vreinterpret_u16_i16_v_16m2 (vint16m2_t src);
vuint16m4_t vreinterpret_u16_i16_v_16m4 (vint16m4_t src);
vuint16m8_t vreinterpret_u16_i16_v_16m8 (vint16m8_t src);
vint16m1_t vreinterpret_i16_u16_v_16m1 (vuint16m1_t src);
vint16m2_t vreinterpret_i16_u16_v_16m2 (vuint16m2_t src);
vint16m4_t vreinterpret_i16_u16_v_16m4 (vuint16m4_t src);
vint16m8_t vreinterpret_i16_u16_v_16m8 (vuint16m8_t src);
vint16m1_t vreinterpret_i16_f16_v_16m1 (vfloat16m1_t src);
vint16m2_t vreinterpret_i16_f16_v_16m2 (vfloat16m2_t src);
vint16m4_t vreinterpret_i16_f16_v_16m4 (vfloat16m4_t src);
vint16m8_t vreinterpret_i16_f16_v_16m8 (vfloat16m8_t src);
vuint16m1_t vreinterpret_u16_f16_v_16m1 (vfloat16m1_t src);
vuint16m2_t vreinterpret_u16_f16_v_16m2 (vfloat16m2_t src);
vuint16m4_t vreinterpret_u16_f16_v_16m4 (vfloat16m4_t src);
vuint16m8_t vreinterpret_u16_f16_v_16m8 (vfloat16m8_t src);
vfloat16m1_t vreinterpret_f16_i16_v_16m1 (vint16m1_t src);
vfloat16m2_t vreinterpret_f16_i16_v_16m2 (vint16m2_t src);
vfloat16m4_t vreinterpret_f16_i16_v_16m4 (vint16m4_t src);
vfloat16m8_t vreinterpret_f16_i16_v_16m8 (vint16m8_t src);
vfloat16m1_t vreinterpret_f16_u16_v_16m1 (vuint16m1_t src);
vfloat16m2_t vreinterpret_f16_u16_v_16m2 (vuint16m2_t src);
vfloat16m4_t vreinterpret_f16_u16_v_16m4 (vuint16m4_t src);
vfloat16m8_t vreinterpret_f16_u16_v_16m8 (vuint16m8_t src);
vuint32m1_t vreinterpret_u32_i32_v_32m1 (vint32m1_t src);
vuint32m2_t vreinterpret_u32_i32_v_32m2 (vint32m2_t src);
vuint32m4_t vreinterpret_u32_i32_v_32m4 (vint32m4_t src);
vuint32m8_t vreinterpret_u32_i32_v_32m8 (vint32m8_t src);
vint32m1_t vreinterpret_i32_u32_v_32m1 (vuint32m1_t src);
vint32m2_t vreinterpret_i32_u32_v_32m2 (vuint32m2_t src);
vint32m4_t vreinterpret_i32_u32_v_32m4 (vuint32m4_t src);
vint32m8_t vreinterpret_i32_u32_v_32m8 (vuint32m8_t src);
vint32m1_t vreinterpret_i32_f32_v_32m1 (vfloat32m1_t src);
vint32m2_t vreinterpret_i32_f32_v_32m2 (vfloat32m2_t src);
vint32m4_t vreinterpret_i32_f32_v_32m4 (vfloat32m4_t src);
vint32m8_t vreinterpret_i32_f32_v_32m8 (vfloat32m8_t src);
vuint32m1_t vreinterpret_u32_f32_v_32m1 (vfloat32m1_t src);
vuint32m2_t vreinterpret_u32_f32_v_32m2 (vfloat32m2_t src);
vuint32m4_t vreinterpret_u32_f32_v_32m4 (vfloat32m4_t src);
vuint32m8_t vreinterpret_u32_f32_v_32m8 (vfloat32m8_t src);
vfloat32m1_t vreinterpret_f32_i32_v_32m1 (vint32m1_t src);
vfloat32m2_t vreinterpret_f32_i32_v_32m2 (vint32m2_t src);
vfloat32m4_t vreinterpret_f32_i32_v_32m4 (vint32m4_t src);
vfloat32m8_t vreinterpret_f32_i32_v_32m8 (vint32m8_t src);
vfloat32m1_t vreinterpret_f32_u32_v_32m1 (vuint32m1_t src);
vfloat32m2_t vreinterpret_f32_u32_v_32m2 (vuint32m2_t src);
vfloat32m4_t vreinterpret_f32_u32_v_32m4 (vuint32m4_t src);
vfloat32m8_t vreinterpret_f32_u32_v_32m8 (vuint32m8_t src);
vuint64m1_t vreinterpret_u64_i64_v_64m1 (vint64m1_t src);
vuint64m2_t vreinterpret_u64_i64_v_64m2 (vint64m2_t src);
vuint64m4_t vreinterpret_u64_i64_v_64m4 (vint64m4_t src);
vuint64m8_t vreinterpret_u64_i64_v_64m8 (vint64m8_t src);
vint64m1_t vreinterpret_i64_u64_v_64m1 (vuint64m1_t src);
vint64m2_t vreinterpret_i64_u64_v_64m2 (vuint64m2_t src);
vint64m4_t vreinterpret_i64_u64_v_64m4 (vuint64m4_t src);
vint64m8_t vreinterpret_i64_u64_v_64m8 (vuint64m8_t src);
vint64m1_t vreinterpret_i64_f64_v_64m1 (vfloat64m1_t src);
vint64m2_t vreinterpret_i64_f64_v_64m2 (vfloat64m2_t src);
vint64m4_t vreinterpret_i64_f64_v_64m4 (vfloat64m4_t src);
vint64m8_t vreinterpret_i64_f64_v_64m8 (vfloat64m8_t src);
vuint64m1_t vreinterpret_u64_f64_v_64m1 (vfloat64m1_t src);
vuint64m2_t vreinterpret_u64_f64_v_64m2 (vfloat64m2_t src);
vuint64m4_t vreinterpret_u64_f64_v_64m4 (vfloat64m4_t src);
vuint64m8_t vreinterpret_u64_f64_v_64m8 (vfloat64m8_t src);
vfloat64m1_t vreinterpret_f64_i64_v_64m1 (vint64m1_t src);
vfloat64m2_t vreinterpret_f64_i64_v_64m2 (vint64m2_t src);
vfloat64m4_t vreinterpret_f64_i64_v_64m4 (vint64m4_t src);
vfloat64m8_t vreinterpret_f64_i64_v_64m8 (vint64m8_t src);
vfloat64m1_t vreinterpret_f64_u64_v_64m1 (vuint64m1_t src);
vfloat64m2_t vreinterpret_f64_u64_v_64m2 (vuint64m2_t src);
vfloat64m4_t vreinterpret_f64_u64_v_64m4 (vuint64m4_t src);
vfloat64m8_t vreinterpret_f64_u64_v_64m8 (vuint64m8_t src);
```
