<!--NOTE: This file is generated by rvv_intrinsic_gen.py-->

### [RVV C extension types](rvv-intrinsic-api.md#51-vector-types):

**Prototypes:**
``` C
vint8m1_t
vint8m2_t
vint8m4_t
vint8m8_t
vint16m1_t
vint16m2_t
vint16m4_t
vint16m8_t
vint32m1_t
vint32m2_t
vint32m4_t
vint32m8_t
vint64m1_t
vint64m2_t
vint64m4_t
vint64m8_t
vuint8m1_t
vuint8m2_t
vuint8m4_t
vuint8m8_t
vuint16m1_t
vuint16m2_t
vuint16m4_t
vuint16m8_t
vuint32m1_t
vuint32m2_t
vuint32m4_t
vuint32m8_t
vuint64m1_t
vuint64m2_t
vuint64m4_t
vuint64m8_t
vfloat16m1_t
vfloat16m2_t
vfloat16m4_t
vfloat16m8_t
vfloat32m1_t
vfloat32m2_t
vfloat32m4_t
vfloat32m8_t
vfloat64m1_t
vfloat64m2_t
vfloat64m4_t
vfloat64m8_t
```
### [RVV C extension mask types](rvv-intrinsic-api.md#52-mask-types):
- The Syntax is `vbool<MLEN>_t`
 - `vbool1_t`
 - `vbool2_t`
 - `vbool4_t`
 - `vbool8_t`
 - `vbool16_t`
 - `vbool32_t`
 - `vbool64_t`

# RVV intrinsic Functions:

## Configuration-Setting Functions:

### [Set `vl` and `vtype` Functions](rvv-intrinsic-api.md#set-vl-and-vtype-functions):

**Prototypes:**
``` C
_VL_T vsetvl_e8m1 (size_t avl);
_VL_T vsetvl_e8m2 (size_t avl);
_VL_T vsetvl_e8m4 (size_t avl);
_VL_T vsetvl_e8m8 (size_t avl);
_VL_T vsetvl_e16m1 (size_t avl);
_VL_T vsetvl_e16m2 (size_t avl);
_VL_T vsetvl_e16m4 (size_t avl);
_VL_T vsetvl_e16m8 (size_t avl);
_VL_T vsetvl_e32m1 (size_t avl);
_VL_T vsetvl_e32m2 (size_t avl);
_VL_T vsetvl_e32m4 (size_t avl);
_VL_T vsetvl_e32m8 (size_t avl);
_VL_T vsetvl_e64m1 (size_t avl);
_VL_T vsetvl_e64m2 (size_t avl);
_VL_T vsetvl_e64m4 (size_t avl);
_VL_T vsetvl_e64m8 (size_t avl);
```
### [Set the vl to VLMAX with specific vtype](rvv-intrinsic-api.md#set-vl-to-vlmax-with-specific-vtype):

**Prototypes:**
``` C
_VL_T vsetvlmax_e8m1 ();
_VL_T vsetvlmax_e8m2 ();
_VL_T vsetvlmax_e8m4 ();
_VL_T vsetvlmax_e8m8 ();
_VL_T vsetvlmax_e16m1 ();
_VL_T vsetvlmax_e16m2 ();
_VL_T vsetvlmax_e16m4 ();
_VL_T vsetvlmax_e16m8 ();
_VL_T vsetvlmax_e32m1 ();
_VL_T vsetvlmax_e32m2 ();
_VL_T vsetvlmax_e32m4 ();
_VL_T vsetvlmax_e32m8 ();
_VL_T vsetvlmax_e64m1 ();
_VL_T vsetvlmax_e64m2 ();
_VL_T vsetvlmax_e64m4 ();
_VL_T vsetvlmax_e64m8 ();
```
### [Read the vl](rvv-intrinsic-api.md#read-vl-value):

**Prototypes:**
``` C
size_t vreadvl ();
```
## Vector Loads and Stores Functions:

### [Vector Unit-Stride Load Functions](rvv-intrinsic-api.md#74-vector-unit-stride-operations):

**Prototypes:**
``` C
vint8m1_t vlb_v_i8m1 (const int8_t *base);
vint8m2_t vlb_v_i8m2 (const int8_t *base);
vint8m4_t vlb_v_i8m4 (const int8_t *base);
vint8m8_t vlb_v_i8m8 (const int8_t *base);
vint16m1_t vlb_v_i16m1 (const int8_t *base);
vint16m2_t vlb_v_i16m2 (const int8_t *base);
vint16m4_t vlb_v_i16m4 (const int8_t *base);
vint16m8_t vlb_v_i16m8 (const int8_t *base);
vint32m1_t vlb_v_i32m1 (const int8_t *base);
vint32m2_t vlb_v_i32m2 (const int8_t *base);
vint32m4_t vlb_v_i32m4 (const int8_t *base);
vint32m8_t vlb_v_i32m8 (const int8_t *base);
vint64m1_t vlb_v_i64m1 (const int8_t *base);
vint64m2_t vlb_v_i64m2 (const int8_t *base);
vint64m4_t vlb_v_i64m4 (const int8_t *base);
vint64m8_t vlb_v_i64m8 (const int8_t *base);
vuint8m1_t vlbu_v_u8m1 (const uint8_t *base);
vuint8m2_t vlbu_v_u8m2 (const uint8_t *base);
vuint8m4_t vlbu_v_u8m4 (const uint8_t *base);
vuint8m8_t vlbu_v_u8m8 (const uint8_t *base);
vuint16m1_t vlbu_v_u16m1 (const uint8_t *base);
vuint16m2_t vlbu_v_u16m2 (const uint8_t *base);
vuint16m4_t vlbu_v_u16m4 (const uint8_t *base);
vuint16m8_t vlbu_v_u16m8 (const uint8_t *base);
vuint32m1_t vlbu_v_u32m1 (const uint8_t *base);
vuint32m2_t vlbu_v_u32m2 (const uint8_t *base);
vuint32m4_t vlbu_v_u32m4 (const uint8_t *base);
vuint32m8_t vlbu_v_u32m8 (const uint8_t *base);
vuint64m1_t vlbu_v_u64m1 (const uint8_t *base);
vuint64m2_t vlbu_v_u64m2 (const uint8_t *base);
vuint64m4_t vlbu_v_u64m4 (const uint8_t *base);
vuint64m8_t vlbu_v_u64m8 (const uint8_t *base);
vint16m1_t vlh_v_i16m1 (const int16_t *base);
vint16m2_t vlh_v_i16m2 (const int16_t *base);
vint16m4_t vlh_v_i16m4 (const int16_t *base);
vint16m8_t vlh_v_i16m8 (const int16_t *base);
vint32m1_t vlh_v_i32m1 (const int16_t *base);
vint32m2_t vlh_v_i32m2 (const int16_t *base);
vint32m4_t vlh_v_i32m4 (const int16_t *base);
vint32m8_t vlh_v_i32m8 (const int16_t *base);
vint64m1_t vlh_v_i64m1 (const int16_t *base);
vint64m2_t vlh_v_i64m2 (const int16_t *base);
vint64m4_t vlh_v_i64m4 (const int16_t *base);
vint64m8_t vlh_v_i64m8 (const int16_t *base);
vuint16m1_t vlhu_v_u16m1 (const uint16_t *base);
vuint16m2_t vlhu_v_u16m2 (const uint16_t *base);
vuint16m4_t vlhu_v_u16m4 (const uint16_t *base);
vuint16m8_t vlhu_v_u16m8 (const uint16_t *base);
vuint32m1_t vlhu_v_u32m1 (const uint16_t *base);
vuint32m2_t vlhu_v_u32m2 (const uint16_t *base);
vuint32m4_t vlhu_v_u32m4 (const uint16_t *base);
vuint32m8_t vlhu_v_u32m8 (const uint16_t *base);
vuint64m1_t vlhu_v_u64m1 (const uint16_t *base);
vuint64m2_t vlhu_v_u64m2 (const uint16_t *base);
vuint64m4_t vlhu_v_u64m4 (const uint16_t *base);
vuint64m8_t vlhu_v_u64m8 (const uint16_t *base);
vint32m1_t vlw_v_i32m1 (const int32_t *base);
vint32m2_t vlw_v_i32m2 (const int32_t *base);
vint32m4_t vlw_v_i32m4 (const int32_t *base);
vint32m8_t vlw_v_i32m8 (const int32_t *base);
vint64m1_t vlw_v_i64m1 (const int32_t *base);
vint64m2_t vlw_v_i64m2 (const int32_t *base);
vint64m4_t vlw_v_i64m4 (const int32_t *base);
vint64m8_t vlw_v_i64m8 (const int32_t *base);
vuint32m1_t vlwu_v_u32m1 (const uint32_t *base);
vuint32m2_t vlwu_v_u32m2 (const uint32_t *base);
vuint32m4_t vlwu_v_u32m4 (const uint32_t *base);
vuint32m8_t vlwu_v_u32m8 (const uint32_t *base);
vuint64m1_t vlwu_v_u64m1 (const uint32_t *base);
vuint64m2_t vlwu_v_u64m2 (const uint32_t *base);
vuint64m4_t vlwu_v_u64m4 (const uint32_t *base);
vuint64m8_t vlwu_v_u64m8 (const uint32_t *base);
vint8m1_t vle_v_i8m1 (const int8_t *base);
vint8m2_t vle_v_i8m2 (const int8_t *base);
vint8m4_t vle_v_i8m4 (const int8_t *base);
vint8m8_t vle_v_i8m8 (const int8_t *base);
vint16m1_t vle_v_i16m1 (const int16_t *base);
vint16m2_t vle_v_i16m2 (const int16_t *base);
vint16m4_t vle_v_i16m4 (const int16_t *base);
vint16m8_t vle_v_i16m8 (const int16_t *base);
vint32m1_t vle_v_i32m1 (const int32_t *base);
vint32m2_t vle_v_i32m2 (const int32_t *base);
vint32m4_t vle_v_i32m4 (const int32_t *base);
vint32m8_t vle_v_i32m8 (const int32_t *base);
vint64m1_t vle_v_i64m1 (const int64_t *base);
vint64m2_t vle_v_i64m2 (const int64_t *base);
vint64m4_t vle_v_i64m4 (const int64_t *base);
vint64m8_t vle_v_i64m8 (const int64_t *base);
vuint8m1_t vle_v_u8m1 (const uint8_t *base);
vuint8m2_t vle_v_u8m2 (const uint8_t *base);
vuint8m4_t vle_v_u8m4 (const uint8_t *base);
vuint8m8_t vle_v_u8m8 (const uint8_t *base);
vuint16m1_t vle_v_u16m1 (const uint16_t *base);
vuint16m2_t vle_v_u16m2 (const uint16_t *base);
vuint16m4_t vle_v_u16m4 (const uint16_t *base);
vuint16m8_t vle_v_u16m8 (const uint16_t *base);
vuint32m1_t vle_v_u32m1 (const uint32_t *base);
vuint32m2_t vle_v_u32m2 (const uint32_t *base);
vuint32m4_t vle_v_u32m4 (const uint32_t *base);
vuint32m8_t vle_v_u32m8 (const uint32_t *base);
vuint64m1_t vle_v_u64m1 (const uint64_t *base);
vuint64m2_t vle_v_u64m2 (const uint64_t *base);
vuint64m4_t vle_v_u64m4 (const uint64_t *base);
vuint64m8_t vle_v_u64m8 (const uint64_t *base);
vfloat16m1_t vle_v_f16m1 (const float16_t *base);
vfloat16m2_t vle_v_f16m2 (const float16_t *base);
vfloat16m4_t vle_v_f16m4 (const float16_t *base);
vfloat16m8_t vle_v_f16m8 (const float16_t *base);
vfloat32m1_t vle_v_f32m1 (const float32_t *base);
vfloat32m2_t vle_v_f32m2 (const float32_t *base);
vfloat32m4_t vle_v_f32m4 (const float32_t *base);
vfloat32m8_t vle_v_f32m8 (const float32_t *base);
vfloat64m1_t vle_v_f64m1 (const float64_t *base);
vfloat64m2_t vle_v_f64m2 (const float64_t *base);
vfloat64m4_t vle_v_f64m4 (const float64_t *base);
vfloat64m8_t vle_v_f64m8 (const float64_t *base);
// masked functions
vint8m1_t vlb_v_i8m1_m (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vlb_v_i8m2_m (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vlb_v_i8m4_m (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vlb_v_i8m8_m (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vlb_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base);
vint16m2_t vlb_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base);
vint16m4_t vlb_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base);
vint16m8_t vlb_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base);
vint32m1_t vlb_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base);
vint32m2_t vlb_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base);
vint32m4_t vlb_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base);
vint32m8_t vlb_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base);
vint64m1_t vlb_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base);
vint64m2_t vlb_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base);
vint64m4_t vlb_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base);
vint64m8_t vlb_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base);
vuint8m1_t vlbu_v_u8m1_m (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vlbu_v_u8m2_m (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vlbu_v_u8m4_m (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vlbu_v_u8m8_m (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vlbu_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base);
vuint16m2_t vlbu_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base);
vuint16m4_t vlbu_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base);
vuint16m8_t vlbu_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base);
vuint32m1_t vlbu_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base);
vuint32m2_t vlbu_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base);
vuint32m4_t vlbu_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base);
vuint32m8_t vlbu_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base);
vuint64m1_t vlbu_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base);
vuint64m2_t vlbu_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base);
vuint64m4_t vlbu_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base);
vuint64m8_t vlbu_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base);
vint16m1_t vlh_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vlh_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vlh_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vlh_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vlh_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base);
vint32m2_t vlh_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base);
vint32m4_t vlh_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base);
vint32m8_t vlh_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base);
vint64m1_t vlh_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base);
vint64m2_t vlh_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base);
vint64m4_t vlh_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base);
vint64m8_t vlh_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base);
vuint16m1_t vlhu_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vlhu_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vlhu_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vlhu_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vlhu_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base);
vuint32m2_t vlhu_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base);
vuint32m4_t vlhu_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base);
vuint32m8_t vlhu_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base);
vuint64m1_t vlhu_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base);
vuint64m2_t vlhu_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base);
vuint64m4_t vlhu_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base);
vuint64m8_t vlhu_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base);
vint32m1_t vlw_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vlw_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vlw_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vlw_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vlw_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base);
vint64m2_t vlw_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base);
vint64m4_t vlw_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base);
vint64m8_t vlw_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base);
vuint32m1_t vlwu_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vlwu_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vlwu_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vlwu_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vlwu_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base);
vuint64m2_t vlwu_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base);
vuint64m4_t vlwu_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base);
vuint64m8_t vlwu_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base);
vint8m1_t vle_v_i8m1_m (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vle_v_i8m2_m (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vle_v_i8m4_m (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vle_v_i8m8_m (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vle_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vle_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vle_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vle_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vle_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vle_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vle_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vle_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vle_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base);
vint64m2_t vle_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base);
vint64m4_t vle_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base);
vint64m8_t vle_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base);
vuint8m1_t vle_v_u8m1_m (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vle_v_u8m2_m (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vle_v_u8m4_m (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vle_v_u8m8_m (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vle_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vle_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vle_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vle_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vle_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vle_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vle_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vle_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vle_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base);
vuint64m2_t vle_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base);
vuint64m4_t vle_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base);
vuint64m8_t vle_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base);
vfloat16m1_t vle_v_f16m1_m (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base);
vfloat16m2_t vle_v_f16m2_m (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base);
vfloat16m4_t vle_v_f16m4_m (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base);
vfloat16m8_t vle_v_f16m8_m (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base);
vfloat32m1_t vle_v_f32m1_m (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base);
vfloat32m2_t vle_v_f32m2_m (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base);
vfloat32m4_t vle_v_f32m4_m (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base);
vfloat32m8_t vle_v_f32m8_m (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base);
vfloat64m1_t vle_v_f64m1_m (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base);
vfloat64m2_t vle_v_f64m2_m (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base);
vfloat64m4_t vle_v_f64m4_m (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base);
vfloat64m8_t vle_v_f64m8_m (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base);
```
### [Vector Unit-Stride Store Functions](rvv-intrinsic-api.md#74-vector-unit-stride-operations):

**Prototypes:**
``` C
void vsb_v_i8m1 (int8_t *base, vint8m1_t value);
void vsb_v_i8m2 (int8_t *base, vint8m2_t value);
void vsb_v_i8m4 (int8_t *base, vint8m4_t value);
void vsb_v_i8m8 (int8_t *base, vint8m8_t value);
void vsb_v_i16m1 (int8_t *base, vint16m1_t value);
void vsb_v_i16m2 (int8_t *base, vint16m2_t value);
void vsb_v_i16m4 (int8_t *base, vint16m4_t value);
void vsb_v_i16m8 (int8_t *base, vint16m8_t value);
void vsb_v_i32m1 (int8_t *base, vint32m1_t value);
void vsb_v_i32m2 (int8_t *base, vint32m2_t value);
void vsb_v_i32m4 (int8_t *base, vint32m4_t value);
void vsb_v_i32m8 (int8_t *base, vint32m8_t value);
void vsb_v_i64m1 (int8_t *base, vint64m1_t value);
void vsb_v_i64m2 (int8_t *base, vint64m2_t value);
void vsb_v_i64m4 (int8_t *base, vint64m4_t value);
void vsb_v_i64m8 (int8_t *base, vint64m8_t value);
void vsb_v_u8m1 (uint8_t *base, vuint8m1_t value);
void vsb_v_u8m2 (uint8_t *base, vuint8m2_t value);
void vsb_v_u8m4 (uint8_t *base, vuint8m4_t value);
void vsb_v_u8m8 (uint8_t *base, vuint8m8_t value);
void vsb_v_u16m1 (uint8_t *base, vuint16m1_t value);
void vsb_v_u16m2 (uint8_t *base, vuint16m2_t value);
void vsb_v_u16m4 (uint8_t *base, vuint16m4_t value);
void vsb_v_u16m8 (uint8_t *base, vuint16m8_t value);
void vsb_v_u32m1 (uint8_t *base, vuint32m1_t value);
void vsb_v_u32m2 (uint8_t *base, vuint32m2_t value);
void vsb_v_u32m4 (uint8_t *base, vuint32m4_t value);
void vsb_v_u32m8 (uint8_t *base, vuint32m8_t value);
void vsb_v_u64m1 (uint8_t *base, vuint64m1_t value);
void vsb_v_u64m2 (uint8_t *base, vuint64m2_t value);
void vsb_v_u64m4 (uint8_t *base, vuint64m4_t value);
void vsb_v_u64m8 (uint8_t *base, vuint64m8_t value);
void vsh_v_i16m1 (int16_t *base, vint16m1_t value);
void vsh_v_i16m2 (int16_t *base, vint16m2_t value);
void vsh_v_i16m4 (int16_t *base, vint16m4_t value);
void vsh_v_i16m8 (int16_t *base, vint16m8_t value);
void vsh_v_i32m1 (int16_t *base, vint32m1_t value);
void vsh_v_i32m2 (int16_t *base, vint32m2_t value);
void vsh_v_i32m4 (int16_t *base, vint32m4_t value);
void vsh_v_i32m8 (int16_t *base, vint32m8_t value);
void vsh_v_i64m1 (int16_t *base, vint64m1_t value);
void vsh_v_i64m2 (int16_t *base, vint64m2_t value);
void vsh_v_i64m4 (int16_t *base, vint64m4_t value);
void vsh_v_i64m8 (int16_t *base, vint64m8_t value);
void vsh_v_u16m1 (uint16_t *base, vuint16m1_t value);
void vsh_v_u16m2 (uint16_t *base, vuint16m2_t value);
void vsh_v_u16m4 (uint16_t *base, vuint16m4_t value);
void vsh_v_u16m8 (uint16_t *base, vuint16m8_t value);
void vsh_v_u32m1 (uint16_t *base, vuint32m1_t value);
void vsh_v_u32m2 (uint16_t *base, vuint32m2_t value);
void vsh_v_u32m4 (uint16_t *base, vuint32m4_t value);
void vsh_v_u32m8 (uint16_t *base, vuint32m8_t value);
void vsh_v_u64m1 (uint16_t *base, vuint64m1_t value);
void vsh_v_u64m2 (uint16_t *base, vuint64m2_t value);
void vsh_v_u64m4 (uint16_t *base, vuint64m4_t value);
void vsh_v_u64m8 (uint16_t *base, vuint64m8_t value);
void vsw_v_i32m1 (int32_t *base, vint32m1_t value);
void vsw_v_i32m2 (int32_t *base, vint32m2_t value);
void vsw_v_i32m4 (int32_t *base, vint32m4_t value);
void vsw_v_i32m8 (int32_t *base, vint32m8_t value);
void vsw_v_i64m1 (int32_t *base, vint64m1_t value);
void vsw_v_i64m2 (int32_t *base, vint64m2_t value);
void vsw_v_i64m4 (int32_t *base, vint64m4_t value);
void vsw_v_i64m8 (int32_t *base, vint64m8_t value);
void vsw_v_u32m1 (uint32_t *base, vuint32m1_t value);
void vsw_v_u32m2 (uint32_t *base, vuint32m2_t value);
void vsw_v_u32m4 (uint32_t *base, vuint32m4_t value);
void vsw_v_u32m8 (uint32_t *base, vuint32m8_t value);
void vsw_v_u64m1 (uint32_t *base, vuint64m1_t value);
void vsw_v_u64m2 (uint32_t *base, vuint64m2_t value);
void vsw_v_u64m4 (uint32_t *base, vuint64m4_t value);
void vsw_v_u64m8 (uint32_t *base, vuint64m8_t value);
void vse_v_i8m1 (int8_t *base, vint8m1_t value);
void vse_v_i8m2 (int8_t *base, vint8m2_t value);
void vse_v_i8m4 (int8_t *base, vint8m4_t value);
void vse_v_i8m8 (int8_t *base, vint8m8_t value);
void vse_v_i16m1 (int16_t *base, vint16m1_t value);
void vse_v_i16m2 (int16_t *base, vint16m2_t value);
void vse_v_i16m4 (int16_t *base, vint16m4_t value);
void vse_v_i16m8 (int16_t *base, vint16m8_t value);
void vse_v_i32m1 (int32_t *base, vint32m1_t value);
void vse_v_i32m2 (int32_t *base, vint32m2_t value);
void vse_v_i32m4 (int32_t *base, vint32m4_t value);
void vse_v_i32m8 (int32_t *base, vint32m8_t value);
void vse_v_i64m1 (int64_t *base, vint64m1_t value);
void vse_v_i64m2 (int64_t *base, vint64m2_t value);
void vse_v_i64m4 (int64_t *base, vint64m4_t value);
void vse_v_i64m8 (int64_t *base, vint64m8_t value);
void vse_v_u8m1 (uint8_t *base, vuint8m1_t value);
void vse_v_u8m2 (uint8_t *base, vuint8m2_t value);
void vse_v_u8m4 (uint8_t *base, vuint8m4_t value);
void vse_v_u8m8 (uint8_t *base, vuint8m8_t value);
void vse_v_u16m1 (uint16_t *base, vuint16m1_t value);
void vse_v_u16m2 (uint16_t *base, vuint16m2_t value);
void vse_v_u16m4 (uint16_t *base, vuint16m4_t value);
void vse_v_u16m8 (uint16_t *base, vuint16m8_t value);
void vse_v_u32m1 (uint32_t *base, vuint32m1_t value);
void vse_v_u32m2 (uint32_t *base, vuint32m2_t value);
void vse_v_u32m4 (uint32_t *base, vuint32m4_t value);
void vse_v_u32m8 (uint32_t *base, vuint32m8_t value);
void vse_v_u64m1 (uint64_t *base, vuint64m1_t value);
void vse_v_u64m2 (uint64_t *base, vuint64m2_t value);
void vse_v_u64m4 (uint64_t *base, vuint64m4_t value);
void vse_v_u64m8 (uint64_t *base, vuint64m8_t value);
void vse_v_f16m1 (float16_t *base, vfloat16m1_t value);
void vse_v_f16m2 (float16_t *base, vfloat16m2_t value);
void vse_v_f16m4 (float16_t *base, vfloat16m4_t value);
void vse_v_f16m8 (float16_t *base, vfloat16m8_t value);
void vse_v_f32m1 (float32_t *base, vfloat32m1_t value);
void vse_v_f32m2 (float32_t *base, vfloat32m2_t value);
void vse_v_f32m4 (float32_t *base, vfloat32m4_t value);
void vse_v_f32m8 (float32_t *base, vfloat32m8_t value);
void vse_v_f64m1 (float64_t *base, vfloat64m1_t value);
void vse_v_f64m2 (float64_t *base, vfloat64m2_t value);
void vse_v_f64m4 (float64_t *base, vfloat64m4_t value);
void vse_v_f64m8 (float64_t *base, vfloat64m8_t value);
// masked functions
void vsb_v_i8m1_m (int8_t *base, vbool8_t mask, vint8m1_t value);
void vsb_v_i8m2_m (int8_t *base, vbool4_t mask, vint8m2_t value);
void vsb_v_i8m4_m (int8_t *base, vbool2_t mask, vint8m4_t value);
void vsb_v_i8m8_m (int8_t *base, vbool1_t mask, vint8m8_t value);
void vsb_v_i16m1_m (int8_t *base, vbool16_t mask, vint16m1_t value);
void vsb_v_i16m2_m (int8_t *base, vbool8_t mask, vint16m2_t value);
void vsb_v_i16m4_m (int8_t *base, vbool4_t mask, vint16m4_t value);
void vsb_v_i16m8_m (int8_t *base, vbool2_t mask, vint16m8_t value);
void vsb_v_i32m1_m (int8_t *base, vbool32_t mask, vint32m1_t value);
void vsb_v_i32m2_m (int8_t *base, vbool16_t mask, vint32m2_t value);
void vsb_v_i32m4_m (int8_t *base, vbool8_t mask, vint32m4_t value);
void vsb_v_i32m8_m (int8_t *base, vbool4_t mask, vint32m8_t value);
void vsb_v_i64m1_m (int8_t *base, vbool64_t mask, vint64m1_t value);
void vsb_v_i64m2_m (int8_t *base, vbool32_t mask, vint64m2_t value);
void vsb_v_i64m4_m (int8_t *base, vbool16_t mask, vint64m4_t value);
void vsb_v_i64m8_m (int8_t *base, vbool8_t mask, vint64m8_t value);
void vsb_v_u8m1_m (uint8_t *base, vbool8_t mask, vuint8m1_t value);
void vsb_v_u8m2_m (uint8_t *base, vbool4_t mask, vuint8m2_t value);
void vsb_v_u8m4_m (uint8_t *base, vbool2_t mask, vuint8m4_t value);
void vsb_v_u8m8_m (uint8_t *base, vbool1_t mask, vuint8m8_t value);
void vsb_v_u16m1_m (uint8_t *base, vbool16_t mask, vuint16m1_t value);
void vsb_v_u16m2_m (uint8_t *base, vbool8_t mask, vuint16m2_t value);
void vsb_v_u16m4_m (uint8_t *base, vbool4_t mask, vuint16m4_t value);
void vsb_v_u16m8_m (uint8_t *base, vbool2_t mask, vuint16m8_t value);
void vsb_v_u32m1_m (uint8_t *base, vbool32_t mask, vuint32m1_t value);
void vsb_v_u32m2_m (uint8_t *base, vbool16_t mask, vuint32m2_t value);
void vsb_v_u32m4_m (uint8_t *base, vbool8_t mask, vuint32m4_t value);
void vsb_v_u32m8_m (uint8_t *base, vbool4_t mask, vuint32m8_t value);
void vsb_v_u64m1_m (uint8_t *base, vbool64_t mask, vuint64m1_t value);
void vsb_v_u64m2_m (uint8_t *base, vbool32_t mask, vuint64m2_t value);
void vsb_v_u64m4_m (uint8_t *base, vbool16_t mask, vuint64m4_t value);
void vsb_v_u64m8_m (uint8_t *base, vbool8_t mask, vuint64m8_t value);
void vsh_v_i16m1_m (int16_t *base, vbool16_t mask, vint16m1_t value);
void vsh_v_i16m2_m (int16_t *base, vbool8_t mask, vint16m2_t value);
void vsh_v_i16m4_m (int16_t *base, vbool4_t mask, vint16m4_t value);
void vsh_v_i16m8_m (int16_t *base, vbool2_t mask, vint16m8_t value);
void vsh_v_i32m1_m (int16_t *base, vbool32_t mask, vint32m1_t value);
void vsh_v_i32m2_m (int16_t *base, vbool16_t mask, vint32m2_t value);
void vsh_v_i32m4_m (int16_t *base, vbool8_t mask, vint32m4_t value);
void vsh_v_i32m8_m (int16_t *base, vbool4_t mask, vint32m8_t value);
void vsh_v_i64m1_m (int16_t *base, vbool64_t mask, vint64m1_t value);
void vsh_v_i64m2_m (int16_t *base, vbool32_t mask, vint64m2_t value);
void vsh_v_i64m4_m (int16_t *base, vbool16_t mask, vint64m4_t value);
void vsh_v_i64m8_m (int16_t *base, vbool8_t mask, vint64m8_t value);
void vsh_v_u16m1_m (uint16_t *base, vbool16_t mask, vuint16m1_t value);
void vsh_v_u16m2_m (uint16_t *base, vbool8_t mask, vuint16m2_t value);
void vsh_v_u16m4_m (uint16_t *base, vbool4_t mask, vuint16m4_t value);
void vsh_v_u16m8_m (uint16_t *base, vbool2_t mask, vuint16m8_t value);
void vsh_v_u32m1_m (uint16_t *base, vbool32_t mask, vuint32m1_t value);
void vsh_v_u32m2_m (uint16_t *base, vbool16_t mask, vuint32m2_t value);
void vsh_v_u32m4_m (uint16_t *base, vbool8_t mask, vuint32m4_t value);
void vsh_v_u32m8_m (uint16_t *base, vbool4_t mask, vuint32m8_t value);
void vsh_v_u64m1_m (uint16_t *base, vbool64_t mask, vuint64m1_t value);
void vsh_v_u64m2_m (uint16_t *base, vbool32_t mask, vuint64m2_t value);
void vsh_v_u64m4_m (uint16_t *base, vbool16_t mask, vuint64m4_t value);
void vsh_v_u64m8_m (uint16_t *base, vbool8_t mask, vuint64m8_t value);
void vsw_v_i32m1_m (int32_t *base, vbool32_t mask, vint32m1_t value);
void vsw_v_i32m2_m (int32_t *base, vbool16_t mask, vint32m2_t value);
void vsw_v_i32m4_m (int32_t *base, vbool8_t mask, vint32m4_t value);
void vsw_v_i32m8_m (int32_t *base, vbool4_t mask, vint32m8_t value);
void vsw_v_i64m1_m (int32_t *base, vbool64_t mask, vint64m1_t value);
void vsw_v_i64m2_m (int32_t *base, vbool32_t mask, vint64m2_t value);
void vsw_v_i64m4_m (int32_t *base, vbool16_t mask, vint64m4_t value);
void vsw_v_i64m8_m (int32_t *base, vbool8_t mask, vint64m8_t value);
void vsw_v_u32m1_m (uint32_t *base, vbool32_t mask, vuint32m1_t value);
void vsw_v_u32m2_m (uint32_t *base, vbool16_t mask, vuint32m2_t value);
void vsw_v_u32m4_m (uint32_t *base, vbool8_t mask, vuint32m4_t value);
void vsw_v_u32m8_m (uint32_t *base, vbool4_t mask, vuint32m8_t value);
void vsw_v_u64m1_m (uint32_t *base, vbool64_t mask, vuint64m1_t value);
void vsw_v_u64m2_m (uint32_t *base, vbool32_t mask, vuint64m2_t value);
void vsw_v_u64m4_m (uint32_t *base, vbool16_t mask, vuint64m4_t value);
void vsw_v_u64m8_m (uint32_t *base, vbool8_t mask, vuint64m8_t value);
void vse_v_i8m1_m (int8_t *base, vbool8_t mask, vint8m1_t value);
void vse_v_i8m2_m (int8_t *base, vbool4_t mask, vint8m2_t value);
void vse_v_i8m4_m (int8_t *base, vbool2_t mask, vint8m4_t value);
void vse_v_i8m8_m (int8_t *base, vbool1_t mask, vint8m8_t value);
void vse_v_i16m1_m (int16_t *base, vbool16_t mask, vint16m1_t value);
void vse_v_i16m2_m (int16_t *base, vbool8_t mask, vint16m2_t value);
void vse_v_i16m4_m (int16_t *base, vbool4_t mask, vint16m4_t value);
void vse_v_i16m8_m (int16_t *base, vbool2_t mask, vint16m8_t value);
void vse_v_i32m1_m (int32_t *base, vbool32_t mask, vint32m1_t value);
void vse_v_i32m2_m (int32_t *base, vbool16_t mask, vint32m2_t value);
void vse_v_i32m4_m (int32_t *base, vbool8_t mask, vint32m4_t value);
void vse_v_i32m8_m (int32_t *base, vbool4_t mask, vint32m8_t value);
void vse_v_i64m1_m (int64_t *base, vbool64_t mask, vint64m1_t value);
void vse_v_i64m2_m (int64_t *base, vbool32_t mask, vint64m2_t value);
void vse_v_i64m4_m (int64_t *base, vbool16_t mask, vint64m4_t value);
void vse_v_i64m8_m (int64_t *base, vbool8_t mask, vint64m8_t value);
void vse_v_u8m1_m (uint8_t *base, vbool8_t mask, vuint8m1_t value);
void vse_v_u8m2_m (uint8_t *base, vbool4_t mask, vuint8m2_t value);
void vse_v_u8m4_m (uint8_t *base, vbool2_t mask, vuint8m4_t value);
void vse_v_u8m8_m (uint8_t *base, vbool1_t mask, vuint8m8_t value);
void vse_v_u16m1_m (uint16_t *base, vbool16_t mask, vuint16m1_t value);
void vse_v_u16m2_m (uint16_t *base, vbool8_t mask, vuint16m2_t value);
void vse_v_u16m4_m (uint16_t *base, vbool4_t mask, vuint16m4_t value);
void vse_v_u16m8_m (uint16_t *base, vbool2_t mask, vuint16m8_t value);
void vse_v_u32m1_m (uint32_t *base, vbool32_t mask, vuint32m1_t value);
void vse_v_u32m2_m (uint32_t *base, vbool16_t mask, vuint32m2_t value);
void vse_v_u32m4_m (uint32_t *base, vbool8_t mask, vuint32m4_t value);
void vse_v_u32m8_m (uint32_t *base, vbool4_t mask, vuint32m8_t value);
void vse_v_u64m1_m (uint64_t *base, vbool64_t mask, vuint64m1_t value);
void vse_v_u64m2_m (uint64_t *base, vbool32_t mask, vuint64m2_t value);
void vse_v_u64m4_m (uint64_t *base, vbool16_t mask, vuint64m4_t value);
void vse_v_u64m8_m (uint64_t *base, vbool8_t mask, vuint64m8_t value);
void vse_v_f16m1_m (float16_t *base, vbool16_t mask, vfloat16m1_t value);
void vse_v_f16m2_m (float16_t *base, vbool8_t mask, vfloat16m2_t value);
void vse_v_f16m4_m (float16_t *base, vbool4_t mask, vfloat16m4_t value);
void vse_v_f16m8_m (float16_t *base, vbool2_t mask, vfloat16m8_t value);
void vse_v_f32m1_m (float32_t *base, vbool32_t mask, vfloat32m1_t value);
void vse_v_f32m2_m (float32_t *base, vbool16_t mask, vfloat32m2_t value);
void vse_v_f32m4_m (float32_t *base, vbool8_t mask, vfloat32m4_t value);
void vse_v_f32m8_m (float32_t *base, vbool4_t mask, vfloat32m8_t value);
void vse_v_f64m1_m (float64_t *base, vbool64_t mask, vfloat64m1_t value);
void vse_v_f64m2_m (float64_t *base, vbool32_t mask, vfloat64m2_t value);
void vse_v_f64m4_m (float64_t *base, vbool16_t mask, vfloat64m4_t value);
void vse_v_f64m8_m (float64_t *base, vbool8_t mask, vfloat64m8_t value);
```
### [Vector Strided Load Functions](rvv-intrinsic-api.md#75-vector-strided-loadstore-operations):

**Prototypes:**
``` C
vint8m1_t vlsb_v_i8m1 (const int8_t *base, ptrdiff_t bstride);
vint8m2_t vlsb_v_i8m2 (const int8_t *base, ptrdiff_t bstride);
vint8m4_t vlsb_v_i8m4 (const int8_t *base, ptrdiff_t bstride);
vint8m8_t vlsb_v_i8m8 (const int8_t *base, ptrdiff_t bstride);
vint16m1_t vlsb_v_i16m1 (const int8_t *base, ptrdiff_t bstride);
vint16m2_t vlsb_v_i16m2 (const int8_t *base, ptrdiff_t bstride);
vint16m4_t vlsb_v_i16m4 (const int8_t *base, ptrdiff_t bstride);
vint16m8_t vlsb_v_i16m8 (const int8_t *base, ptrdiff_t bstride);
vint32m1_t vlsb_v_i32m1 (const int8_t *base, ptrdiff_t bstride);
vint32m2_t vlsb_v_i32m2 (const int8_t *base, ptrdiff_t bstride);
vint32m4_t vlsb_v_i32m4 (const int8_t *base, ptrdiff_t bstride);
vint32m8_t vlsb_v_i32m8 (const int8_t *base, ptrdiff_t bstride);
vint64m1_t vlsb_v_i64m1 (const int8_t *base, ptrdiff_t bstride);
vint64m2_t vlsb_v_i64m2 (const int8_t *base, ptrdiff_t bstride);
vint64m4_t vlsb_v_i64m4 (const int8_t *base, ptrdiff_t bstride);
vint64m8_t vlsb_v_i64m8 (const int8_t *base, ptrdiff_t bstride);
vuint8m1_t vlsbu_v_u8m1 (const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vlsbu_v_u8m2 (const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vlsbu_v_u8m4 (const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vlsbu_v_u8m8 (const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vlsbu_v_u16m1 (const uint8_t *base, ptrdiff_t bstride);
vuint16m2_t vlsbu_v_u16m2 (const uint8_t *base, ptrdiff_t bstride);
vuint16m4_t vlsbu_v_u16m4 (const uint8_t *base, ptrdiff_t bstride);
vuint16m8_t vlsbu_v_u16m8 (const uint8_t *base, ptrdiff_t bstride);
vuint32m1_t vlsbu_v_u32m1 (const uint8_t *base, ptrdiff_t bstride);
vuint32m2_t vlsbu_v_u32m2 (const uint8_t *base, ptrdiff_t bstride);
vuint32m4_t vlsbu_v_u32m4 (const uint8_t *base, ptrdiff_t bstride);
vuint32m8_t vlsbu_v_u32m8 (const uint8_t *base, ptrdiff_t bstride);
vuint64m1_t vlsbu_v_u64m1 (const uint8_t *base, ptrdiff_t bstride);
vuint64m2_t vlsbu_v_u64m2 (const uint8_t *base, ptrdiff_t bstride);
vuint64m4_t vlsbu_v_u64m4 (const uint8_t *base, ptrdiff_t bstride);
vuint64m8_t vlsbu_v_u64m8 (const uint8_t *base, ptrdiff_t bstride);
vint16m1_t vlsh_v_i16m1 (const int16_t *base, ptrdiff_t bstride);
vint16m2_t vlsh_v_i16m2 (const int16_t *base, ptrdiff_t bstride);
vint16m4_t vlsh_v_i16m4 (const int16_t *base, ptrdiff_t bstride);
vint16m8_t vlsh_v_i16m8 (const int16_t *base, ptrdiff_t bstride);
vint32m1_t vlsh_v_i32m1 (const int16_t *base, ptrdiff_t bstride);
vint32m2_t vlsh_v_i32m2 (const int16_t *base, ptrdiff_t bstride);
vint32m4_t vlsh_v_i32m4 (const int16_t *base, ptrdiff_t bstride);
vint32m8_t vlsh_v_i32m8 (const int16_t *base, ptrdiff_t bstride);
vint64m1_t vlsh_v_i64m1 (const int16_t *base, ptrdiff_t bstride);
vint64m2_t vlsh_v_i64m2 (const int16_t *base, ptrdiff_t bstride);
vint64m4_t vlsh_v_i64m4 (const int16_t *base, ptrdiff_t bstride);
vint64m8_t vlsh_v_i64m8 (const int16_t *base, ptrdiff_t bstride);
vuint16m1_t vlshu_v_u16m1 (const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vlshu_v_u16m2 (const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vlshu_v_u16m4 (const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vlshu_v_u16m8 (const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vlshu_v_u32m1 (const uint16_t *base, ptrdiff_t bstride);
vuint32m2_t vlshu_v_u32m2 (const uint16_t *base, ptrdiff_t bstride);
vuint32m4_t vlshu_v_u32m4 (const uint16_t *base, ptrdiff_t bstride);
vuint32m8_t vlshu_v_u32m8 (const uint16_t *base, ptrdiff_t bstride);
vuint64m1_t vlshu_v_u64m1 (const uint16_t *base, ptrdiff_t bstride);
vuint64m2_t vlshu_v_u64m2 (const uint16_t *base, ptrdiff_t bstride);
vuint64m4_t vlshu_v_u64m4 (const uint16_t *base, ptrdiff_t bstride);
vuint64m8_t vlshu_v_u64m8 (const uint16_t *base, ptrdiff_t bstride);
vint32m1_t vlsw_v_i32m1 (const int32_t *base, ptrdiff_t bstride);
vint32m2_t vlsw_v_i32m2 (const int32_t *base, ptrdiff_t bstride);
vint32m4_t vlsw_v_i32m4 (const int32_t *base, ptrdiff_t bstride);
vint32m8_t vlsw_v_i32m8 (const int32_t *base, ptrdiff_t bstride);
vint64m1_t vlsw_v_i64m1 (const int32_t *base, ptrdiff_t bstride);
vint64m2_t vlsw_v_i64m2 (const int32_t *base, ptrdiff_t bstride);
vint64m4_t vlsw_v_i64m4 (const int32_t *base, ptrdiff_t bstride);
vint64m8_t vlsw_v_i64m8 (const int32_t *base, ptrdiff_t bstride);
vuint32m1_t vlswu_v_u32m1 (const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vlswu_v_u32m2 (const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vlswu_v_u32m4 (const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vlswu_v_u32m8 (const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vlswu_v_u64m1 (const uint32_t *base, ptrdiff_t bstride);
vuint64m2_t vlswu_v_u64m2 (const uint32_t *base, ptrdiff_t bstride);
vuint64m4_t vlswu_v_u64m4 (const uint32_t *base, ptrdiff_t bstride);
vuint64m8_t vlswu_v_u64m8 (const uint32_t *base, ptrdiff_t bstride);
vint8m1_t vlse_v_i8m1 (const int8_t *base, ptrdiff_t bstride);
vint8m2_t vlse_v_i8m2 (const int8_t *base, ptrdiff_t bstride);
vint8m4_t vlse_v_i8m4 (const int8_t *base, ptrdiff_t bstride);
vint8m8_t vlse_v_i8m8 (const int8_t *base, ptrdiff_t bstride);
vint16m1_t vlse_v_i16m1 (const int16_t *base, ptrdiff_t bstride);
vint16m2_t vlse_v_i16m2 (const int16_t *base, ptrdiff_t bstride);
vint16m4_t vlse_v_i16m4 (const int16_t *base, ptrdiff_t bstride);
vint16m8_t vlse_v_i16m8 (const int16_t *base, ptrdiff_t bstride);
vint32m1_t vlse_v_i32m1 (const int32_t *base, ptrdiff_t bstride);
vint32m2_t vlse_v_i32m2 (const int32_t *base, ptrdiff_t bstride);
vint32m4_t vlse_v_i32m4 (const int32_t *base, ptrdiff_t bstride);
vint32m8_t vlse_v_i32m8 (const int32_t *base, ptrdiff_t bstride);
vint64m1_t vlse_v_i64m1 (const int64_t *base, ptrdiff_t bstride);
vint64m2_t vlse_v_i64m2 (const int64_t *base, ptrdiff_t bstride);
vint64m4_t vlse_v_i64m4 (const int64_t *base, ptrdiff_t bstride);
vint64m8_t vlse_v_i64m8 (const int64_t *base, ptrdiff_t bstride);
vuint8m1_t vlse_v_u8m1 (const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vlse_v_u8m2 (const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vlse_v_u8m4 (const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vlse_v_u8m8 (const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vlse_v_u16m1 (const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vlse_v_u16m2 (const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vlse_v_u16m4 (const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vlse_v_u16m8 (const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vlse_v_u32m1 (const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vlse_v_u32m2 (const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vlse_v_u32m4 (const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vlse_v_u32m8 (const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vlse_v_u64m1 (const uint64_t *base, ptrdiff_t bstride);
vuint64m2_t vlse_v_u64m2 (const uint64_t *base, ptrdiff_t bstride);
vuint64m4_t vlse_v_u64m4 (const uint64_t *base, ptrdiff_t bstride);
vuint64m8_t vlse_v_u64m8 (const uint64_t *base, ptrdiff_t bstride);
vfloat16m1_t vlse_v_f16m1 (const float16_t *base, ptrdiff_t bstride);
vfloat16m2_t vlse_v_f16m2 (const float16_t *base, ptrdiff_t bstride);
vfloat16m4_t vlse_v_f16m4 (const float16_t *base, ptrdiff_t bstride);
vfloat16m8_t vlse_v_f16m8 (const float16_t *base, ptrdiff_t bstride);
vfloat32m1_t vlse_v_f32m1 (const float32_t *base, ptrdiff_t bstride);
vfloat32m2_t vlse_v_f32m2 (const float32_t *base, ptrdiff_t bstride);
vfloat32m4_t vlse_v_f32m4 (const float32_t *base, ptrdiff_t bstride);
vfloat32m8_t vlse_v_f32m8 (const float32_t *base, ptrdiff_t bstride);
vfloat64m1_t vlse_v_f64m1 (const float64_t *base, ptrdiff_t bstride);
vfloat64m2_t vlse_v_f64m2 (const float64_t *base, ptrdiff_t bstride);
vfloat64m4_t vlse_v_f64m4 (const float64_t *base, ptrdiff_t bstride);
vfloat64m8_t vlse_v_f64m8 (const float64_t *base, ptrdiff_t bstride);
// masked functions
vint8m1_t vlsb_v_i8m1_m (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m2_t vlsb_v_i8m2_m (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m4_t vlsb_v_i8m4_m (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m8_t vlsb_v_i8m8_m (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m1_t vlsb_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m2_t vlsb_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m4_t vlsb_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m8_t vlsb_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m1_t vlsb_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m2_t vlsb_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m4_t vlsb_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m8_t vlsb_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m1_t vlsb_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m2_t vlsb_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m4_t vlsb_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m8_t vlsb_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vuint8m1_t vlsbu_v_u8m1_m (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vlsbu_v_u8m2_m (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vlsbu_v_u8m4_m (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vlsbu_v_u8m8_m (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vlsbu_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m2_t vlsbu_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m4_t vlsbu_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m8_t vlsbu_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m1_t vlsbu_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m2_t vlsbu_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m4_t vlsbu_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m8_t vlsbu_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m1_t vlsbu_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m2_t vlsbu_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m4_t vlsbu_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m8_t vlsbu_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vint16m1_t vlsh_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m2_t vlsh_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m4_t vlsh_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m8_t vlsh_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m1_t vlsh_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m2_t vlsh_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m4_t vlsh_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m8_t vlsh_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m1_t vlsh_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m2_t vlsh_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m4_t vlsh_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m8_t vlsh_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vuint16m1_t vlshu_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vlshu_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vlshu_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vlshu_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vlshu_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m2_t vlshu_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m4_t vlshu_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m8_t vlshu_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m1_t vlshu_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m2_t vlshu_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m4_t vlshu_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m8_t vlshu_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vint32m1_t vlsw_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m2_t vlsw_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m4_t vlsw_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m8_t vlsw_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m1_t vlsw_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m2_t vlsw_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m4_t vlsw_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m8_t vlsw_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vuint32m1_t vlswu_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vlswu_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vlswu_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vlswu_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vlswu_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m2_t vlswu_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m4_t vlswu_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m8_t vlswu_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vint8m1_t vlse_v_i8m1_m (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m2_t vlse_v_i8m2_m (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m4_t vlse_v_i8m4_m (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m8_t vlse_v_i8m8_m (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m1_t vlse_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m2_t vlse_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m4_t vlse_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m8_t vlse_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m1_t vlse_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m2_t vlse_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m4_t vlse_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m8_t vlse_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m1_t vlse_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m2_t vlse_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m4_t vlse_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m8_t vlse_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vuint8m1_t vlse_v_u8m1_m (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vlse_v_u8m2_m (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vlse_v_u8m4_m (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vlse_v_u8m8_m (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vlse_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vlse_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vlse_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vlse_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vlse_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vlse_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vlse_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vlse_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vlse_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m2_t vlse_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m4_t vlse_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m8_t vlse_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vfloat16m1_t vlse_v_f16m1_m (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m2_t vlse_v_f16m2_m (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m4_t vlse_v_f16m4_m (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m8_t vlse_v_f16m8_m (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat32m1_t vlse_v_f32m1_m (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m2_t vlse_v_f32m2_m (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m4_t vlse_v_f32m4_m (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m8_t vlse_v_f32m8_m (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat64m1_t vlse_v_f64m1_m (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m2_t vlse_v_f64m2_m (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m4_t vlse_v_f64m4_m (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m8_t vlse_v_f64m8_m (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, ptrdiff_t bstride);
```
### [Vector Strided Store Functions](rvv-intrinsic-api.md#75-vector-strided-loadstore-operations):

**Prototypes:**
``` C
void vssb_v_i8m1 (int8_t *base, ptrdiff_t bstride, vint8m1_t value);
void vssb_v_i8m2 (int8_t *base, ptrdiff_t bstride, vint8m2_t value);
void vssb_v_i8m4 (int8_t *base, ptrdiff_t bstride, vint8m4_t value);
void vssb_v_i8m8 (int8_t *base, ptrdiff_t bstride, vint8m8_t value);
void vssb_v_i16m1 (int8_t *base, ptrdiff_t bstride, vint16m1_t value);
void vssb_v_i16m2 (int8_t *base, ptrdiff_t bstride, vint16m2_t value);
void vssb_v_i16m4 (int8_t *base, ptrdiff_t bstride, vint16m4_t value);
void vssb_v_i16m8 (int8_t *base, ptrdiff_t bstride, vint16m8_t value);
void vssb_v_i32m1 (int8_t *base, ptrdiff_t bstride, vint32m1_t value);
void vssb_v_i32m2 (int8_t *base, ptrdiff_t bstride, vint32m2_t value);
void vssb_v_i32m4 (int8_t *base, ptrdiff_t bstride, vint32m4_t value);
void vssb_v_i32m8 (int8_t *base, ptrdiff_t bstride, vint32m8_t value);
void vssb_v_i64m1 (int8_t *base, ptrdiff_t bstride, vint64m1_t value);
void vssb_v_i64m2 (int8_t *base, ptrdiff_t bstride, vint64m2_t value);
void vssb_v_i64m4 (int8_t *base, ptrdiff_t bstride, vint64m4_t value);
void vssb_v_i64m8 (int8_t *base, ptrdiff_t bstride, vint64m8_t value);
void vssb_v_u8m1 (uint8_t *base, ptrdiff_t bstride, vuint8m1_t value);
void vssb_v_u8m2 (uint8_t *base, ptrdiff_t bstride, vuint8m2_t value);
void vssb_v_u8m4 (uint8_t *base, ptrdiff_t bstride, vuint8m4_t value);
void vssb_v_u8m8 (uint8_t *base, ptrdiff_t bstride, vuint8m8_t value);
void vssb_v_u16m1 (uint8_t *base, ptrdiff_t bstride, vuint16m1_t value);
void vssb_v_u16m2 (uint8_t *base, ptrdiff_t bstride, vuint16m2_t value);
void vssb_v_u16m4 (uint8_t *base, ptrdiff_t bstride, vuint16m4_t value);
void vssb_v_u16m8 (uint8_t *base, ptrdiff_t bstride, vuint16m8_t value);
void vssb_v_u32m1 (uint8_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vssb_v_u32m2 (uint8_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vssb_v_u32m4 (uint8_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vssb_v_u32m8 (uint8_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vssb_v_u64m1 (uint8_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vssb_v_u64m2 (uint8_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vssb_v_u64m4 (uint8_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vssb_v_u64m8 (uint8_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vssh_v_i16m1 (int16_t *base, ptrdiff_t bstride, vint16m1_t value);
void vssh_v_i16m2 (int16_t *base, ptrdiff_t bstride, vint16m2_t value);
void vssh_v_i16m4 (int16_t *base, ptrdiff_t bstride, vint16m4_t value);
void vssh_v_i16m8 (int16_t *base, ptrdiff_t bstride, vint16m8_t value);
void vssh_v_i32m1 (int16_t *base, ptrdiff_t bstride, vint32m1_t value);
void vssh_v_i32m2 (int16_t *base, ptrdiff_t bstride, vint32m2_t value);
void vssh_v_i32m4 (int16_t *base, ptrdiff_t bstride, vint32m4_t value);
void vssh_v_i32m8 (int16_t *base, ptrdiff_t bstride, vint32m8_t value);
void vssh_v_i64m1 (int16_t *base, ptrdiff_t bstride, vint64m1_t value);
void vssh_v_i64m2 (int16_t *base, ptrdiff_t bstride, vint64m2_t value);
void vssh_v_i64m4 (int16_t *base, ptrdiff_t bstride, vint64m4_t value);
void vssh_v_i64m8 (int16_t *base, ptrdiff_t bstride, vint64m8_t value);
void vssh_v_u16m1 (uint16_t *base, ptrdiff_t bstride, vuint16m1_t value);
void vssh_v_u16m2 (uint16_t *base, ptrdiff_t bstride, vuint16m2_t value);
void vssh_v_u16m4 (uint16_t *base, ptrdiff_t bstride, vuint16m4_t value);
void vssh_v_u16m8 (uint16_t *base, ptrdiff_t bstride, vuint16m8_t value);
void vssh_v_u32m1 (uint16_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vssh_v_u32m2 (uint16_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vssh_v_u32m4 (uint16_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vssh_v_u32m8 (uint16_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vssh_v_u64m1 (uint16_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vssh_v_u64m2 (uint16_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vssh_v_u64m4 (uint16_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vssh_v_u64m8 (uint16_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vssw_v_i32m1 (int32_t *base, ptrdiff_t bstride, vint32m1_t value);
void vssw_v_i32m2 (int32_t *base, ptrdiff_t bstride, vint32m2_t value);
void vssw_v_i32m4 (int32_t *base, ptrdiff_t bstride, vint32m4_t value);
void vssw_v_i32m8 (int32_t *base, ptrdiff_t bstride, vint32m8_t value);
void vssw_v_i64m1 (int32_t *base, ptrdiff_t bstride, vint64m1_t value);
void vssw_v_i64m2 (int32_t *base, ptrdiff_t bstride, vint64m2_t value);
void vssw_v_i64m4 (int32_t *base, ptrdiff_t bstride, vint64m4_t value);
void vssw_v_i64m8 (int32_t *base, ptrdiff_t bstride, vint64m8_t value);
void vssw_v_u32m1 (uint32_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vssw_v_u32m2 (uint32_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vssw_v_u32m4 (uint32_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vssw_v_u32m8 (uint32_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vssw_v_u64m1 (uint32_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vssw_v_u64m2 (uint32_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vssw_v_u64m4 (uint32_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vssw_v_u64m8 (uint32_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vsse_v_i8m1 (int8_t *base, ptrdiff_t bstride, vint8m1_t value);
void vsse_v_i8m2 (int8_t *base, ptrdiff_t bstride, vint8m2_t value);
void vsse_v_i8m4 (int8_t *base, ptrdiff_t bstride, vint8m4_t value);
void vsse_v_i8m8 (int8_t *base, ptrdiff_t bstride, vint8m8_t value);
void vsse_v_i16m1 (int16_t *base, ptrdiff_t bstride, vint16m1_t value);
void vsse_v_i16m2 (int16_t *base, ptrdiff_t bstride, vint16m2_t value);
void vsse_v_i16m4 (int16_t *base, ptrdiff_t bstride, vint16m4_t value);
void vsse_v_i16m8 (int16_t *base, ptrdiff_t bstride, vint16m8_t value);
void vsse_v_i32m1 (int32_t *base, ptrdiff_t bstride, vint32m1_t value);
void vsse_v_i32m2 (int32_t *base, ptrdiff_t bstride, vint32m2_t value);
void vsse_v_i32m4 (int32_t *base, ptrdiff_t bstride, vint32m4_t value);
void vsse_v_i32m8 (int32_t *base, ptrdiff_t bstride, vint32m8_t value);
void vsse_v_i64m1 (int64_t *base, ptrdiff_t bstride, vint64m1_t value);
void vsse_v_i64m2 (int64_t *base, ptrdiff_t bstride, vint64m2_t value);
void vsse_v_i64m4 (int64_t *base, ptrdiff_t bstride, vint64m4_t value);
void vsse_v_i64m8 (int64_t *base, ptrdiff_t bstride, vint64m8_t value);
void vsse_v_u8m1 (uint8_t *base, ptrdiff_t bstride, vuint8m1_t value);
void vsse_v_u8m2 (uint8_t *base, ptrdiff_t bstride, vuint8m2_t value);
void vsse_v_u8m4 (uint8_t *base, ptrdiff_t bstride, vuint8m4_t value);
void vsse_v_u8m8 (uint8_t *base, ptrdiff_t bstride, vuint8m8_t value);
void vsse_v_u16m1 (uint16_t *base, ptrdiff_t bstride, vuint16m1_t value);
void vsse_v_u16m2 (uint16_t *base, ptrdiff_t bstride, vuint16m2_t value);
void vsse_v_u16m4 (uint16_t *base, ptrdiff_t bstride, vuint16m4_t value);
void vsse_v_u16m8 (uint16_t *base, ptrdiff_t bstride, vuint16m8_t value);
void vsse_v_u32m1 (uint32_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vsse_v_u32m2 (uint32_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vsse_v_u32m4 (uint32_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vsse_v_u32m8 (uint32_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vsse_v_u64m1 (uint64_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vsse_v_u64m2 (uint64_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vsse_v_u64m4 (uint64_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vsse_v_u64m8 (uint64_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vsse_v_f16m1 (float16_t *base, ptrdiff_t bstride, vfloat16m1_t value);
void vsse_v_f16m2 (float16_t *base, ptrdiff_t bstride, vfloat16m2_t value);
void vsse_v_f16m4 (float16_t *base, ptrdiff_t bstride, vfloat16m4_t value);
void vsse_v_f16m8 (float16_t *base, ptrdiff_t bstride, vfloat16m8_t value);
void vsse_v_f32m1 (float32_t *base, ptrdiff_t bstride, vfloat32m1_t value);
void vsse_v_f32m2 (float32_t *base, ptrdiff_t bstride, vfloat32m2_t value);
void vsse_v_f32m4 (float32_t *base, ptrdiff_t bstride, vfloat32m4_t value);
void vsse_v_f32m8 (float32_t *base, ptrdiff_t bstride, vfloat32m8_t value);
void vsse_v_f64m1 (float64_t *base, ptrdiff_t bstride, vfloat64m1_t value);
void vsse_v_f64m2 (float64_t *base, ptrdiff_t bstride, vfloat64m2_t value);
void vsse_v_f64m4 (float64_t *base, ptrdiff_t bstride, vfloat64m4_t value);
void vsse_v_f64m8 (float64_t *base, ptrdiff_t bstride, vfloat64m8_t value);
// masked functions
void vssb_v_i8m1_m (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint8m1_t value);
void vssb_v_i8m2_m (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint8m2_t value);
void vssb_v_i8m4_m (int8_t *base, ptrdiff_t bstride, vbool2_t mask, vint8m4_t value);
void vssb_v_i8m8_m (int8_t *base, ptrdiff_t bstride, vbool1_t mask, vint8m8_t value);
void vssb_v_i16m1_m (int8_t *base, ptrdiff_t bstride, vbool16_t mask, vint16m1_t value);
void vssb_v_i16m2_m (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint16m2_t value);
void vssb_v_i16m4_m (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint16m4_t value);
void vssb_v_i16m8_m (int8_t *base, ptrdiff_t bstride, vbool2_t mask, vint16m8_t value);
void vssb_v_i32m1_m (int8_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vssb_v_i32m2_m (int8_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vssb_v_i32m4_m (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vssb_v_i32m8_m (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vssb_v_i64m1_m (int8_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vssb_v_i64m2_m (int8_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vssb_v_i64m4_m (int8_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vssb_v_i64m8_m (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vssb_v_u8m1_m (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint8m1_t value);
void vssb_v_u8m2_m (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint8m2_t value);
void vssb_v_u8m4_m (uint8_t *base, ptrdiff_t bstride, vbool2_t mask, vuint8m4_t value);
void vssb_v_u8m8_m (uint8_t *base, ptrdiff_t bstride, vbool1_t mask, vuint8m8_t value);
void vssb_v_u16m1_m (uint8_t *base, ptrdiff_t bstride, vbool16_t mask, vuint16m1_t value);
void vssb_v_u16m2_m (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint16m2_t value);
void vssb_v_u16m4_m (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint16m4_t value);
void vssb_v_u16m8_m (uint8_t *base, ptrdiff_t bstride, vbool2_t mask, vuint16m8_t value);
void vssb_v_u32m1_m (uint8_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vssb_v_u32m2_m (uint8_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vssb_v_u32m4_m (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vssb_v_u32m8_m (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vssb_v_u64m1_m (uint8_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vssb_v_u64m2_m (uint8_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vssb_v_u64m4_m (uint8_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vssb_v_u64m8_m (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vssh_v_i16m1_m (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint16m1_t value);
void vssh_v_i16m2_m (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint16m2_t value);
void vssh_v_i16m4_m (int16_t *base, ptrdiff_t bstride, vbool4_t mask, vint16m4_t value);
void vssh_v_i16m8_m (int16_t *base, ptrdiff_t bstride, vbool2_t mask, vint16m8_t value);
void vssh_v_i32m1_m (int16_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vssh_v_i32m2_m (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vssh_v_i32m4_m (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vssh_v_i32m8_m (int16_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vssh_v_i64m1_m (int16_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vssh_v_i64m2_m (int16_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vssh_v_i64m4_m (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vssh_v_i64m8_m (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vssh_v_u16m1_m (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint16m1_t value);
void vssh_v_u16m2_m (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint16m2_t value);
void vssh_v_u16m4_m (uint16_t *base, ptrdiff_t bstride, vbool4_t mask, vuint16m4_t value);
void vssh_v_u16m8_m (uint16_t *base, ptrdiff_t bstride, vbool2_t mask, vuint16m8_t value);
void vssh_v_u32m1_m (uint16_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vssh_v_u32m2_m (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vssh_v_u32m4_m (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vssh_v_u32m8_m (uint16_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vssh_v_u64m1_m (uint16_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vssh_v_u64m2_m (uint16_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vssh_v_u64m4_m (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vssh_v_u64m8_m (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vssw_v_i32m1_m (int32_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vssw_v_i32m2_m (int32_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vssw_v_i32m4_m (int32_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vssw_v_i32m8_m (int32_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vssw_v_i64m1_m (int32_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vssw_v_i64m2_m (int32_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vssw_v_i64m4_m (int32_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vssw_v_i64m8_m (int32_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vssw_v_u32m1_m (uint32_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vssw_v_u32m2_m (uint32_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vssw_v_u32m4_m (uint32_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vssw_v_u32m8_m (uint32_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vssw_v_u64m1_m (uint32_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vssw_v_u64m2_m (uint32_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vssw_v_u64m4_m (uint32_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vssw_v_u64m8_m (uint32_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vsse_v_i8m1_m (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint8m1_t value);
void vsse_v_i8m2_m (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint8m2_t value);
void vsse_v_i8m4_m (int8_t *base, ptrdiff_t bstride, vbool2_t mask, vint8m4_t value);
void vsse_v_i8m8_m (int8_t *base, ptrdiff_t bstride, vbool1_t mask, vint8m8_t value);
void vsse_v_i16m1_m (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint16m1_t value);
void vsse_v_i16m2_m (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint16m2_t value);
void vsse_v_i16m4_m (int16_t *base, ptrdiff_t bstride, vbool4_t mask, vint16m4_t value);
void vsse_v_i16m8_m (int16_t *base, ptrdiff_t bstride, vbool2_t mask, vint16m8_t value);
void vsse_v_i32m1_m (int32_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vsse_v_i32m2_m (int32_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vsse_v_i32m4_m (int32_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vsse_v_i32m8_m (int32_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vsse_v_i64m1_m (int64_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vsse_v_i64m2_m (int64_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vsse_v_i64m4_m (int64_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vsse_v_i64m8_m (int64_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vsse_v_u8m1_m (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint8m1_t value);
void vsse_v_u8m2_m (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint8m2_t value);
void vsse_v_u8m4_m (uint8_t *base, ptrdiff_t bstride, vbool2_t mask, vuint8m4_t value);
void vsse_v_u8m8_m (uint8_t *base, ptrdiff_t bstride, vbool1_t mask, vuint8m8_t value);
void vsse_v_u16m1_m (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint16m1_t value);
void vsse_v_u16m2_m (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint16m2_t value);
void vsse_v_u16m4_m (uint16_t *base, ptrdiff_t bstride, vbool4_t mask, vuint16m4_t value);
void vsse_v_u16m8_m (uint16_t *base, ptrdiff_t bstride, vbool2_t mask, vuint16m8_t value);
void vsse_v_u32m1_m (uint32_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vsse_v_u32m2_m (uint32_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vsse_v_u32m4_m (uint32_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vsse_v_u32m8_m (uint32_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vsse_v_u64m1_m (uint64_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vsse_v_u64m2_m (uint64_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vsse_v_u64m4_m (uint64_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vsse_v_u64m8_m (uint64_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vsse_v_f16m1_m (float16_t *base, ptrdiff_t bstride, vbool16_t mask, vfloat16m1_t value);
void vsse_v_f16m2_m (float16_t *base, ptrdiff_t bstride, vbool8_t mask, vfloat16m2_t value);
void vsse_v_f16m4_m (float16_t *base, ptrdiff_t bstride, vbool4_t mask, vfloat16m4_t value);
void vsse_v_f16m8_m (float16_t *base, ptrdiff_t bstride, vbool2_t mask, vfloat16m8_t value);
void vsse_v_f32m1_m (float32_t *base, ptrdiff_t bstride, vbool32_t mask, vfloat32m1_t value);
void vsse_v_f32m2_m (float32_t *base, ptrdiff_t bstride, vbool16_t mask, vfloat32m2_t value);
void vsse_v_f32m4_m (float32_t *base, ptrdiff_t bstride, vbool8_t mask, vfloat32m4_t value);
void vsse_v_f32m8_m (float32_t *base, ptrdiff_t bstride, vbool4_t mask, vfloat32m8_t value);
void vsse_v_f64m1_m (float64_t *base, ptrdiff_t bstride, vbool64_t mask, vfloat64m1_t value);
void vsse_v_f64m2_m (float64_t *base, ptrdiff_t bstride, vbool32_t mask, vfloat64m2_t value);
void vsse_v_f64m4_m (float64_t *base, ptrdiff_t bstride, vbool16_t mask, vfloat64m4_t value);
void vsse_v_f64m8_m (float64_t *base, ptrdiff_t bstride, vbool8_t mask, vfloat64m8_t value);
```
### [Vector Indexed Load Functions](rvv-intrinsic-api.md#76-vector-indexed-loadstore-operations):

**Prototypes:**
``` C
vint8m1_t vlxb_v_i8m1 (const int8_t *base, vuint8m1_t bindex);
vint8m2_t vlxb_v_i8m2 (const int8_t *base, vuint8m2_t bindex);
vint8m4_t vlxb_v_i8m4 (const int8_t *base, vuint8m4_t bindex);
vint8m8_t vlxb_v_i8m8 (const int8_t *base, vuint8m8_t bindex);
vint16m1_t vlxb_v_i16m1 (const int8_t *base, vuint16m1_t bindex);
vint16m2_t vlxb_v_i16m2 (const int8_t *base, vuint16m2_t bindex);
vint16m4_t vlxb_v_i16m4 (const int8_t *base, vuint16m4_t bindex);
vint16m8_t vlxb_v_i16m8 (const int8_t *base, vuint16m8_t bindex);
vint32m1_t vlxb_v_i32m1 (const int8_t *base, vuint32m1_t bindex);
vint32m2_t vlxb_v_i32m2 (const int8_t *base, vuint32m2_t bindex);
vint32m4_t vlxb_v_i32m4 (const int8_t *base, vuint32m4_t bindex);
vint32m8_t vlxb_v_i32m8 (const int8_t *base, vuint32m8_t bindex);
vint64m1_t vlxb_v_i64m1 (const int8_t *base, vuint64m1_t bindex);
vint64m2_t vlxb_v_i64m2 (const int8_t *base, vuint64m2_t bindex);
vint64m4_t vlxb_v_i64m4 (const int8_t *base, vuint64m4_t bindex);
vint64m8_t vlxb_v_i64m8 (const int8_t *base, vuint64m8_t bindex);
vuint8m1_t vlxbu_v_u8m1 (const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vlxbu_v_u8m2 (const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vlxbu_v_u8m4 (const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vlxbu_v_u8m8 (const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vlxbu_v_u16m1 (const uint8_t *base, vuint16m1_t bindex);
vuint16m2_t vlxbu_v_u16m2 (const uint8_t *base, vuint16m2_t bindex);
vuint16m4_t vlxbu_v_u16m4 (const uint8_t *base, vuint16m4_t bindex);
vuint16m8_t vlxbu_v_u16m8 (const uint8_t *base, vuint16m8_t bindex);
vuint32m1_t vlxbu_v_u32m1 (const uint8_t *base, vuint32m1_t bindex);
vuint32m2_t vlxbu_v_u32m2 (const uint8_t *base, vuint32m2_t bindex);
vuint32m4_t vlxbu_v_u32m4 (const uint8_t *base, vuint32m4_t bindex);
vuint32m8_t vlxbu_v_u32m8 (const uint8_t *base, vuint32m8_t bindex);
vuint64m1_t vlxbu_v_u64m1 (const uint8_t *base, vuint64m1_t bindex);
vuint64m2_t vlxbu_v_u64m2 (const uint8_t *base, vuint64m2_t bindex);
vuint64m4_t vlxbu_v_u64m4 (const uint8_t *base, vuint64m4_t bindex);
vuint64m8_t vlxbu_v_u64m8 (const uint8_t *base, vuint64m8_t bindex);
vint16m1_t vlxh_v_i16m1 (const int16_t *base, vuint16m1_t bindex);
vint16m2_t vlxh_v_i16m2 (const int16_t *base, vuint16m2_t bindex);
vint16m4_t vlxh_v_i16m4 (const int16_t *base, vuint16m4_t bindex);
vint16m8_t vlxh_v_i16m8 (const int16_t *base, vuint16m8_t bindex);
vint32m1_t vlxh_v_i32m1 (const int16_t *base, vuint32m1_t bindex);
vint32m2_t vlxh_v_i32m2 (const int16_t *base, vuint32m2_t bindex);
vint32m4_t vlxh_v_i32m4 (const int16_t *base, vuint32m4_t bindex);
vint32m8_t vlxh_v_i32m8 (const int16_t *base, vuint32m8_t bindex);
vint64m1_t vlxh_v_i64m1 (const int16_t *base, vuint64m1_t bindex);
vint64m2_t vlxh_v_i64m2 (const int16_t *base, vuint64m2_t bindex);
vint64m4_t vlxh_v_i64m4 (const int16_t *base, vuint64m4_t bindex);
vint64m8_t vlxh_v_i64m8 (const int16_t *base, vuint64m8_t bindex);
vuint16m1_t vlxhu_v_u16m1 (const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vlxhu_v_u16m2 (const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vlxhu_v_u16m4 (const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vlxhu_v_u16m8 (const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vlxhu_v_u32m1 (const uint16_t *base, vuint32m1_t bindex);
vuint32m2_t vlxhu_v_u32m2 (const uint16_t *base, vuint32m2_t bindex);
vuint32m4_t vlxhu_v_u32m4 (const uint16_t *base, vuint32m4_t bindex);
vuint32m8_t vlxhu_v_u32m8 (const uint16_t *base, vuint32m8_t bindex);
vuint64m1_t vlxhu_v_u64m1 (const uint16_t *base, vuint64m1_t bindex);
vuint64m2_t vlxhu_v_u64m2 (const uint16_t *base, vuint64m2_t bindex);
vuint64m4_t vlxhu_v_u64m4 (const uint16_t *base, vuint64m4_t bindex);
vuint64m8_t vlxhu_v_u64m8 (const uint16_t *base, vuint64m8_t bindex);
vint32m1_t vlxw_v_i32m1 (const int32_t *base, vuint32m1_t bindex);
vint32m2_t vlxw_v_i32m2 (const int32_t *base, vuint32m2_t bindex);
vint32m4_t vlxw_v_i32m4 (const int32_t *base, vuint32m4_t bindex);
vint32m8_t vlxw_v_i32m8 (const int32_t *base, vuint32m8_t bindex);
vint64m1_t vlxw_v_i64m1 (const int32_t *base, vuint64m1_t bindex);
vint64m2_t vlxw_v_i64m2 (const int32_t *base, vuint64m2_t bindex);
vint64m4_t vlxw_v_i64m4 (const int32_t *base, vuint64m4_t bindex);
vint64m8_t vlxw_v_i64m8 (const int32_t *base, vuint64m8_t bindex);
vuint32m1_t vlxwu_v_u32m1 (const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vlxwu_v_u32m2 (const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vlxwu_v_u32m4 (const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vlxwu_v_u32m8 (const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vlxwu_v_u64m1 (const uint32_t *base, vuint64m1_t bindex);
vuint64m2_t vlxwu_v_u64m2 (const uint32_t *base, vuint64m2_t bindex);
vuint64m4_t vlxwu_v_u64m4 (const uint32_t *base, vuint64m4_t bindex);
vuint64m8_t vlxwu_v_u64m8 (const uint32_t *base, vuint64m8_t bindex);
vint8m1_t vlxe_v_i8m1 (const int8_t *base, vuint8m1_t bindex);
vint8m2_t vlxe_v_i8m2 (const int8_t *base, vuint8m2_t bindex);
vint8m4_t vlxe_v_i8m4 (const int8_t *base, vuint8m4_t bindex);
vint8m8_t vlxe_v_i8m8 (const int8_t *base, vuint8m8_t bindex);
vint16m1_t vlxe_v_i16m1 (const int16_t *base, vuint16m1_t bindex);
vint16m2_t vlxe_v_i16m2 (const int16_t *base, vuint16m2_t bindex);
vint16m4_t vlxe_v_i16m4 (const int16_t *base, vuint16m4_t bindex);
vint16m8_t vlxe_v_i16m8 (const int16_t *base, vuint16m8_t bindex);
vint32m1_t vlxe_v_i32m1 (const int32_t *base, vuint32m1_t bindex);
vint32m2_t vlxe_v_i32m2 (const int32_t *base, vuint32m2_t bindex);
vint32m4_t vlxe_v_i32m4 (const int32_t *base, vuint32m4_t bindex);
vint32m8_t vlxe_v_i32m8 (const int32_t *base, vuint32m8_t bindex);
vint64m1_t vlxe_v_i64m1 (const int64_t *base, vuint64m1_t bindex);
vint64m2_t vlxe_v_i64m2 (const int64_t *base, vuint64m2_t bindex);
vint64m4_t vlxe_v_i64m4 (const int64_t *base, vuint64m4_t bindex);
vint64m8_t vlxe_v_i64m8 (const int64_t *base, vuint64m8_t bindex);
vuint8m1_t vlxe_v_u8m1 (const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vlxe_v_u8m2 (const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vlxe_v_u8m4 (const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vlxe_v_u8m8 (const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vlxe_v_u16m1 (const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vlxe_v_u16m2 (const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vlxe_v_u16m4 (const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vlxe_v_u16m8 (const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vlxe_v_u32m1 (const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vlxe_v_u32m2 (const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vlxe_v_u32m4 (const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vlxe_v_u32m8 (const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vlxe_v_u64m1 (const uint64_t *base, vuint64m1_t bindex);
vuint64m2_t vlxe_v_u64m2 (const uint64_t *base, vuint64m2_t bindex);
vuint64m4_t vlxe_v_u64m4 (const uint64_t *base, vuint64m4_t bindex);
vuint64m8_t vlxe_v_u64m8 (const uint64_t *base, vuint64m8_t bindex);
vfloat16m1_t vlxe_v_f16m1 (const float16_t *base, vuint16m1_t bindex);
vfloat16m2_t vlxe_v_f16m2 (const float16_t *base, vuint16m2_t bindex);
vfloat16m4_t vlxe_v_f16m4 (const float16_t *base, vuint16m4_t bindex);
vfloat16m8_t vlxe_v_f16m8 (const float16_t *base, vuint16m8_t bindex);
vfloat32m1_t vlxe_v_f32m1 (const float32_t *base, vuint32m1_t bindex);
vfloat32m2_t vlxe_v_f32m2 (const float32_t *base, vuint32m2_t bindex);
vfloat32m4_t vlxe_v_f32m4 (const float32_t *base, vuint32m4_t bindex);
vfloat32m8_t vlxe_v_f32m8 (const float32_t *base, vuint32m8_t bindex);
vfloat64m1_t vlxe_v_f64m1 (const float64_t *base, vuint64m1_t bindex);
vfloat64m2_t vlxe_v_f64m2 (const float64_t *base, vuint64m2_t bindex);
vfloat64m4_t vlxe_v_f64m4 (const float64_t *base, vuint64m4_t bindex);
vfloat64m8_t vlxe_v_f64m8 (const float64_t *base, vuint64m8_t bindex);
// masked functions
vint8m1_t vlxb_v_i8m1_m (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex);
vint8m2_t vlxb_v_i8m2_m (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex);
vint8m4_t vlxb_v_i8m4_m (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex);
vint8m8_t vlxb_v_i8m8_m (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex);
vint16m1_t vlxb_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base, vuint16m1_t bindex);
vint16m2_t vlxb_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base, vuint16m2_t bindex);
vint16m4_t vlxb_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base, vuint16m4_t bindex);
vint16m8_t vlxb_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base, vuint16m8_t bindex);
vint32m1_t vlxb_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base, vuint32m1_t bindex);
vint32m2_t vlxb_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base, vuint32m2_t bindex);
vint32m4_t vlxb_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base, vuint32m4_t bindex);
vint32m8_t vlxb_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base, vuint32m8_t bindex);
vint64m1_t vlxb_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base, vuint64m1_t bindex);
vint64m2_t vlxb_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base, vuint64m2_t bindex);
vint64m4_t vlxb_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base, vuint64m4_t bindex);
vint64m8_t vlxb_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base, vuint64m8_t bindex);
vuint8m1_t vlxbu_v_u8m1_m (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vlxbu_v_u8m2_m (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vlxbu_v_u8m4_m (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vlxbu_v_u8m8_m (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vlxbu_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base, vuint16m1_t bindex);
vuint16m2_t vlxbu_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base, vuint16m2_t bindex);
vuint16m4_t vlxbu_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base, vuint16m4_t bindex);
vuint16m8_t vlxbu_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base, vuint16m8_t bindex);
vuint32m1_t vlxbu_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base, vuint32m1_t bindex);
vuint32m2_t vlxbu_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base, vuint32m2_t bindex);
vuint32m4_t vlxbu_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base, vuint32m4_t bindex);
vuint32m8_t vlxbu_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base, vuint32m8_t bindex);
vuint64m1_t vlxbu_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base, vuint64m1_t bindex);
vuint64m2_t vlxbu_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base, vuint64m2_t bindex);
vuint64m4_t vlxbu_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base, vuint64m4_t bindex);
vuint64m8_t vlxbu_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base, vuint64m8_t bindex);
vint16m1_t vlxh_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex);
vint16m2_t vlxh_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex);
vint16m4_t vlxh_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex);
vint16m8_t vlxh_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex);
vint32m1_t vlxh_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base, vuint32m1_t bindex);
vint32m2_t vlxh_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base, vuint32m2_t bindex);
vint32m4_t vlxh_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base, vuint32m4_t bindex);
vint32m8_t vlxh_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base, vuint32m8_t bindex);
vint64m1_t vlxh_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base, vuint64m1_t bindex);
vint64m2_t vlxh_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base, vuint64m2_t bindex);
vint64m4_t vlxh_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base, vuint64m4_t bindex);
vint64m8_t vlxh_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base, vuint64m8_t bindex);
vuint16m1_t vlxhu_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vlxhu_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vlxhu_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vlxhu_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vlxhu_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base, vuint32m1_t bindex);
vuint32m2_t vlxhu_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base, vuint32m2_t bindex);
vuint32m4_t vlxhu_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base, vuint32m4_t bindex);
vuint32m8_t vlxhu_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base, vuint32m8_t bindex);
vuint64m1_t vlxhu_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base, vuint64m1_t bindex);
vuint64m2_t vlxhu_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base, vuint64m2_t bindex);
vuint64m4_t vlxhu_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base, vuint64m4_t bindex);
vuint64m8_t vlxhu_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base, vuint64m8_t bindex);
vint32m1_t vlxw_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex);
vint32m2_t vlxw_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex);
vint32m4_t vlxw_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex);
vint32m8_t vlxw_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex);
vint64m1_t vlxw_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base, vuint64m1_t bindex);
vint64m2_t vlxw_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base, vuint64m2_t bindex);
vint64m4_t vlxw_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base, vuint64m4_t bindex);
vint64m8_t vlxw_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base, vuint64m8_t bindex);
vuint32m1_t vlxwu_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vlxwu_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vlxwu_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vlxwu_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vlxwu_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base, vuint64m1_t bindex);
vuint64m2_t vlxwu_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base, vuint64m2_t bindex);
vuint64m4_t vlxwu_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base, vuint64m4_t bindex);
vuint64m8_t vlxwu_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base, vuint64m8_t bindex);
vint8m1_t vlxe_v_i8m1_m (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex);
vint8m2_t vlxe_v_i8m2_m (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex);
vint8m4_t vlxe_v_i8m4_m (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex);
vint8m8_t vlxe_v_i8m8_m (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex);
vint16m1_t vlxe_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex);
vint16m2_t vlxe_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex);
vint16m4_t vlxe_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex);
vint16m8_t vlxe_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex);
vint32m1_t vlxe_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex);
vint32m2_t vlxe_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex);
vint32m4_t vlxe_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex);
vint32m8_t vlxe_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex);
vint64m1_t vlxe_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex);
vint64m2_t vlxe_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex);
vint64m4_t vlxe_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex);
vint64m8_t vlxe_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex);
vuint8m1_t vlxe_v_u8m1_m (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vlxe_v_u8m2_m (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vlxe_v_u8m4_m (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vlxe_v_u8m8_m (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vlxe_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vlxe_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vlxe_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vlxe_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vlxe_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vlxe_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vlxe_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vlxe_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vlxe_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex);
vuint64m2_t vlxe_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex);
vuint64m4_t vlxe_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex);
vuint64m8_t vlxe_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex);
vfloat16m1_t vlxe_v_f16m1_m (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex);
vfloat16m2_t vlxe_v_f16m2_m (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex);
vfloat16m4_t vlxe_v_f16m4_m (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex);
vfloat16m8_t vlxe_v_f16m8_m (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex);
vfloat32m1_t vlxe_v_f32m1_m (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex);
vfloat32m2_t vlxe_v_f32m2_m (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex);
vfloat32m4_t vlxe_v_f32m4_m (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex);
vfloat32m8_t vlxe_v_f32m8_m (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex);
vfloat64m1_t vlxe_v_f64m1_m (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex);
vfloat64m2_t vlxe_v_f64m2_m (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex);
vfloat64m4_t vlxe_v_f64m4_m (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex);
vfloat64m8_t vlxe_v_f64m8_m (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex);
```
### [Vector Indexed Store Functions](rvv-intrinsic-api.md#76-vector-indexed-loadstore-operations):

**Prototypes:**
``` C
void vsxb_v_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vsxb_v_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vsxb_v_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vsxb_v_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vsxb_v_i16m1 (int8_t *base, vuint16m1_t bindex, vint16m1_t value);
void vsxb_v_i16m2 (int8_t *base, vuint16m2_t bindex, vint16m2_t value);
void vsxb_v_i16m4 (int8_t *base, vuint16m4_t bindex, vint16m4_t value);
void vsxb_v_i16m8 (int8_t *base, vuint16m8_t bindex, vint16m8_t value);
void vsxb_v_i32m1 (int8_t *base, vuint32m1_t bindex, vint32m1_t value);
void vsxb_v_i32m2 (int8_t *base, vuint32m2_t bindex, vint32m2_t value);
void vsxb_v_i32m4 (int8_t *base, vuint32m4_t bindex, vint32m4_t value);
void vsxb_v_i32m8 (int8_t *base, vuint32m8_t bindex, vint32m8_t value);
void vsxb_v_i64m1 (int8_t *base, vuint64m1_t bindex, vint64m1_t value);
void vsxb_v_i64m2 (int8_t *base, vuint64m2_t bindex, vint64m2_t value);
void vsxb_v_i64m4 (int8_t *base, vuint64m4_t bindex, vint64m4_t value);
void vsxb_v_i64m8 (int8_t *base, vuint64m8_t bindex, vint64m8_t value);
void vsxb_v_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vsxb_v_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vsxb_v_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vsxb_v_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vsxb_v_u16m1 (uint8_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vsxb_v_u16m2 (uint8_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vsxb_v_u16m4 (uint8_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vsxb_v_u16m8 (uint8_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vsxb_v_u32m1 (uint8_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vsxb_v_u32m2 (uint8_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vsxb_v_u32m4 (uint8_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vsxb_v_u32m8 (uint8_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vsxb_v_u64m1 (uint8_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vsxb_v_u64m2 (uint8_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vsxb_v_u64m4 (uint8_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vsxb_v_u64m8 (uint8_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vsxh_v_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vsxh_v_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vsxh_v_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vsxh_v_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vsxh_v_i32m1 (int16_t *base, vuint32m1_t bindex, vint32m1_t value);
void vsxh_v_i32m2 (int16_t *base, vuint32m2_t bindex, vint32m2_t value);
void vsxh_v_i32m4 (int16_t *base, vuint32m4_t bindex, vint32m4_t value);
void vsxh_v_i32m8 (int16_t *base, vuint32m8_t bindex, vint32m8_t value);
void vsxh_v_i64m1 (int16_t *base, vuint64m1_t bindex, vint64m1_t value);
void vsxh_v_i64m2 (int16_t *base, vuint64m2_t bindex, vint64m2_t value);
void vsxh_v_i64m4 (int16_t *base, vuint64m4_t bindex, vint64m4_t value);
void vsxh_v_i64m8 (int16_t *base, vuint64m8_t bindex, vint64m8_t value);
void vsxh_v_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vsxh_v_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vsxh_v_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vsxh_v_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vsxh_v_u32m1 (uint16_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vsxh_v_u32m2 (uint16_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vsxh_v_u32m4 (uint16_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vsxh_v_u32m8 (uint16_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vsxh_v_u64m1 (uint16_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vsxh_v_u64m2 (uint16_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vsxh_v_u64m4 (uint16_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vsxh_v_u64m8 (uint16_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vsxw_v_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vsxw_v_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vsxw_v_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vsxw_v_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vsxw_v_i64m1 (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
void vsxw_v_i64m2 (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
void vsxw_v_i64m4 (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
void vsxw_v_i64m8 (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
void vsxw_v_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vsxw_v_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vsxw_v_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vsxw_v_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vsxw_v_u64m1 (uint32_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vsxw_v_u64m2 (uint32_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vsxw_v_u64m4 (uint32_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vsxw_v_u64m8 (uint32_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vsxe_v_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vsxe_v_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vsxe_v_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vsxe_v_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vsxe_v_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vsxe_v_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vsxe_v_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vsxe_v_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vsxe_v_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vsxe_v_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vsxe_v_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vsxe_v_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vsxe_v_i64m1 (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
void vsxe_v_i64m2 (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
void vsxe_v_i64m4 (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
void vsxe_v_i64m8 (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
void vsxe_v_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vsxe_v_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vsxe_v_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vsxe_v_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vsxe_v_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vsxe_v_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vsxe_v_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vsxe_v_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vsxe_v_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vsxe_v_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vsxe_v_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vsxe_v_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vsxe_v_u64m1 (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vsxe_v_u64m2 (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vsxe_v_u64m4 (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vsxe_v_u64m8 (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vsxe_v_f16m1 (float16_t *base, vuint16m1_t bindex, vfloat16m1_t value);
void vsxe_v_f16m2 (float16_t *base, vuint16m2_t bindex, vfloat16m2_t value);
void vsxe_v_f16m4 (float16_t *base, vuint16m4_t bindex, vfloat16m4_t value);
void vsxe_v_f16m8 (float16_t *base, vuint16m8_t bindex, vfloat16m8_t value);
void vsxe_v_f32m1 (float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
void vsxe_v_f32m2 (float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
void vsxe_v_f32m4 (float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
void vsxe_v_f32m8 (float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
void vsxe_v_f64m1 (float64_t *base, vuint64m1_t bindex, vfloat64m1_t value);
void vsxe_v_f64m2 (float64_t *base, vuint64m2_t bindex, vfloat64m2_t value);
void vsxe_v_f64m4 (float64_t *base, vuint64m4_t bindex, vfloat64m4_t value);
void vsxe_v_f64m8 (float64_t *base, vuint64m8_t bindex, vfloat64m8_t value);
void vsuxb_v_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vsuxb_v_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vsuxb_v_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vsuxb_v_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vsuxb_v_i16m1 (int8_t *base, vuint16m1_t bindex, vint16m1_t value);
void vsuxb_v_i16m2 (int8_t *base, vuint16m2_t bindex, vint16m2_t value);
void vsuxb_v_i16m4 (int8_t *base, vuint16m4_t bindex, vint16m4_t value);
void vsuxb_v_i16m8 (int8_t *base, vuint16m8_t bindex, vint16m8_t value);
void vsuxb_v_i32m1 (int8_t *base, vuint32m1_t bindex, vint32m1_t value);
void vsuxb_v_i32m2 (int8_t *base, vuint32m2_t bindex, vint32m2_t value);
void vsuxb_v_i32m4 (int8_t *base, vuint32m4_t bindex, vint32m4_t value);
void vsuxb_v_i32m8 (int8_t *base, vuint32m8_t bindex, vint32m8_t value);
void vsuxb_v_i64m1 (int8_t *base, vuint64m1_t bindex, vint64m1_t value);
void vsuxb_v_i64m2 (int8_t *base, vuint64m2_t bindex, vint64m2_t value);
void vsuxb_v_i64m4 (int8_t *base, vuint64m4_t bindex, vint64m4_t value);
void vsuxb_v_i64m8 (int8_t *base, vuint64m8_t bindex, vint64m8_t value);
void vsuxb_v_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vsuxb_v_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vsuxb_v_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vsuxb_v_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vsuxb_v_u16m1 (uint8_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vsuxb_v_u16m2 (uint8_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vsuxb_v_u16m4 (uint8_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vsuxb_v_u16m8 (uint8_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vsuxb_v_u32m1 (uint8_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vsuxb_v_u32m2 (uint8_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vsuxb_v_u32m4 (uint8_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vsuxb_v_u32m8 (uint8_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vsuxb_v_u64m1 (uint8_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vsuxb_v_u64m2 (uint8_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vsuxb_v_u64m4 (uint8_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vsuxb_v_u64m8 (uint8_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vsuxh_v_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vsuxh_v_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vsuxh_v_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vsuxh_v_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vsuxh_v_i32m1 (int16_t *base, vuint32m1_t bindex, vint32m1_t value);
void vsuxh_v_i32m2 (int16_t *base, vuint32m2_t bindex, vint32m2_t value);
void vsuxh_v_i32m4 (int16_t *base, vuint32m4_t bindex, vint32m4_t value);
void vsuxh_v_i32m8 (int16_t *base, vuint32m8_t bindex, vint32m8_t value);
void vsuxh_v_i64m1 (int16_t *base, vuint64m1_t bindex, vint64m1_t value);
void vsuxh_v_i64m2 (int16_t *base, vuint64m2_t bindex, vint64m2_t value);
void vsuxh_v_i64m4 (int16_t *base, vuint64m4_t bindex, vint64m4_t value);
void vsuxh_v_i64m8 (int16_t *base, vuint64m8_t bindex, vint64m8_t value);
void vsuxh_v_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vsuxh_v_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vsuxh_v_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vsuxh_v_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vsuxh_v_u32m1 (uint16_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vsuxh_v_u32m2 (uint16_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vsuxh_v_u32m4 (uint16_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vsuxh_v_u32m8 (uint16_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vsuxh_v_u64m1 (uint16_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vsuxh_v_u64m2 (uint16_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vsuxh_v_u64m4 (uint16_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vsuxh_v_u64m8 (uint16_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vsuxw_v_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vsuxw_v_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vsuxw_v_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vsuxw_v_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vsuxw_v_i64m1 (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
void vsuxw_v_i64m2 (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
void vsuxw_v_i64m4 (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
void vsuxw_v_i64m8 (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
void vsuxw_v_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vsuxw_v_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vsuxw_v_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vsuxw_v_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vsuxw_v_u64m1 (uint32_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vsuxw_v_u64m2 (uint32_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vsuxw_v_u64m4 (uint32_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vsuxw_v_u64m8 (uint32_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vsuxe_v_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vsuxe_v_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vsuxe_v_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vsuxe_v_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vsuxe_v_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vsuxe_v_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vsuxe_v_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vsuxe_v_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vsuxe_v_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vsuxe_v_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vsuxe_v_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vsuxe_v_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vsuxe_v_i64m1 (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
void vsuxe_v_i64m2 (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
void vsuxe_v_i64m4 (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
void vsuxe_v_i64m8 (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
void vsuxe_v_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vsuxe_v_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vsuxe_v_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vsuxe_v_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vsuxe_v_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vsuxe_v_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vsuxe_v_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vsuxe_v_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vsuxe_v_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vsuxe_v_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vsuxe_v_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vsuxe_v_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vsuxe_v_u64m1 (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vsuxe_v_u64m2 (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vsuxe_v_u64m4 (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vsuxe_v_u64m8 (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vsuxe_v_f16m1 (float16_t *base, vuint16m1_t bindex, vfloat16m1_t value);
void vsuxe_v_f16m2 (float16_t *base, vuint16m2_t bindex, vfloat16m2_t value);
void vsuxe_v_f16m4 (float16_t *base, vuint16m4_t bindex, vfloat16m4_t value);
void vsuxe_v_f16m8 (float16_t *base, vuint16m8_t bindex, vfloat16m8_t value);
void vsuxe_v_f32m1 (float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
void vsuxe_v_f32m2 (float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
void vsuxe_v_f32m4 (float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
void vsuxe_v_f32m8 (float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
void vsuxe_v_f64m1 (float64_t *base, vuint64m1_t bindex, vfloat64m1_t value);
void vsuxe_v_f64m2 (float64_t *base, vuint64m2_t bindex, vfloat64m2_t value);
void vsuxe_v_f64m4 (float64_t *base, vuint64m4_t bindex, vfloat64m4_t value);
void vsuxe_v_f64m8 (float64_t *base, vuint64m8_t bindex, vfloat64m8_t value);
// masked functions
void vsxb_v_i8m1_m (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vsxb_v_i8m2_m (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vsxb_v_i8m4_m (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vsxb_v_i8m8_m (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vsxb_v_i16m1_m (int8_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vsxb_v_i16m2_m (int8_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vsxb_v_i16m4_m (int8_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vsxb_v_i16m8_m (int8_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vsxb_v_i32m1_m (int8_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vsxb_v_i32m2_m (int8_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vsxb_v_i32m4_m (int8_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vsxb_v_i32m8_m (int8_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vsxb_v_i64m1_m (int8_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vsxb_v_i64m2_m (int8_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vsxb_v_i64m4_m (int8_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vsxb_v_i64m8_m (int8_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vsxb_v_u8m1_m (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vsxb_v_u8m2_m (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vsxb_v_u8m4_m (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vsxb_v_u8m8_m (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vsxb_v_u16m1_m (uint8_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vsxb_v_u16m2_m (uint8_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vsxb_v_u16m4_m (uint8_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vsxb_v_u16m8_m (uint8_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vsxb_v_u32m1_m (uint8_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vsxb_v_u32m2_m (uint8_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vsxb_v_u32m4_m (uint8_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vsxb_v_u32m8_m (uint8_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vsxb_v_u64m1_m (uint8_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vsxb_v_u64m2_m (uint8_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vsxb_v_u64m4_m (uint8_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vsxb_v_u64m8_m (uint8_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vsxh_v_i16m1_m (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vsxh_v_i16m2_m (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vsxh_v_i16m4_m (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vsxh_v_i16m8_m (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vsxh_v_i32m1_m (int16_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vsxh_v_i32m2_m (int16_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vsxh_v_i32m4_m (int16_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vsxh_v_i32m8_m (int16_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vsxh_v_i64m1_m (int16_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vsxh_v_i64m2_m (int16_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vsxh_v_i64m4_m (int16_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vsxh_v_i64m8_m (int16_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vsxh_v_u16m1_m (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vsxh_v_u16m2_m (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vsxh_v_u16m4_m (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vsxh_v_u16m8_m (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vsxh_v_u32m1_m (uint16_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vsxh_v_u32m2_m (uint16_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vsxh_v_u32m4_m (uint16_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vsxh_v_u32m8_m (uint16_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vsxh_v_u64m1_m (uint16_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vsxh_v_u64m2_m (uint16_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vsxh_v_u64m4_m (uint16_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vsxh_v_u64m8_m (uint16_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vsxw_v_i32m1_m (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vsxw_v_i32m2_m (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vsxw_v_i32m4_m (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vsxw_v_i32m8_m (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vsxw_v_i64m1_m (int32_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vsxw_v_i64m2_m (int32_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vsxw_v_i64m4_m (int32_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vsxw_v_i64m8_m (int32_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vsxw_v_u32m1_m (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vsxw_v_u32m2_m (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vsxw_v_u32m4_m (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vsxw_v_u32m8_m (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vsxw_v_u64m1_m (uint32_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vsxw_v_u64m2_m (uint32_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vsxw_v_u64m4_m (uint32_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vsxw_v_u64m8_m (uint32_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vsxe_v_i8m1_m (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vsxe_v_i8m2_m (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vsxe_v_i8m4_m (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vsxe_v_i8m8_m (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vsxe_v_i16m1_m (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vsxe_v_i16m2_m (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vsxe_v_i16m4_m (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vsxe_v_i16m8_m (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vsxe_v_i32m1_m (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vsxe_v_i32m2_m (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vsxe_v_i32m4_m (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vsxe_v_i32m8_m (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vsxe_v_i64m1_m (int64_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vsxe_v_i64m2_m (int64_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vsxe_v_i64m4_m (int64_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vsxe_v_i64m8_m (int64_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vsxe_v_u8m1_m (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vsxe_v_u8m2_m (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vsxe_v_u8m4_m (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vsxe_v_u8m8_m (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vsxe_v_u16m1_m (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vsxe_v_u16m2_m (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vsxe_v_u16m4_m (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vsxe_v_u16m8_m (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vsxe_v_u32m1_m (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vsxe_v_u32m2_m (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vsxe_v_u32m4_m (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vsxe_v_u32m8_m (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vsxe_v_u64m1_m (uint64_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vsxe_v_u64m2_m (uint64_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vsxe_v_u64m4_m (uint64_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vsxe_v_u64m8_m (uint64_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vsxe_v_f16m1_m (float16_t *base, vuint16m1_t bindex, vbool16_t mask, vfloat16m1_t value);
void vsxe_v_f16m2_m (float16_t *base, vuint16m2_t bindex, vbool8_t mask, vfloat16m2_t value);
void vsxe_v_f16m4_m (float16_t *base, vuint16m4_t bindex, vbool4_t mask, vfloat16m4_t value);
void vsxe_v_f16m8_m (float16_t *base, vuint16m8_t bindex, vbool2_t mask, vfloat16m8_t value);
void vsxe_v_f32m1_m (float32_t *base, vuint32m1_t bindex, vbool32_t mask, vfloat32m1_t value);
void vsxe_v_f32m2_m (float32_t *base, vuint32m2_t bindex, vbool16_t mask, vfloat32m2_t value);
void vsxe_v_f32m4_m (float32_t *base, vuint32m4_t bindex, vbool8_t mask, vfloat32m4_t value);
void vsxe_v_f32m8_m (float32_t *base, vuint32m8_t bindex, vbool4_t mask, vfloat32m8_t value);
void vsxe_v_f64m1_m (float64_t *base, vuint64m1_t bindex, vbool64_t mask, vfloat64m1_t value);
void vsxe_v_f64m2_m (float64_t *base, vuint64m2_t bindex, vbool32_t mask, vfloat64m2_t value);
void vsxe_v_f64m4_m (float64_t *base, vuint64m4_t bindex, vbool16_t mask, vfloat64m4_t value);
void vsxe_v_f64m8_m (float64_t *base, vuint64m8_t bindex, vbool8_t mask, vfloat64m8_t value);
void vsuxb_v_i8m1_m (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vsuxb_v_i8m2_m (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vsuxb_v_i8m4_m (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vsuxb_v_i8m8_m (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vsuxb_v_i16m1_m (int8_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vsuxb_v_i16m2_m (int8_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vsuxb_v_i16m4_m (int8_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vsuxb_v_i16m8_m (int8_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vsuxb_v_i32m1_m (int8_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vsuxb_v_i32m2_m (int8_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vsuxb_v_i32m4_m (int8_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vsuxb_v_i32m8_m (int8_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vsuxb_v_i64m1_m (int8_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vsuxb_v_i64m2_m (int8_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vsuxb_v_i64m4_m (int8_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vsuxb_v_i64m8_m (int8_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vsuxb_v_u8m1_m (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vsuxb_v_u8m2_m (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vsuxb_v_u8m4_m (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vsuxb_v_u8m8_m (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vsuxb_v_u16m1_m (uint8_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vsuxb_v_u16m2_m (uint8_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vsuxb_v_u16m4_m (uint8_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vsuxb_v_u16m8_m (uint8_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vsuxb_v_u32m1_m (uint8_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vsuxb_v_u32m2_m (uint8_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vsuxb_v_u32m4_m (uint8_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vsuxb_v_u32m8_m (uint8_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vsuxb_v_u64m1_m (uint8_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vsuxb_v_u64m2_m (uint8_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vsuxb_v_u64m4_m (uint8_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vsuxb_v_u64m8_m (uint8_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vsuxh_v_i16m1_m (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vsuxh_v_i16m2_m (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vsuxh_v_i16m4_m (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vsuxh_v_i16m8_m (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vsuxh_v_i32m1_m (int16_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vsuxh_v_i32m2_m (int16_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vsuxh_v_i32m4_m (int16_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vsuxh_v_i32m8_m (int16_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vsuxh_v_i64m1_m (int16_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vsuxh_v_i64m2_m (int16_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vsuxh_v_i64m4_m (int16_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vsuxh_v_i64m8_m (int16_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vsuxh_v_u16m1_m (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vsuxh_v_u16m2_m (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vsuxh_v_u16m4_m (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vsuxh_v_u16m8_m (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vsuxh_v_u32m1_m (uint16_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vsuxh_v_u32m2_m (uint16_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vsuxh_v_u32m4_m (uint16_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vsuxh_v_u32m8_m (uint16_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vsuxh_v_u64m1_m (uint16_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vsuxh_v_u64m2_m (uint16_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vsuxh_v_u64m4_m (uint16_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vsuxh_v_u64m8_m (uint16_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vsuxw_v_i32m1_m (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vsuxw_v_i32m2_m (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vsuxw_v_i32m4_m (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vsuxw_v_i32m8_m (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vsuxw_v_i64m1_m (int32_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vsuxw_v_i64m2_m (int32_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vsuxw_v_i64m4_m (int32_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vsuxw_v_i64m8_m (int32_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vsuxw_v_u32m1_m (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vsuxw_v_u32m2_m (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vsuxw_v_u32m4_m (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vsuxw_v_u32m8_m (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vsuxw_v_u64m1_m (uint32_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vsuxw_v_u64m2_m (uint32_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vsuxw_v_u64m4_m (uint32_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vsuxw_v_u64m8_m (uint32_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vsuxe_v_i8m1_m (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vsuxe_v_i8m2_m (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vsuxe_v_i8m4_m (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vsuxe_v_i8m8_m (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vsuxe_v_i16m1_m (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vsuxe_v_i16m2_m (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vsuxe_v_i16m4_m (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vsuxe_v_i16m8_m (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vsuxe_v_i32m1_m (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vsuxe_v_i32m2_m (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vsuxe_v_i32m4_m (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vsuxe_v_i32m8_m (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vsuxe_v_i64m1_m (int64_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vsuxe_v_i64m2_m (int64_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vsuxe_v_i64m4_m (int64_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vsuxe_v_i64m8_m (int64_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vsuxe_v_u8m1_m (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vsuxe_v_u8m2_m (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vsuxe_v_u8m4_m (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vsuxe_v_u8m8_m (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vsuxe_v_u16m1_m (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vsuxe_v_u16m2_m (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vsuxe_v_u16m4_m (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vsuxe_v_u16m8_m (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vsuxe_v_u32m1_m (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vsuxe_v_u32m2_m (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vsuxe_v_u32m4_m (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vsuxe_v_u32m8_m (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vsuxe_v_u64m1_m (uint64_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vsuxe_v_u64m2_m (uint64_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vsuxe_v_u64m4_m (uint64_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vsuxe_v_u64m8_m (uint64_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vsuxe_v_f16m1_m (float16_t *base, vuint16m1_t bindex, vbool16_t mask, vfloat16m1_t value);
void vsuxe_v_f16m2_m (float16_t *base, vuint16m2_t bindex, vbool8_t mask, vfloat16m2_t value);
void vsuxe_v_f16m4_m (float16_t *base, vuint16m4_t bindex, vbool4_t mask, vfloat16m4_t value);
void vsuxe_v_f16m8_m (float16_t *base, vuint16m8_t bindex, vbool2_t mask, vfloat16m8_t value);
void vsuxe_v_f32m1_m (float32_t *base, vuint32m1_t bindex, vbool32_t mask, vfloat32m1_t value);
void vsuxe_v_f32m2_m (float32_t *base, vuint32m2_t bindex, vbool16_t mask, vfloat32m2_t value);
void vsuxe_v_f32m4_m (float32_t *base, vuint32m4_t bindex, vbool8_t mask, vfloat32m4_t value);
void vsuxe_v_f32m8_m (float32_t *base, vuint32m8_t bindex, vbool4_t mask, vfloat32m8_t value);
void vsuxe_v_f64m1_m (float64_t *base, vuint64m1_t bindex, vbool64_t mask, vfloat64m1_t value);
void vsuxe_v_f64m2_m (float64_t *base, vuint64m2_t bindex, vbool32_t mask, vfloat64m2_t value);
void vsuxe_v_f64m4_m (float64_t *base, vuint64m4_t bindex, vbool16_t mask, vfloat64m4_t value);
void vsuxe_v_f64m8_m (float64_t *base, vuint64m8_t bindex, vbool8_t mask, vfloat64m8_t value);
```
### [Unit-stride Fault-Only-First Loads Functions](rvv-intrinsic-api.md#77-unit-stride-fault-only-first-loads-operations):

**Prototypes:**
``` C
vint8m1_t vlbff_v_i8m1 (const int8_t *base);
vint8m2_t vlbff_v_i8m2 (const int8_t *base);
vint8m4_t vlbff_v_i8m4 (const int8_t *base);
vint8m8_t vlbff_v_i8m8 (const int8_t *base);
vint16m1_t vlbff_v_i16m1 (const int8_t *base);
vint16m2_t vlbff_v_i16m2 (const int8_t *base);
vint16m4_t vlbff_v_i16m4 (const int8_t *base);
vint16m8_t vlbff_v_i16m8 (const int8_t *base);
vint32m1_t vlbff_v_i32m1 (const int8_t *base);
vint32m2_t vlbff_v_i32m2 (const int8_t *base);
vint32m4_t vlbff_v_i32m4 (const int8_t *base);
vint32m8_t vlbff_v_i32m8 (const int8_t *base);
vint64m1_t vlbff_v_i64m1 (const int8_t *base);
vint64m2_t vlbff_v_i64m2 (const int8_t *base);
vint64m4_t vlbff_v_i64m4 (const int8_t *base);
vint64m8_t vlbff_v_i64m8 (const int8_t *base);
vuint8m1_t vlbuff_v_u8m1 (const uint8_t *base);
vuint8m2_t vlbuff_v_u8m2 (const uint8_t *base);
vuint8m4_t vlbuff_v_u8m4 (const uint8_t *base);
vuint8m8_t vlbuff_v_u8m8 (const uint8_t *base);
vuint16m1_t vlbuff_v_u16m1 (const uint8_t *base);
vuint16m2_t vlbuff_v_u16m2 (const uint8_t *base);
vuint16m4_t vlbuff_v_u16m4 (const uint8_t *base);
vuint16m8_t vlbuff_v_u16m8 (const uint8_t *base);
vuint32m1_t vlbuff_v_u32m1 (const uint8_t *base);
vuint32m2_t vlbuff_v_u32m2 (const uint8_t *base);
vuint32m4_t vlbuff_v_u32m4 (const uint8_t *base);
vuint32m8_t vlbuff_v_u32m8 (const uint8_t *base);
vuint64m1_t vlbuff_v_u64m1 (const uint8_t *base);
vuint64m2_t vlbuff_v_u64m2 (const uint8_t *base);
vuint64m4_t vlbuff_v_u64m4 (const uint8_t *base);
vuint64m8_t vlbuff_v_u64m8 (const uint8_t *base);
vint16m1_t vlhff_v_i16m1 (const int16_t *base);
vint16m2_t vlhff_v_i16m2 (const int16_t *base);
vint16m4_t vlhff_v_i16m4 (const int16_t *base);
vint16m8_t vlhff_v_i16m8 (const int16_t *base);
vint32m1_t vlhff_v_i32m1 (const int16_t *base);
vint32m2_t vlhff_v_i32m2 (const int16_t *base);
vint32m4_t vlhff_v_i32m4 (const int16_t *base);
vint32m8_t vlhff_v_i32m8 (const int16_t *base);
vint64m1_t vlhff_v_i64m1 (const int16_t *base);
vint64m2_t vlhff_v_i64m2 (const int16_t *base);
vint64m4_t vlhff_v_i64m4 (const int16_t *base);
vint64m8_t vlhff_v_i64m8 (const int16_t *base);
vuint16m1_t vlhuff_v_u16m1 (const uint16_t *base);
vuint16m2_t vlhuff_v_u16m2 (const uint16_t *base);
vuint16m4_t vlhuff_v_u16m4 (const uint16_t *base);
vuint16m8_t vlhuff_v_u16m8 (const uint16_t *base);
vuint32m1_t vlhuff_v_u32m1 (const uint16_t *base);
vuint32m2_t vlhuff_v_u32m2 (const uint16_t *base);
vuint32m4_t vlhuff_v_u32m4 (const uint16_t *base);
vuint32m8_t vlhuff_v_u32m8 (const uint16_t *base);
vuint64m1_t vlhuff_v_u64m1 (const uint16_t *base);
vuint64m2_t vlhuff_v_u64m2 (const uint16_t *base);
vuint64m4_t vlhuff_v_u64m4 (const uint16_t *base);
vuint64m8_t vlhuff_v_u64m8 (const uint16_t *base);
vint32m1_t vlwff_v_i32m1 (const int32_t *base);
vint32m2_t vlwff_v_i32m2 (const int32_t *base);
vint32m4_t vlwff_v_i32m4 (const int32_t *base);
vint32m8_t vlwff_v_i32m8 (const int32_t *base);
vint64m1_t vlwff_v_i64m1 (const int32_t *base);
vint64m2_t vlwff_v_i64m2 (const int32_t *base);
vint64m4_t vlwff_v_i64m4 (const int32_t *base);
vint64m8_t vlwff_v_i64m8 (const int32_t *base);
vuint32m1_t vlwuff_v_u32m1 (const uint32_t *base);
vuint32m2_t vlwuff_v_u32m2 (const uint32_t *base);
vuint32m4_t vlwuff_v_u32m4 (const uint32_t *base);
vuint32m8_t vlwuff_v_u32m8 (const uint32_t *base);
vuint64m1_t vlwuff_v_u64m1 (const uint32_t *base);
vuint64m2_t vlwuff_v_u64m2 (const uint32_t *base);
vuint64m4_t vlwuff_v_u64m4 (const uint32_t *base);
vuint64m8_t vlwuff_v_u64m8 (const uint32_t *base);
vint8m1_t vleff_v_i8m1 (const int8_t *base);
vint8m2_t vleff_v_i8m2 (const int8_t *base);
vint8m4_t vleff_v_i8m4 (const int8_t *base);
vint8m8_t vleff_v_i8m8 (const int8_t *base);
vint16m1_t vleff_v_i16m1 (const int16_t *base);
vint16m2_t vleff_v_i16m2 (const int16_t *base);
vint16m4_t vleff_v_i16m4 (const int16_t *base);
vint16m8_t vleff_v_i16m8 (const int16_t *base);
vint32m1_t vleff_v_i32m1 (const int32_t *base);
vint32m2_t vleff_v_i32m2 (const int32_t *base);
vint32m4_t vleff_v_i32m4 (const int32_t *base);
vint32m8_t vleff_v_i32m8 (const int32_t *base);
vint64m1_t vleff_v_i64m1 (const int64_t *base);
vint64m2_t vleff_v_i64m2 (const int64_t *base);
vint64m4_t vleff_v_i64m4 (const int64_t *base);
vint64m8_t vleff_v_i64m8 (const int64_t *base);
vuint8m1_t vleffu_v_u8m1 (const uint8_t *base);
vuint8m2_t vleffu_v_u8m2 (const uint8_t *base);
vuint8m4_t vleffu_v_u8m4 (const uint8_t *base);
vuint8m8_t vleffu_v_u8m8 (const uint8_t *base);
vuint16m1_t vleffu_v_u16m1 (const uint16_t *base);
vuint16m2_t vleffu_v_u16m2 (const uint16_t *base);
vuint16m4_t vleffu_v_u16m4 (const uint16_t *base);
vuint16m8_t vleffu_v_u16m8 (const uint16_t *base);
vuint32m1_t vleffu_v_u32m1 (const uint32_t *base);
vuint32m2_t vleffu_v_u32m2 (const uint32_t *base);
vuint32m4_t vleffu_v_u32m4 (const uint32_t *base);
vuint32m8_t vleffu_v_u32m8 (const uint32_t *base);
vuint64m1_t vleffu_v_u64m1 (const uint64_t *base);
vuint64m2_t vleffu_v_u64m2 (const uint64_t *base);
vuint64m4_t vleffu_v_u64m4 (const uint64_t *base);
vuint64m8_t vleffu_v_u64m8 (const uint64_t *base);
vfloat16m1_t vleff_v_f16m1 (const float16_t *base);
vfloat16m2_t vleff_v_f16m2 (const float16_t *base);
vfloat16m4_t vleff_v_f16m4 (const float16_t *base);
vfloat16m8_t vleff_v_f16m8 (const float16_t *base);
vfloat32m1_t vleff_v_f32m1 (const float32_t *base);
vfloat32m2_t vleff_v_f32m2 (const float32_t *base);
vfloat32m4_t vleff_v_f32m4 (const float32_t *base);
vfloat32m8_t vleff_v_f32m8 (const float32_t *base);
vfloat64m1_t vleff_v_f64m1 (const float64_t *base);
vfloat64m2_t vleff_v_f64m2 (const float64_t *base);
vfloat64m4_t vleff_v_f64m4 (const float64_t *base);
vfloat64m8_t vleff_v_f64m8 (const float64_t *base);
// masked functions
vint8m1_t vlbff_v_i8m1_m (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vlbff_v_i8m2_m (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vlbff_v_i8m4_m (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vlbff_v_i8m8_m (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vlbff_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base);
vint16m2_t vlbff_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base);
vint16m4_t vlbff_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base);
vint16m8_t vlbff_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base);
vint32m1_t vlbff_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base);
vint32m2_t vlbff_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base);
vint32m4_t vlbff_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base);
vint32m8_t vlbff_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base);
vint64m1_t vlbff_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base);
vint64m2_t vlbff_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base);
vint64m4_t vlbff_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base);
vint64m8_t vlbff_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base);
vuint8m1_t vlbuff_v_u8m1_m (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vlbuff_v_u8m2_m (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vlbuff_v_u8m4_m (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vlbuff_v_u8m8_m (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vlbuff_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base);
vuint16m2_t vlbuff_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base);
vuint16m4_t vlbuff_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base);
vuint16m8_t vlbuff_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base);
vuint32m1_t vlbuff_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base);
vuint32m2_t vlbuff_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base);
vuint32m4_t vlbuff_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base);
vuint32m8_t vlbuff_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base);
vuint64m1_t vlbuff_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base);
vuint64m2_t vlbuff_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base);
vuint64m4_t vlbuff_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base);
vuint64m8_t vlbuff_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base);
vint16m1_t vlhff_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vlhff_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vlhff_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vlhff_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vlhff_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base);
vint32m2_t vlhff_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base);
vint32m4_t vlhff_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base);
vint32m8_t vlhff_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base);
vint64m1_t vlhff_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base);
vint64m2_t vlhff_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base);
vint64m4_t vlhff_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base);
vint64m8_t vlhff_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base);
vuint16m1_t vlhuff_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vlhuff_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vlhuff_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vlhuff_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vlhuff_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base);
vuint32m2_t vlhuff_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base);
vuint32m4_t vlhuff_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base);
vuint32m8_t vlhuff_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base);
vuint64m1_t vlhuff_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base);
vuint64m2_t vlhuff_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base);
vuint64m4_t vlhuff_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base);
vuint64m8_t vlhuff_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base);
vint32m1_t vlwff_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vlwff_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vlwff_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vlwff_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vlwff_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base);
vint64m2_t vlwff_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base);
vint64m4_t vlwff_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base);
vint64m8_t vlwff_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base);
vuint32m1_t vlwuff_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vlwuff_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vlwuff_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vlwuff_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vlwuff_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base);
vuint64m2_t vlwuff_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base);
vuint64m4_t vlwuff_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base);
vuint64m8_t vlwuff_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base);
vint8m1_t vleff_v_i8m1_m (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vleff_v_i8m2_m (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vleff_v_i8m4_m (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vleff_v_i8m8_m (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vleff_v_i16m1_m (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vleff_v_i16m2_m (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vleff_v_i16m4_m (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vleff_v_i16m8_m (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vleff_v_i32m1_m (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vleff_v_i32m2_m (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vleff_v_i32m4_m (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vleff_v_i32m8_m (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vleff_v_i64m1_m (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base);
vint64m2_t vleff_v_i64m2_m (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base);
vint64m4_t vleff_v_i64m4_m (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base);
vint64m8_t vleff_v_i64m8_m (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base);
vuint8m1_t vleffu_v_u8m1_m (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vleffu_v_u8m2_m (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vleffu_v_u8m4_m (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vleffu_v_u8m8_m (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vleffu_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vleffu_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vleffu_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vleffu_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vleffu_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vleffu_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vleffu_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vleffu_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vleffu_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base);
vuint64m2_t vleffu_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base);
vuint64m4_t vleffu_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base);
vuint64m8_t vleffu_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base);
vfloat16m1_t vleff_v_f16m1_m (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base);
vfloat16m2_t vleff_v_f16m2_m (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base);
vfloat16m4_t vleff_v_f16m4_m (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base);
vfloat16m8_t vleff_v_f16m8_m (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base);
vfloat32m1_t vleff_v_f32m1_m (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base);
vfloat32m2_t vleff_v_f32m2_m (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base);
vfloat32m4_t vleff_v_f32m4_m (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base);
vfloat32m8_t vleff_v_f32m8_m (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base);
vfloat64m1_t vleff_v_f64m1_m (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base);
vfloat64m2_t vleff_v_f64m2_m (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base);
vfloat64m4_t vleff_v_f64m4_m (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base);
vfloat64m8_t vleff_v_f64m8_m (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base);
```
## Vector AMO Operations Functions (Zvamo):

### [Vector AMO Operations Functions](rvv-intrinsic-api.md#8-vector-amo-operations-zvamo):

**Prototypes:**
``` C
vint8m1_t vamoswape (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamoswape (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamoswape (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamoswape (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamoswape (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamoswape (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamoswape (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamoswape (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamoswape (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamoswapw (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamoswape (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamoswapw (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamoswape (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamoswapw (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamoswape (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamoswapw (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamoswape (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamoswapw (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamoswape (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamoswapw (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamoswape (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamoswapw (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamoswape (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamoswapw (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamoswape (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamoswape (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamoswape (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamoswape (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamoswape (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamoswape (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamoswape (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamoswape (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamoswape (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamoswapw (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamoswape (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamoswapw (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamoswape (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamoswapw (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamoswape (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamoswapw (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamoswape (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamoswapw (int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamoswape (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamoswapw (int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamoswape (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamoswapw (int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamoswape (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamoswapw (int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vfloat16m1_t vamoswape (float16_t *base, vuint16m1_t bindex, vfloat16m1_t value);
vfloat16m2_t vamoswape (float16_t *base, vuint16m2_t bindex, vfloat16m2_t value);
vfloat16m4_t vamoswape (float16_t *base, vuint16m4_t bindex, vfloat16m4_t value);
vfloat16m8_t vamoswape (float16_t *base, vuint16m8_t bindex, vfloat16m8_t value);
vfloat32m1_t vamoswape (float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
vfloat32m1_t vamoswapw (float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
vfloat32m2_t vamoswape (float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
vfloat32m2_t vamoswapw (float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
vfloat32m4_t vamoswape (float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
vfloat32m4_t vamoswapw (float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
vfloat32m8_t vamoswape (float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
vfloat32m8_t vamoswapw (float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
vfloat64m1_t vamoswape (float64_t *base, vuint64m1_t bindex, vfloat64m1_t value);
vfloat64m1_t vamoswapw (int32_t *base, vuint64m1_t bindex, vfloat64m1_t value);
vfloat64m2_t vamoswape (float64_t *base, vuint64m2_t bindex, vfloat64m2_t value);
vfloat64m2_t vamoswapw (int32_t *base, vuint64m2_t bindex, vfloat64m2_t value);
vfloat64m4_t vamoswape (float64_t *base, vuint64m4_t bindex, vfloat64m4_t value);
vfloat64m4_t vamoswapw (int32_t *base, vuint64m4_t bindex, vfloat64m4_t value);
vfloat64m8_t vamoswape (float64_t *base, vuint64m8_t bindex, vfloat64m8_t value);
vfloat64m8_t vamoswapw (int32_t *base, vuint64m8_t bindex, vfloat64m8_t value);
vint8m1_t vamoadde (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamoadde (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamoadde (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamoadde (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamoadde (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamoadde (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamoadde (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamoadde (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamoadde (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamoaddw (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamoadde (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamoaddw (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamoadde (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamoaddw (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamoadde (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamoaddw (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamoadde (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamoaddw (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamoadde (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamoaddw (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamoadde (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamoaddw (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamoadde (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamoaddw (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamoadde (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamoadde (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamoadde (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamoadde (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamoadde (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamoadde (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamoadde (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamoadde (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamoadde (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamoaddw (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamoadde (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamoaddw (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamoadde (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamoaddw (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamoadde (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamoaddw (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamoadde (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamoaddw (int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamoadde (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamoaddw (int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamoadde (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamoaddw (int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamoadde (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamoaddw (int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vint8m1_t vamoxore (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamoxore (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamoxore (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamoxore (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamoxore (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamoxore (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamoxore (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamoxore (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamoxore (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamoxorw (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamoxore (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamoxorw (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamoxore (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamoxorw (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamoxore (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamoxorw (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamoxore (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamoxorw (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamoxore (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamoxorw (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamoxore (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamoxorw (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamoxore (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamoxorw (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamoxore (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamoxore (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamoxore (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamoxore (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamoxore (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamoxore (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamoxore (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamoxore (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamoxore (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamoxorw (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamoxore (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamoxorw (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamoxore (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamoxorw (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamoxore (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamoxorw (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamoxore (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamoxorw (int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamoxore (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamoxorw (int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamoxore (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamoxorw (int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamoxore (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamoxorw (int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vint8m1_t vamoande (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamoande (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamoande (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamoande (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamoande (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamoande (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamoande (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamoande (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamoande (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamoandw (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamoande (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamoandw (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamoande (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamoandw (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamoande (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamoandw (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamoande (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamoandw (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamoande (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamoandw (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamoande (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamoandw (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamoande (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamoandw (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamoande (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamoande (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamoande (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamoande (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamoande (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamoande (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamoande (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamoande (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamoande (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamoandw (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamoande (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamoandw (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamoande (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamoandw (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamoande (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamoandw (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamoande (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamoandw (int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamoande (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamoandw (int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamoande (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamoandw (int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamoande (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamoandw (int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vint8m1_t vamoore (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamoore (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamoore (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamoore (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamoore (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamoore (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamoore (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamoore (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamoore (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamoorw (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamoore (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamoorw (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamoore (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamoorw (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamoore (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamoorw (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamoore (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamoorw (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamoore (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamoorw (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamoore (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamoorw (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamoore (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamoorw (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamoore (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamoore (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamoore (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamoore (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamoore (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamoore (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamoore (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamoore (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamoore (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamoorw (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamoore (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamoorw (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamoore (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamoorw (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamoore (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamoorw (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamoore (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamoorw (int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamoore (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamoorw (int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamoore (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamoorw (int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamoore (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamoorw (int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vint8m1_t vamomine (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamomine (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamomine (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamomine (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamomine (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamomine (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamomine (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamomine (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamomine (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamominw (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamomine (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamominw (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamomine (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamominw (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamomine (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamominw (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamomine (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamominw (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamomine (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamominw (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamomine (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamominw (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamomine (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamominw (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamominue (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamominue (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamominue (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamominue (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamominue (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamominue (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamominue (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamominue (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamominue (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamominuw (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamominue (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamominuw (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamominue (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamominuw (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamominue (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamominuw (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamominue (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamominuw (int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamominue (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamominuw (int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamominue (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamominuw (int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamominue (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamominuw (int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vint8m1_t vamomaxe (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamomaxe (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamomaxe (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamomaxe (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamomaxe (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamomaxe (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamomaxe (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamomaxe (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamomaxe (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamomaxw (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamomaxe (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamomaxw (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamomaxe (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamomaxw (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamomaxe (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamomaxw (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamomaxe (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamomaxw (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamomaxe (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamomaxw (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamomaxe (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamomaxw (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamomaxe (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamomaxw (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamomaxue (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamomaxue (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamomaxue (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamomaxue (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamomaxue (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamomaxue (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamomaxue (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamomaxue (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamomaxue (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamomaxuw (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamomaxue (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamomaxuw (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamomaxue (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamomaxuw (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamomaxue (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamomaxuw (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamomaxue (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamomaxuw (int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamomaxue (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamomaxuw (int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamomaxue (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamomaxuw (int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamomaxue (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamomaxuw (int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
// masked functions
vint8m1_t vamoswape_m (vbool8_t mask, int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamoswape_m (vbool4_t mask, int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamoswape_m (vbool2_t mask, int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamoswape_m (vbool1_t mask, int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamoswape_m (vbool16_t mask, int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamoswape_m (vbool8_t mask, int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamoswape_m (vbool4_t mask, int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamoswape_m (vbool2_t mask, int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamoswape_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamoswapw_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamoswape_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamoswapw_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamoswape_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamoswapw_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamoswape_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamoswapw_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamoswape_m (vbool64_t mask, int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamoswapw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamoswape_m (vbool32_t mask, int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamoswapw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamoswape_m (vbool16_t mask, int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamoswapw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamoswape_m (vbool8_t mask, int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamoswapw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamoswape_m (vbool8_t mask, uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamoswape_m (vbool4_t mask, uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamoswape_m (vbool2_t mask, uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamoswape_m (vbool1_t mask, uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamoswape_m (vbool16_t mask, uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamoswape_m (vbool8_t mask, uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamoswape_m (vbool4_t mask, uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamoswape_m (vbool2_t mask, uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamoswape_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamoswapw_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamoswape_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamoswapw_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamoswape_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamoswapw_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamoswape_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamoswapw_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamoswape_m (vbool64_t mask, uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamoswapw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamoswape_m (vbool32_t mask, uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamoswapw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamoswape_m (vbool16_t mask, uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamoswapw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamoswape_m (vbool8_t mask, uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamoswapw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vfloat16m1_t vamoswape_m (vbool16_t mask, float16_t *base, vuint16m1_t bindex, vfloat16m1_t value);
vfloat16m2_t vamoswape_m (vbool8_t mask, float16_t *base, vuint16m2_t bindex, vfloat16m2_t value);
vfloat16m4_t vamoswape_m (vbool4_t mask, float16_t *base, vuint16m4_t bindex, vfloat16m4_t value);
vfloat16m8_t vamoswape_m (vbool2_t mask, float16_t *base, vuint16m8_t bindex, vfloat16m8_t value);
vfloat32m1_t vamoswape_m (vbool32_t mask, float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
vfloat32m1_t vamoswapw_m (vbool32_t mask, float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
vfloat32m2_t vamoswape_m (vbool16_t mask, float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
vfloat32m2_t vamoswapw_m (vbool16_t mask, float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
vfloat32m4_t vamoswape_m (vbool8_t mask, float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
vfloat32m4_t vamoswapw_m (vbool8_t mask, float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
vfloat32m8_t vamoswape_m (vbool4_t mask, float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
vfloat32m8_t vamoswapw_m (vbool4_t mask, float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
vfloat64m1_t vamoswape_m (vbool64_t mask, float64_t *base, vuint64m1_t bindex, vfloat64m1_t value);
vfloat64m1_t vamoswapw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vfloat64m1_t value);
vfloat64m2_t vamoswape_m (vbool32_t mask, float64_t *base, vuint64m2_t bindex, vfloat64m2_t value);
vfloat64m2_t vamoswapw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vfloat64m2_t value);
vfloat64m4_t vamoswape_m (vbool16_t mask, float64_t *base, vuint64m4_t bindex, vfloat64m4_t value);
vfloat64m4_t vamoswapw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vfloat64m4_t value);
vfloat64m8_t vamoswape_m (vbool8_t mask, float64_t *base, vuint64m8_t bindex, vfloat64m8_t value);
vfloat64m8_t vamoswapw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vfloat64m8_t value);
vint8m1_t vamoadde_m (vbool8_t mask, int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamoadde_m (vbool4_t mask, int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamoadde_m (vbool2_t mask, int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamoadde_m (vbool1_t mask, int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamoadde_m (vbool16_t mask, int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamoadde_m (vbool8_t mask, int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamoadde_m (vbool4_t mask, int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamoadde_m (vbool2_t mask, int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamoadde_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamoaddw_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamoadde_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamoaddw_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamoadde_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamoaddw_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamoadde_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamoaddw_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamoadde_m (vbool64_t mask, int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamoaddw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamoadde_m (vbool32_t mask, int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamoaddw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamoadde_m (vbool16_t mask, int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamoaddw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamoadde_m (vbool8_t mask, int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamoaddw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamoadde_m (vbool8_t mask, uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamoadde_m (vbool4_t mask, uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamoadde_m (vbool2_t mask, uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamoadde_m (vbool1_t mask, uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamoadde_m (vbool16_t mask, uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamoadde_m (vbool8_t mask, uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamoadde_m (vbool4_t mask, uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamoadde_m (vbool2_t mask, uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamoadde_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamoaddw_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamoadde_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamoaddw_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamoadde_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamoaddw_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamoadde_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamoaddw_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamoadde_m (vbool64_t mask, uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamoaddw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamoadde_m (vbool32_t mask, uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamoaddw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamoadde_m (vbool16_t mask, uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamoaddw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamoadde_m (vbool8_t mask, uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamoaddw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vint8m1_t vamoxore_m (vbool8_t mask, int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamoxore_m (vbool4_t mask, int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamoxore_m (vbool2_t mask, int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamoxore_m (vbool1_t mask, int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamoxore_m (vbool16_t mask, int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamoxore_m (vbool8_t mask, int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamoxore_m (vbool4_t mask, int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamoxore_m (vbool2_t mask, int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamoxore_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamoxorw_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamoxore_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamoxorw_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamoxore_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamoxorw_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamoxore_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamoxorw_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamoxore_m (vbool64_t mask, int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamoxorw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamoxore_m (vbool32_t mask, int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamoxorw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamoxore_m (vbool16_t mask, int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamoxorw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamoxore_m (vbool8_t mask, int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamoxorw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamoxore_m (vbool8_t mask, uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamoxore_m (vbool4_t mask, uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamoxore_m (vbool2_t mask, uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamoxore_m (vbool1_t mask, uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamoxore_m (vbool16_t mask, uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamoxore_m (vbool8_t mask, uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamoxore_m (vbool4_t mask, uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamoxore_m (vbool2_t mask, uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamoxore_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamoxorw_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamoxore_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamoxorw_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamoxore_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamoxorw_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamoxore_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamoxorw_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamoxore_m (vbool64_t mask, uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamoxorw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamoxore_m (vbool32_t mask, uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamoxorw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamoxore_m (vbool16_t mask, uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamoxorw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamoxore_m (vbool8_t mask, uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamoxorw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vint8m1_t vamoande_m (vbool8_t mask, int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamoande_m (vbool4_t mask, int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamoande_m (vbool2_t mask, int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamoande_m (vbool1_t mask, int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamoande_m (vbool16_t mask, int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamoande_m (vbool8_t mask, int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamoande_m (vbool4_t mask, int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamoande_m (vbool2_t mask, int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamoande_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamoandw_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamoande_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamoandw_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamoande_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamoandw_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamoande_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamoandw_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamoande_m (vbool64_t mask, int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamoandw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamoande_m (vbool32_t mask, int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamoandw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamoande_m (vbool16_t mask, int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamoandw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamoande_m (vbool8_t mask, int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamoandw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamoande_m (vbool8_t mask, uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamoande_m (vbool4_t mask, uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamoande_m (vbool2_t mask, uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamoande_m (vbool1_t mask, uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamoande_m (vbool16_t mask, uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamoande_m (vbool8_t mask, uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamoande_m (vbool4_t mask, uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamoande_m (vbool2_t mask, uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamoande_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamoandw_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamoande_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamoandw_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamoande_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamoandw_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamoande_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamoandw_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamoande_m (vbool64_t mask, uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamoandw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamoande_m (vbool32_t mask, uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamoandw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamoande_m (vbool16_t mask, uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamoandw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamoande_m (vbool8_t mask, uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamoandw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vint8m1_t vamoore_m (vbool8_t mask, int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamoore_m (vbool4_t mask, int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamoore_m (vbool2_t mask, int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamoore_m (vbool1_t mask, int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamoore_m (vbool16_t mask, int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamoore_m (vbool8_t mask, int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamoore_m (vbool4_t mask, int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamoore_m (vbool2_t mask, int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamoore_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamoorw_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamoore_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamoorw_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamoore_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamoorw_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamoore_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamoorw_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamoore_m (vbool64_t mask, int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamoorw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamoore_m (vbool32_t mask, int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamoorw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamoore_m (vbool16_t mask, int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamoorw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamoore_m (vbool8_t mask, int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamoorw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamoore_m (vbool8_t mask, uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamoore_m (vbool4_t mask, uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamoore_m (vbool2_t mask, uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamoore_m (vbool1_t mask, uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamoore_m (vbool16_t mask, uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamoore_m (vbool8_t mask, uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamoore_m (vbool4_t mask, uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamoore_m (vbool2_t mask, uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamoore_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamoorw_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamoore_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamoorw_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamoore_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamoorw_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamoore_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamoorw_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamoore_m (vbool64_t mask, uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamoorw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamoore_m (vbool32_t mask, uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamoorw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamoore_m (vbool16_t mask, uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamoorw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamoore_m (vbool8_t mask, uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamoorw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vint8m1_t vamomine_m (vbool8_t mask, int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamomine_m (vbool4_t mask, int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamomine_m (vbool2_t mask, int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamomine_m (vbool1_t mask, int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamomine_m (vbool16_t mask, int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamomine_m (vbool8_t mask, int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamomine_m (vbool4_t mask, int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamomine_m (vbool2_t mask, int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamomine_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamominw_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamomine_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamominw_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamomine_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamominw_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamomine_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamominw_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamomine_m (vbool64_t mask, int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamominw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamomine_m (vbool32_t mask, int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamominw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamomine_m (vbool16_t mask, int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamominw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamomine_m (vbool8_t mask, int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamominw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamominue_m (vbool8_t mask, uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamominue_m (vbool4_t mask, uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamominue_m (vbool2_t mask, uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamominue_m (vbool1_t mask, uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamominue_m (vbool16_t mask, uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamominue_m (vbool8_t mask, uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamominue_m (vbool4_t mask, uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamominue_m (vbool2_t mask, uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamominue_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamominuw_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamominue_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamominuw_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamominue_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamominuw_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamominue_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamominuw_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamominue_m (vbool64_t mask, uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamominuw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamominue_m (vbool32_t mask, uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamominuw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamominue_m (vbool16_t mask, uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamominuw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamominue_m (vbool8_t mask, uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamominuw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
vint8m1_t vamomaxe_m (vbool8_t mask, int8_t *base, vuint8m1_t bindex, vint8m1_t value);
vint8m2_t vamomaxe_m (vbool4_t mask, int8_t *base, vuint8m2_t bindex, vint8m2_t value);
vint8m4_t vamomaxe_m (vbool2_t mask, int8_t *base, vuint8m4_t bindex, vint8m4_t value);
vint8m8_t vamomaxe_m (vbool1_t mask, int8_t *base, vuint8m8_t bindex, vint8m8_t value);
vint16m1_t vamomaxe_m (vbool16_t mask, int16_t *base, vuint16m1_t bindex, vint16m1_t value);
vint16m2_t vamomaxe_m (vbool8_t mask, int16_t *base, vuint16m2_t bindex, vint16m2_t value);
vint16m4_t vamomaxe_m (vbool4_t mask, int16_t *base, vuint16m4_t bindex, vint16m4_t value);
vint16m8_t vamomaxe_m (vbool2_t mask, int16_t *base, vuint16m8_t bindex, vint16m8_t value);
vint32m1_t vamomaxe_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m1_t vamomaxw_m (vbool32_t mask, int32_t *base, vuint32m1_t bindex, vint32m1_t value);
vint32m2_t vamomaxe_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m2_t vamomaxw_m (vbool16_t mask, int32_t *base, vuint32m2_t bindex, vint32m2_t value);
vint32m4_t vamomaxe_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m4_t vamomaxw_m (vbool8_t mask, int32_t *base, vuint32m4_t bindex, vint32m4_t value);
vint32m8_t vamomaxe_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint32m8_t vamomaxw_m (vbool4_t mask, int32_t *base, vuint32m8_t bindex, vint32m8_t value);
vint64m1_t vamomaxe_m (vbool64_t mask, int64_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m1_t vamomaxw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vint64m1_t value);
vint64m2_t vamomaxe_m (vbool32_t mask, int64_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m2_t vamomaxw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vint64m2_t value);
vint64m4_t vamomaxe_m (vbool16_t mask, int64_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m4_t vamomaxw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vint64m4_t value);
vint64m8_t vamomaxe_m (vbool8_t mask, int64_t *base, vuint64m8_t bindex, vint64m8_t value);
vint64m8_t vamomaxw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vint64m8_t value);
vuint8m1_t vamomaxue_m (vbool8_t mask, uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
vuint8m2_t vamomaxue_m (vbool4_t mask, uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
vuint8m4_t vamomaxue_m (vbool2_t mask, uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
vuint8m8_t vamomaxue_m (vbool1_t mask, uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
vuint16m1_t vamomaxue_m (vbool16_t mask, uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
vuint16m2_t vamomaxue_m (vbool8_t mask, uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
vuint16m4_t vamomaxue_m (vbool4_t mask, uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
vuint16m8_t vamomaxue_m (vbool2_t mask, uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
vuint32m1_t vamomaxue_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m1_t vamomaxuw_m (vbool32_t mask, uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
vuint32m2_t vamomaxue_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m2_t vamomaxuw_m (vbool16_t mask, uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
vuint32m4_t vamomaxue_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m4_t vamomaxuw_m (vbool8_t mask, uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
vuint32m8_t vamomaxue_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint32m8_t vamomaxuw_m (vbool4_t mask, uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
vuint64m1_t vamomaxue_m (vbool64_t mask, uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m1_t vamomaxuw_m (vbool64_t mask, int32_t *base, vuint64m1_t bindex, vuint64m1_t value);
vuint64m2_t vamomaxue_m (vbool32_t mask, uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m2_t vamomaxuw_m (vbool32_t mask, int32_t *base, vuint64m2_t bindex, vuint64m2_t value);
vuint64m4_t vamomaxue_m (vbool16_t mask, uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m4_t vamomaxuw_m (vbool16_t mask, int32_t *base, vuint64m4_t bindex, vuint64m4_t value);
vuint64m8_t vamomaxue_m (vbool8_t mask, uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
vuint64m8_t vamomaxuw_m (vbool8_t mask, int32_t *base, vuint64m8_t bindex, vuint64m8_t value);
```
## Vector Integer Arithmetic Functions:

### [Vector Single-Width Integer Add and Subtract Functions](rvv-intrinsic-api.md#121-vector-single-width-integer-add-and-subtract):

**Prototypes:**
``` C
vint8m1_t vadd (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vadd (vint8m1_t op1, int8_t op2);
vint8m2_t vadd (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vadd (vint8m2_t op1, int8_t op2);
vint8m4_t vadd (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vadd (vint8m4_t op1, int8_t op2);
vint8m8_t vadd (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vadd (vint8m8_t op1, int8_t op2);
vint16m1_t vadd (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vadd (vint16m1_t op1, int16_t op2);
vint16m2_t vadd (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vadd (vint16m2_t op1, int16_t op2);
vint16m4_t vadd (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vadd (vint16m4_t op1, int16_t op2);
vint16m8_t vadd (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vadd (vint16m8_t op1, int16_t op2);
vint32m1_t vadd (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vadd (vint32m1_t op1, int32_t op2);
vint32m2_t vadd (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vadd (vint32m2_t op1, int32_t op2);
vint32m4_t vadd (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vadd (vint32m4_t op1, int32_t op2);
vint32m8_t vadd (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vadd (vint32m8_t op1, int32_t op2);
vint64m1_t vadd (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vadd (vint64m1_t op1, int64_t op2);
vint64m2_t vadd (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vadd (vint64m2_t op1, int64_t op2);
vint64m4_t vadd (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vadd (vint64m4_t op1, int64_t op2);
vint64m8_t vadd (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vadd (vint64m8_t op1, int64_t op2);
vuint8m1_t vadd (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vadd (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vadd (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vadd (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vadd (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vadd (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vadd (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vadd (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vadd (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vadd (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vadd (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vadd (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vadd (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vadd (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vadd (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vadd (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vadd (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vadd (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vadd (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vadd (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vadd (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vadd (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vadd (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vadd (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vadd (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vadd (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vadd (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vadd (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vadd (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vadd (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vadd (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vadd (vuint64m8_t op1, uint64_t op2);
vint8m1_t vsub (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsub (vint8m1_t op1, int8_t op2);
vint8m2_t vsub (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsub (vint8m2_t op1, int8_t op2);
vint8m4_t vsub (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsub (vint8m4_t op1, int8_t op2);
vint8m8_t vsub (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsub (vint8m8_t op1, int8_t op2);
vint16m1_t vsub (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsub (vint16m1_t op1, int16_t op2);
vint16m2_t vsub (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsub (vint16m2_t op1, int16_t op2);
vint16m4_t vsub (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsub (vint16m4_t op1, int16_t op2);
vint16m8_t vsub (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsub (vint16m8_t op1, int16_t op2);
vint32m1_t vsub (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsub (vint32m1_t op1, int32_t op2);
vint32m2_t vsub (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsub (vint32m2_t op1, int32_t op2);
vint32m4_t vsub (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsub (vint32m4_t op1, int32_t op2);
vint32m8_t vsub (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsub (vint32m8_t op1, int32_t op2);
vint64m1_t vsub (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsub (vint64m1_t op1, int64_t op2);
vint64m2_t vsub (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsub (vint64m2_t op1, int64_t op2);
vint64m4_t vsub (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsub (vint64m4_t op1, int64_t op2);
vint64m8_t vsub (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsub (vint64m8_t op1, int64_t op2);
vuint8m1_t vsub (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsub (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsub (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsub (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsub (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsub (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsub (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsub (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsub (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsub (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsub (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsub (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsub (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsub (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsub (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsub (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsub (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsub (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsub (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsub (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsub (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsub (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsub (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsub (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsub (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsub (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsub (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsub (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsub (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsub (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsub (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsub (vuint64m8_t op1, uint64_t op2);
vint8m1_t vrsub (vint8m1_t op1, int8_t op2);
vint8m2_t vrsub (vint8m2_t op1, int8_t op2);
vint8m4_t vrsub (vint8m4_t op1, int8_t op2);
vint8m8_t vrsub (vint8m8_t op1, int8_t op2);
vint16m1_t vrsub (vint16m1_t op1, int16_t op2);
vint16m2_t vrsub (vint16m2_t op1, int16_t op2);
vint16m4_t vrsub (vint16m4_t op1, int16_t op2);
vint16m8_t vrsub (vint16m8_t op1, int16_t op2);
vint32m1_t vrsub (vint32m1_t op1, int32_t op2);
vint32m2_t vrsub (vint32m2_t op1, int32_t op2);
vint32m4_t vrsub (vint32m4_t op1, int32_t op2);
vint32m8_t vrsub (vint32m8_t op1, int32_t op2);
vint64m1_t vrsub (vint64m1_t op1, int64_t op2);
vint64m2_t vrsub (vint64m2_t op1, int64_t op2);
vint64m4_t vrsub (vint64m4_t op1, int64_t op2);
vint64m8_t vrsub (vint64m8_t op1, int64_t op2);
vuint8m1_t vrsub (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrsub (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrsub (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrsub (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrsub (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrsub (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrsub (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrsub (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrsub (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrsub (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrsub (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrsub (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrsub (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrsub (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrsub (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrsub (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vadd_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vadd_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vadd_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vadd_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vadd_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vadd_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vadd_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vadd_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vadd_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vadd_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vadd_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vadd_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vadd_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vadd_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vadd_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vadd_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vadd_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vadd_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vadd_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vadd_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vadd_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vadd_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vadd_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vadd_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vadd_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vadd_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vadd_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vadd_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vadd_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vadd_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vadd_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vadd_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vadd_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vadd_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vadd_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vadd_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vadd_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vadd_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vadd_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vadd_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vadd_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vadd_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vadd_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vadd_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vadd_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vadd_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vadd_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vadd_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vadd_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vadd_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vadd_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vadd_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vadd_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vadd_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vadd_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vadd_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vadd_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vadd_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vadd_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vadd_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vadd_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vadd_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vadd_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vadd_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vsub_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsub_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsub_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsub_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsub_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsub_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsub_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsub_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsub_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsub_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsub_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsub_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsub_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsub_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsub_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsub_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsub_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsub_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsub_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsub_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsub_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsub_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsub_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsub_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsub_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsub_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsub_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsub_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsub_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsub_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsub_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsub_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsub_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsub_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsub_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsub_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsub_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsub_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsub_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsub_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsub_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsub_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsub_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsub_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsub_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsub_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsub_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsub_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsub_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsub_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsub_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsub_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsub_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsub_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsub_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsub_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsub_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsub_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsub_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsub_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsub_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsub_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsub_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsub_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vrsub_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vrsub_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vrsub_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vrsub_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vrsub_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vrsub_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vrsub_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vrsub_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vrsub_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vrsub_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vrsub_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vrsub_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vrsub_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vrsub_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vrsub_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vrsub_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vrsub_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrsub_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrsub_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrsub_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrsub_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrsub_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrsub_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrsub_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrsub_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrsub_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrsub_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrsub_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrsub_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrsub_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrsub_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrsub_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Widening Integer Add/Subtract Functions](rvv-intrinsic-api.md#122-vector-widening-integer-addsubtract-operations):

**Prototypes:**
``` C
vint16m2_t vwadd (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwadd (vint8m1_t op1, int8_t op2);
vint16m2_t vwadd (vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwadd (vint16m2_t op1, int8_t op2);
vint16m4_t vwadd (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwadd (vint8m2_t op1, int8_t op2);
vint16m4_t vwadd (vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwadd (vint16m4_t op1, int8_t op2);
vint16m8_t vwadd (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwadd (vint8m4_t op1, int8_t op2);
vint16m8_t vwadd (vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwadd (vint16m8_t op1, int8_t op2);
vint32m2_t vwadd (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwadd (vint16m1_t op1, int16_t op2);
vint32m2_t vwadd (vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwadd (vint32m2_t op1, int16_t op2);
vint32m4_t vwadd (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwadd (vint16m2_t op1, int16_t op2);
vint32m4_t vwadd (vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwadd (vint32m4_t op1, int16_t op2);
vint32m8_t vwadd (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwadd (vint16m4_t op1, int16_t op2);
vint32m8_t vwadd (vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwadd (vint32m8_t op1, int16_t op2);
vint64m2_t vwadd (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwadd (vint32m1_t op1, int32_t op2);
vint64m2_t vwadd (vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwadd (vint64m2_t op1, int32_t op2);
vint64m4_t vwadd (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwadd (vint32m2_t op1, int32_t op2);
vint64m4_t vwadd (vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwadd (vint64m4_t op1, int32_t op2);
vint64m8_t vwadd (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwadd (vint32m4_t op1, int32_t op2);
vint64m8_t vwadd (vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwadd (vint64m8_t op1, int32_t op2);
vuint16m2_t vwaddu (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwaddu (vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwaddu (vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwaddu (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwaddu (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwaddu (vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwaddu (vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwaddu (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwaddu (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwaddu (vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwaddu (vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwaddu (vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwaddu (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwaddu (vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwaddu (vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwaddu (vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwaddu (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwaddu (vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwaddu (vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwaddu (vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwaddu (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwaddu (vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwaddu (vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwaddu (vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwaddu (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwaddu (vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwaddu (vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwaddu (vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwaddu (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwaddu (vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwaddu (vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwaddu (vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwaddu (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwaddu (vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwaddu (vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwaddu (vuint64m8_t op1, uint32_t op2);
vint16m2_t vwsub (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwsub (vint8m1_t op1, int8_t op2);
vint16m2_t vwsub (vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwsub (vint16m2_t op1, int8_t op2);
vint16m4_t vwsub (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwsub (vint8m2_t op1, int8_t op2);
vint16m4_t vwsub (vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwsub (vint16m4_t op1, int8_t op2);
vint16m8_t vwsub (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwsub (vint8m4_t op1, int8_t op2);
vint16m8_t vwsub (vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwsub (vint16m8_t op1, int8_t op2);
vint32m2_t vwsub (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwsub (vint16m1_t op1, int16_t op2);
vint32m2_t vwsub (vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwsub (vint32m2_t op1, int16_t op2);
vint32m4_t vwsub (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwsub (vint16m2_t op1, int16_t op2);
vint32m4_t vwsub (vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwsub (vint32m4_t op1, int16_t op2);
vint32m8_t vwsub (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwsub (vint16m4_t op1, int16_t op2);
vint32m8_t vwsub (vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwsub (vint32m8_t op1, int16_t op2);
vint64m2_t vwsub (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwsub (vint32m1_t op1, int32_t op2);
vint64m2_t vwsub (vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwsub (vint64m2_t op1, int32_t op2);
vint64m4_t vwsub (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwsub (vint32m2_t op1, int32_t op2);
vint64m4_t vwsub (vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwsub (vint64m4_t op1, int32_t op2);
vint64m8_t vwsub (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwsub (vint32m4_t op1, int32_t op2);
vint64m8_t vwsub (vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwsub (vint64m8_t op1, int32_t op2);
vuint16m2_t vwsubu (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwsubu (vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwsubu (vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwsubu (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwsubu (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwsubu (vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwsubu (vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwsubu (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwsubu (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwsubu (vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwsubu (vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwsubu (vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwsubu (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwsubu (vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwsubu (vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwsubu (vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwsubu (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwsubu (vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwsubu (vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwsubu (vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwsubu (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwsubu (vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwsubu (vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwsubu (vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwsubu (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwsubu (vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwsubu (vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwsubu (vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwsubu (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwsubu (vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwsubu (vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwsubu (vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwsubu (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwsubu (vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwsubu (vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwsubu (vuint64m8_t op1, uint32_t op2);
// masked functions
vint16m2_t vwadd_m (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwadd_m (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m2_t vwadd_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwadd_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2);
vint16m4_t vwadd_m (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwadd_m (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m4_t vwadd_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwadd_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2);
vint16m8_t vwadd_m (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwadd_m (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint16m8_t vwadd_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwadd_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2);
vint32m2_t vwadd_m (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwadd_m (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m2_t vwadd_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwadd_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2);
vint32m4_t vwadd_m (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwadd_m (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m4_t vwadd_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwadd_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2);
vint32m8_t vwadd_m (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwadd_m (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint32m8_t vwadd_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwadd_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2);
vint64m2_t vwadd_m (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwadd_m (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m2_t vwadd_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwadd_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2);
vint64m4_t vwadd_m (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwadd_m (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m4_t vwadd_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwadd_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2);
vint64m8_t vwadd_m (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwadd_m (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vint64m8_t vwadd_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwadd_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2);
vuint16m2_t vwaddu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwaddu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwaddu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwaddu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwaddu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwaddu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwaddu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwaddu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwaddu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwaddu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwaddu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwaddu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwaddu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwaddu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwaddu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwaddu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwaddu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwaddu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwaddu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwaddu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwaddu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwaddu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwaddu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwaddu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwaddu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwaddu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwaddu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwaddu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwaddu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwaddu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwaddu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwaddu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwaddu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwaddu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwaddu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwaddu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2);
vint16m2_t vwsub_m (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwsub_m (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m2_t vwsub_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwsub_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2);
vint16m4_t vwsub_m (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwsub_m (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m4_t vwsub_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwsub_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2);
vint16m8_t vwsub_m (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwsub_m (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint16m8_t vwsub_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwsub_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2);
vint32m2_t vwsub_m (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwsub_m (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m2_t vwsub_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwsub_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2);
vint32m4_t vwsub_m (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwsub_m (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m4_t vwsub_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwsub_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2);
vint32m8_t vwsub_m (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwsub_m (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint32m8_t vwsub_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwsub_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2);
vint64m2_t vwsub_m (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwsub_m (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m2_t vwsub_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwsub_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2);
vint64m4_t vwsub_m (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwsub_m (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m4_t vwsub_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwsub_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2);
vint64m8_t vwsub_m (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwsub_m (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vint64m8_t vwsub_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwsub_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2);
vuint16m2_t vwsubu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwsubu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwsubu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwsubu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwsubu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwsubu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwsubu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwsubu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwsubu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwsubu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwsubu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwsubu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwsubu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwsubu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwsubu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwsubu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwsubu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwsubu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwsubu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwsubu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwsubu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwsubu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwsubu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwsubu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwsubu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwsubu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwsubu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwsubu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwsubu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwsubu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwsubu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwsubu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwsubu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwsubu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwsubu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwsubu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2);
```
### [Vector Integer Add-with-Carry / Subtract-with-Borrow Functions](rvv-intrinsic-api.md#123-vector-integer-add-with-carry--subtract-with-borrow-operations):

**Prototypes:**
``` C
vint8m1_t vadc_vvm (vint8m1_t op1, vint8m1_t op2, vbool8_t carryin);
vint8m1_t vadc_vxm (vint8m1_t op1, int8_t op2, vbool8_t carryin);
vint8m2_t vadc_vvm (vint8m2_t op1, vint8m2_t op2, vbool4_t carryin);
vint8m2_t vadc_vxm (vint8m2_t op1, int8_t op2, vbool4_t carryin);
vint8m4_t vadc_vvm (vint8m4_t op1, vint8m4_t op2, vbool2_t carryin);
vint8m4_t vadc_vxm (vint8m4_t op1, int8_t op2, vbool2_t carryin);
vint8m8_t vadc_vvm (vint8m8_t op1, vint8m8_t op2, vbool1_t carryin);
vint8m8_t vadc_vxm (vint8m8_t op1, int8_t op2, vbool1_t carryin);
vint16m1_t vadc_vvm (vint16m1_t op1, vint16m1_t op2, vbool16_t carryin);
vint16m1_t vadc_vxm (vint16m1_t op1, int16_t op2, vbool16_t carryin);
vint16m2_t vadc_vvm (vint16m2_t op1, vint16m2_t op2, vbool8_t carryin);
vint16m2_t vadc_vxm (vint16m2_t op1, int16_t op2, vbool8_t carryin);
vint16m4_t vadc_vvm (vint16m4_t op1, vint16m4_t op2, vbool4_t carryin);
vint16m4_t vadc_vxm (vint16m4_t op1, int16_t op2, vbool4_t carryin);
vint16m8_t vadc_vvm (vint16m8_t op1, vint16m8_t op2, vbool2_t carryin);
vint16m8_t vadc_vxm (vint16m8_t op1, int16_t op2, vbool2_t carryin);
vint32m1_t vadc_vvm (vint32m1_t op1, vint32m1_t op2, vbool32_t carryin);
vint32m1_t vadc_vxm (vint32m1_t op1, int32_t op2, vbool32_t carryin);
vint32m2_t vadc_vvm (vint32m2_t op1, vint32m2_t op2, vbool16_t carryin);
vint32m2_t vadc_vxm (vint32m2_t op1, int32_t op2, vbool16_t carryin);
vint32m4_t vadc_vvm (vint32m4_t op1, vint32m4_t op2, vbool8_t carryin);
vint32m4_t vadc_vxm (vint32m4_t op1, int32_t op2, vbool8_t carryin);
vint32m8_t vadc_vvm (vint32m8_t op1, vint32m8_t op2, vbool4_t carryin);
vint32m8_t vadc_vxm (vint32m8_t op1, int32_t op2, vbool4_t carryin);
vint64m1_t vadc_vvm (vint64m1_t op1, vint64m1_t op2, vbool64_t carryin);
vint64m1_t vadc_vxm (vint64m1_t op1, int64_t op2, vbool64_t carryin);
vint64m2_t vadc_vvm (vint64m2_t op1, vint64m2_t op2, vbool32_t carryin);
vint64m2_t vadc_vxm (vint64m2_t op1, int64_t op2, vbool32_t carryin);
vint64m4_t vadc_vvm (vint64m4_t op1, vint64m4_t op2, vbool16_t carryin);
vint64m4_t vadc_vxm (vint64m4_t op1, int64_t op2, vbool16_t carryin);
vint64m8_t vadc_vvm (vint64m8_t op1, vint64m8_t op2, vbool8_t carryin);
vint64m8_t vadc_vxm (vint64m8_t op1, int64_t op2, vbool8_t carryin);
vuint8m1_t vadc_vvm (vuint8m1_t op1, vuint8m1_t op2, vbool8_t carryin);
vuint8m1_t vadc_vxm (vuint8m1_t op1, uint8_t op2, vbool8_t carryin);
vuint8m2_t vadc_vvm (vuint8m2_t op1, vuint8m2_t op2, vbool4_t carryin);
vuint8m2_t vadc_vxm (vuint8m2_t op1, uint8_t op2, vbool4_t carryin);
vuint8m4_t vadc_vvm (vuint8m4_t op1, vuint8m4_t op2, vbool2_t carryin);
vuint8m4_t vadc_vxm (vuint8m4_t op1, uint8_t op2, vbool2_t carryin);
vuint8m8_t vadc_vvm (vuint8m8_t op1, vuint8m8_t op2, vbool1_t carryin);
vuint8m8_t vadc_vxm (vuint8m8_t op1, uint8_t op2, vbool1_t carryin);
vuint16m1_t vadc_vvm (vuint16m1_t op1, vuint16m1_t op2, vbool16_t carryin);
vuint16m1_t vadc_vxm (vuint16m1_t op1, uint16_t op2, vbool16_t carryin);
vuint16m2_t vadc_vvm (vuint16m2_t op1, vuint16m2_t op2, vbool8_t carryin);
vuint16m2_t vadc_vxm (vuint16m2_t op1, uint16_t op2, vbool8_t carryin);
vuint16m4_t vadc_vvm (vuint16m4_t op1, vuint16m4_t op2, vbool4_t carryin);
vuint16m4_t vadc_vxm (vuint16m4_t op1, uint16_t op2, vbool4_t carryin);
vuint16m8_t vadc_vvm (vuint16m8_t op1, vuint16m8_t op2, vbool2_t carryin);
vuint16m8_t vadc_vxm (vuint16m8_t op1, uint16_t op2, vbool2_t carryin);
vuint32m1_t vadc_vvm (vuint32m1_t op1, vuint32m1_t op2, vbool32_t carryin);
vuint32m1_t vadc_vxm (vuint32m1_t op1, uint32_t op2, vbool32_t carryin);
vuint32m2_t vadc_vvm (vuint32m2_t op1, vuint32m2_t op2, vbool16_t carryin);
vuint32m2_t vadc_vxm (vuint32m2_t op1, uint32_t op2, vbool16_t carryin);
vuint32m4_t vadc_vvm (vuint32m4_t op1, vuint32m4_t op2, vbool8_t carryin);
vuint32m4_t vadc_vxm (vuint32m4_t op1, uint32_t op2, vbool8_t carryin);
vuint32m8_t vadc_vvm (vuint32m8_t op1, vuint32m8_t op2, vbool4_t carryin);
vuint32m8_t vadc_vxm (vuint32m8_t op1, uint32_t op2, vbool4_t carryin);
vuint64m1_t vadc_vvm (vuint64m1_t op1, vuint64m1_t op2, vbool64_t carryin);
vuint64m1_t vadc_vxm (vuint64m1_t op1, uint64_t op2, vbool64_t carryin);
vuint64m2_t vadc_vvm (vuint64m2_t op1, vuint64m2_t op2, vbool32_t carryin);
vuint64m2_t vadc_vxm (vuint64m2_t op1, uint64_t op2, vbool32_t carryin);
vuint64m4_t vadc_vvm (vuint64m4_t op1, vuint64m4_t op2, vbool16_t carryin);
vuint64m4_t vadc_vxm (vuint64m4_t op1, uint64_t op2, vbool16_t carryin);
vuint64m8_t vadc_vvm (vuint64m8_t op1, vuint64m8_t op2, vbool8_t carryin);
vuint64m8_t vadc_vxm (vuint64m8_t op1, uint64_t op2, vbool8_t carryin);
vbool8_t vmadc_vvm (vint8m1_t op1, vint8m1_t op2, vbool8_t carryin);
vbool8_t vmadc_vxm (vint8m1_t op1, int8_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmadc_vx (vint8m1_t op1, int8_t op2);
vbool4_t vmadc_vvm (vint8m2_t op1, vint8m2_t op2, vbool4_t carryin);
vbool4_t vmadc_vxm (vint8m2_t op1, int8_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmadc_vx (vint8m2_t op1, int8_t op2);
vbool2_t vmadc_vvm (vint8m4_t op1, vint8m4_t op2, vbool2_t carryin);
vbool2_t vmadc_vxm (vint8m4_t op1, int8_t op2, vbool2_t carryin);
vbool2_t vmadc_vv (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmadc_vx (vint8m4_t op1, int8_t op2);
vbool1_t vmadc_vvm (vint8m8_t op1, vint8m8_t op2, vbool1_t carryin);
vbool1_t vmadc_vxm (vint8m8_t op1, int8_t op2, vbool1_t carryin);
vbool1_t vmadc_vv (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmadc_vx (vint8m8_t op1, int8_t op2);
vbool16_t vmadc_vvm (vint16m1_t op1, vint16m1_t op2, vbool16_t carryin);
vbool16_t vmadc_vxm (vint16m1_t op1, int16_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmadc_vx (vint16m1_t op1, int16_t op2);
vbool8_t vmadc_vvm (vint16m2_t op1, vint16m2_t op2, vbool8_t carryin);
vbool8_t vmadc_vxm (vint16m2_t op1, int16_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmadc_vx (vint16m2_t op1, int16_t op2);
vbool4_t vmadc_vvm (vint16m4_t op1, vint16m4_t op2, vbool4_t carryin);
vbool4_t vmadc_vxm (vint16m4_t op1, int16_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmadc_vx (vint16m4_t op1, int16_t op2);
vbool2_t vmadc_vvm (vint16m8_t op1, vint16m8_t op2, vbool2_t carryin);
vbool2_t vmadc_vxm (vint16m8_t op1, int16_t op2, vbool2_t carryin);
vbool2_t vmadc_vv (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmadc_vx (vint16m8_t op1, int16_t op2);
vbool32_t vmadc_vvm (vint32m1_t op1, vint32m1_t op2, vbool32_t carryin);
vbool32_t vmadc_vxm (vint32m1_t op1, int32_t op2, vbool32_t carryin);
vbool32_t vmadc_vv (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmadc_vx (vint32m1_t op1, int32_t op2);
vbool16_t vmadc_vvm (vint32m2_t op1, vint32m2_t op2, vbool16_t carryin);
vbool16_t vmadc_vxm (vint32m2_t op1, int32_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmadc_vx (vint32m2_t op1, int32_t op2);
vbool8_t vmadc_vvm (vint32m4_t op1, vint32m4_t op2, vbool8_t carryin);
vbool8_t vmadc_vxm (vint32m4_t op1, int32_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmadc_vx (vint32m4_t op1, int32_t op2);
vbool4_t vmadc_vvm (vint32m8_t op1, vint32m8_t op2, vbool4_t carryin);
vbool4_t vmadc_vxm (vint32m8_t op1, int32_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmadc_vx (vint32m8_t op1, int32_t op2);
vbool64_t vmadc_vvm (vint64m1_t op1, vint64m1_t op2, vbool64_t carryin);
vbool64_t vmadc_vxm (vint64m1_t op1, int64_t op2, vbool64_t carryin);
vbool64_t vmadc_vv (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmadc_vx (vint64m1_t op1, int64_t op2);
vbool32_t vmadc_vvm (vint64m2_t op1, vint64m2_t op2, vbool32_t carryin);
vbool32_t vmadc_vxm (vint64m2_t op1, int64_t op2, vbool32_t carryin);
vbool32_t vmadc_vv (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmadc_vx (vint64m2_t op1, int64_t op2);
vbool16_t vmadc_vvm (vint64m4_t op1, vint64m4_t op2, vbool16_t carryin);
vbool16_t vmadc_vxm (vint64m4_t op1, int64_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmadc_vx (vint64m4_t op1, int64_t op2);
vbool8_t vmadc_vvm (vint64m8_t op1, vint64m8_t op2, vbool8_t carryin);
vbool8_t vmadc_vxm (vint64m8_t op1, int64_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmadc_vx (vint64m8_t op1, int64_t op2);
vbool8_t vmadc_vvm (vuint8m1_t op1, vuint8m1_t op2, vbool8_t carryin);
vbool8_t vmadc_vxm (vuint8m1_t op1, uint8_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmadc_vx (vuint8m1_t op1, uint8_t op2);
vbool4_t vmadc_vvm (vuint8m2_t op1, vuint8m2_t op2, vbool4_t carryin);
vbool4_t vmadc_vxm (vuint8m2_t op1, uint8_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmadc_vx (vuint8m2_t op1, uint8_t op2);
vbool2_t vmadc_vvm (vuint8m4_t op1, vuint8m4_t op2, vbool2_t carryin);
vbool2_t vmadc_vxm (vuint8m4_t op1, uint8_t op2, vbool2_t carryin);
vbool2_t vmadc_vv (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmadc_vx (vuint8m4_t op1, uint8_t op2);
vbool1_t vmadc_vvm (vuint8m8_t op1, vuint8m8_t op2, vbool1_t carryin);
vbool1_t vmadc_vxm (vuint8m8_t op1, uint8_t op2, vbool1_t carryin);
vbool1_t vmadc_vv (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmadc_vx (vuint8m8_t op1, uint8_t op2);
vbool16_t vmadc_vvm (vuint16m1_t op1, vuint16m1_t op2, vbool16_t carryin);
vbool16_t vmadc_vxm (vuint16m1_t op1, uint16_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmadc_vx (vuint16m1_t op1, uint16_t op2);
vbool8_t vmadc_vvm (vuint16m2_t op1, vuint16m2_t op2, vbool8_t carryin);
vbool8_t vmadc_vxm (vuint16m2_t op1, uint16_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmadc_vx (vuint16m2_t op1, uint16_t op2);
vbool4_t vmadc_vvm (vuint16m4_t op1, vuint16m4_t op2, vbool4_t carryin);
vbool4_t vmadc_vxm (vuint16m4_t op1, uint16_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmadc_vx (vuint16m4_t op1, uint16_t op2);
vbool2_t vmadc_vvm (vuint16m8_t op1, vuint16m8_t op2, vbool2_t carryin);
vbool2_t vmadc_vxm (vuint16m8_t op1, uint16_t op2, vbool2_t carryin);
vbool2_t vmadc_vv (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmadc_vx (vuint16m8_t op1, uint16_t op2);
vbool32_t vmadc_vvm (vuint32m1_t op1, vuint32m1_t op2, vbool32_t carryin);
vbool32_t vmadc_vxm (vuint32m1_t op1, uint32_t op2, vbool32_t carryin);
vbool32_t vmadc_vv (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmadc_vx (vuint32m1_t op1, uint32_t op2);
vbool16_t vmadc_vvm (vuint32m2_t op1, vuint32m2_t op2, vbool16_t carryin);
vbool16_t vmadc_vxm (vuint32m2_t op1, uint32_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmadc_vx (vuint32m2_t op1, uint32_t op2);
vbool8_t vmadc_vvm (vuint32m4_t op1, vuint32m4_t op2, vbool8_t carryin);
vbool8_t vmadc_vxm (vuint32m4_t op1, uint32_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmadc_vx (vuint32m4_t op1, uint32_t op2);
vbool4_t vmadc_vvm (vuint32m8_t op1, vuint32m8_t op2, vbool4_t carryin);
vbool4_t vmadc_vxm (vuint32m8_t op1, uint32_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmadc_vx (vuint32m8_t op1, uint32_t op2);
vbool64_t vmadc_vvm (vuint64m1_t op1, vuint64m1_t op2, vbool64_t carryin);
vbool64_t vmadc_vxm (vuint64m1_t op1, uint64_t op2, vbool64_t carryin);
vbool64_t vmadc_vv (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmadc_vx (vuint64m1_t op1, uint64_t op2);
vbool32_t vmadc_vvm (vuint64m2_t op1, vuint64m2_t op2, vbool32_t carryin);
vbool32_t vmadc_vxm (vuint64m2_t op1, uint64_t op2, vbool32_t carryin);
vbool32_t vmadc_vv (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmadc_vx (vuint64m2_t op1, uint64_t op2);
vbool16_t vmadc_vvm (vuint64m4_t op1, vuint64m4_t op2, vbool16_t carryin);
vbool16_t vmadc_vxm (vuint64m4_t op1, uint64_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmadc_vx (vuint64m4_t op1, uint64_t op2);
vbool8_t vmadc_vvm (vuint64m8_t op1, vuint64m8_t op2, vbool8_t carryin);
vbool8_t vmadc_vxm (vuint64m8_t op1, uint64_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmadc_vx (vuint64m8_t op1, uint64_t op2);
vint8m1_t vsbc_vvm (vint8m1_t op1, vint8m1_t op2, vbool8_t borrowin);
vint8m1_t vsbc_vxm (vint8m1_t op1, int8_t op2, vbool8_t borrowin);
vint8m2_t vsbc_vvm (vint8m2_t op1, vint8m2_t op2, vbool4_t borrowin);
vint8m2_t vsbc_vxm (vint8m2_t op1, int8_t op2, vbool4_t borrowin);
vint8m4_t vsbc_vvm (vint8m4_t op1, vint8m4_t op2, vbool2_t borrowin);
vint8m4_t vsbc_vxm (vint8m4_t op1, int8_t op2, vbool2_t borrowin);
vint8m8_t vsbc_vvm (vint8m8_t op1, vint8m8_t op2, vbool1_t borrowin);
vint8m8_t vsbc_vxm (vint8m8_t op1, int8_t op2, vbool1_t borrowin);
vint16m1_t vsbc_vvm (vint16m1_t op1, vint16m1_t op2, vbool16_t borrowin);
vint16m1_t vsbc_vxm (vint16m1_t op1, int16_t op2, vbool16_t borrowin);
vint16m2_t vsbc_vvm (vint16m2_t op1, vint16m2_t op2, vbool8_t borrowin);
vint16m2_t vsbc_vxm (vint16m2_t op1, int16_t op2, vbool8_t borrowin);
vint16m4_t vsbc_vvm (vint16m4_t op1, vint16m4_t op2, vbool4_t borrowin);
vint16m4_t vsbc_vxm (vint16m4_t op1, int16_t op2, vbool4_t borrowin);
vint16m8_t vsbc_vvm (vint16m8_t op1, vint16m8_t op2, vbool2_t borrowin);
vint16m8_t vsbc_vxm (vint16m8_t op1, int16_t op2, vbool2_t borrowin);
vint32m1_t vsbc_vvm (vint32m1_t op1, vint32m1_t op2, vbool32_t borrowin);
vint32m1_t vsbc_vxm (vint32m1_t op1, int32_t op2, vbool32_t borrowin);
vint32m2_t vsbc_vvm (vint32m2_t op1, vint32m2_t op2, vbool16_t borrowin);
vint32m2_t vsbc_vxm (vint32m2_t op1, int32_t op2, vbool16_t borrowin);
vint32m4_t vsbc_vvm (vint32m4_t op1, vint32m4_t op2, vbool8_t borrowin);
vint32m4_t vsbc_vxm (vint32m4_t op1, int32_t op2, vbool8_t borrowin);
vint32m8_t vsbc_vvm (vint32m8_t op1, vint32m8_t op2, vbool4_t borrowin);
vint32m8_t vsbc_vxm (vint32m8_t op1, int32_t op2, vbool4_t borrowin);
vint64m1_t vsbc_vvm (vint64m1_t op1, vint64m1_t op2, vbool64_t borrowin);
vint64m1_t vsbc_vxm (vint64m1_t op1, int64_t op2, vbool64_t borrowin);
vint64m2_t vsbc_vvm (vint64m2_t op1, vint64m2_t op2, vbool32_t borrowin);
vint64m2_t vsbc_vxm (vint64m2_t op1, int64_t op2, vbool32_t borrowin);
vint64m4_t vsbc_vvm (vint64m4_t op1, vint64m4_t op2, vbool16_t borrowin);
vint64m4_t vsbc_vxm (vint64m4_t op1, int64_t op2, vbool16_t borrowin);
vint64m8_t vsbc_vvm (vint64m8_t op1, vint64m8_t op2, vbool8_t borrowin);
vint64m8_t vsbc_vxm (vint64m8_t op1, int64_t op2, vbool8_t borrowin);
vuint8m1_t vsbc_vvm (vuint8m1_t op1, vuint8m1_t op2, vbool8_t borrowin);
vuint8m1_t vsbc_vxm (vuint8m1_t op1, uint8_t op2, vbool8_t borrowin);
vuint8m2_t vsbc_vvm (vuint8m2_t op1, vuint8m2_t op2, vbool4_t borrowin);
vuint8m2_t vsbc_vxm (vuint8m2_t op1, uint8_t op2, vbool4_t borrowin);
vuint8m4_t vsbc_vvm (vuint8m4_t op1, vuint8m4_t op2, vbool2_t borrowin);
vuint8m4_t vsbc_vxm (vuint8m4_t op1, uint8_t op2, vbool2_t borrowin);
vuint8m8_t vsbc_vvm (vuint8m8_t op1, vuint8m8_t op2, vbool1_t borrowin);
vuint8m8_t vsbc_vxm (vuint8m8_t op1, uint8_t op2, vbool1_t borrowin);
vuint16m1_t vsbc_vvm (vuint16m1_t op1, vuint16m1_t op2, vbool16_t borrowin);
vuint16m1_t vsbc_vxm (vuint16m1_t op1, uint16_t op2, vbool16_t borrowin);
vuint16m2_t vsbc_vvm (vuint16m2_t op1, vuint16m2_t op2, vbool8_t borrowin);
vuint16m2_t vsbc_vxm (vuint16m2_t op1, uint16_t op2, vbool8_t borrowin);
vuint16m4_t vsbc_vvm (vuint16m4_t op1, vuint16m4_t op2, vbool4_t borrowin);
vuint16m4_t vsbc_vxm (vuint16m4_t op1, uint16_t op2, vbool4_t borrowin);
vuint16m8_t vsbc_vvm (vuint16m8_t op1, vuint16m8_t op2, vbool2_t borrowin);
vuint16m8_t vsbc_vxm (vuint16m8_t op1, uint16_t op2, vbool2_t borrowin);
vuint32m1_t vsbc_vvm (vuint32m1_t op1, vuint32m1_t op2, vbool32_t borrowin);
vuint32m1_t vsbc_vxm (vuint32m1_t op1, uint32_t op2, vbool32_t borrowin);
vuint32m2_t vsbc_vvm (vuint32m2_t op1, vuint32m2_t op2, vbool16_t borrowin);
vuint32m2_t vsbc_vxm (vuint32m2_t op1, uint32_t op2, vbool16_t borrowin);
vuint32m4_t vsbc_vvm (vuint32m4_t op1, vuint32m4_t op2, vbool8_t borrowin);
vuint32m4_t vsbc_vxm (vuint32m4_t op1, uint32_t op2, vbool8_t borrowin);
vuint32m8_t vsbc_vvm (vuint32m8_t op1, vuint32m8_t op2, vbool4_t borrowin);
vuint32m8_t vsbc_vxm (vuint32m8_t op1, uint32_t op2, vbool4_t borrowin);
vuint64m1_t vsbc_vvm (vuint64m1_t op1, vuint64m1_t op2, vbool64_t borrowin);
vuint64m1_t vsbc_vxm (vuint64m1_t op1, uint64_t op2, vbool64_t borrowin);
vuint64m2_t vsbc_vvm (vuint64m2_t op1, vuint64m2_t op2, vbool32_t borrowin);
vuint64m2_t vsbc_vxm (vuint64m2_t op1, uint64_t op2, vbool32_t borrowin);
vuint64m4_t vsbc_vvm (vuint64m4_t op1, vuint64m4_t op2, vbool16_t borrowin);
vuint64m4_t vsbc_vxm (vuint64m4_t op1, uint64_t op2, vbool16_t borrowin);
vuint64m8_t vsbc_vvm (vuint64m8_t op1, vuint64m8_t op2, vbool8_t borrowin);
vuint64m8_t vsbc_vxm (vuint64m8_t op1, uint64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vvm (vint8m1_t op1, vint8m1_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vxm (vint8m1_t op1, int8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsbc_vx (vint8m1_t op1, int8_t op2);
vbool4_t vmsbc_vvm (vint8m2_t op1, vint8m2_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vxm (vint8m2_t op1, int8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsbc_vx (vint8m2_t op1, int8_t op2);
vbool2_t vmsbc_vvm (vint8m4_t op1, vint8m4_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vxm (vint8m4_t op1, int8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsbc_vx (vint8m4_t op1, int8_t op2);
vbool1_t vmsbc_vvm (vint8m8_t op1, vint8m8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vxm (vint8m8_t op1, int8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vv (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsbc_vx (vint8m8_t op1, int8_t op2);
vbool16_t vmsbc_vvm (vint16m1_t op1, vint16m1_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vxm (vint16m1_t op1, int16_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsbc_vx (vint16m1_t op1, int16_t op2);
vbool8_t vmsbc_vvm (vint16m2_t op1, vint16m2_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vxm (vint16m2_t op1, int16_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsbc_vx (vint16m2_t op1, int16_t op2);
vbool4_t vmsbc_vvm (vint16m4_t op1, vint16m4_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vxm (vint16m4_t op1, int16_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsbc_vx (vint16m4_t op1, int16_t op2);
vbool2_t vmsbc_vvm (vint16m8_t op1, vint16m8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vxm (vint16m8_t op1, int16_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsbc_vx (vint16m8_t op1, int16_t op2);
vbool32_t vmsbc_vvm (vint32m1_t op1, vint32m1_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vxm (vint32m1_t op1, int32_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsbc_vx (vint32m1_t op1, int32_t op2);
vbool16_t vmsbc_vvm (vint32m2_t op1, vint32m2_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vxm (vint32m2_t op1, int32_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsbc_vx (vint32m2_t op1, int32_t op2);
vbool8_t vmsbc_vvm (vint32m4_t op1, vint32m4_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vxm (vint32m4_t op1, int32_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsbc_vx (vint32m4_t op1, int32_t op2);
vbool4_t vmsbc_vvm (vint32m8_t op1, vint32m8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vxm (vint32m8_t op1, int32_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsbc_vx (vint32m8_t op1, int32_t op2);
vbool64_t vmsbc_vvm (vint64m1_t op1, vint64m1_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vxm (vint64m1_t op1, int64_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vv (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsbc_vx (vint64m1_t op1, int64_t op2);
vbool32_t vmsbc_vvm (vint64m2_t op1, vint64m2_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vxm (vint64m2_t op1, int64_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsbc_vx (vint64m2_t op1, int64_t op2);
vbool16_t vmsbc_vvm (vint64m4_t op1, vint64m4_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vxm (vint64m4_t op1, int64_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsbc_vx (vint64m4_t op1, int64_t op2);
vbool8_t vmsbc_vvm (vint64m8_t op1, vint64m8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vxm (vint64m8_t op1, int64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsbc_vx (vint64m8_t op1, int64_t op2);
vbool8_t vmsbc_vvm (vuint8m1_t op1, vuint8m1_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vxm (vuint8m1_t op1, uint8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsbc_vx (vuint8m1_t op1, uint8_t op2);
vbool4_t vmsbc_vvm (vuint8m2_t op1, vuint8m2_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vxm (vuint8m2_t op1, uint8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsbc_vx (vuint8m2_t op1, uint8_t op2);
vbool2_t vmsbc_vvm (vuint8m4_t op1, vuint8m4_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vxm (vuint8m4_t op1, uint8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsbc_vx (vuint8m4_t op1, uint8_t op2);
vbool1_t vmsbc_vvm (vuint8m8_t op1, vuint8m8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vxm (vuint8m8_t op1, uint8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vv (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsbc_vx (vuint8m8_t op1, uint8_t op2);
vbool16_t vmsbc_vvm (vuint16m1_t op1, vuint16m1_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vxm (vuint16m1_t op1, uint16_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsbc_vx (vuint16m1_t op1, uint16_t op2);
vbool8_t vmsbc_vvm (vuint16m2_t op1, vuint16m2_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vxm (vuint16m2_t op1, uint16_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsbc_vx (vuint16m2_t op1, uint16_t op2);
vbool4_t vmsbc_vvm (vuint16m4_t op1, vuint16m4_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vxm (vuint16m4_t op1, uint16_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsbc_vx (vuint16m4_t op1, uint16_t op2);
vbool2_t vmsbc_vvm (vuint16m8_t op1, vuint16m8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vxm (vuint16m8_t op1, uint16_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsbc_vx (vuint16m8_t op1, uint16_t op2);
vbool32_t vmsbc_vvm (vuint32m1_t op1, vuint32m1_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vxm (vuint32m1_t op1, uint32_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsbc_vx (vuint32m1_t op1, uint32_t op2);
vbool16_t vmsbc_vvm (vuint32m2_t op1, vuint32m2_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vxm (vuint32m2_t op1, uint32_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsbc_vx (vuint32m2_t op1, uint32_t op2);
vbool8_t vmsbc_vvm (vuint32m4_t op1, vuint32m4_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vxm (vuint32m4_t op1, uint32_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsbc_vx (vuint32m4_t op1, uint32_t op2);
vbool4_t vmsbc_vvm (vuint32m8_t op1, vuint32m8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vxm (vuint32m8_t op1, uint32_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsbc_vx (vuint32m8_t op1, uint32_t op2);
vbool64_t vmsbc_vvm (vuint64m1_t op1, vuint64m1_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vxm (vuint64m1_t op1, uint64_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vv (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsbc_vx (vuint64m1_t op1, uint64_t op2);
vbool32_t vmsbc_vvm (vuint64m2_t op1, vuint64m2_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vxm (vuint64m2_t op1, uint64_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsbc_vx (vuint64m2_t op1, uint64_t op2);
vbool16_t vmsbc_vvm (vuint64m4_t op1, vuint64m4_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vxm (vuint64m4_t op1, uint64_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsbc_vx (vuint64m4_t op1, uint64_t op2);
vbool8_t vmsbc_vvm (vuint64m8_t op1, vuint64m8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vxm (vuint64m8_t op1, uint64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsbc_vx (vuint64m8_t op1, uint64_t op2);
```
### [Vector Bitwise Logical Functions](rvv-intrinsic-api.md#124-vector-bitwise-logical-operations):

**Prototypes:**
``` C
vint8m1_t vand (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vand (vint8m1_t op1, int8_t op2);
vint8m2_t vand (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vand (vint8m2_t op1, int8_t op2);
vint8m4_t vand (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vand (vint8m4_t op1, int8_t op2);
vint8m8_t vand (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vand (vint8m8_t op1, int8_t op2);
vint16m1_t vand (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vand (vint16m1_t op1, int16_t op2);
vint16m2_t vand (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vand (vint16m2_t op1, int16_t op2);
vint16m4_t vand (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vand (vint16m4_t op1, int16_t op2);
vint16m8_t vand (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vand (vint16m8_t op1, int16_t op2);
vint32m1_t vand (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vand (vint32m1_t op1, int32_t op2);
vint32m2_t vand (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vand (vint32m2_t op1, int32_t op2);
vint32m4_t vand (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vand (vint32m4_t op1, int32_t op2);
vint32m8_t vand (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vand (vint32m8_t op1, int32_t op2);
vint64m1_t vand (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vand (vint64m1_t op1, int64_t op2);
vint64m2_t vand (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vand (vint64m2_t op1, int64_t op2);
vint64m4_t vand (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vand (vint64m4_t op1, int64_t op2);
vint64m8_t vand (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vand (vint64m8_t op1, int64_t op2);
vuint8m1_t vand (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vand (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vand (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vand (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vand (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vand (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vand (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vand (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vand (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vand (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vand (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vand (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vand (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vand (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vand (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vand (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vand (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vand (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vand (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vand (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vand (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vand (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vand (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vand (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vand (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vand (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vand (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vand (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vand (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vand (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vand (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vand (vuint64m8_t op1, uint64_t op2);
vint8m1_t vor (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vor (vint8m1_t op1, int8_t op2);
vint8m2_t vor (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vor (vint8m2_t op1, int8_t op2);
vint8m4_t vor (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vor (vint8m4_t op1, int8_t op2);
vint8m8_t vor (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vor (vint8m8_t op1, int8_t op2);
vint16m1_t vor (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vor (vint16m1_t op1, int16_t op2);
vint16m2_t vor (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vor (vint16m2_t op1, int16_t op2);
vint16m4_t vor (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vor (vint16m4_t op1, int16_t op2);
vint16m8_t vor (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vor (vint16m8_t op1, int16_t op2);
vint32m1_t vor (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vor (vint32m1_t op1, int32_t op2);
vint32m2_t vor (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vor (vint32m2_t op1, int32_t op2);
vint32m4_t vor (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vor (vint32m4_t op1, int32_t op2);
vint32m8_t vor (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vor (vint32m8_t op1, int32_t op2);
vint64m1_t vor (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vor (vint64m1_t op1, int64_t op2);
vint64m2_t vor (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vor (vint64m2_t op1, int64_t op2);
vint64m4_t vor (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vor (vint64m4_t op1, int64_t op2);
vint64m8_t vor (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vor (vint64m8_t op1, int64_t op2);
vuint8m1_t vor (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vor (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vor (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vor (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vor (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vor (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vor (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vor (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vor (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vor (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vor (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vor (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vor (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vor (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vor (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vor (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vor (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vor (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vor (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vor (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vor (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vor (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vor (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vor (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vor (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vor (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vor (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vor (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vor (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vor (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vor (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vor (vuint64m8_t op1, uint64_t op2);
vint8m1_t vxor (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vxor (vint8m1_t op1, int8_t op2);
vint8m2_t vxor (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vxor (vint8m2_t op1, int8_t op2);
vint8m4_t vxor (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vxor (vint8m4_t op1, int8_t op2);
vint8m8_t vxor (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vxor (vint8m8_t op1, int8_t op2);
vint16m1_t vxor (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vxor (vint16m1_t op1, int16_t op2);
vint16m2_t vxor (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vxor (vint16m2_t op1, int16_t op2);
vint16m4_t vxor (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vxor (vint16m4_t op1, int16_t op2);
vint16m8_t vxor (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vxor (vint16m8_t op1, int16_t op2);
vint32m1_t vxor (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vxor (vint32m1_t op1, int32_t op2);
vint32m2_t vxor (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vxor (vint32m2_t op1, int32_t op2);
vint32m4_t vxor (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vxor (vint32m4_t op1, int32_t op2);
vint32m8_t vxor (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vxor (vint32m8_t op1, int32_t op2);
vint64m1_t vxor (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vxor (vint64m1_t op1, int64_t op2);
vint64m2_t vxor (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vxor (vint64m2_t op1, int64_t op2);
vint64m4_t vxor (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vxor (vint64m4_t op1, int64_t op2);
vint64m8_t vxor (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vxor (vint64m8_t op1, int64_t op2);
vuint8m1_t vxor (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vxor (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vxor (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vxor (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vxor (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vxor (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vxor (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vxor (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vxor (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vxor (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vxor (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vxor (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vxor (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vxor (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vxor (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vxor (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vxor (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vxor (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vxor (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vxor (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vxor (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vxor (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vxor (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vxor (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vxor (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vxor (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vxor (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vxor (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vxor (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vxor (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vxor (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vxor (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vand_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vand_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vand_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vand_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vand_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vand_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vand_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vand_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vand_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vand_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vand_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vand_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vand_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vand_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vand_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vand_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vand_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vand_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vand_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vand_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vand_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vand_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vand_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vand_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vand_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vand_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vand_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vand_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vand_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vand_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vand_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vand_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vand_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vand_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vand_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vand_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vand_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vand_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vand_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vand_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vand_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vand_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vand_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vand_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vand_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vand_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vand_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vand_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vand_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vand_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vand_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vand_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vand_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vand_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vand_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vand_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vand_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vand_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vand_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vand_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vand_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vand_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vand_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vand_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vor_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vor_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vor_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vor_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vor_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vor_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vor_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vor_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vor_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vor_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vor_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vor_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vor_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vor_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vor_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vor_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vor_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vor_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vor_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vor_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vor_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vor_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vor_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vor_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vor_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vor_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vor_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vor_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vor_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vor_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vor_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vor_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vor_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vor_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vor_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vor_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vor_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vor_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vor_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vor_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vor_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vor_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vor_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vor_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vor_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vor_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vor_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vor_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vor_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vor_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vor_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vor_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vor_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vor_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vor_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vor_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vor_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vor_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vor_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vor_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vor_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vor_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vor_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vor_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vxor_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vxor_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vxor_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vxor_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vxor_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vxor_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vxor_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vxor_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vxor_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vxor_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vxor_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vxor_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vxor_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vxor_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vxor_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vxor_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vxor_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vxor_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vxor_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vxor_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vxor_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vxor_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vxor_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vxor_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vxor_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vxor_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vxor_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vxor_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vxor_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vxor_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vxor_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vxor_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vxor_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vxor_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vxor_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vxor_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vxor_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vxor_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vxor_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vxor_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vxor_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vxor_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vxor_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vxor_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vxor_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vxor_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vxor_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vxor_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vxor_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vxor_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vxor_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vxor_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vxor_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vxor_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vxor_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vxor_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vxor_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vxor_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vxor_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vxor_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vxor_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vxor_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vxor_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vxor_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Bitwise Logical Functions](rvv-intrinsic-api.md#124-vector-bitwise-logical-operations):

**Prototypes:**
``` C
vint8m1_t vnot (vint8m1_t op1);
vint8m2_t vnot (vint8m2_t op1);
vint8m4_t vnot (vint8m4_t op1);
vint8m8_t vnot (vint8m8_t op1);
vint16m1_t vnot (vint16m1_t op1);
vint16m2_t vnot (vint16m2_t op1);
vint16m4_t vnot (vint16m4_t op1);
vint16m8_t vnot (vint16m8_t op1);
vint32m1_t vnot (vint32m1_t op1);
vint32m2_t vnot (vint32m2_t op1);
vint32m4_t vnot (vint32m4_t op1);
vint32m8_t vnot (vint32m8_t op1);
vint64m1_t vnot (vint64m1_t op1);
vint64m2_t vnot (vint64m2_t op1);
vint64m4_t vnot (vint64m4_t op1);
vint64m8_t vnot (vint64m8_t op1);
vuint8m1_t vnot (vuint8m1_t op1);
vuint8m2_t vnot (vuint8m2_t op1);
vuint8m4_t vnot (vuint8m4_t op1);
vuint8m8_t vnot (vuint8m8_t op1);
vuint16m1_t vnot (vuint16m1_t op1);
vuint16m2_t vnot (vuint16m2_t op1);
vuint16m4_t vnot (vuint16m4_t op1);
vuint16m8_t vnot (vuint16m8_t op1);
vuint32m1_t vnot (vuint32m1_t op1);
vuint32m2_t vnot (vuint32m2_t op1);
vuint32m4_t vnot (vuint32m4_t op1);
vuint32m8_t vnot (vuint32m8_t op1);
vuint64m1_t vnot (vuint64m1_t op1);
vuint64m2_t vnot (vuint64m2_t op1);
vuint64m4_t vnot (vuint64m4_t op1);
vuint64m8_t vnot (vuint64m8_t op1);
// masked functions
vint8m1_t vnot_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1);
vint8m2_t vnot_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1);
vint8m4_t vnot_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1);
vint8m8_t vnot_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1);
vint16m1_t vnot_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1);
vint16m2_t vnot_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1);
vint16m4_t vnot_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1);
vint16m8_t vnot_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1);
vint32m1_t vnot_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1);
vint32m2_t vnot_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1);
vint32m4_t vnot_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1);
vint32m8_t vnot_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1);
vint64m1_t vnot_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1);
vint64m2_t vnot_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1);
vint64m4_t vnot_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1);
vint64m8_t vnot_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1);
vuint8m1_t vnot_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1);
vuint8m2_t vnot_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1);
vuint8m4_t vnot_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1);
vuint8m8_t vnot_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1);
vuint16m1_t vnot_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1);
vuint16m2_t vnot_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1);
vuint16m4_t vnot_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1);
vuint16m8_t vnot_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1);
vuint32m1_t vnot_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1);
vuint32m2_t vnot_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1);
vuint32m4_t vnot_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1);
vuint32m8_t vnot_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1);
vuint64m1_t vnot_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1);
vuint64m2_t vnot_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1);
vuint64m4_t vnot_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1);
vuint64m8_t vnot_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1);
```
### [Vector Single-Width Bit Shift Functioans](rvv-intrinsic-api.md#125-vector-single-width-bit-shift-operations):

**Prototypes:**
``` C
vint8m1_t vsll (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vsll (vint8m1_t op1, uint8_t op2);
vint8m2_t vsll (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vsll (vint8m2_t op1, uint8_t op2);
vint8m4_t vsll (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vsll (vint8m4_t op1, uint8_t op2);
vint8m8_t vsll (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vsll (vint8m8_t op1, uint8_t op2);
vint16m1_t vsll (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vsll (vint16m1_t op1, uint8_t op2);
vint16m2_t vsll (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vsll (vint16m2_t op1, uint8_t op2);
vint16m4_t vsll (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vsll (vint16m4_t op1, uint8_t op2);
vint16m8_t vsll (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vsll (vint16m8_t op1, uint8_t op2);
vint32m1_t vsll (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vsll (vint32m1_t op1, uint8_t op2);
vint32m2_t vsll (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vsll (vint32m2_t op1, uint8_t op2);
vint32m4_t vsll (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vsll (vint32m4_t op1, uint8_t op2);
vint32m8_t vsll (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vsll (vint32m8_t op1, uint8_t op2);
vint64m1_t vsll (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vsll (vint64m1_t op1, uint8_t op2);
vint64m2_t vsll (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vsll (vint64m2_t op1, uint8_t op2);
vint64m4_t vsll (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vsll (vint64m4_t op1, uint8_t op2);
vint64m8_t vsll (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vsll (vint64m8_t op1, uint8_t op2);
vuint8m1_t vsll (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsll (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsll (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsll (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsll (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsll (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsll (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsll (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsll (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsll (vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsll (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsll (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsll (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsll (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsll (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsll (vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsll (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsll (vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsll (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsll (vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsll (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsll (vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsll (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsll (vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsll (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsll (vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsll (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsll (vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsll (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsll (vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsll (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsll (vuint64m8_t op1, uint8_t op2);
vuint8m1_t vsrl (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsrl (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsrl (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsrl (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsrl (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsrl (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsrl (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsrl (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsrl (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsrl (vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsrl (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsrl (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsrl (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsrl (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsrl (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsrl (vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsrl (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsrl (vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsrl (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsrl (vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsrl (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsrl (vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsrl (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsrl (vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsrl (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsrl (vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsrl (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsrl (vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsrl (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsrl (vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsrl (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsrl (vuint64m8_t op1, uint8_t op2);
vint8m1_t vsra (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vsra (vint8m1_t op1, uint8_t op2);
vint8m2_t vsra (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vsra (vint8m2_t op1, uint8_t op2);
vint8m4_t vsra (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vsra (vint8m4_t op1, uint8_t op2);
vint8m8_t vsra (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vsra (vint8m8_t op1, uint8_t op2);
vint16m1_t vsra (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vsra (vint16m1_t op1, uint8_t op2);
vint16m2_t vsra (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vsra (vint16m2_t op1, uint8_t op2);
vint16m4_t vsra (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vsra (vint16m4_t op1, uint8_t op2);
vint16m8_t vsra (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vsra (vint16m8_t op1, uint8_t op2);
vint32m1_t vsra (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vsra (vint32m1_t op1, uint8_t op2);
vint32m2_t vsra (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vsra (vint32m2_t op1, uint8_t op2);
vint32m4_t vsra (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vsra (vint32m4_t op1, uint8_t op2);
vint32m8_t vsra (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vsra (vint32m8_t op1, uint8_t op2);
vint64m1_t vsra (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vsra (vint64m1_t op1, uint8_t op2);
vint64m2_t vsra (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vsra (vint64m2_t op1, uint8_t op2);
vint64m4_t vsra (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vsra (vint64m4_t op1, uint8_t op2);
vint64m8_t vsra (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vsra (vint64m8_t op1, uint8_t op2);
// masked functions
vint8m1_t vsll_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vsll_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vsll_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vsll_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vsll_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vsll_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vsll_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vsll_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vsll_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vsll_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint8_t op2);
vint16m2_t vsll_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vsll_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint8_t op2);
vint16m4_t vsll_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vsll_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint8_t op2);
vint16m8_t vsll_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vsll_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint8_t op2);
vint32m1_t vsll_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vsll_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint8_t op2);
vint32m2_t vsll_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vsll_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint8_t op2);
vint32m4_t vsll_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vsll_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint8_t op2);
vint32m8_t vsll_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vsll_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint8_t op2);
vint64m1_t vsll_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vsll_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint8_t op2);
vint64m2_t vsll_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vsll_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint8_t op2);
vint64m4_t vsll_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vsll_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint8_t op2);
vint64m8_t vsll_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vsll_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint8_t op2);
vuint8m1_t vsll_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsll_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsll_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsll_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsll_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsll_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsll_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsll_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsll_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsll_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsll_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsll_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsll_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsll_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsll_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsll_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsll_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsll_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsll_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsll_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsll_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsll_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsll_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsll_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsll_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsll_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsll_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsll_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsll_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsll_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsll_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsll_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint8_t op2);
vuint8m1_t vsrl_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsrl_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsrl_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsrl_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsrl_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsrl_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsrl_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsrl_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsrl_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsrl_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsrl_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsrl_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsrl_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsrl_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsrl_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsrl_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsrl_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsrl_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsrl_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsrl_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsrl_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsrl_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsrl_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsrl_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsrl_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsrl_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsrl_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsrl_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsrl_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsrl_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsrl_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsrl_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint8_t op2);
vint8m1_t vsra_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vsra_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vsra_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vsra_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vsra_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vsra_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vsra_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vsra_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vsra_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vsra_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint8_t op2);
vint16m2_t vsra_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vsra_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint8_t op2);
vint16m4_t vsra_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vsra_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint8_t op2);
vint16m8_t vsra_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vsra_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint8_t op2);
vint32m1_t vsra_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vsra_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint8_t op2);
vint32m2_t vsra_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vsra_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint8_t op2);
vint32m4_t vsra_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vsra_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint8_t op2);
vint32m8_t vsra_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vsra_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint8_t op2);
vint64m1_t vsra_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vsra_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint8_t op2);
vint64m2_t vsra_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vsra_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint8_t op2);
vint64m4_t vsra_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vsra_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint8_t op2);
vint64m8_t vsra_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vsra_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint8_t op2);
```
### [Vector Narrowing Integer Right Shift Functions](rvv-intrinsic-api.md#126-vector-narrowing-integer-right-shift-operations):

**Prototypes:**
``` C
vuint8m1_t vnsrl (vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnsrl (vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnsrl (vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnsrl (vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnsrl (vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnsrl (vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnsrl (vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnsrl (vuint32m2_t op1, uint8_t op2);
vuint16m2_t vnsrl (vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnsrl (vuint32m4_t op1, uint8_t op2);
vuint16m4_t vnsrl (vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnsrl (vuint32m8_t op1, uint8_t op2);
vuint32m1_t vnsrl (vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnsrl (vuint64m2_t op1, uint8_t op2);
vuint32m2_t vnsrl (vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnsrl (vuint64m4_t op1, uint8_t op2);
vuint32m4_t vnsrl (vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnsrl (vuint64m8_t op1, uint8_t op2);
vint8m1_t vnsra (vint16m2_t op1, vuint8m1_t op2);
vint8m1_t vnsra (vint16m2_t op1, uint8_t op2);
vint8m2_t vnsra (vint16m4_t op1, vuint8m2_t op2);
vint8m2_t vnsra (vint16m4_t op1, uint8_t op2);
vint8m4_t vnsra (vint16m8_t op1, vuint8m4_t op2);
vint8m4_t vnsra (vint16m8_t op1, uint8_t op2);
vint16m1_t vnsra (vint32m2_t op1, vuint16m1_t op2);
vint16m1_t vnsra (vint32m2_t op1, uint8_t op2);
vint16m2_t vnsra (vint32m4_t op1, vuint16m2_t op2);
vint16m2_t vnsra (vint32m4_t op1, uint8_t op2);
vint16m4_t vnsra (vint32m8_t op1, vuint16m4_t op2);
vint16m4_t vnsra (vint32m8_t op1, uint8_t op2);
vint32m1_t vnsra (vint64m2_t op1, vuint32m1_t op2);
vint32m1_t vnsra (vint64m2_t op1, uint8_t op2);
vint32m2_t vnsra (vint64m4_t op1, vuint32m2_t op2);
vint32m2_t vnsra (vint64m4_t op1, uint8_t op2);
vint32m4_t vnsra (vint64m8_t op1, vuint32m4_t op2);
vint32m4_t vnsra (vint64m8_t op1, uint8_t op2);
// masked functions
vuint8m1_t vnsrl_m (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnsrl_m (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnsrl_m (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnsrl_m (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnsrl_m (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnsrl_m (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnsrl_m (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnsrl_m (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint16m2_t vnsrl_m (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnsrl_m (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint16m4_t vnsrl_m (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnsrl_m (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint32m1_t vnsrl_m (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnsrl_m (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint32m2_t vnsrl_m (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnsrl_m (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint32m4_t vnsrl_m (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnsrl_m (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, uint8_t op2);
vint8m1_t vnsra_m (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t op2);
vint8m1_t vnsra_m (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, uint8_t op2);
vint8m2_t vnsra_m (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t op2);
vint8m2_t vnsra_m (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, uint8_t op2);
vint8m4_t vnsra_m (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t op2);
vint8m4_t vnsra_m (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, uint8_t op2);
vint16m1_t vnsra_m (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t op2);
vint16m1_t vnsra_m (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, uint8_t op2);
vint16m2_t vnsra_m (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t op2);
vint16m2_t vnsra_m (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, uint8_t op2);
vint16m4_t vnsra_m (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t op2);
vint16m4_t vnsra_m (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, uint8_t op2);
vint32m1_t vnsra_m (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t op2);
vint32m1_t vnsra_m (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, uint8_t op2);
vint32m2_t vnsra_m (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t op2);
vint32m2_t vnsra_m (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, uint8_t op2);
vint32m4_t vnsra_m (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t op2);
vint32m4_t vnsra_m (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, uint8_t op2);
```
### [Vector Integer Comparison Functions](rvv-intrinsic-api.md#127-vector-integer-comparison-operations):

**Prototypes:**
``` C
vbool8_t vmseq (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmseq (vint8m1_t op1, int8_t op2);
vbool4_t vmseq (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmseq (vint8m2_t op1, int8_t op2);
vbool2_t vmseq (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmseq (vint8m4_t op1, int8_t op2);
vbool1_t vmseq (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmseq (vint8m8_t op1, int8_t op2);
vbool16_t vmseq (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmseq (vint16m1_t op1, int16_t op2);
vbool8_t vmseq (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmseq (vint16m2_t op1, int16_t op2);
vbool4_t vmseq (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmseq (vint16m4_t op1, int16_t op2);
vbool2_t vmseq (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmseq (vint16m8_t op1, int16_t op2);
vbool32_t vmseq (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmseq (vint32m1_t op1, int32_t op2);
vbool16_t vmseq (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmseq (vint32m2_t op1, int32_t op2);
vbool8_t vmseq (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmseq (vint32m4_t op1, int32_t op2);
vbool4_t vmseq (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmseq (vint32m8_t op1, int32_t op2);
vbool64_t vmseq (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmseq (vint64m1_t op1, int64_t op2);
vbool32_t vmseq (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmseq (vint64m2_t op1, int64_t op2);
vbool16_t vmseq (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmseq (vint64m4_t op1, int64_t op2);
vbool8_t vmseq (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmseq (vint64m8_t op1, int64_t op2);
vbool8_t vmseq (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmseq (vuint8m1_t op1, uint8_t op2);
vbool4_t vmseq (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmseq (vuint8m2_t op1, uint8_t op2);
vbool2_t vmseq (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmseq (vuint8m4_t op1, uint8_t op2);
vbool1_t vmseq (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmseq (vuint8m8_t op1, uint8_t op2);
vbool16_t vmseq (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmseq (vuint16m1_t op1, uint16_t op2);
vbool8_t vmseq (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmseq (vuint16m2_t op1, uint16_t op2);
vbool4_t vmseq (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmseq (vuint16m4_t op1, uint16_t op2);
vbool2_t vmseq (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmseq (vuint16m8_t op1, uint16_t op2);
vbool32_t vmseq (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmseq (vuint32m1_t op1, uint32_t op2);
vbool16_t vmseq (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmseq (vuint32m2_t op1, uint32_t op2);
vbool8_t vmseq (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmseq (vuint32m4_t op1, uint32_t op2);
vbool4_t vmseq (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmseq (vuint32m8_t op1, uint32_t op2);
vbool64_t vmseq (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmseq (vuint64m1_t op1, uint64_t op2);
vbool32_t vmseq (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmseq (vuint64m2_t op1, uint64_t op2);
vbool16_t vmseq (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmseq (vuint64m4_t op1, uint64_t op2);
vbool8_t vmseq (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmseq (vuint64m8_t op1, uint64_t op2);
vbool8_t vmsne (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsne (vint8m1_t op1, int8_t op2);
vbool4_t vmsne (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsne (vint8m2_t op1, int8_t op2);
vbool2_t vmsne (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsne (vint8m4_t op1, int8_t op2);
vbool1_t vmsne (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsne (vint8m8_t op1, int8_t op2);
vbool16_t vmsne (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsne (vint16m1_t op1, int16_t op2);
vbool8_t vmsne (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsne (vint16m2_t op1, int16_t op2);
vbool4_t vmsne (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsne (vint16m4_t op1, int16_t op2);
vbool2_t vmsne (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsne (vint16m8_t op1, int16_t op2);
vbool32_t vmsne (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsne (vint32m1_t op1, int32_t op2);
vbool16_t vmsne (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsne (vint32m2_t op1, int32_t op2);
vbool8_t vmsne (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsne (vint32m4_t op1, int32_t op2);
vbool4_t vmsne (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsne (vint32m8_t op1, int32_t op2);
vbool64_t vmsne (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsne (vint64m1_t op1, int64_t op2);
vbool32_t vmsne (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsne (vint64m2_t op1, int64_t op2);
vbool16_t vmsne (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsne (vint64m4_t op1, int64_t op2);
vbool8_t vmsne (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsne (vint64m8_t op1, int64_t op2);
vbool8_t vmsne (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsne (vuint8m1_t op1, uint8_t op2);
vbool4_t vmsne (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsne (vuint8m2_t op1, uint8_t op2);
vbool2_t vmsne (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsne (vuint8m4_t op1, uint8_t op2);
vbool1_t vmsne (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsne (vuint8m8_t op1, uint8_t op2);
vbool16_t vmsne (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsne (vuint16m1_t op1, uint16_t op2);
vbool8_t vmsne (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsne (vuint16m2_t op1, uint16_t op2);
vbool4_t vmsne (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsne (vuint16m4_t op1, uint16_t op2);
vbool2_t vmsne (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsne (vuint16m8_t op1, uint16_t op2);
vbool32_t vmsne (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsne (vuint32m1_t op1, uint32_t op2);
vbool16_t vmsne (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsne (vuint32m2_t op1, uint32_t op2);
vbool8_t vmsne (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsne (vuint32m4_t op1, uint32_t op2);
vbool4_t vmsne (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsne (vuint32m8_t op1, uint32_t op2);
vbool64_t vmsne (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsne (vuint64m1_t op1, uint64_t op2);
vbool32_t vmsne (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsne (vuint64m2_t op1, uint64_t op2);
vbool16_t vmsne (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsne (vuint64m4_t op1, uint64_t op2);
vbool8_t vmsne (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsne (vuint64m8_t op1, uint64_t op2);
vbool8_t vmslt (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmslt (vint8m1_t op1, int8_t op2);
vbool4_t vmslt (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmslt (vint8m2_t op1, int8_t op2);
vbool2_t vmslt (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmslt (vint8m4_t op1, int8_t op2);
vbool1_t vmslt (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmslt (vint8m8_t op1, int8_t op2);
vbool16_t vmslt (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmslt (vint16m1_t op1, int16_t op2);
vbool8_t vmslt (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmslt (vint16m2_t op1, int16_t op2);
vbool4_t vmslt (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmslt (vint16m4_t op1, int16_t op2);
vbool2_t vmslt (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmslt (vint16m8_t op1, int16_t op2);
vbool32_t vmslt (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmslt (vint32m1_t op1, int32_t op2);
vbool16_t vmslt (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmslt (vint32m2_t op1, int32_t op2);
vbool8_t vmslt (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmslt (vint32m4_t op1, int32_t op2);
vbool4_t vmslt (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmslt (vint32m8_t op1, int32_t op2);
vbool64_t vmslt (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmslt (vint64m1_t op1, int64_t op2);
vbool32_t vmslt (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmslt (vint64m2_t op1, int64_t op2);
vbool16_t vmslt (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmslt (vint64m4_t op1, int64_t op2);
vbool8_t vmslt (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmslt (vint64m8_t op1, int64_t op2);
vbool8_t vmsltu (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsltu (vuint8m1_t op1, uint8_t op2);
vbool4_t vmsltu (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsltu (vuint8m2_t op1, uint8_t op2);
vbool2_t vmsltu (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsltu (vuint8m4_t op1, uint8_t op2);
vbool1_t vmsltu (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsltu (vuint8m8_t op1, uint8_t op2);
vbool16_t vmsltu (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsltu (vuint16m1_t op1, uint16_t op2);
vbool8_t vmsltu (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsltu (vuint16m2_t op1, uint16_t op2);
vbool4_t vmsltu (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsltu (vuint16m4_t op1, uint16_t op2);
vbool2_t vmsltu (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsltu (vuint16m8_t op1, uint16_t op2);
vbool32_t vmsltu (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsltu (vuint32m1_t op1, uint32_t op2);
vbool16_t vmsltu (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsltu (vuint32m2_t op1, uint32_t op2);
vbool8_t vmsltu (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsltu (vuint32m4_t op1, uint32_t op2);
vbool4_t vmsltu (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsltu (vuint32m8_t op1, uint32_t op2);
vbool64_t vmsltu (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsltu (vuint64m1_t op1, uint64_t op2);
vbool32_t vmsltu (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsltu (vuint64m2_t op1, uint64_t op2);
vbool16_t vmsltu (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsltu (vuint64m4_t op1, uint64_t op2);
vbool8_t vmsltu (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsltu (vuint64m8_t op1, uint64_t op2);
vbool8_t vmsle (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsle (vint8m1_t op1, int8_t op2);
vbool4_t vmsle (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsle (vint8m2_t op1, int8_t op2);
vbool2_t vmsle (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsle (vint8m4_t op1, int8_t op2);
vbool1_t vmsle (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsle (vint8m8_t op1, int8_t op2);
vbool16_t vmsle (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsle (vint16m1_t op1, int16_t op2);
vbool8_t vmsle (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsle (vint16m2_t op1, int16_t op2);
vbool4_t vmsle (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsle (vint16m4_t op1, int16_t op2);
vbool2_t vmsle (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsle (vint16m8_t op1, int16_t op2);
vbool32_t vmsle (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsle (vint32m1_t op1, int32_t op2);
vbool16_t vmsle (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsle (vint32m2_t op1, int32_t op2);
vbool8_t vmsle (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsle (vint32m4_t op1, int32_t op2);
vbool4_t vmsle (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsle (vint32m8_t op1, int32_t op2);
vbool64_t vmsle (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsle (vint64m1_t op1, int64_t op2);
vbool32_t vmsle (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsle (vint64m2_t op1, int64_t op2);
vbool16_t vmsle (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsle (vint64m4_t op1, int64_t op2);
vbool8_t vmsle (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsle (vint64m8_t op1, int64_t op2);
vbool8_t vmsleu (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsleu (vuint8m1_t op1, uint8_t op2);
vbool4_t vmsleu (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsleu (vuint8m2_t op1, uint8_t op2);
vbool2_t vmsleu (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsleu (vuint8m4_t op1, uint8_t op2);
vbool1_t vmsleu (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsleu (vuint8m8_t op1, uint8_t op2);
vbool16_t vmsleu (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsleu (vuint16m1_t op1, uint16_t op2);
vbool8_t vmsleu (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsleu (vuint16m2_t op1, uint16_t op2);
vbool4_t vmsleu (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsleu (vuint16m4_t op1, uint16_t op2);
vbool2_t vmsleu (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsleu (vuint16m8_t op1, uint16_t op2);
vbool32_t vmsleu (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsleu (vuint32m1_t op1, uint32_t op2);
vbool16_t vmsleu (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsleu (vuint32m2_t op1, uint32_t op2);
vbool8_t vmsleu (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsleu (vuint32m4_t op1, uint32_t op2);
vbool4_t vmsleu (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsleu (vuint32m8_t op1, uint32_t op2);
vbool64_t vmsleu (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsleu (vuint64m1_t op1, uint64_t op2);
vbool32_t vmsleu (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsleu (vuint64m2_t op1, uint64_t op2);
vbool16_t vmsleu (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsleu (vuint64m4_t op1, uint64_t op2);
vbool8_t vmsleu (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsleu (vuint64m8_t op1, uint64_t op2);
vbool8_t vmsgt (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsgt (vint8m1_t op1, int8_t op2);
vbool4_t vmsgt (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsgt (vint8m2_t op1, int8_t op2);
vbool2_t vmsgt (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsgt (vint8m4_t op1, int8_t op2);
vbool1_t vmsgt (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsgt (vint8m8_t op1, int8_t op2);
vbool16_t vmsgt (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsgt (vint16m1_t op1, int16_t op2);
vbool8_t vmsgt (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsgt (vint16m2_t op1, int16_t op2);
vbool4_t vmsgt (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsgt (vint16m4_t op1, int16_t op2);
vbool2_t vmsgt (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsgt (vint16m8_t op1, int16_t op2);
vbool32_t vmsgt (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsgt (vint32m1_t op1, int32_t op2);
vbool16_t vmsgt (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsgt (vint32m2_t op1, int32_t op2);
vbool8_t vmsgt (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsgt (vint32m4_t op1, int32_t op2);
vbool4_t vmsgt (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsgt (vint32m8_t op1, int32_t op2);
vbool64_t vmsgt (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsgt (vint64m1_t op1, int64_t op2);
vbool32_t vmsgt (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsgt (vint64m2_t op1, int64_t op2);
vbool16_t vmsgt (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsgt (vint64m4_t op1, int64_t op2);
vbool8_t vmsgt (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsgt (vint64m8_t op1, int64_t op2);
vbool8_t vmsgtu (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsgtu (vuint8m1_t op1, uint8_t op2);
vbool4_t vmsgtu (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsgtu (vuint8m2_t op1, uint8_t op2);
vbool2_t vmsgtu (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsgtu (vuint8m4_t op1, uint8_t op2);
vbool1_t vmsgtu (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsgtu (vuint8m8_t op1, uint8_t op2);
vbool16_t vmsgtu (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsgtu (vuint16m1_t op1, uint16_t op2);
vbool8_t vmsgtu (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsgtu (vuint16m2_t op1, uint16_t op2);
vbool4_t vmsgtu (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsgtu (vuint16m4_t op1, uint16_t op2);
vbool2_t vmsgtu (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsgtu (vuint16m8_t op1, uint16_t op2);
vbool32_t vmsgtu (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsgtu (vuint32m1_t op1, uint32_t op2);
vbool16_t vmsgtu (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsgtu (vuint32m2_t op1, uint32_t op2);
vbool8_t vmsgtu (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsgtu (vuint32m4_t op1, uint32_t op2);
vbool4_t vmsgtu (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsgtu (vuint32m8_t op1, uint32_t op2);
vbool64_t vmsgtu (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsgtu (vuint64m1_t op1, uint64_t op2);
vbool32_t vmsgtu (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsgtu (vuint64m2_t op1, uint64_t op2);
vbool16_t vmsgtu (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsgtu (vuint64m4_t op1, uint64_t op2);
vbool8_t vmsgtu (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsgtu (vuint64m8_t op1, uint64_t op2);
vbool8_t vmsge (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsge (vint8m1_t op1, int8_t op2);
vbool4_t vmsge (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsge (vint8m2_t op1, int8_t op2);
vbool2_t vmsge (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsge (vint8m4_t op1, int8_t op2);
vbool1_t vmsge (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsge (vint8m8_t op1, int8_t op2);
vbool16_t vmsge (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsge (vint16m1_t op1, int16_t op2);
vbool8_t vmsge (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsge (vint16m2_t op1, int16_t op2);
vbool4_t vmsge (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsge (vint16m4_t op1, int16_t op2);
vbool2_t vmsge (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsge (vint16m8_t op1, int16_t op2);
vbool32_t vmsge (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsge (vint32m1_t op1, int32_t op2);
vbool16_t vmsge (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsge (vint32m2_t op1, int32_t op2);
vbool8_t vmsge (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsge (vint32m4_t op1, int32_t op2);
vbool4_t vmsge (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsge (vint32m8_t op1, int32_t op2);
vbool64_t vmsge (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsge (vint64m1_t op1, int64_t op2);
vbool32_t vmsge (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsge (vint64m2_t op1, int64_t op2);
vbool16_t vmsge (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsge (vint64m4_t op1, int64_t op2);
vbool8_t vmsge (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsge (vint64m8_t op1, int64_t op2);
vbool8_t vmsgeu (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsgeu (vuint8m1_t op1, uint8_t op2);
vbool4_t vmsgeu (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsgeu (vuint8m2_t op1, uint8_t op2);
vbool2_t vmsgeu (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsgeu (vuint8m4_t op1, uint8_t op2);
vbool1_t vmsgeu (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsgeu (vuint8m8_t op1, uint8_t op2);
vbool16_t vmsgeu (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsgeu (vuint16m1_t op1, uint16_t op2);
vbool8_t vmsgeu (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsgeu (vuint16m2_t op1, uint16_t op2);
vbool4_t vmsgeu (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsgeu (vuint16m4_t op1, uint16_t op2);
vbool2_t vmsgeu (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsgeu (vuint16m8_t op1, uint16_t op2);
vbool32_t vmsgeu (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsgeu (vuint32m1_t op1, uint32_t op2);
vbool16_t vmsgeu (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsgeu (vuint32m2_t op1, uint32_t op2);
vbool8_t vmsgeu (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsgeu (vuint32m4_t op1, uint32_t op2);
vbool4_t vmsgeu (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsgeu (vuint32m8_t op1, uint32_t op2);
vbool64_t vmsgeu (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsgeu (vuint64m1_t op1, uint64_t op2);
vbool32_t vmsgeu (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsgeu (vuint64m2_t op1, uint64_t op2);
vbool16_t vmsgeu (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsgeu (vuint64m4_t op1, uint64_t op2);
vbool8_t vmsgeu (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsgeu (vuint64m8_t op1, uint64_t op2);
// masked functions
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vmseq_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vmseq_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vmseq_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vmseq_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vmseq_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vmseq_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vmseq_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vmseq_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vmseq_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vmseq_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vmseq_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vmseq_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vmseq_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmseq_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vmseq_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmseq_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vmseq_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmseq_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vmseq_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmseq_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmseq_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vmseq_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmseq_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vmseq_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmseq_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmseq_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmseq_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vmsne_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsne_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vmsne_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsne_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vmsne_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsne_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vmsne_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsne_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vmsne_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsne_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vmsne_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsne_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vmsne_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsne_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vmsne_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsne_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vmsne_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsne_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vmsne_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsne_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsne_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vmsne_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsne_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vmsne_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsne_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsne_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsne_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vmslt_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vmslt_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vmslt_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vmslt_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vmslt_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vmslt_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vmslt_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vmslt_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vmslt_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vmslt_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vmslt_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vmslt_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vmslt_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vmslt_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vmslt_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vmslt_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vmslt_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vmslt_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vmslt_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vmslt_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vmslt_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vmslt_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vmslt_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vmslt_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vmslt_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vmslt_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vmslt_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vmslt_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vmslt_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vmslt_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vmslt_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vmslt_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vmsltu_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsltu_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vmsltu_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsltu_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vmsltu_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsltu_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vmsltu_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsltu_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vmsltu_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsltu_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vmsltu_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsltu_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vmsltu_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsltu_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vmsltu_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsltu_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vmsltu_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsltu_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vmsltu_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsltu_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vmsltu_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsltu_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vmsltu_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsltu_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vmsltu_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsltu_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vmsltu_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsltu_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vmsltu_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsltu_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vmsltu_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsltu_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vmsle_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsle_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vmsle_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsle_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vmsle_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsle_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vmsle_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsle_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vmsle_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsle_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vmsle_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsle_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vmsle_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsle_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vmsle_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsle_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vmsle_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsle_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vmsle_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsle_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vmsle_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsle_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vmsle_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsle_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vmsle_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsle_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vmsle_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsle_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vmsle_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsle_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vmsle_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsle_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vmsleu_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsleu_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vmsleu_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsleu_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vmsleu_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsleu_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vmsleu_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsleu_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vmsleu_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsleu_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vmsleu_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsleu_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vmsleu_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsleu_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vmsleu_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsleu_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vmsleu_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsleu_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vmsleu_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsleu_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vmsleu_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsleu_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vmsleu_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsleu_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vmsleu_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsleu_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vmsleu_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsleu_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vmsleu_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsleu_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vmsleu_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsleu_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vmsgt_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsgt_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vmsgt_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsgt_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vmsgt_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsgt_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vmsgt_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsgt_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vmsgt_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsgt_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vmsgt_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsgt_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vmsgt_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsgt_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vmsgt_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsgt_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vmsgt_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsgt_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vmsgt_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsgt_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vmsgt_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsgt_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vmsgt_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsgt_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vmsgt_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsgt_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vmsgt_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsgt_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vmsgt_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsgt_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vmsgt_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsgt_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vmsgtu_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsgtu_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vmsgtu_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsgtu_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vmsgtu_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsgtu_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vmsgtu_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsgtu_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vmsgtu_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsgtu_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vmsgtu_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsgtu_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vmsgtu_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsgtu_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vmsgtu_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsgtu_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vmsgtu_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsgtu_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vmsgtu_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsgtu_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vmsgtu_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsgtu_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vmsgtu_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsgtu_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vmsgtu_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsgtu_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vmsgtu_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsgtu_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vmsgtu_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsgtu_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vmsgtu_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsgtu_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vmsge_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsge_m (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vmsge_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsge_m (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vmsge_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsge_m (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vmsge_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsge_m (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vmsge_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsge_m (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vmsge_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsge_m (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vmsge_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsge_m (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vmsge_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsge_m (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vmsge_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsge_m (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vmsge_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsge_m (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vmsge_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsge_m (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vmsge_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsge_m (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vmsge_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsge_m (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vmsge_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsge_m (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vmsge_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsge_m (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vmsge_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsge_m (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vmsgeu_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsgeu_m (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vmsgeu_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsgeu_m (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vmsgeu_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsgeu_m (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vmsgeu_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsgeu_m (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vmsgeu_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsgeu_m (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vmsgeu_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsgeu_m (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vmsgeu_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsgeu_m (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vmsgeu_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsgeu_m (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vmsgeu_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsgeu_m (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vmsgeu_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsgeu_m (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vmsgeu_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsgeu_m (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vmsgeu_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsgeu_m (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vmsgeu_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsgeu_m (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vmsgeu_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsgeu_m (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vmsgeu_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsgeu_m (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vmsgeu_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsgeu_m (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Integer Min/Max Functions](rvv-intrinsic-api.md#128-vector-integer-minmax-operations):

**Prototypes:**
``` C
vint8m1_t vmin (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmin (vint8m1_t op1, int8_t op2);
vint8m2_t vmin (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmin (vint8m2_t op1, int8_t op2);
vint8m4_t vmin (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmin (vint8m4_t op1, int8_t op2);
vint8m8_t vmin (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmin (vint8m8_t op1, int8_t op2);
vint16m1_t vmin (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmin (vint16m1_t op1, int16_t op2);
vint16m2_t vmin (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmin (vint16m2_t op1, int16_t op2);
vint16m4_t vmin (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmin (vint16m4_t op1, int16_t op2);
vint16m8_t vmin (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmin (vint16m8_t op1, int16_t op2);
vint32m1_t vmin (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmin (vint32m1_t op1, int32_t op2);
vint32m2_t vmin (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmin (vint32m2_t op1, int32_t op2);
vint32m4_t vmin (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmin (vint32m4_t op1, int32_t op2);
vint32m8_t vmin (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmin (vint32m8_t op1, int32_t op2);
vint64m1_t vmin (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmin (vint64m1_t op1, int64_t op2);
vint64m2_t vmin (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmin (vint64m2_t op1, int64_t op2);
vint64m4_t vmin (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmin (vint64m4_t op1, int64_t op2);
vint64m8_t vmin (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmin (vint64m8_t op1, int64_t op2);
vuint8m1_t vminu (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vminu (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vminu (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vminu (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vminu (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vminu (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vminu (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vminu (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vminu (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vminu (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vminu (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vminu (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vminu (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vminu (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vminu (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vminu (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vminu (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vminu (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vminu (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vminu (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vminu (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vminu (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vminu (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vminu (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vminu (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vminu (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vminu (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vminu (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vminu (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vminu (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vminu (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vminu (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmax (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmax (vint8m1_t op1, int8_t op2);
vint8m2_t vmax (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmax (vint8m2_t op1, int8_t op2);
vint8m4_t vmax (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmax (vint8m4_t op1, int8_t op2);
vint8m8_t vmax (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmax (vint8m8_t op1, int8_t op2);
vint16m1_t vmax (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmax (vint16m1_t op1, int16_t op2);
vint16m2_t vmax (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmax (vint16m2_t op1, int16_t op2);
vint16m4_t vmax (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmax (vint16m4_t op1, int16_t op2);
vint16m8_t vmax (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmax (vint16m8_t op1, int16_t op2);
vint32m1_t vmax (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmax (vint32m1_t op1, int32_t op2);
vint32m2_t vmax (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmax (vint32m2_t op1, int32_t op2);
vint32m4_t vmax (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmax (vint32m4_t op1, int32_t op2);
vint32m8_t vmax (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmax (vint32m8_t op1, int32_t op2);
vint64m1_t vmax (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmax (vint64m1_t op1, int64_t op2);
vint64m2_t vmax (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmax (vint64m2_t op1, int64_t op2);
vint64m4_t vmax (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmax (vint64m4_t op1, int64_t op2);
vint64m8_t vmax (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmax (vint64m8_t op1, int64_t op2);
vuint8m1_t vmaxu (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmaxu (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmaxu (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmaxu (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmaxu (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmaxu (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmaxu (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmaxu (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmaxu (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmaxu (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmaxu (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmaxu (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmaxu (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmaxu (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmaxu (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmaxu (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmaxu (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmaxu (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmaxu (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmaxu (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmaxu (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmaxu (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmaxu (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmaxu (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmaxu (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmaxu (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmaxu (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmaxu (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmaxu (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmaxu (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmaxu (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmaxu (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vmin_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmin_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmin_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmin_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmin_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmin_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmin_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmin_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmin_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmin_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmin_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmin_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmin_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmin_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmin_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmin_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmin_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmin_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmin_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmin_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmin_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmin_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmin_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmin_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmin_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmin_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmin_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmin_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmin_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmin_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmin_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmin_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vminu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vminu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vminu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vminu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vminu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vminu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vminu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vminu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vminu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vminu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vminu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vminu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vminu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vminu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vminu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vminu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vminu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vminu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vminu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vminu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vminu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vminu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vminu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vminu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vminu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vminu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vminu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vminu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vminu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vminu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vminu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vminu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmax_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmax_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmax_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmax_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmax_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmax_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmax_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmax_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmax_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmax_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmax_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmax_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmax_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmax_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmax_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmax_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmax_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmax_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmax_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmax_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmax_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmax_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmax_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmax_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmax_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmax_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmax_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmax_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmax_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmax_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmax_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmax_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmaxu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmaxu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmaxu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmaxu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmaxu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmaxu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmaxu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmaxu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmaxu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmaxu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmaxu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmaxu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmaxu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmaxu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmaxu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmaxu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmaxu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmaxu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmaxu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmaxu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmaxu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmaxu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmaxu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmaxu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmaxu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmaxu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmaxu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmaxu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmaxu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmaxu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmaxu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmaxu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Integer Multiply Functions](rvv-intrinsic-api.md#129-vector-single-width-integer-multiply-operations):

**Prototypes:**
``` C
vint8m1_t vmul (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmul (vint8m1_t op1, uint8_t op2);
vint8m2_t vmul (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmul (vint8m2_t op1, uint8_t op2);
vint8m4_t vmul (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmul (vint8m4_t op1, uint8_t op2);
vint8m8_t vmul (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmul (vint8m8_t op1, uint8_t op2);
vint16m1_t vmul (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmul (vint16m1_t op1, uint16_t op2);
vint16m2_t vmul (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmul (vint16m2_t op1, uint16_t op2);
vint16m4_t vmul (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmul (vint16m4_t op1, uint16_t op2);
vint16m8_t vmul (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmul (vint16m8_t op1, uint16_t op2);
vint32m1_t vmul (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmul (vint32m1_t op1, uint32_t op2);
vint32m2_t vmul (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmul (vint32m2_t op1, uint32_t op2);
vint32m4_t vmul (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmul (vint32m4_t op1, uint32_t op2);
vint32m8_t vmul (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmul (vint32m8_t op1, uint32_t op2);
vint64m1_t vmul (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmul (vint64m1_t op1, uint64_t op2);
vint64m2_t vmul (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmul (vint64m2_t op1, uint64_t op2);
vint64m4_t vmul (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmul (vint64m4_t op1, uint64_t op2);
vint64m8_t vmul (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmul (vint64m8_t op1, uint64_t op2);
vuint8m1_t vmul (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmul (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmul (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmul (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmul (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmul (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmul (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmul (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmul (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmul (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmul (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmul (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmul (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmul (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmul (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmul (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmul (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmul (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmul (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmul (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmul (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmul (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmul (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmul (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmul (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmul (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmul (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmul (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmul (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmul (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmul (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmul (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulh (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmulh (vint8m1_t op1, uint8_t op2);
vint8m2_t vmulh (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmulh (vint8m2_t op1, uint8_t op2);
vint8m4_t vmulh (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmulh (vint8m4_t op1, uint8_t op2);
vint8m8_t vmulh (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmulh (vint8m8_t op1, uint8_t op2);
vint16m1_t vmulh (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmulh (vint16m1_t op1, uint16_t op2);
vint16m2_t vmulh (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmulh (vint16m2_t op1, uint16_t op2);
vint16m4_t vmulh (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmulh (vint16m4_t op1, uint16_t op2);
vint16m8_t vmulh (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmulh (vint16m8_t op1, uint16_t op2);
vint32m1_t vmulh (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmulh (vint32m1_t op1, uint32_t op2);
vint32m2_t vmulh (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmulh (vint32m2_t op1, uint32_t op2);
vint32m4_t vmulh (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmulh (vint32m4_t op1, uint32_t op2);
vint32m8_t vmulh (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmulh (vint32m8_t op1, uint32_t op2);
vint64m1_t vmulh (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmulh (vint64m1_t op1, uint64_t op2);
vint64m2_t vmulh (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmulh (vint64m2_t op1, uint64_t op2);
vint64m4_t vmulh (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmulh (vint64m4_t op1, uint64_t op2);
vint64m8_t vmulh (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmulh (vint64m8_t op1, uint64_t op2);
vuint8m1_t vmulhu (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmulhu (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmulhu (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmulhu (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmulhu (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmulhu (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmulhu (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmulhu (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmulhu (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmulhu (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmulhu (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmulhu (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmulhu (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmulhu (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmulhu (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmulhu (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmulhu (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmulhu (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmulhu (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmulhu (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmulhu (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmulhu (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmulhu (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmulhu (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmulhu (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmulhu (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmulhu (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmulhu (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmulhu (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmulhu (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmulhu (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmulhu (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulhsu (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmulhsu (vint8m1_t op1, uint8_t op2);
vint8m2_t vmulhsu (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmulhsu (vint8m2_t op1, uint8_t op2);
vint8m4_t vmulhsu (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmulhsu (vint8m4_t op1, uint8_t op2);
vint8m8_t vmulhsu (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmulhsu (vint8m8_t op1, uint8_t op2);
vint16m1_t vmulhsu (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmulhsu (vint16m1_t op1, uint16_t op2);
vint16m2_t vmulhsu (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmulhsu (vint16m2_t op1, uint16_t op2);
vint16m4_t vmulhsu (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmulhsu (vint16m4_t op1, uint16_t op2);
vint16m8_t vmulhsu (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmulhsu (vint16m8_t op1, uint16_t op2);
vint32m1_t vmulhsu (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmulhsu (vint32m1_t op1, uint32_t op2);
vint32m2_t vmulhsu (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmulhsu (vint32m2_t op1, uint32_t op2);
vint32m4_t vmulhsu (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmulhsu (vint32m4_t op1, uint32_t op2);
vint32m8_t vmulhsu (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmulhsu (vint32m8_t op1, uint32_t op2);
vint64m1_t vmulhsu (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmulhsu (vint64m1_t op1, uint64_t op2);
vint64m2_t vmulhsu (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmulhsu (vint64m2_t op1, uint64_t op2);
vint64m4_t vmulhsu (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmulhsu (vint64m4_t op1, uint64_t op2);
vint64m8_t vmulhsu (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmulhsu (vint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vmul_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmul_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vmul_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmul_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vmul_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmul_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vmul_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmul_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vmul_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmul_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2);
vint16m2_t vmul_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmul_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2);
vint16m4_t vmul_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmul_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2);
vint16m8_t vmul_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmul_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2);
vint32m1_t vmul_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmul_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2);
vint32m2_t vmul_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmul_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2);
vint32m4_t vmul_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmul_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2);
vint32m8_t vmul_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmul_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2);
vint64m1_t vmul_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmul_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2);
vint64m2_t vmul_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmul_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2);
vint64m4_t vmul_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmul_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2);
vint64m8_t vmul_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmul_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2);
vuint8m1_t vmul_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmul_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmul_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmul_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmul_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmul_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmul_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmul_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmul_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmul_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmul_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmul_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmul_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmul_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmul_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmul_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmul_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmul_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmul_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmul_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmul_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmul_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmul_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmul_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmul_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmul_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmul_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmul_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmul_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmul_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmul_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmul_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulh_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmulh_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vmulh_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmulh_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vmulh_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmulh_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vmulh_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmulh_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vmulh_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmulh_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2);
vint16m2_t vmulh_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmulh_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2);
vint16m4_t vmulh_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmulh_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2);
vint16m8_t vmulh_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmulh_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2);
vint32m1_t vmulh_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmulh_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2);
vint32m2_t vmulh_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmulh_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2);
vint32m4_t vmulh_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmulh_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2);
vint32m8_t vmulh_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmulh_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2);
vint64m1_t vmulh_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmulh_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2);
vint64m2_t vmulh_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmulh_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2);
vint64m4_t vmulh_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmulh_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2);
vint64m8_t vmulh_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmulh_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2);
vuint8m1_t vmulhu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmulhu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmulhu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmulhu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmulhu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmulhu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmulhu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmulhu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmulhu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmulhu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmulhu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmulhu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmulhu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmulhu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmulhu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmulhu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmulhu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmulhu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmulhu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmulhu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmulhu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmulhu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmulhu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmulhu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmulhu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmulhu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmulhu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmulhu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmulhu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmulhu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmulhu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmulhu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulhsu_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmulhsu_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vmulhsu_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmulhsu_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vmulhsu_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmulhsu_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vmulhsu_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmulhsu_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vmulhsu_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmulhsu_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2);
vint16m2_t vmulhsu_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmulhsu_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2);
vint16m4_t vmulhsu_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmulhsu_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2);
vint16m8_t vmulhsu_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmulhsu_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2);
vint32m1_t vmulhsu_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmulhsu_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2);
vint32m2_t vmulhsu_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmulhsu_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2);
vint32m4_t vmulhsu_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmulhsu_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2);
vint32m8_t vmulhsu_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmulhsu_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2);
vint64m1_t vmulhsu_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmulhsu_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2);
vint64m2_t vmulhsu_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmulhsu_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2);
vint64m4_t vmulhsu_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmulhsu_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2);
vint64m8_t vmulhsu_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmulhsu_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2);
```
### [Vector Integer Divide Functions](rvv-intrinsic-api.md#1210-vector-integer-divide-operations):

**Prototypes:**
``` C
vint8m1_t vdiv (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vdiv (vint8m1_t op1, int8_t op2);
vint8m2_t vdiv (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vdiv (vint8m2_t op1, int8_t op2);
vint8m4_t vdiv (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vdiv (vint8m4_t op1, int8_t op2);
vint8m8_t vdiv (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vdiv (vint8m8_t op1, int8_t op2);
vint16m1_t vdiv (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vdiv (vint16m1_t op1, int16_t op2);
vint16m2_t vdiv (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vdiv (vint16m2_t op1, int16_t op2);
vint16m4_t vdiv (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vdiv (vint16m4_t op1, int16_t op2);
vint16m8_t vdiv (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vdiv (vint16m8_t op1, int16_t op2);
vint32m1_t vdiv (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vdiv (vint32m1_t op1, int32_t op2);
vint32m2_t vdiv (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vdiv (vint32m2_t op1, int32_t op2);
vint32m4_t vdiv (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vdiv (vint32m4_t op1, int32_t op2);
vint32m8_t vdiv (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vdiv (vint32m8_t op1, int32_t op2);
vint64m1_t vdiv (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vdiv (vint64m1_t op1, int64_t op2);
vint64m2_t vdiv (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vdiv (vint64m2_t op1, int64_t op2);
vint64m4_t vdiv (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vdiv (vint64m4_t op1, int64_t op2);
vint64m8_t vdiv (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vdiv (vint64m8_t op1, int64_t op2);
vuint8m1_t vdivu (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vdivu (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vdivu (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vdivu (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vdivu (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vdivu (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vdivu (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vdivu (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vdivu (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vdivu (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vdivu (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vdivu (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vdivu (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vdivu (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vdivu (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vdivu (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vdivu (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vdivu (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vdivu (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vdivu (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vdivu (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vdivu (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vdivu (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vdivu (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vdivu (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vdivu (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vdivu (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vdivu (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vdivu (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vdivu (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vdivu (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vdivu (vuint64m8_t op1, uint64_t op2);
vint8m1_t vrem (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vrem (vint8m1_t op1, int8_t op2);
vint8m2_t vrem (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vrem (vint8m2_t op1, int8_t op2);
vint8m4_t vrem (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vrem (vint8m4_t op1, int8_t op2);
vint8m8_t vrem (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vrem (vint8m8_t op1, int8_t op2);
vint16m1_t vrem (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vrem (vint16m1_t op1, int16_t op2);
vint16m2_t vrem (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vrem (vint16m2_t op1, int16_t op2);
vint16m4_t vrem (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vrem (vint16m4_t op1, int16_t op2);
vint16m8_t vrem (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vrem (vint16m8_t op1, int16_t op2);
vint32m1_t vrem (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vrem (vint32m1_t op1, int32_t op2);
vint32m2_t vrem (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vrem (vint32m2_t op1, int32_t op2);
vint32m4_t vrem (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vrem (vint32m4_t op1, int32_t op2);
vint32m8_t vrem (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vrem (vint32m8_t op1, int32_t op2);
vint64m1_t vrem (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vrem (vint64m1_t op1, int64_t op2);
vint64m2_t vrem (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vrem (vint64m2_t op1, int64_t op2);
vint64m4_t vrem (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vrem (vint64m4_t op1, int64_t op2);
vint64m8_t vrem (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vrem (vint64m8_t op1, int64_t op2);
vuint8m1_t vremu (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vremu (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vremu (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vremu (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vremu (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vremu (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vremu (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vremu (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vremu (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vremu (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vremu (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vremu (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vremu (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vremu (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vremu (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vremu (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vremu (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vremu (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vremu (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vremu (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vremu (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vremu (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vremu (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vremu (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vremu (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vremu (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vremu (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vremu (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vremu (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vremu (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vremu (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vremu (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vdiv_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vdiv_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vdiv_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vdiv_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vdiv_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vdiv_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vdiv_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vdiv_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vdiv_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vdiv_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vdiv_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vdiv_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vdiv_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vdiv_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vdiv_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vdiv_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vdiv_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vdiv_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vdiv_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vdiv_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vdiv_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vdiv_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vdiv_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vdiv_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vdiv_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vdiv_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vdiv_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vdiv_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vdiv_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vdiv_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vdiv_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vdiv_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vdivu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vdivu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vdivu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vdivu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vdivu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vdivu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vdivu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vdivu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vdivu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vdivu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vdivu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vdivu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vdivu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vdivu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vdivu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vdivu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vdivu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vdivu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vdivu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vdivu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vdivu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vdivu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vdivu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vdivu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vdivu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vdivu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vdivu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vdivu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vdivu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vdivu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vdivu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vdivu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vrem_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vrem_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vrem_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vrem_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vrem_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vrem_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vrem_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vrem_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vrem_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vrem_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vrem_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vrem_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vrem_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vrem_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vrem_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vrem_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vrem_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vrem_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vrem_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vrem_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vrem_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vrem_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vrem_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vrem_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vrem_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vrem_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vrem_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vrem_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vrem_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vrem_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vrem_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vrem_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vremu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vremu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vremu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vremu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vremu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vremu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vremu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vremu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vremu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vremu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vremu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vremu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vremu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vremu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vremu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vremu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vremu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vremu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vremu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vremu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vremu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vremu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vremu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vremu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vremu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vremu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vremu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vremu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vremu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vremu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vremu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vremu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Widening Integer Multiply Functions](rvv-intrinsic-api.md#1211-vector-widening-integer-multiply-operations):

**Prototypes:**
``` C
vint16m2_t vwmul (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmul (vint8m1_t op1, int8_t op2);
vint16m4_t vwmul (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmul (vint8m2_t op1, int8_t op2);
vint16m8_t vwmul (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmul (vint8m4_t op1, int8_t op2);
vint32m2_t vwmul (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmul (vint16m1_t op1, int16_t op2);
vint32m4_t vwmul (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmul (vint16m2_t op1, int16_t op2);
vint32m8_t vwmul (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmul (vint16m4_t op1, int16_t op2);
vint64m2_t vwmul (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmul (vint32m1_t op1, int32_t op2);
vint64m4_t vwmul (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmul (vint32m2_t op1, int32_t op2);
vint64m8_t vwmul (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmul (vint32m4_t op1, int32_t op2);
vuint16m2_t vwmul (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmul (vuint8m1_t op1, uint8_t op2);
vuint16m4_t vwmul (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmul (vuint8m2_t op1, uint8_t op2);
vuint16m8_t vwmul (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmul (vuint8m4_t op1, uint8_t op2);
vuint32m2_t vwmul (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmul (vuint16m1_t op1, uint16_t op2);
vuint32m4_t vwmul (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmul (vuint16m2_t op1, uint16_t op2);
vuint32m8_t vwmul (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmul (vuint16m4_t op1, uint16_t op2);
vuint64m2_t vwmul (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmul (vuint32m1_t op1, uint32_t op2);
vuint64m4_t vwmul (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmul (vuint32m2_t op1, uint32_t op2);
vuint64m8_t vwmul (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmul (vuint32m4_t op1, uint32_t op2);
vint16m2_t vwmulsu (vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmulsu (vint8m1_t op1, uint8_t op2);
vint16m4_t vwmulsu (vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmulsu (vint8m2_t op1, uint8_t op2);
vint16m8_t vwmulsu (vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmulsu (vint8m4_t op1, uint8_t op2);
vint32m2_t vwmulsu (vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmulsu (vint16m1_t op1, uint16_t op2);
vint32m4_t vwmulsu (vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmulsu (vint16m2_t op1, uint16_t op2);
vint32m8_t vwmulsu (vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmulsu (vint16m4_t op1, uint16_t op2);
vint64m2_t vwmulsu (vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmulsu (vint32m1_t op1, uint32_t op2);
vint64m4_t vwmulsu (vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmulsu (vint32m2_t op1, uint32_t op2);
vint64m8_t vwmulsu (vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmulsu (vint32m4_t op1, uint32_t op2);
// masked functions
vint16m2_t vwmul_m (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmul_m (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m4_t vwmul_m (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmul_m (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m8_t vwmul_m (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmul_m (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint32m2_t vwmul_m (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmul_m (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m4_t vwmul_m (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmul_m (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m8_t vwmul_m (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmul_m (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint64m2_t vwmul_m (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmul_m (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m4_t vwmul_m (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmul_m (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m8_t vwmul_m (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmul_m (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vuint16m2_t vwmul_m (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmul_m (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m4_t vwmul_m (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmul_m (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m8_t vwmul_m (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmul_m (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint32m2_t vwmul_m (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmul_m (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m4_t vwmul_m (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmul_m (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m8_t vwmul_m (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmul_m (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint64m2_t vwmul_m (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmul_m (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m4_t vwmul_m (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmul_m (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m8_t vwmul_m (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmul_m (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vint16m2_t vwmulsu_m (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmulsu_m (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, uint8_t op2);
vint16m4_t vwmulsu_m (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmulsu_m (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, uint8_t op2);
vint16m8_t vwmulsu_m (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmulsu_m (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, uint8_t op2);
vint32m2_t vwmulsu_m (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmulsu_m (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, uint16_t op2);
vint32m4_t vwmulsu_m (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmulsu_m (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, uint16_t op2);
vint32m8_t vwmulsu_m (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmulsu_m (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, uint16_t op2);
vint64m2_t vwmulsu_m (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmulsu_m (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, uint32_t op2);
vint64m4_t vwmulsu_m (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmulsu_m (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, uint32_t op2);
vint64m8_t vwmulsu_m (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmulsu_m (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, uint32_t op2);
```
### [Vector Single-Width Integer Multiply-Add Functions](rvv-intrinsic-api.md#1212-vector-single-width-integer-multiply-add-operations):

**Prototypes:**
``` C
vint8m1_t vmacc (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmacc (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmacc (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmacc (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmacc (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmacc (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmacc (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmacc (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmacc (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmacc (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmacc (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmacc (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmacc (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmacc (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmacc (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmacc (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmacc (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmacc (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmacc (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmacc (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmacc (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmacc (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmacc (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmacc (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmacc (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmacc (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmacc (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmacc (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmacc (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmacc (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmacc (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmacc (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmacc (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmacc (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmacc (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmacc (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmacc (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmacc (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmacc (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmacc (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmacc (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmacc (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmacc (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmacc (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmacc (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmacc (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmacc (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmacc (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmacc (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmacc (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmacc (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmacc (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmacc (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmacc (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmacc (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmacc (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmacc (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmacc (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmacc (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmacc (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmacc (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmacc (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmacc (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmacc (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsac (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsac (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsac (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsac (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsac (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsac (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsac (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsac (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsac (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsac (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsac (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsac (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsac (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsac (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsac (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsac (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsac (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsac (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsac (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsac (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsac (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsac (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsac (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsac (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsac (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsac (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsac (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsac (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsac (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsac (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsac (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsac (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsac (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsac (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsac (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsac (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsac (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsac (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsac (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsac (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsac (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsac (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsac (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsac (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsac (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsac (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsac (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsac (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsac (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsac (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsac (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsac (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsac (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsac (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsac (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsac (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsac (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsac (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsac (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsac (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsac (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsac (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsac (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsac (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vmadd (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmadd (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmadd (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmadd (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmadd (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmadd (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmadd (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmadd (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmadd (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmadd (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmadd (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmadd (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmadd (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmadd (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmadd (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmadd (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmadd (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmadd (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmadd (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmadd (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmadd (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmadd (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmadd (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmadd (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmadd (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmadd (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmadd (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmadd (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmadd (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmadd (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmadd (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmadd (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmadd (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmadd (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmadd (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmadd (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmadd (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmadd (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmadd (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmadd (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmadd (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmadd (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmadd (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmadd (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmadd (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmadd (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmadd (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmadd (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmadd (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmadd (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmadd (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmadd (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmadd (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmadd (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmadd (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmadd (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmadd (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmadd (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmadd (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmadd (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmadd (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmadd (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmadd (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmadd (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsub (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsub (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsub (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsub (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsub (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsub (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsub (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsub (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsub (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsub (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsub (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsub (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsub (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsub (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsub (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsub (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsub (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsub (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsub (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsub (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsub (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsub (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsub (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsub (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsub (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsub (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsub (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsub (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsub (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsub (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsub (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsub (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsub (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsub (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsub (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsub (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsub (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsub (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsub (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsub (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsub (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsub (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsub (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsub (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsub (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsub (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsub (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsub (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsub (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsub (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsub (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsub (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsub (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsub (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsub (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsub (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsub (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsub (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsub (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsub (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsub (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsub (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsub (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsub (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
// masked functions
vint8m1_t vmacc_m (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmacc_m (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmacc_m (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmacc_m (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmacc_m (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmacc_m (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmacc_m (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmacc_m (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmacc_m (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmacc_m (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmacc_m (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmacc_m (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmacc_m (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmacc_m (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmacc_m (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmacc_m (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmacc_m (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmacc_m (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmacc_m (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmacc_m (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmacc_m (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmacc_m (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmacc_m (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmacc_m (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmacc_m (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmacc_m (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmacc_m (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmacc_m (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmacc_m (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmacc_m (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmacc_m (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmacc_m (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmacc_m (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmacc_m (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmacc_m (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmacc_m (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmacc_m (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmacc_m (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmacc_m (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmacc_m (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmacc_m (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmacc_m (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmacc_m (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmacc_m (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmacc_m (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmacc_m (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmacc_m (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmacc_m (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmacc_m (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmacc_m (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmacc_m (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmacc_m (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmacc_m (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmacc_m (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmacc_m (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmacc_m (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmacc_m (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmacc_m (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmacc_m (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmacc_m (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmacc_m (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmacc_m (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmacc_m (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmacc_m (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsac_m (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsac_m (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsac_m (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsac_m (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsac_m (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsac_m (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsac_m (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsac_m (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsac_m (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsac_m (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsac_m (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsac_m (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsac_m (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsac_m (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsac_m (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsac_m (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsac_m (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsac_m (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsac_m (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsac_m (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsac_m (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsac_m (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsac_m (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsac_m (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsac_m (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsac_m (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsac_m (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsac_m (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsac_m (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsac_m (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsac_m (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsac_m (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsac_m (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsac_m (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsac_m (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsac_m (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsac_m (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsac_m (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsac_m (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsac_m (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsac_m (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsac_m (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsac_m (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsac_m (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsac_m (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsac_m (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsac_m (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsac_m (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsac_m (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsac_m (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsac_m (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsac_m (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsac_m (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsac_m (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsac_m (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsac_m (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsac_m (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsac_m (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsac_m (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsac_m (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsac_m (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsac_m (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsac_m (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsac_m (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vmadd_m (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmadd_m (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmadd_m (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmadd_m (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmadd_m (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmadd_m (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmadd_m (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmadd_m (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmadd_m (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmadd_m (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmadd_m (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmadd_m (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmadd_m (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmadd_m (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmadd_m (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmadd_m (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmadd_m (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmadd_m (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmadd_m (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmadd_m (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmadd_m (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmadd_m (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmadd_m (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmadd_m (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmadd_m (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmadd_m (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmadd_m (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmadd_m (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmadd_m (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmadd_m (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmadd_m (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmadd_m (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmadd_m (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmadd_m (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmadd_m (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmadd_m (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmadd_m (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmadd_m (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmadd_m (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmadd_m (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmadd_m (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmadd_m (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmadd_m (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmadd_m (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmadd_m (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmadd_m (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmadd_m (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmadd_m (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmadd_m (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmadd_m (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmadd_m (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmadd_m (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmadd_m (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmadd_m (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmadd_m (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmadd_m (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmadd_m (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmadd_m (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmadd_m (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmadd_m (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmadd_m (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmadd_m (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmadd_m (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmadd_m (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsub_m (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsub_m (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsub_m (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsub_m (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsub_m (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsub_m (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsub_m (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsub_m (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsub_m (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsub_m (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsub_m (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsub_m (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsub_m (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsub_m (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsub_m (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsub_m (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsub_m (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsub_m (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsub_m (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsub_m (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsub_m (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsub_m (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsub_m (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsub_m (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsub_m (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsub_m (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsub_m (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsub_m (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsub_m (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsub_m (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsub_m (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsub_m (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsub_m (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsub_m (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsub_m (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsub_m (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsub_m (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsub_m (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsub_m (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsub_m (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsub_m (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsub_m (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsub_m (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsub_m (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsub_m (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsub_m (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsub_m (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsub_m (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsub_m (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsub_m (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsub_m (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsub_m (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsub_m (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsub_m (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsub_m (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsub_m (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsub_m (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsub_m (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsub_m (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsub_m (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsub_m (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsub_m (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsub_m (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsub_m (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
```
### [Vector Widening Integer Multiply-Add Functions](rvv-intrinsic-api.md#1213-vector-widening-integer-multiply-add-operations):

**Prototypes:**
``` C
vint16m2_t vwmacc (vint16m2_t acc, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmacc (vint16m2_t acc, int8_t op1, vint8m1_t op2);
vint16m4_t vwmacc (vint16m4_t acc, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmacc (vint16m4_t acc, int8_t op1, vint8m2_t op2);
vint16m8_t vwmacc (vint16m8_t acc, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmacc (vint16m8_t acc, int8_t op1, vint8m4_t op2);
vint32m2_t vwmacc (vint32m2_t acc, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmacc (vint32m2_t acc, int16_t op1, vint16m1_t op2);
vint32m4_t vwmacc (vint32m4_t acc, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmacc (vint32m4_t acc, int16_t op1, vint16m2_t op2);
vint32m8_t vwmacc (vint32m8_t acc, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmacc (vint32m8_t acc, int16_t op1, vint16m4_t op2);
vint64m2_t vwmacc (vint64m2_t acc, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmacc (vint64m2_t acc, int32_t op1, vint32m1_t op2);
vint64m4_t vwmacc (vint64m4_t acc, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmacc (vint64m4_t acc, int32_t op1, vint32m2_t op2);
vint64m8_t vwmacc (vint64m8_t acc, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmacc (vint64m8_t acc, int32_t op1, vint32m4_t op2);
vuint16m2_t vwmaccu (vuint16m2_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmaccu (vuint16m2_t acc, uint8_t op1, vuint8m1_t op2);
vuint16m4_t vwmaccu (vuint16m4_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmaccu (vuint16m4_t acc, uint8_t op1, vuint8m2_t op2);
vuint16m8_t vwmaccu (vuint16m8_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmaccu (vuint16m8_t acc, uint8_t op1, vuint8m4_t op2);
vuint32m2_t vwmaccu (vuint32m2_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmaccu (vuint32m2_t acc, uint16_t op1, vuint16m1_t op2);
vuint32m4_t vwmaccu (vuint32m4_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmaccu (vuint32m4_t acc, uint16_t op1, vuint16m2_t op2);
vuint32m8_t vwmaccu (vuint32m8_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmaccu (vuint32m8_t acc, uint16_t op1, vuint16m4_t op2);
vuint64m2_t vwmaccu (vuint64m2_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmaccu (vuint64m2_t acc, uint32_t op1, vuint32m1_t op2);
vuint64m4_t vwmaccu (vuint64m4_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmaccu (vuint64m4_t acc, uint32_t op1, vuint32m2_t op2);
vuint64m8_t vwmaccu (vuint64m8_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmaccu (vuint64m8_t acc, uint32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccsu (vint16m2_t acc, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmaccsu (vint16m2_t acc, int8_t op1, vuint8m1_t op2);
vint16m4_t vwmaccsu (vint16m4_t acc, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmaccsu (vint16m4_t acc, int8_t op1, vuint8m2_t op2);
vint16m8_t vwmaccsu (vint16m8_t acc, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmaccsu (vint16m8_t acc, int8_t op1, vuint8m4_t op2);
vint32m2_t vwmaccsu (vint32m2_t acc, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmaccsu (vint32m2_t acc, int16_t op1, vuint16m1_t op2);
vint32m4_t vwmaccsu (vint32m4_t acc, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmaccsu (vint32m4_t acc, int16_t op1, vuint16m2_t op2);
vint32m8_t vwmaccsu (vint32m8_t acc, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmaccsu (vint32m8_t acc, int16_t op1, vuint16m4_t op2);
vint64m2_t vwmaccsu (vint64m2_t acc, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmaccsu (vint64m2_t acc, int32_t op1, vuint32m1_t op2);
vint64m4_t vwmaccsu (vint64m4_t acc, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmaccsu (vint64m4_t acc, int32_t op1, vuint32m2_t op2);
vint64m8_t vwmaccsu (vint64m8_t acc, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmaccsu (vint64m8_t acc, int32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccus (vint16m2_t acc, uint8_t op1, vint8m1_t op2);
vint16m4_t vwmaccus (vint16m4_t acc, uint8_t op1, vint8m2_t op2);
vint16m8_t vwmaccus (vint16m8_t acc, uint8_t op1, vint8m4_t op2);
vint32m2_t vwmaccus (vint32m2_t acc, uint16_t op1, vint16m1_t op2);
vint32m4_t vwmaccus (vint32m4_t acc, uint16_t op1, vint16m2_t op2);
vint32m8_t vwmaccus (vint32m8_t acc, uint16_t op1, vint16m4_t op2);
vint64m2_t vwmaccus (vint64m2_t acc, uint32_t op1, vint32m1_t op2);
vint64m4_t vwmaccus (vint64m4_t acc, uint32_t op1, vint32m2_t op2);
vint64m8_t vwmaccus (vint64m8_t acc, uint32_t op1, vint32m4_t op2);
// masked functions
vint16m2_t vwmacc_m (vbool8_t mask, vint16m2_t acc, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmacc_m (vbool8_t mask, vint16m2_t acc, int8_t op1, vint8m1_t op2);
vint16m4_t vwmacc_m (vbool4_t mask, vint16m4_t acc, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmacc_m (vbool4_t mask, vint16m4_t acc, int8_t op1, vint8m2_t op2);
vint16m8_t vwmacc_m (vbool2_t mask, vint16m8_t acc, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmacc_m (vbool2_t mask, vint16m8_t acc, int8_t op1, vint8m4_t op2);
vint32m2_t vwmacc_m (vbool16_t mask, vint32m2_t acc, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmacc_m (vbool16_t mask, vint32m2_t acc, int16_t op1, vint16m1_t op2);
vint32m4_t vwmacc_m (vbool8_t mask, vint32m4_t acc, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmacc_m (vbool8_t mask, vint32m4_t acc, int16_t op1, vint16m2_t op2);
vint32m8_t vwmacc_m (vbool4_t mask, vint32m8_t acc, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmacc_m (vbool4_t mask, vint32m8_t acc, int16_t op1, vint16m4_t op2);
vint64m2_t vwmacc_m (vbool32_t mask, vint64m2_t acc, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmacc_m (vbool32_t mask, vint64m2_t acc, int32_t op1, vint32m1_t op2);
vint64m4_t vwmacc_m (vbool16_t mask, vint64m4_t acc, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmacc_m (vbool16_t mask, vint64m4_t acc, int32_t op1, vint32m2_t op2);
vint64m8_t vwmacc_m (vbool8_t mask, vint64m8_t acc, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmacc_m (vbool8_t mask, vint64m8_t acc, int32_t op1, vint32m4_t op2);
vuint16m2_t vwmaccu_m (vbool8_t mask, vuint16m2_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmaccu_m (vbool8_t mask, vuint16m2_t acc, uint8_t op1, vuint8m1_t op2);
vuint16m4_t vwmaccu_m (vbool4_t mask, vuint16m4_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmaccu_m (vbool4_t mask, vuint16m4_t acc, uint8_t op1, vuint8m2_t op2);
vuint16m8_t vwmaccu_m (vbool2_t mask, vuint16m8_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmaccu_m (vbool2_t mask, vuint16m8_t acc, uint8_t op1, vuint8m4_t op2);
vuint32m2_t vwmaccu_m (vbool16_t mask, vuint32m2_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmaccu_m (vbool16_t mask, vuint32m2_t acc, uint16_t op1, vuint16m1_t op2);
vuint32m4_t vwmaccu_m (vbool8_t mask, vuint32m4_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmaccu_m (vbool8_t mask, vuint32m4_t acc, uint16_t op1, vuint16m2_t op2);
vuint32m8_t vwmaccu_m (vbool4_t mask, vuint32m8_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmaccu_m (vbool4_t mask, vuint32m8_t acc, uint16_t op1, vuint16m4_t op2);
vuint64m2_t vwmaccu_m (vbool32_t mask, vuint64m2_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmaccu_m (vbool32_t mask, vuint64m2_t acc, uint32_t op1, vuint32m1_t op2);
vuint64m4_t vwmaccu_m (vbool16_t mask, vuint64m4_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmaccu_m (vbool16_t mask, vuint64m4_t acc, uint32_t op1, vuint32m2_t op2);
vuint64m8_t vwmaccu_m (vbool8_t mask, vuint64m8_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmaccu_m (vbool8_t mask, vuint64m8_t acc, uint32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccsu_m (vbool8_t mask, vint16m2_t acc, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmaccsu_m (vbool8_t mask, vint16m2_t acc, int8_t op1, vuint8m1_t op2);
vint16m4_t vwmaccsu_m (vbool4_t mask, vint16m4_t acc, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmaccsu_m (vbool4_t mask, vint16m4_t acc, int8_t op1, vuint8m2_t op2);
vint16m8_t vwmaccsu_m (vbool2_t mask, vint16m8_t acc, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmaccsu_m (vbool2_t mask, vint16m8_t acc, int8_t op1, vuint8m4_t op2);
vint32m2_t vwmaccsu_m (vbool16_t mask, vint32m2_t acc, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmaccsu_m (vbool16_t mask, vint32m2_t acc, int16_t op1, vuint16m1_t op2);
vint32m4_t vwmaccsu_m (vbool8_t mask, vint32m4_t acc, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmaccsu_m (vbool8_t mask, vint32m4_t acc, int16_t op1, vuint16m2_t op2);
vint32m8_t vwmaccsu_m (vbool4_t mask, vint32m8_t acc, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmaccsu_m (vbool4_t mask, vint32m8_t acc, int16_t op1, vuint16m4_t op2);
vint64m2_t vwmaccsu_m (vbool32_t mask, vint64m2_t acc, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmaccsu_m (vbool32_t mask, vint64m2_t acc, int32_t op1, vuint32m1_t op2);
vint64m4_t vwmaccsu_m (vbool16_t mask, vint64m4_t acc, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmaccsu_m (vbool16_t mask, vint64m4_t acc, int32_t op1, vuint32m2_t op2);
vint64m8_t vwmaccsu_m (vbool8_t mask, vint64m8_t acc, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmaccsu_m (vbool8_t mask, vint64m8_t acc, int32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccus_m (vbool8_t mask, vint16m2_t acc, uint8_t op1, vint8m1_t op2);
vint16m4_t vwmaccus_m (vbool4_t mask, vint16m4_t acc, uint8_t op1, vint8m2_t op2);
vint16m8_t vwmaccus_m (vbool2_t mask, vint16m8_t acc, uint8_t op1, vint8m4_t op2);
vint32m2_t vwmaccus_m (vbool16_t mask, vint32m2_t acc, uint16_t op1, vint16m1_t op2);
vint32m4_t vwmaccus_m (vbool8_t mask, vint32m4_t acc, uint16_t op1, vint16m2_t op2);
vint32m8_t vwmaccus_m (vbool4_t mask, vint32m8_t acc, uint16_t op1, vint16m4_t op2);
vint64m2_t vwmaccus_m (vbool32_t mask, vint64m2_t acc, uint32_t op1, vint32m1_t op2);
vint64m4_t vwmaccus_m (vbool16_t mask, vint64m4_t acc, uint32_t op1, vint32m2_t op2);
vint64m8_t vwmaccus_m (vbool8_t mask, vint64m8_t acc, uint32_t op1, vint32m4_t op2);
```
### [Vector Quad-Widening Integer Multiply-Add Functions](rvv-intrinsic-api.md#1214-vector-quad-widening-integer-multiply-add-operations-extension-zvqmac):

**Prototypes:**
``` C
vint32m4_t vqmacc (vint32m4_t acc, vint8m1_t op1, vint8m1_t op2);
vint32m4_t vqmacc (vint32m4_t acc, int8_t op1, vint8m1_t op2);
vint32m8_t vqmacc (vint32m8_t acc, vint8m2_t op1, vint8m2_t op2);
vint32m8_t vqmacc (vint32m8_t acc, int8_t op1, vint8m2_t op2);
vint64m4_t vqmacc (vint64m4_t acc, vint16m1_t op1, vint16m1_t op2);
vint64m4_t vqmacc (vint64m4_t acc, int16_t op1, vint16m1_t op2);
vint64m8_t vqmacc (vint64m8_t acc, vint16m2_t op1, vint16m2_t op2);
vint64m8_t vqmacc (vint64m8_t acc, int16_t op1, vint16m2_t op2);
vuint32m4_t vqmaccu (vuint32m4_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint32m4_t vqmaccu (vuint32m4_t acc, uint8_t op1, vuint8m1_t op2);
vuint32m8_t vqmaccu (vuint32m8_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint32m8_t vqmaccu (vuint32m8_t acc, uint8_t op1, vuint8m2_t op2);
vuint64m4_t vqmaccu (vuint64m4_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint64m4_t vqmaccu (vuint64m4_t acc, uint16_t op1, vuint16m1_t op2);
vuint64m8_t vqmaccu (vuint64m8_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint64m8_t vqmaccu (vuint64m8_t acc, uint16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccsu (vint32m4_t acc, vint8m1_t op1, vuint8m1_t op2);
vint32m4_t vqmaccsu (vint32m4_t acc, int8_t op1, vuint8m1_t op2);
vint32m8_t vqmaccsu (vint32m8_t acc, vint8m2_t op1, vuint8m2_t op2);
vint32m8_t vqmaccsu (vint32m8_t acc, int8_t op1, vuint8m2_t op2);
vint64m4_t vqmaccsu (vint64m4_t acc, vint16m1_t op1, vuint16m1_t op2);
vint64m4_t vqmaccsu (vint64m4_t acc, int16_t op1, vuint16m1_t op2);
vint64m8_t vqmaccsu (vint64m8_t acc, vint16m2_t op1, vuint16m2_t op2);
vint64m8_t vqmaccsu (vint64m8_t acc, int16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccus (vint32m4_t acc, uint8_t op1, vint8m1_t op2);
vint32m8_t vqmaccus (vint32m8_t acc, uint8_t op1, vint8m2_t op2);
vint64m4_t vqmaccus (vint64m4_t acc, uint16_t op1, vint16m1_t op2);
vint64m8_t vqmaccus (vint64m8_t acc, uint16_t op1, vint16m2_t op2);
// masked functions
vint32m4_t vqmacc_m (vbool8_t mask, vint32m4_t acc, vint8m1_t op1, vint8m1_t op2);
vint32m4_t vqmacc_m (vbool8_t mask, vint32m4_t acc, int8_t op1, vint8m1_t op2);
vint32m8_t vqmacc_m (vbool4_t mask, vint32m8_t acc, vint8m2_t op1, vint8m2_t op2);
vint32m8_t vqmacc_m (vbool4_t mask, vint32m8_t acc, int8_t op1, vint8m2_t op2);
vint64m4_t vqmacc_m (vbool16_t mask, vint64m4_t acc, vint16m1_t op1, vint16m1_t op2);
vint64m4_t vqmacc_m (vbool16_t mask, vint64m4_t acc, int16_t op1, vint16m1_t op2);
vint64m8_t vqmacc_m (vbool8_t mask, vint64m8_t acc, vint16m2_t op1, vint16m2_t op2);
vint64m8_t vqmacc_m (vbool8_t mask, vint64m8_t acc, int16_t op1, vint16m2_t op2);
vuint32m4_t vqmaccu_m (vbool8_t mask, vuint32m4_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint32m4_t vqmaccu_m (vbool8_t mask, vuint32m4_t acc, uint8_t op1, vuint8m1_t op2);
vuint32m8_t vqmaccu_m (vbool4_t mask, vuint32m8_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint32m8_t vqmaccu_m (vbool4_t mask, vuint32m8_t acc, uint8_t op1, vuint8m2_t op2);
vuint64m4_t vqmaccu_m (vbool16_t mask, vuint64m4_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint64m4_t vqmaccu_m (vbool16_t mask, vuint64m4_t acc, uint16_t op1, vuint16m1_t op2);
vuint64m8_t vqmaccu_m (vbool8_t mask, vuint64m8_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint64m8_t vqmaccu_m (vbool8_t mask, vuint64m8_t acc, uint16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccsu_m (vbool8_t mask, vint32m4_t acc, vint8m1_t op1, vuint8m1_t op2);
vint32m4_t vqmaccsu_m (vbool8_t mask, vint32m4_t acc, int8_t op1, vuint8m1_t op2);
vint32m8_t vqmaccsu_m (vbool4_t mask, vint32m8_t acc, vint8m2_t op1, vuint8m2_t op2);
vint32m8_t vqmaccsu_m (vbool4_t mask, vint32m8_t acc, int8_t op1, vuint8m2_t op2);
vint64m4_t vqmaccsu_m (vbool16_t mask, vint64m4_t acc, vint16m1_t op1, vuint16m1_t op2);
vint64m4_t vqmaccsu_m (vbool16_t mask, vint64m4_t acc, int16_t op1, vuint16m1_t op2);
vint64m8_t vqmaccsu_m (vbool8_t mask, vint64m8_t acc, vint16m2_t op1, vuint16m2_t op2);
vint64m8_t vqmaccsu_m (vbool8_t mask, vint64m8_t acc, int16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccus_m (vbool8_t mask, vint32m4_t acc, uint8_t op1, vint8m1_t op2);
vint32m8_t vqmaccus_m (vbool4_t mask, vint32m8_t acc, uint8_t op1, vint8m2_t op2);
vint64m4_t vqmaccus_m (vbool16_t mask, vint64m4_t acc, uint16_t op1, vint16m1_t op2);
vint64m8_t vqmaccus_m (vbool8_t mask, vint64m8_t acc, uint16_t op1, vint16m2_t op2);
```
### [Vector Integer Merge Functions](rvv-intrinsic-api.md#1215-vector-integer-merge-operations):

**Prototypes:**
``` C
vint8m1_t vmerge_m (vbool8_t mask, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmerge_m (vbool8_t mask, vint8m1_t op1, int8_t op2);
vint8m2_t vmerge_m (vbool4_t mask, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmerge_m (vbool4_t mask, vint8m2_t op1, int8_t op2);
vint8m4_t vmerge_m (vbool2_t mask, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmerge_m (vbool2_t mask, vint8m4_t op1, int8_t op2);
vint8m8_t vmerge_m (vbool1_t mask, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmerge_m (vbool1_t mask, vint8m8_t op1, int8_t op2);
vint16m1_t vmerge_m (vbool16_t mask, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmerge_m (vbool16_t mask, vint16m1_t op1, int16_t op2);
vint16m2_t vmerge_m (vbool8_t mask, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmerge_m (vbool8_t mask, vint16m2_t op1, int16_t op2);
vint16m4_t vmerge_m (vbool4_t mask, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmerge_m (vbool4_t mask, vint16m4_t op1, int16_t op2);
vint16m8_t vmerge_m (vbool2_t mask, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmerge_m (vbool2_t mask, vint16m8_t op1, int16_t op2);
vint32m1_t vmerge_m (vbool32_t mask, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmerge_m (vbool32_t mask, vint32m1_t op1, int32_t op2);
vint32m2_t vmerge_m (vbool16_t mask, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmerge_m (vbool16_t mask, vint32m2_t op1, int32_t op2);
vint32m4_t vmerge_m (vbool8_t mask, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmerge_m (vbool8_t mask, vint32m4_t op1, int32_t op2);
vint32m8_t vmerge_m (vbool4_t mask, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmerge_m (vbool4_t mask, vint32m8_t op1, int32_t op2);
vint64m1_t vmerge_m (vbool64_t mask, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmerge_m (vbool64_t mask, vint64m1_t op1, int64_t op2);
vint64m2_t vmerge_m (vbool32_t mask, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmerge_m (vbool32_t mask, vint64m2_t op1, int64_t op2);
vint64m4_t vmerge_m (vbool16_t mask, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmerge_m (vbool16_t mask, vint64m4_t op1, int64_t op2);
vint64m8_t vmerge_m (vbool8_t mask, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmerge_m (vbool8_t mask, vint64m8_t op1, int64_t op2);
vuint8m1_t vmerge_m (vbool8_t mask, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmerge_m (vbool8_t mask, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmerge_m (vbool4_t mask, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmerge_m (vbool4_t mask, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmerge_m (vbool2_t mask, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmerge_m (vbool2_t mask, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmerge_m (vbool1_t mask, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmerge_m (vbool1_t mask, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmerge_m (vbool16_t mask, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmerge_m (vbool16_t mask, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmerge_m (vbool8_t mask, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmerge_m (vbool8_t mask, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmerge_m (vbool4_t mask, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmerge_m (vbool4_t mask, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmerge_m (vbool2_t mask, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmerge_m (vbool2_t mask, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmerge_m (vbool32_t mask, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmerge_m (vbool32_t mask, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmerge_m (vbool16_t mask, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmerge_m (vbool16_t mask, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmerge_m (vbool8_t mask, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmerge_m (vbool8_t mask, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmerge_m (vbool4_t mask, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmerge_m (vbool4_t mask, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmerge_m (vbool64_t mask, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmerge_m (vbool64_t mask, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmerge_m (vbool32_t mask, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmerge_m (vbool32_t mask, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmerge_m (vbool16_t mask, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmerge_m (vbool16_t mask, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmerge_m (vbool8_t mask, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmerge_m (vbool8_t mask, vuint64m8_t op1, uint64_t op2);
```
### [Vector Integer Move Functions](rvv-intrinsic-api.md#1216-vector-integer-move-operations):

**Prototypes:**
``` C
vint8m1_t vmv_v_v (vint8m1_t src);
vint8m1_t vmv_v_x (int8_t src);
vint8m2_t vmv_v_v (vint8m2_t src);
vint8m2_t vmv_v_x (int8_t src);
vint8m4_t vmv_v_v (vint8m4_t src);
vint8m4_t vmv_v_x (int8_t src);
vint8m8_t vmv_v_v (vint8m8_t src);
vint8m8_t vmv_v_x (int8_t src);
vint16m1_t vmv_v_v (vint16m1_t src);
vint16m1_t vmv_v_x (int16_t src);
vint16m2_t vmv_v_v (vint16m2_t src);
vint16m2_t vmv_v_x (int16_t src);
vint16m4_t vmv_v_v (vint16m4_t src);
vint16m4_t vmv_v_x (int16_t src);
vint16m8_t vmv_v_v (vint16m8_t src);
vint16m8_t vmv_v_x (int16_t src);
vint32m1_t vmv_v_v (vint32m1_t src);
vint32m1_t vmv_v_x (int32_t src);
vint32m2_t vmv_v_v (vint32m2_t src);
vint32m2_t vmv_v_x (int32_t src);
vint32m4_t vmv_v_v (vint32m4_t src);
vint32m4_t vmv_v_x (int32_t src);
vint32m8_t vmv_v_v (vint32m8_t src);
vint32m8_t vmv_v_x (int32_t src);
vint64m1_t vmv_v_v (vint64m1_t src);
vint64m1_t vmv_v_x (int64_t src);
vint64m2_t vmv_v_v (vint64m2_t src);
vint64m2_t vmv_v_x (int64_t src);
vint64m4_t vmv_v_v (vint64m4_t src);
vint64m4_t vmv_v_x (int64_t src);
vint64m8_t vmv_v_v (vint64m8_t src);
vint64m8_t vmv_v_x (int64_t src);
vuint8m1_t vmv_v_v (vuint8m1_t src);
vuint8m1_t vmv_v_x (uint8_t src);
vuint8m2_t vmv_v_v (vuint8m2_t src);
vuint8m2_t vmv_v_x (uint8_t src);
vuint8m4_t vmv_v_v (vuint8m4_t src);
vuint8m4_t vmv_v_x (uint8_t src);
vuint8m8_t vmv_v_v (vuint8m8_t src);
vuint8m8_t vmv_v_x (uint8_t src);
vuint16m1_t vmv_v_v (vuint16m1_t src);
vuint16m1_t vmv_v_x (uint16_t src);
vuint16m2_t vmv_v_v (vuint16m2_t src);
vuint16m2_t vmv_v_x (uint16_t src);
vuint16m4_t vmv_v_v (vuint16m4_t src);
vuint16m4_t vmv_v_x (uint16_t src);
vuint16m8_t vmv_v_v (vuint16m8_t src);
vuint16m8_t vmv_v_x (uint16_t src);
vuint32m1_t vmv_v_v (vuint32m1_t src);
vuint32m1_t vmv_v_x (uint32_t src);
vuint32m2_t vmv_v_v (vuint32m2_t src);
vuint32m2_t vmv_v_x (uint32_t src);
vuint32m4_t vmv_v_v (vuint32m4_t src);
vuint32m4_t vmv_v_x (uint32_t src);
vuint32m8_t vmv_v_v (vuint32m8_t src);
vuint32m8_t vmv_v_x (uint32_t src);
vuint64m1_t vmv_v_v (vuint64m1_t src);
vuint64m1_t vmv_v_x (uint64_t src);
vuint64m2_t vmv_v_v (vuint64m2_t src);
vuint64m2_t vmv_v_x (uint64_t src);
vuint64m4_t vmv_v_v (vuint64m4_t src);
vuint64m4_t vmv_v_x (uint64_t src);
vuint64m8_t vmv_v_v (vuint64m8_t src);
vuint64m8_t vmv_v_x (uint64_t src);
```
## Vector Fixed-Point Arithmetic Functions:

### [Vector Single-Width Saturating Add and Subtract Functions](rvv-intrinsic-api.md#131-vector-single-width-saturating-add-and-subtract):

**Prototypes:**
``` C
vint8m1_t vsadd (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsadd (vint8m1_t op1, int8_t op2);
vint8m2_t vsadd (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsadd (vint8m2_t op1, int8_t op2);
vint8m4_t vsadd (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsadd (vint8m4_t op1, int8_t op2);
vint8m8_t vsadd (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsadd (vint8m8_t op1, int8_t op2);
vint16m1_t vsadd (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsadd (vint16m1_t op1, int16_t op2);
vint16m2_t vsadd (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsadd (vint16m2_t op1, int16_t op2);
vint16m4_t vsadd (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsadd (vint16m4_t op1, int16_t op2);
vint16m8_t vsadd (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsadd (vint16m8_t op1, int16_t op2);
vint32m1_t vsadd (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsadd (vint32m1_t op1, int32_t op2);
vint32m2_t vsadd (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsadd (vint32m2_t op1, int32_t op2);
vint32m4_t vsadd (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsadd (vint32m4_t op1, int32_t op2);
vint32m8_t vsadd (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsadd (vint32m8_t op1, int32_t op2);
vint64m1_t vsadd (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsadd (vint64m1_t op1, int64_t op2);
vint64m2_t vsadd (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsadd (vint64m2_t op1, int64_t op2);
vint64m4_t vsadd (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsadd (vint64m4_t op1, int64_t op2);
vint64m8_t vsadd (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsadd (vint64m8_t op1, int64_t op2);
vuint8m1_t vsaddu (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsaddu (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsaddu (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsaddu (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsaddu (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsaddu (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsaddu (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsaddu (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsaddu (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsaddu (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsaddu (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsaddu (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsaddu (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsaddu (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsaddu (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsaddu (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsaddu (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsaddu (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsaddu (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsaddu (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsaddu (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsaddu (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsaddu (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsaddu (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsaddu (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsaddu (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsaddu (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsaddu (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsaddu (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsaddu (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsaddu (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsaddu (vuint64m8_t op1, uint64_t op2);
vint8m1_t vssub (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssub (vint8m1_t op1, int8_t op2);
vint8m2_t vssub (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssub (vint8m2_t op1, int8_t op2);
vint8m4_t vssub (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssub (vint8m4_t op1, int8_t op2);
vint8m8_t vssub (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssub (vint8m8_t op1, int8_t op2);
vint16m1_t vssub (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssub (vint16m1_t op1, int16_t op2);
vint16m2_t vssub (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssub (vint16m2_t op1, int16_t op2);
vint16m4_t vssub (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssub (vint16m4_t op1, int16_t op2);
vint16m8_t vssub (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssub (vint16m8_t op1, int16_t op2);
vint32m1_t vssub (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssub (vint32m1_t op1, int32_t op2);
vint32m2_t vssub (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssub (vint32m2_t op1, int32_t op2);
vint32m4_t vssub (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssub (vint32m4_t op1, int32_t op2);
vint32m8_t vssub (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssub (vint32m8_t op1, int32_t op2);
vint64m1_t vssub (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssub (vint64m1_t op1, int64_t op2);
vint64m2_t vssub (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssub (vint64m2_t op1, int64_t op2);
vint64m4_t vssub (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssub (vint64m4_t op1, int64_t op2);
vint64m8_t vssub (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssub (vint64m8_t op1, int64_t op2);
vuint8m1_t vssubu (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssubu (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssubu (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssubu (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssubu (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssubu (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssubu (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssubu (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssubu (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssubu (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssubu (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssubu (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssubu (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssubu (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssubu (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssubu (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssubu (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssubu (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssubu (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssubu (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssubu (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssubu (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssubu (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssubu (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssubu (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssubu (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssubu (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssubu (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssubu (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssubu (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssubu (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssubu (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vsadd_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsadd_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsadd_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsadd_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsadd_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsadd_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsadd_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsadd_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsadd_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsadd_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsadd_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsadd_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsadd_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsadd_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsadd_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsadd_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsadd_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsadd_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsadd_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsadd_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsadd_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsadd_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsadd_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsadd_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsadd_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsadd_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsadd_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsadd_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsadd_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsadd_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsadd_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsadd_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsaddu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsaddu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsaddu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsaddu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsaddu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsaddu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsaddu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsaddu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsaddu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsaddu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsaddu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsaddu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsaddu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsaddu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsaddu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsaddu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsaddu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsaddu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsaddu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsaddu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsaddu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsaddu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsaddu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsaddu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsaddu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsaddu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsaddu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsaddu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsaddu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsaddu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsaddu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsaddu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vssub_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssub_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vssub_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssub_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vssub_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssub_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vssub_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssub_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vssub_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssub_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vssub_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssub_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vssub_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssub_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vssub_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssub_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vssub_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssub_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vssub_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssub_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vssub_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssub_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vssub_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssub_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vssub_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssub_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vssub_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssub_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vssub_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssub_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vssub_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssub_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vssubu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssubu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssubu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssubu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssubu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssubu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssubu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssubu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssubu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssubu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssubu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssubu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssubu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssubu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssubu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssubu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssubu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssubu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssubu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssubu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssubu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssubu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssubu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssubu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssubu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssubu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssubu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssubu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssubu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssubu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssubu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssubu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Averaging Add and Subtract Functions](rvv-intrinsic-api.md#132-vector-single-width-averaging-add-and-subtract):

**Prototypes:**
``` C
vint8m1_t vaadd (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vaadd (vint8m1_t op1, int8_t op2);
vint8m2_t vaadd (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vaadd (vint8m2_t op1, int8_t op2);
vint8m4_t vaadd (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vaadd (vint8m4_t op1, int8_t op2);
vint8m8_t vaadd (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vaadd (vint8m8_t op1, int8_t op2);
vint16m1_t vaadd (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vaadd (vint16m1_t op1, int16_t op2);
vint16m2_t vaadd (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vaadd (vint16m2_t op1, int16_t op2);
vint16m4_t vaadd (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vaadd (vint16m4_t op1, int16_t op2);
vint16m8_t vaadd (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vaadd (vint16m8_t op1, int16_t op2);
vint32m1_t vaadd (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vaadd (vint32m1_t op1, int32_t op2);
vint32m2_t vaadd (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vaadd (vint32m2_t op1, int32_t op2);
vint32m4_t vaadd (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vaadd (vint32m4_t op1, int32_t op2);
vint32m8_t vaadd (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vaadd (vint32m8_t op1, int32_t op2);
vint64m1_t vaadd (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vaadd (vint64m1_t op1, int64_t op2);
vint64m2_t vaadd (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vaadd (vint64m2_t op1, int64_t op2);
vint64m4_t vaadd (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vaadd (vint64m4_t op1, int64_t op2);
vint64m8_t vaadd (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vaadd (vint64m8_t op1, int64_t op2);
vuint8m1_t vaaddu (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vaaddu (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vaaddu (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vaaddu (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vaaddu (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vaaddu (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vaaddu (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vaaddu (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vaaddu (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vaaddu (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vaaddu (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vaaddu (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vaaddu (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vaaddu (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vaaddu (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vaaddu (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vaaddu (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vaaddu (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vaaddu (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vaaddu (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vaaddu (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vaaddu (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vaaddu (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vaaddu (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vaaddu (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vaaddu (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vaaddu (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vaaddu (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vaaddu (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vaaddu (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vaaddu (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vaaddu (vuint64m8_t op1, uint64_t op2);
vint8m1_t vasub (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vasub (vint8m1_t op1, int8_t op2);
vint8m2_t vasub (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vasub (vint8m2_t op1, int8_t op2);
vint8m4_t vasub (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vasub (vint8m4_t op1, int8_t op2);
vint8m8_t vasub (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vasub (vint8m8_t op1, int8_t op2);
vint16m1_t vasub (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vasub (vint16m1_t op1, int16_t op2);
vint16m2_t vasub (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vasub (vint16m2_t op1, int16_t op2);
vint16m4_t vasub (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vasub (vint16m4_t op1, int16_t op2);
vint16m8_t vasub (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vasub (vint16m8_t op1, int16_t op2);
vint32m1_t vasub (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vasub (vint32m1_t op1, int32_t op2);
vint32m2_t vasub (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vasub (vint32m2_t op1, int32_t op2);
vint32m4_t vasub (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vasub (vint32m4_t op1, int32_t op2);
vint32m8_t vasub (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vasub (vint32m8_t op1, int32_t op2);
vint64m1_t vasub (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vasub (vint64m1_t op1, int64_t op2);
vint64m2_t vasub (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vasub (vint64m2_t op1, int64_t op2);
vint64m4_t vasub (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vasub (vint64m4_t op1, int64_t op2);
vint64m8_t vasub (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vasub (vint64m8_t op1, int64_t op2);
vuint8m1_t vasubu (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vasubu (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vasubu (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vasubu (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vasubu (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vasubu (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vasubu (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vasubu (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vasubu (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vasubu (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vasubu (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vasubu (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vasubu (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vasubu (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vasubu (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vasubu (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vasubu (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vasubu (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vasubu (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vasubu (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vasubu (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vasubu (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vasubu (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vasubu (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vasubu (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vasubu (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vasubu (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vasubu (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vasubu (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vasubu (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vasubu (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vasubu (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vaadd_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vaadd_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vaadd_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vaadd_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vaadd_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vaadd_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vaadd_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vaadd_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vaadd_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vaadd_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vaadd_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vaadd_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vaadd_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vaadd_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vaadd_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vaadd_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vaadd_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vaadd_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vaadd_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vaadd_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vaadd_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vaadd_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vaadd_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vaadd_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vaadd_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vaadd_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vaadd_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vaadd_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vaadd_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vaadd_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vaadd_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vaadd_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vaaddu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vaaddu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vaaddu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vaaddu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vaaddu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vaaddu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vaaddu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vaaddu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vaaddu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vaaddu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vaaddu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vaaddu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vaaddu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vaaddu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vaaddu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vaaddu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vaaddu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vaaddu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vaaddu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vaaddu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vaaddu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vaaddu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vaaddu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vaaddu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vaaddu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vaaddu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vaaddu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vaaddu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vaaddu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vaaddu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vaaddu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vaaddu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vasub_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vasub_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vasub_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vasub_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vasub_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vasub_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vasub_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vasub_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vasub_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vasub_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vasub_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vasub_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vasub_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vasub_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vasub_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vasub_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vasub_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vasub_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vasub_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vasub_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vasub_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vasub_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vasub_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vasub_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vasub_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vasub_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vasub_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vasub_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vasub_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vasub_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vasub_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vasub_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vasubu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vasubu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vasubu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vasubu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vasubu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vasubu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vasubu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vasubu_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vasubu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vasubu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vasubu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vasubu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vasubu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vasubu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vasubu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vasubu_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vasubu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vasubu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vasubu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vasubu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vasubu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vasubu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vasubu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vasubu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vasubu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vasubu_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vasubu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vasubu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vasubu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vasubu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vasubu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vasubu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Fractional Multiply with Rounding and Saturation Functions](rvv-intrinsic-api.md#133-vector-single-width-fractional-multiply-with-rounding-and-saturation):

**Prototypes:**
``` C
vint8m1_t vsmul (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsmul (vint8m1_t op1, int8_t op2);
vint8m2_t vsmul (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsmul (vint8m2_t op1, int8_t op2);
vint8m4_t vsmul (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsmul (vint8m4_t op1, int8_t op2);
vint8m8_t vsmul (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsmul (vint8m8_t op1, int8_t op2);
vint16m1_t vsmul (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsmul (vint16m1_t op1, int16_t op2);
vint16m2_t vsmul (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsmul (vint16m2_t op1, int16_t op2);
vint16m4_t vsmul (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsmul (vint16m4_t op1, int16_t op2);
vint16m8_t vsmul (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsmul (vint16m8_t op1, int16_t op2);
vint32m1_t vsmul (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsmul (vint32m1_t op1, int32_t op2);
vint32m2_t vsmul (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsmul (vint32m2_t op1, int32_t op2);
vint32m4_t vsmul (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsmul (vint32m4_t op1, int32_t op2);
vint32m8_t vsmul (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsmul (vint32m8_t op1, int32_t op2);
vint64m1_t vsmul (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsmul (vint64m1_t op1, int64_t op2);
vint64m2_t vsmul (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsmul (vint64m2_t op1, int64_t op2);
vint64m4_t vsmul (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsmul (vint64m4_t op1, int64_t op2);
vint64m8_t vsmul (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsmul (vint64m8_t op1, int64_t op2);
// masked functions
vint8m1_t vsmul_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsmul_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsmul_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsmul_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsmul_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsmul_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsmul_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsmul_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsmul_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsmul_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsmul_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsmul_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsmul_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsmul_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsmul_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsmul_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsmul_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsmul_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsmul_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsmul_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsmul_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsmul_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsmul_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsmul_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsmul_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsmul_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsmul_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsmul_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsmul_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsmul_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsmul_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsmul_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
```
### [Vector Single-Width Scaling Shift Functions](rvv-intrinsic-api.md#134-vector-single-width-scaling-shift-operations):

**Prototypes:**
``` C
vuint8m1_t vssrl (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssrl (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssrl (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssrl (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssrl (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssrl (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssrl (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssrl (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssrl (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssrl (vuint16m1_t op1, uint8_t op2);
vuint16m2_t vssrl (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssrl (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vssrl (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssrl (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vssrl (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssrl (vuint16m8_t op1, uint8_t op2);
vuint32m1_t vssrl (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssrl (vuint32m1_t op1, uint8_t op2);
vuint32m2_t vssrl (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssrl (vuint32m2_t op1, uint8_t op2);
vuint32m4_t vssrl (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssrl (vuint32m4_t op1, uint8_t op2);
vuint32m8_t vssrl (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssrl (vuint32m8_t op1, uint8_t op2);
vuint64m1_t vssrl (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssrl (vuint64m1_t op1, uint8_t op2);
vuint64m2_t vssrl (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssrl (vuint64m2_t op1, uint8_t op2);
vuint64m4_t vssrl (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssrl (vuint64m4_t op1, uint8_t op2);
vuint64m8_t vssrl (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssrl (vuint64m8_t op1, uint8_t op2);
vint8m1_t vssra (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vssra (vint8m1_t op1, uint8_t op2);
vint8m2_t vssra (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vssra (vint8m2_t op1, uint8_t op2);
vint8m4_t vssra (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vssra (vint8m4_t op1, uint8_t op2);
vint8m8_t vssra (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vssra (vint8m8_t op1, uint8_t op2);
vint16m1_t vssra (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vssra (vint16m1_t op1, uint8_t op2);
vint16m2_t vssra (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vssra (vint16m2_t op1, uint8_t op2);
vint16m4_t vssra (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vssra (vint16m4_t op1, uint8_t op2);
vint16m8_t vssra (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vssra (vint16m8_t op1, uint8_t op2);
vint32m1_t vssra (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vssra (vint32m1_t op1, uint8_t op2);
vint32m2_t vssra (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vssra (vint32m2_t op1, uint8_t op2);
vint32m4_t vssra (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vssra (vint32m4_t op1, uint8_t op2);
vint32m8_t vssra (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vssra (vint32m8_t op1, uint8_t op2);
vint64m1_t vssra (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vssra (vint64m1_t op1, uint8_t op2);
vint64m2_t vssra (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vssra (vint64m2_t op1, uint8_t op2);
vint64m4_t vssra (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vssra (vint64m4_t op1, uint8_t op2);
vint64m8_t vssra (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vssra (vint64m8_t op1, uint8_t op2);
// masked functions
vuint8m1_t vssrl_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssrl_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssrl_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssrl_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssrl_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssrl_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssrl_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssrl_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssrl_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssrl_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2);
vuint16m2_t vssrl_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssrl_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vssrl_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssrl_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vssrl_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssrl_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m1_t vssrl_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssrl_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint8_t op2);
vuint32m2_t vssrl_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssrl_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint32m4_t vssrl_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssrl_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint32m8_t vssrl_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssrl_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint64m1_t vssrl_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssrl_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint8_t op2);
vuint64m2_t vssrl_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssrl_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint64m4_t vssrl_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssrl_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint64m8_t vssrl_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssrl_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint8_t op2);
vint8m1_t vssra_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vssra_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vssra_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vssra_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vssra_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vssra_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vssra_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vssra_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vssra_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vssra_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint8_t op2);
vint16m2_t vssra_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vssra_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint8_t op2);
vint16m4_t vssra_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vssra_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint8_t op2);
vint16m8_t vssra_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vssra_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint8_t op2);
vint32m1_t vssra_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vssra_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint8_t op2);
vint32m2_t vssra_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vssra_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint8_t op2);
vint32m4_t vssra_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vssra_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint8_t op2);
vint32m8_t vssra_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vssra_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint8_t op2);
vint64m1_t vssra_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vssra_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint8_t op2);
vint64m2_t vssra_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vssra_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint8_t op2);
vint64m4_t vssra_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vssra_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint8_t op2);
vint64m8_t vssra_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vssra_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint8_t op2);
```
### [Vector Narrowing Fixed-Point Clip Functions](rvv-intrinsic-api.md#135-vector-narrowing-fixed-point-clip-operations):

**Prototypes:**
``` C
vint8m1_t vnclip (vint16m2_t op1, vuint8m1_t op2);
vint8m1_t vnclip (vint16m2_t op1, uint8_t op2);
vint8m2_t vnclip (vint16m4_t op1, vuint8m2_t op2);
vint8m2_t vnclip (vint16m4_t op1, uint8_t op2);
vint8m4_t vnclip (vint16m8_t op1, vuint8m4_t op2);
vint8m4_t vnclip (vint16m8_t op1, uint8_t op2);
vint16m1_t vnclip (vint32m2_t op1, vuint16m1_t op2);
vint16m1_t vnclip (vint32m2_t op1, uint8_t op2);
vint16m2_t vnclip (vint32m4_t op1, vuint16m2_t op2);
vint16m2_t vnclip (vint32m4_t op1, uint8_t op2);
vint16m4_t vnclip (vint32m8_t op1, vuint16m4_t op2);
vint16m4_t vnclip (vint32m8_t op1, uint8_t op2);
vint32m1_t vnclip (vint64m2_t op1, vuint32m1_t op2);
vint32m1_t vnclip (vint64m2_t op1, uint8_t op2);
vint32m2_t vnclip (vint64m4_t op1, vuint32m2_t op2);
vint32m2_t vnclip (vint64m4_t op1, uint8_t op2);
vint32m4_t vnclip (vint64m8_t op1, vuint32m4_t op2);
vint32m4_t vnclip (vint64m8_t op1, uint8_t op2);
vuint8m1_t vnclipu (vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnclipu (vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnclipu (vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnclipu (vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnclipu (vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnclipu (vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnclipu (vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnclipu (vuint32m2_t op1, uint8_t op2);
vuint16m2_t vnclipu (vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnclipu (vuint32m4_t op1, uint8_t op2);
vuint16m4_t vnclipu (vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnclipu (vuint32m8_t op1, uint8_t op2);
vuint32m1_t vnclipu (vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnclipu (vuint64m2_t op1, uint8_t op2);
vuint32m2_t vnclipu (vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnclipu (vuint64m4_t op1, uint8_t op2);
vuint32m4_t vnclipu (vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnclipu (vuint64m8_t op1, uint8_t op2);
// masked functions
vint8m1_t vnclip_m (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t op2);
vint8m1_t vnclip_m (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, uint8_t op2);
vint8m2_t vnclip_m (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t op2);
vint8m2_t vnclip_m (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, uint8_t op2);
vint8m4_t vnclip_m (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t op2);
vint8m4_t vnclip_m (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, uint8_t op2);
vint16m1_t vnclip_m (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t op2);
vint16m1_t vnclip_m (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, uint8_t op2);
vint16m2_t vnclip_m (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t op2);
vint16m2_t vnclip_m (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, uint8_t op2);
vint16m4_t vnclip_m (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t op2);
vint16m4_t vnclip_m (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, uint8_t op2);
vint32m1_t vnclip_m (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t op2);
vint32m1_t vnclip_m (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, uint8_t op2);
vint32m2_t vnclip_m (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t op2);
vint32m2_t vnclip_m (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, uint8_t op2);
vint32m4_t vnclip_m (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t op2);
vint32m4_t vnclip_m (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, uint8_t op2);
vuint8m1_t vnclipu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnclipu_m (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnclipu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnclipu_m (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnclipu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnclipu_m (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnclipu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnclipu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint16m2_t vnclipu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnclipu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint16m4_t vnclipu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnclipu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint32m1_t vnclipu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnclipu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint32m2_t vnclipu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnclipu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint32m4_t vnclipu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnclipu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, uint8_t op2);
```
## Vector Floating-Point Functions:

### [Vector Single-Width Floating-Point Add/Subtract Functions](rvv-intrinsic-api.md#142-vector-single-width-floating-point-addsubtract-operations):

**Prototypes:**
``` C
vfloat16m1_t vfadd (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfadd (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfadd (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfadd (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfadd (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfadd (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfadd (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfadd (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfadd (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfadd (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfadd (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfadd (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfadd (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfadd (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfadd (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfadd (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfadd (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfadd (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfadd (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfadd (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfadd (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfadd (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfadd (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfadd (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfsub (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfsub (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfsub (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfsub (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfsub (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfsub (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfsub (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfsub (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfsub (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfsub (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfsub (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfsub (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfsub (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfsub (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfsub (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfsub (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfsub (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfsub (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfsub (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfsub (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfsub (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfsub (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfsub (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfsub (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfrsub (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfrsub (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfrsub (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfrsub (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfrsub (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfrsub (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfrsub (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfrsub (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfrsub (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfrsub (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfrsub (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfrsub (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfrsub (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfrsub (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfrsub (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfrsub (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfrsub (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfrsub (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfrsub (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfrsub (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfrsub (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfrsub (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfrsub (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfrsub (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vfadd_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfadd_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfadd_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfadd_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfadd_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfadd_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfadd_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfadd_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfadd_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfadd_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfadd_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfadd_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfadd_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfadd_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfadd_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfadd_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfadd_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfadd_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfadd_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfadd_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfadd_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfadd_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfadd_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfadd_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfsub_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfsub_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfsub_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfsub_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfsub_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfsub_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfsub_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfsub_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfsub_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfsub_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfsub_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfsub_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfsub_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfsub_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfsub_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfsub_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfsub_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfsub_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfsub_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfsub_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfsub_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfsub_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfsub_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfsub_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfrsub_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfrsub_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfrsub_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfrsub_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfrsub_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfrsub_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfrsub_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfrsub_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfrsub_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfrsub_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfrsub_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfrsub_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfrsub_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfrsub_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfrsub_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfrsub_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfrsub_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfrsub_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfrsub_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfrsub_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfrsub_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfrsub_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfrsub_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfrsub_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Widening Floating-Point Add/Subtract Functions](rvv-intrinsic-api.md#143-vector-widening-floating-point-addsubtract-operations):

**Prototypes:**
``` C
vfloat32m2_t vfwadd (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwadd (vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vfwadd (vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwadd (vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vfwadd (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwadd (vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vfwadd (vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwadd (vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vfwadd (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwadd (vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vfwadd (vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwadd (vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vfwadd (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwadd (vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vfwadd (vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwadd (vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vfwadd (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwadd (vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vfwadd (vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwadd (vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vfwadd (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwadd (vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vfwadd (vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwadd (vfloat64m8_t op1, float32_t op2);
vfloat32m2_t vfwsub (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwsub (vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vfwsub (vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwsub (vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vfwsub (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwsub (vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vfwsub (vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwsub (vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vfwsub (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwsub (vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vfwsub (vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwsub (vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vfwsub (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwsub (vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vfwsub (vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwsub (vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vfwsub (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwsub (vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vfwsub (vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwsub (vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vfwsub (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwsub (vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vfwsub (vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwsub (vfloat64m8_t op1, float32_t op2);
// masked functions
vfloat32m2_t vfwadd_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwadd_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vfwadd_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwadd_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vfwadd_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwadd_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vfwadd_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwadd_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vfwadd_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwadd_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vfwadd_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwadd_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vfwadd_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwadd_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vfwadd_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwadd_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vfwadd_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwadd_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vfwadd_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwadd_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vfwadd_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwadd_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vfwadd_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwadd_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2);
vfloat32m2_t vfwsub_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwsub_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vfwsub_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwsub_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vfwsub_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwsub_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vfwsub_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwsub_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vfwsub_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwsub_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vfwsub_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwsub_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vfwsub_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwsub_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vfwsub_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwsub_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vfwsub_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwsub_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vfwsub_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwsub_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vfwsub_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwsub_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vfwsub_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwsub_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2);
```
### [Vector Single-Width Floating-Point Multiply/Divide Functions](rvv-intrinsic-api.md#144-vector-single-width-floating-point-multiplydivide-operations):

**Prototypes:**
``` C
vfloat16m1_t vfmul (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmul (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfmul (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmul (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfmul (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmul (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfmul (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmul (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfmul (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmul (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfmul (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmul (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfmul (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmul (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfmul (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmul (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfmul (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmul (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfmul (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmul (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfmul (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmul (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfmul (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmul (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfdiv (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfdiv (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfdiv (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfdiv (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfdiv (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfdiv (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfdiv (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfdiv (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfdiv (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfdiv (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfdiv (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfdiv (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfdiv (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfdiv (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfdiv (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfdiv (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfdiv (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfdiv (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfdiv (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfdiv (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfdiv (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfdiv (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfdiv (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfdiv (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfrdiv (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfrdiv (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfrdiv (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfrdiv (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfrdiv (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfrdiv (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfrdiv (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfrdiv (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfrdiv (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfrdiv (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfrdiv (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfrdiv (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfrdiv (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfrdiv (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfrdiv (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfrdiv (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfrdiv (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfrdiv (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfrdiv (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfrdiv (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfrdiv (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfrdiv (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfrdiv (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfrdiv (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vfmul_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmul_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfmul_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmul_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfmul_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmul_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfmul_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmul_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfmul_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmul_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfmul_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmul_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfmul_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmul_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfmul_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmul_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfmul_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmul_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfmul_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmul_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfmul_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmul_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfmul_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmul_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfdiv_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfdiv_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfdiv_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfdiv_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfdiv_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfdiv_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfdiv_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfdiv_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfdiv_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfdiv_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfdiv_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfdiv_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfdiv_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfdiv_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfdiv_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfdiv_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfdiv_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfdiv_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfdiv_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfdiv_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfdiv_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfdiv_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfdiv_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfdiv_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfrdiv_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfrdiv_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfrdiv_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfrdiv_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfrdiv_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfrdiv_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfrdiv_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfrdiv_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfrdiv_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfrdiv_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfrdiv_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfrdiv_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfrdiv_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfrdiv_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfrdiv_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfrdiv_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfrdiv_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfrdiv_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfrdiv_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfrdiv_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfrdiv_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfrdiv_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfrdiv_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfrdiv_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Widening Floating-Point Multiply Functions](rvv-intrinsic-api.md#145-vector-widening-floating-point-multiply-operations):

**Prototypes:**
``` C
vfloat32m2_t vfwmul (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwmul (vfloat16m1_t op1, float16_t op2);
vfloat32m4_t vfwmul (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwmul (vfloat16m2_t op1, float16_t op2);
vfloat32m8_t vfwmul (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwmul (vfloat16m4_t op1, float16_t op2);
vfloat64m2_t vfwmul (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwmul (vfloat32m1_t op1, float32_t op2);
vfloat64m4_t vfwmul (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwmul (vfloat32m2_t op1, float32_t op2);
vfloat64m8_t vfwmul (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwmul (vfloat32m4_t op1, float32_t op2);
// masked functions
vfloat32m2_t vfwmul_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwmul_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m4_t vfwmul_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwmul_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m8_t vfwmul_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwmul_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat64m2_t vfwmul_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwmul_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m4_t vfwmul_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwmul_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m8_t vfwmul_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwmul_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
```
### [Vector Single-Width Floating-Point Fused Multiply-Add Functions](rvv-intrinsic-api.md#146-vector-single-width-floating-point-fused-multiply-add-operations):

**Prototypes:**
``` C
vfloat16m1_t vfmacc (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmacc (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfmacc (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmacc (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfmacc (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmacc (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfmacc (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmacc (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfmacc (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmacc (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfmacc (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmacc (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfmacc (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmacc (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfmacc (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmacc (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfmacc (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmacc (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfmacc (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmacc (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfmacc (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmacc (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfmacc (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmacc (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfnmacc (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfnmacc (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfnmacc (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfnmacc (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfnmacc (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfnmacc (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfnmacc (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfnmacc (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfnmacc (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfnmacc (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfnmacc (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfnmacc (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfnmacc (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfnmacc (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfnmacc (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfnmacc (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfnmacc (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfnmacc (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfnmacc (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfnmacc (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfnmacc (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfnmacc (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfnmacc (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfnmacc (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfmsac (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmsac (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfmsac (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmsac (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfmsac (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmsac (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfmsac (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmsac (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfmsac (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmsac (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfmsac (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmsac (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfmsac (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmsac (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfmsac (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmsac (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfmsac (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmsac (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfmsac (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmsac (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfmsac (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmsac (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfmsac (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmsac (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfnmsac (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfnmsac (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfnmsac (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfnmsac (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfnmsac (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfnmsac (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfnmsac (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfnmsac (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfnmsac (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfnmsac (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfnmsac (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfnmsac (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfnmsac (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfnmsac (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfnmsac (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfnmsac (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfnmsac (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfnmsac (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfnmsac (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfnmsac (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfnmsac (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfnmsac (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfnmsac (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfnmsac (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfmadd (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmadd (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfmadd (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmadd (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfmadd (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmadd (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfmadd (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmadd (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfmadd (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmadd (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfmadd (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmadd (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfmadd (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmadd (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfmadd (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmadd (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfmadd (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmadd (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfmadd (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmadd (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfmadd (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmadd (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfmadd (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmadd (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfnmadd (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfnmadd (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfnmadd (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfnmadd (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfnmadd (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfnmadd (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfnmadd (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfnmadd (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfnmadd (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfnmadd (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfnmadd (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfnmadd (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfnmadd (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfnmadd (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfnmadd (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfnmadd (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfnmadd (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfnmadd (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfnmadd (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfnmadd (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfnmadd (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfnmadd (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfnmadd (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfnmadd (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfmsub (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmsub (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfmsub (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmsub (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfmsub (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmsub (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfmsub (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmsub (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfmsub (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmsub (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfmsub (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmsub (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfmsub (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmsub (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfmsub (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmsub (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfmsub (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmsub (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfmsub (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmsub (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfmsub (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmsub (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfmsub (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmsub (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfnmsub (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfnmsub (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfnmsub (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfnmsub (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfnmsub (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfnmsub (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfnmsub (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfnmsub (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfnmsub (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfnmsub (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfnmsub (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfnmsub (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfnmsub (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfnmsub (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfnmsub (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfnmsub (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfnmsub (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfnmsub (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfnmsub (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfnmsub (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfnmsub (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfnmsub (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfnmsub (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfnmsub (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
// masked functions
vfloat16m1_t vfmacc_m (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmacc_m (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfmacc_m (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmacc_m (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfmacc_m (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmacc_m (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfmacc_m (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmacc_m (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfmacc_m (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmacc_m (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfmacc_m (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmacc_m (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfmacc_m (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmacc_m (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfmacc_m (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmacc_m (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfmacc_m (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmacc_m (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfmacc_m (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmacc_m (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfmacc_m (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmacc_m (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfmacc_m (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmacc_m (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfnmacc_m (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfnmacc_m (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfnmacc_m (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfnmacc_m (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfnmacc_m (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfnmacc_m (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfnmacc_m (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfnmacc_m (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfnmacc_m (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfnmacc_m (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfnmacc_m (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfnmacc_m (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfnmacc_m (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfnmacc_m (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfnmacc_m (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfnmacc_m (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfnmacc_m (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfnmacc_m (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfnmacc_m (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfnmacc_m (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfnmacc_m (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfnmacc_m (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfnmacc_m (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfnmacc_m (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfmsac_m (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmsac_m (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfmsac_m (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmsac_m (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfmsac_m (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmsac_m (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfmsac_m (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmsac_m (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfmsac_m (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmsac_m (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfmsac_m (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmsac_m (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfmsac_m (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmsac_m (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfmsac_m (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmsac_m (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfmsac_m (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmsac_m (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfmsac_m (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmsac_m (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfmsac_m (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmsac_m (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfmsac_m (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmsac_m (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfnmsac_m (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfnmsac_m (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfnmsac_m (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfnmsac_m (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfnmsac_m (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfnmsac_m (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfnmsac_m (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfnmsac_m (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfnmsac_m (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfnmsac_m (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfnmsac_m (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfnmsac_m (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfnmsac_m (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfnmsac_m (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfnmsac_m (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfnmsac_m (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfnmsac_m (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfnmsac_m (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfnmsac_m (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfnmsac_m (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfnmsac_m (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfnmsac_m (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfnmsac_m (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfnmsac_m (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfmadd_m (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmadd_m (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfmadd_m (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmadd_m (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfmadd_m (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmadd_m (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfmadd_m (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmadd_m (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfmadd_m (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmadd_m (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfmadd_m (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmadd_m (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfmadd_m (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmadd_m (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfmadd_m (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmadd_m (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfmadd_m (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmadd_m (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfmadd_m (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmadd_m (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfmadd_m (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmadd_m (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfmadd_m (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmadd_m (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfnmadd_m (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfnmadd_m (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfnmadd_m (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfnmadd_m (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfnmadd_m (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfnmadd_m (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfnmadd_m (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfnmadd_m (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfnmadd_m (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfnmadd_m (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfnmadd_m (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfnmadd_m (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfnmadd_m (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfnmadd_m (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfnmadd_m (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfnmadd_m (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfnmadd_m (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfnmadd_m (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfnmadd_m (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfnmadd_m (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfnmadd_m (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfnmadd_m (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfnmadd_m (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfnmadd_m (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfmsub_m (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmsub_m (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfmsub_m (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmsub_m (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfmsub_m (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmsub_m (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfmsub_m (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmsub_m (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfmsub_m (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmsub_m (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfmsub_m (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmsub_m (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfmsub_m (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmsub_m (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfmsub_m (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmsub_m (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfmsub_m (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmsub_m (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfmsub_m (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmsub_m (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfmsub_m (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmsub_m (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfmsub_m (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmsub_m (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vfnmsub_m (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfnmsub_m (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vfnmsub_m (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfnmsub_m (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vfnmsub_m (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfnmsub_m (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vfnmsub_m (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfnmsub_m (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vfnmsub_m (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfnmsub_m (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vfnmsub_m (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfnmsub_m (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vfnmsub_m (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfnmsub_m (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vfnmsub_m (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfnmsub_m (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vfnmsub_m (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfnmsub_m (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vfnmsub_m (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfnmsub_m (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vfnmsub_m (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfnmsub_m (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vfnmsub_m (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfnmsub_m (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
```
### [Vector Widening Floating-Point Fused Multiply-Add Functions](rvv-intrinsic-api.md#147-vector-widening-floating-point-fused-multiply-add-operations):

**Prototypes:**
``` C
vfloat32m2_t vfwmacc (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwmacc (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vfwmacc (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwmacc (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vfwmacc (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwmacc (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vfwmacc (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwmacc (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vfwmacc (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwmacc (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vfwmacc (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwmacc (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vfwnmacc (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwnmacc (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vfwnmacc (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwnmacc (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vfwnmacc (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwnmacc (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vfwnmacc (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwnmacc (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vfwnmacc (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwnmacc (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vfwnmacc (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwnmacc (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vfwmsac (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwmsac (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vfwmsac (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwmsac (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vfwmsac (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwmsac (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vfwmsac (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwmsac (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vfwmsac (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwmsac (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vfwmsac (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwmsac (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vfwnmsac (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwnmsac (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vfwnmsac (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwnmsac (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vfwnmsac (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwnmsac (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vfwnmsac (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwnmsac (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vfwnmsac (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwnmsac (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vfwnmsac (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwnmsac (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
// masked functions
vfloat32m2_t vfwmacc_m (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwmacc_m (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vfwmacc_m (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwmacc_m (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vfwmacc_m (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwmacc_m (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vfwmacc_m (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwmacc_m (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vfwmacc_m (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwmacc_m (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vfwmacc_m (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwmacc_m (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vfwnmacc_m (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwnmacc_m (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vfwnmacc_m (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwnmacc_m (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vfwnmacc_m (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwnmacc_m (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vfwnmacc_m (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwnmacc_m (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vfwnmacc_m (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwnmacc_m (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vfwnmacc_m (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwnmacc_m (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vfwmsac_m (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwmsac_m (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vfwmsac_m (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwmsac_m (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vfwmsac_m (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwmsac_m (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vfwmsac_m (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwmsac_m (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vfwmsac_m (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwmsac_m (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vfwmsac_m (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwmsac_m (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vfwnmsac_m (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vfwnmsac_m (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vfwnmsac_m (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vfwnmsac_m (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vfwnmsac_m (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vfwnmsac_m (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vfwnmsac_m (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vfwnmsac_m (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vfwnmsac_m (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vfwnmsac_m (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vfwnmsac_m (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vfwnmsac_m (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
```
### [Vector Floating-Point Square-Root Functions](rvv-intrinsic-api.md#148-vector-floating-point-square-root-operations):

**Prototypes:**
``` C
vfloat16m1_t vfsqrt (vfloat16m1_t op1);
vfloat16m2_t vfsqrt (vfloat16m2_t op1);
vfloat16m4_t vfsqrt (vfloat16m4_t op1);
vfloat16m8_t vfsqrt (vfloat16m8_t op1);
vfloat32m1_t vfsqrt (vfloat32m1_t op1);
vfloat32m2_t vfsqrt (vfloat32m2_t op1);
vfloat32m4_t vfsqrt (vfloat32m4_t op1);
vfloat32m8_t vfsqrt (vfloat32m8_t op1);
vfloat64m1_t vfsqrt (vfloat64m1_t op1);
vfloat64m2_t vfsqrt (vfloat64m2_t op1);
vfloat64m4_t vfsqrt (vfloat64m4_t op1);
vfloat64m8_t vfsqrt (vfloat64m8_t op1);
// masked functions
vfloat16m1_t vfsqrt_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1);
vfloat16m2_t vfsqrt_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1);
vfloat16m4_t vfsqrt_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1);
vfloat16m8_t vfsqrt_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1);
vfloat32m1_t vfsqrt_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1);
vfloat32m2_t vfsqrt_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1);
vfloat32m4_t vfsqrt_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1);
vfloat32m8_t vfsqrt_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1);
vfloat64m1_t vfsqrt_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1);
vfloat64m2_t vfsqrt_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1);
vfloat64m4_t vfsqrt_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1);
vfloat64m8_t vfsqrt_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1);
```
### [Vector Floating-Point MIN/MAX Functions](rvv-intrinsic-api.md#149-vector-floating-point-minmax-operations):

**Prototypes:**
``` C
vfloat16m1_t vfmin (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmin (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfmin (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmin (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfmin (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmin (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfmin (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmin (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfmin (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmin (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfmin (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmin (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfmin (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmin (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfmin (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmin (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfmin (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmin (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfmin (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmin (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfmin (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmin (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfmin (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmin (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfmax (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmax (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfmax (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmax (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfmax (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmax (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfmax (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmax (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfmax (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmax (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfmax (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmax (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfmax (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmax (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfmax (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmax (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfmax (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmax (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfmax (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmax (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfmax (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmax (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfmax (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmax (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vfmin_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmin_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfmin_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmin_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfmin_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmin_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfmin_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmin_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfmin_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmin_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfmin_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmin_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfmin_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmin_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfmin_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmin_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfmin_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmin_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfmin_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmin_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfmin_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmin_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfmin_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmin_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfmax_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmax_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfmax_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmax_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfmax_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmax_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfmax_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmax_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfmax_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmax_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfmax_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmax_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfmax_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmax_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfmax_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmax_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfmax_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmax_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfmax_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmax_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfmax_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmax_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfmax_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmax_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Sign-Injection Functions](rvv-intrinsic-api.md#1410-vector-floating-point-sign-injection-operations):

**Prototypes:**
``` C
vfloat16m1_t vfsgnj (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfsgnj (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfsgnj (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfsgnj (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfsgnj (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfsgnj (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfsgnj (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfsgnj (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfsgnj (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfsgnj (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfsgnj (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfsgnj (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfsgnj (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfsgnj (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfsgnj (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfsgnj (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfsgnj (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfsgnj (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfsgnj (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfsgnj (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfsgnj (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfsgnj (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfsgnj (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfsgnj (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfsgnjn (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfsgnjn (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfsgnjn (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfsgnjn (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfsgnjn (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfsgnjn (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfsgnjn (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfsgnjn (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfsgnjn (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfsgnjn (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfsgnjn (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfsgnjn (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfsgnjn (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfsgnjn (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfsgnjn (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfsgnjn (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfsgnjn (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfsgnjn (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfsgnjn (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfsgnjn (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfsgnjn (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfsgnjn (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfsgnjn (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfsgnjn (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfsgnjx (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfsgnjx (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfsgnjx (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfsgnjx (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfsgnjx (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfsgnjx (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfsgnjx (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfsgnjx (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfsgnjx (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfsgnjx (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfsgnjx (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfsgnjx (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfsgnjx (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfsgnjx (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfsgnjx (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfsgnjx (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfsgnjx (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfsgnjx (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfsgnjx (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfsgnjx (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfsgnjx (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfsgnjx (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfsgnjx (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfsgnjx (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vfsgnj_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfsgnj_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfsgnj_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfsgnj_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfsgnj_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfsgnj_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfsgnj_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfsgnj_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfsgnj_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfsgnj_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfsgnj_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfsgnj_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfsgnj_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfsgnj_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfsgnj_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfsgnj_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfsgnj_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfsgnj_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfsgnj_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfsgnj_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfsgnj_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfsgnj_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfsgnj_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfsgnj_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfsgnjn_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfsgnjn_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfsgnjn_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfsgnjn_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfsgnjn_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfsgnjn_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfsgnjn_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfsgnjn_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfsgnjn_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfsgnjn_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfsgnjn_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfsgnjn_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfsgnjn_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfsgnjn_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfsgnjn_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfsgnjn_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfsgnjn_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfsgnjn_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfsgnjn_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfsgnjn_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfsgnjn_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfsgnjn_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfsgnjn_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfsgnjn_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vfsgnjx_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfsgnjx_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfsgnjx_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfsgnjx_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfsgnjx_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfsgnjx_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfsgnjx_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfsgnjx_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfsgnjx_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfsgnjx_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfsgnjx_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfsgnjx_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfsgnjx_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfsgnjx_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfsgnjx_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfsgnjx_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfsgnjx_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfsgnjx_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfsgnjx_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfsgnjx_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfsgnjx_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfsgnjx_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfsgnjx_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfsgnjx_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Compare Functions](rvv-intrinsic-api.md#1411-vector-floating-point-compare-operations):

**Prototypes:**
``` C
vbool16_t vmfeq (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmfeq (vfloat16m1_t op1, float16_t op2);
vbool8_t vmfeq (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmfeq (vfloat16m2_t op1, float16_t op2);
vbool4_t vmfeq (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmfeq (vfloat16m4_t op1, float16_t op2);
vbool2_t vmfeq (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmfeq (vfloat16m8_t op1, float16_t op2);
vbool32_t vmfeq (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmfeq (vfloat32m1_t op1, float32_t op2);
vbool16_t vmfeq (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmfeq (vfloat32m2_t op1, float32_t op2);
vbool8_t vmfeq (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmfeq (vfloat32m4_t op1, float32_t op2);
vbool4_t vmfeq (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmfeq (vfloat32m8_t op1, float32_t op2);
vbool64_t vmfeq (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmfeq (vfloat64m1_t op1, float64_t op2);
vbool32_t vmfeq (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmfeq (vfloat64m2_t op1, float64_t op2);
vbool16_t vmfeq (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmfeq (vfloat64m4_t op1, float64_t op2);
vbool8_t vmfeq (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmfeq (vfloat64m8_t op1, float64_t op2);
vbool16_t vmfne (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmfne (vfloat16m1_t op1, float16_t op2);
vbool8_t vmfne (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmfne (vfloat16m2_t op1, float16_t op2);
vbool4_t vmfne (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmfne (vfloat16m4_t op1, float16_t op2);
vbool2_t vmfne (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmfne (vfloat16m8_t op1, float16_t op2);
vbool32_t vmfne (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmfne (vfloat32m1_t op1, float32_t op2);
vbool16_t vmfne (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmfne (vfloat32m2_t op1, float32_t op2);
vbool8_t vmfne (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmfne (vfloat32m4_t op1, float32_t op2);
vbool4_t vmfne (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmfne (vfloat32m8_t op1, float32_t op2);
vbool64_t vmfne (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmfne (vfloat64m1_t op1, float64_t op2);
vbool32_t vmfne (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmfne (vfloat64m2_t op1, float64_t op2);
vbool16_t vmfne (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmfne (vfloat64m4_t op1, float64_t op2);
vbool8_t vmfne (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmfne (vfloat64m8_t op1, float64_t op2);
vbool16_t vmflt (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmflt (vfloat16m1_t op1, float16_t op2);
vbool8_t vmflt (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmflt (vfloat16m2_t op1, float16_t op2);
vbool4_t vmflt (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmflt (vfloat16m4_t op1, float16_t op2);
vbool2_t vmflt (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmflt (vfloat16m8_t op1, float16_t op2);
vbool32_t vmflt (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmflt (vfloat32m1_t op1, float32_t op2);
vbool16_t vmflt (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmflt (vfloat32m2_t op1, float32_t op2);
vbool8_t vmflt (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmflt (vfloat32m4_t op1, float32_t op2);
vbool4_t vmflt (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmflt (vfloat32m8_t op1, float32_t op2);
vbool64_t vmflt (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmflt (vfloat64m1_t op1, float64_t op2);
vbool32_t vmflt (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmflt (vfloat64m2_t op1, float64_t op2);
vbool16_t vmflt (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmflt (vfloat64m4_t op1, float64_t op2);
vbool8_t vmflt (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmflt (vfloat64m8_t op1, float64_t op2);
vbool16_t vmfle (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmfle (vfloat16m1_t op1, float16_t op2);
vbool8_t vmfle (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmfle (vfloat16m2_t op1, float16_t op2);
vbool4_t vmfle (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmfle (vfloat16m4_t op1, float16_t op2);
vbool2_t vmfle (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmfle (vfloat16m8_t op1, float16_t op2);
vbool32_t vmfle (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmfle (vfloat32m1_t op1, float32_t op2);
vbool16_t vmfle (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmfle (vfloat32m2_t op1, float32_t op2);
vbool8_t vmfle (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmfle (vfloat32m4_t op1, float32_t op2);
vbool4_t vmfle (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmfle (vfloat32m8_t op1, float32_t op2);
vbool64_t vmfle (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmfle (vfloat64m1_t op1, float64_t op2);
vbool32_t vmfle (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmfle (vfloat64m2_t op1, float64_t op2);
vbool16_t vmfle (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmfle (vfloat64m4_t op1, float64_t op2);
vbool8_t vmfle (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmfle (vfloat64m8_t op1, float64_t op2);
vbool16_t vmfgt (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmfgt (vfloat16m1_t op1, float16_t op2);
vbool8_t vmfgt (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmfgt (vfloat16m2_t op1, float16_t op2);
vbool4_t vmfgt (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmfgt (vfloat16m4_t op1, float16_t op2);
vbool2_t vmfgt (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmfgt (vfloat16m8_t op1, float16_t op2);
vbool32_t vmfgt (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmfgt (vfloat32m1_t op1, float32_t op2);
vbool16_t vmfgt (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmfgt (vfloat32m2_t op1, float32_t op2);
vbool8_t vmfgt (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmfgt (vfloat32m4_t op1, float32_t op2);
vbool4_t vmfgt (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmfgt (vfloat32m8_t op1, float32_t op2);
vbool64_t vmfgt (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmfgt (vfloat64m1_t op1, float64_t op2);
vbool32_t vmfgt (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmfgt (vfloat64m2_t op1, float64_t op2);
vbool16_t vmfgt (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmfgt (vfloat64m4_t op1, float64_t op2);
vbool8_t vmfgt (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmfgt (vfloat64m8_t op1, float64_t op2);
vbool16_t vmfge (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmfge (vfloat16m1_t op1, float16_t op2);
vbool8_t vmfge (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmfge (vfloat16m2_t op1, float16_t op2);
vbool4_t vmfge (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmfge (vfloat16m4_t op1, float16_t op2);
vbool2_t vmfge (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmfge (vfloat16m8_t op1, float16_t op2);
vbool32_t vmfge (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmfge (vfloat32m1_t op1, float32_t op2);
vbool16_t vmfge (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmfge (vfloat32m2_t op1, float32_t op2);
vbool8_t vmfge (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmfge (vfloat32m4_t op1, float32_t op2);
vbool4_t vmfge (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmfge (vfloat32m8_t op1, float32_t op2);
vbool64_t vmfge (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmfge (vfloat64m1_t op1, float64_t op2);
vbool32_t vmfge (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmfge (vfloat64m2_t op1, float64_t op2);
vbool16_t vmfge (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmfge (vfloat64m4_t op1, float64_t op2);
vbool8_t vmfge (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmfge (vfloat64m8_t op1, float64_t op2);
// masked functions
vbool16_t vmfeq_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmfeq_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vmfeq_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmfeq_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vmfeq_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmfeq_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vmfeq_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmfeq_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vmfeq_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmfeq_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vmfeq_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmfeq_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vmfeq_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmfeq_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vmfeq_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmfeq_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vmfeq_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmfeq_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vmfeq_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmfeq_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vmfeq_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmfeq_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vmfeq_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmfeq_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vmfne_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmfne_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vmfne_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmfne_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vmfne_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmfne_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vmfne_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmfne_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vmfne_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmfne_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vmfne_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmfne_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vmfne_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmfne_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vmfne_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmfne_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vmfne_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmfne_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vmfne_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmfne_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vmfne_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmfne_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vmfne_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmfne_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vmflt_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmflt_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vmflt_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmflt_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vmflt_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmflt_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vmflt_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmflt_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vmflt_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmflt_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vmflt_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmflt_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vmflt_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmflt_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vmflt_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmflt_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vmflt_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmflt_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vmflt_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmflt_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vmflt_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmflt_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vmflt_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmflt_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vmfle_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmfle_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vmfle_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmfle_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vmfle_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmfle_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vmfle_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmfle_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vmfle_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmfle_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vmfle_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmfle_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vmfle_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmfle_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vmfle_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmfle_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vmfle_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmfle_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vmfle_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmfle_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vmfle_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmfle_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vmfle_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmfle_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vmfgt_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmfgt_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vmfgt_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmfgt_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vmfgt_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmfgt_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vmfgt_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmfgt_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vmfgt_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmfgt_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vmfgt_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmfgt_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vmfgt_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmfgt_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vmfgt_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmfgt_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vmfgt_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmfgt_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vmfgt_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmfgt_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vmfgt_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmfgt_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vmfgt_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmfgt_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vmfge_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vmfge_m (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vmfge_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vmfge_m (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vmfge_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vmfge_m (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vmfge_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vmfge_m (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vmfge_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vmfge_m (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vmfge_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vmfge_m (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vmfge_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vmfge_m (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vmfge_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vmfge_m (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vmfge_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vmfge_m (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vmfge_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vmfge_m (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vmfge_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vmfge_m (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vmfge_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vmfge_m (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Classify Functions](rvv-intrinsic-api.md#1412-vector-floating-point-classify-operations):

**Prototypes:**
``` C
vuint16m1_t vfclass (vfloat16m1_t op1);
vuint16m2_t vfclass (vfloat16m2_t op1);
vuint16m4_t vfclass (vfloat16m4_t op1);
vuint16m8_t vfclass (vfloat16m8_t op1);
vuint32m1_t vfclass (vfloat32m1_t op1);
vuint32m2_t vfclass (vfloat32m2_t op1);
vuint32m4_t vfclass (vfloat32m4_t op1);
vuint32m8_t vfclass (vfloat32m8_t op1);
vuint64m1_t vfclass (vfloat64m1_t op1);
vuint64m2_t vfclass (vfloat64m2_t op1);
vuint64m4_t vfclass (vfloat64m4_t op1);
vuint64m8_t vfclass (vfloat64m8_t op1);
// masked functions
vuint16m1_t vfclass_m (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t op1);
vuint16m2_t vfclass_m (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t op1);
vuint16m4_t vfclass_m (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t op1);
vuint16m8_t vfclass_m (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t op1);
vuint32m1_t vfclass_m (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t op1);
vuint32m2_t vfclass_m (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t op1);
vuint32m4_t vfclass_m (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t op1);
vuint32m8_t vfclass_m (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t op1);
vuint64m1_t vfclass_m (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t op1);
vuint64m2_t vfclass_m (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t op1);
vuint64m4_t vfclass_m (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t op1);
vuint64m8_t vfclass_m (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t op1);
```
### [Vector Floating-Point Merge Functions](rvv-intrinsic-api.md#1413-vector-floating-point-merge-operations):

**Prototypes:**
``` C
vfloat16m1_t vfmerge_m (vbool16_t mask, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vfmerge_m (vbool16_t mask, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vfmerge_m (vbool8_t mask, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vfmerge_m (vbool8_t mask, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vfmerge_m (vbool4_t mask, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vfmerge_m (vbool4_t mask, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vfmerge_m (vbool2_t mask, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vfmerge_m (vbool2_t mask, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vfmerge_m (vbool32_t mask, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vfmerge_m (vbool32_t mask, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vfmerge_m (vbool16_t mask, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vfmerge_m (vbool16_t mask, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vfmerge_m (vbool8_t mask, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vfmerge_m (vbool8_t mask, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vfmerge_m (vbool4_t mask, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vfmerge_m (vbool4_t mask, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vfmerge_m (vbool64_t mask, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vfmerge_m (vbool64_t mask, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vfmerge_m (vbool32_t mask, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vfmerge_m (vbool32_t mask, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vfmerge_m (vbool16_t mask, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vfmerge_m (vbool16_t mask, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vfmerge_m (vbool8_t mask, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vfmerge_m (vbool8_t mask, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Move Functions](rvv-intrinsic-api.md#1414-vector-floating-point-move-operations):

**Prototypes:**
``` C
vfloat16m1_t vfmv (vfloat16m1_t src);
vfloat16m1_t vfmv_v_f (float16_t src);
vfloat16m2_t vfmv (vfloat16m2_t src);
vfloat16m2_t vfmv_v_f (float16_t src);
vfloat16m4_t vfmv (vfloat16m4_t src);
vfloat16m4_t vfmv_v_f (float16_t src);
vfloat16m8_t vfmv (vfloat16m8_t src);
vfloat16m8_t vfmv_v_f (float16_t src);
vfloat32m1_t vfmv (vfloat32m1_t src);
vfloat32m1_t vfmv_v_f (float32_t src);
vfloat32m2_t vfmv (vfloat32m2_t src);
vfloat32m2_t vfmv_v_f (float32_t src);
vfloat32m4_t vfmv (vfloat32m4_t src);
vfloat32m4_t vfmv_v_f (float32_t src);
vfloat32m8_t vfmv (vfloat32m8_t src);
vfloat32m8_t vfmv_v_f (float32_t src);
vfloat64m1_t vfmv (vfloat64m1_t src);
vfloat64m1_t vfmv_v_f (float64_t src);
vfloat64m2_t vfmv (vfloat64m2_t src);
vfloat64m2_t vfmv_v_f (float64_t src);
vfloat64m4_t vfmv (vfloat64m4_t src);
vfloat64m4_t vfmv_v_f (float64_t src);
vfloat64m8_t vfmv (vfloat64m8_t src);
vfloat64m8_t vfmv_v_f (float64_t src);
```
### [Single-Width Floating-Point/Integer Type-Convert Functions](rvv-intrinsic-api.md#1415-single-width-floating-pointinteger-type-convert-operations):

**Prototypes:**
``` C
vint16m1_t vfcvt_x (vfloat16m1_t src);
vint16m1_t vfcvt_rtz_x (vfloat16m1_t src);
vint16m2_t vfcvt_x (vfloat16m2_t src);
vint16m2_t vfcvt_rtz_x (vfloat16m2_t src);
vint16m4_t vfcvt_x (vfloat16m4_t src);
vint16m4_t vfcvt_rtz_x (vfloat16m4_t src);
vint16m8_t vfcvt_x (vfloat16m8_t src);
vint16m8_t vfcvt_rtz_x (vfloat16m8_t src);
vuint16m1_t vfcvt_xu (vfloat16m1_t src);
vuint16m1_t vfcvt_rtz_xu (vfloat16m1_t src);
vuint16m2_t vfcvt_xu (vfloat16m2_t src);
vuint16m2_t vfcvt_rtz_xu (vfloat16m2_t src);
vuint16m4_t vfcvt_xu (vfloat16m4_t src);
vuint16m4_t vfcvt_rtz_xu (vfloat16m4_t src);
vuint16m8_t vfcvt_xu (vfloat16m8_t src);
vuint16m8_t vfcvt_rtz_xu (vfloat16m8_t src);
vfloat16m1_t vfcvt_f (vint16m1_t src);
vfloat16m2_t vfcvt_f (vint16m2_t src);
vfloat16m4_t vfcvt_f (vint16m4_t src);
vfloat16m8_t vfcvt_f (vint16m8_t src);
vfloat16m1_t vfcvt_f (vuint16m1_t src);
vfloat16m2_t vfcvt_f (vuint16m2_t src);
vfloat16m4_t vfcvt_f (vuint16m4_t src);
vfloat16m8_t vfcvt_f (vuint16m8_t src);
vint32m1_t vfcvt_x (vfloat32m1_t src);
vint32m1_t vfcvt_rtz_x (vfloat32m1_t src);
vint32m2_t vfcvt_x (vfloat32m2_t src);
vint32m2_t vfcvt_rtz_x (vfloat32m2_t src);
vint32m4_t vfcvt_x (vfloat32m4_t src);
vint32m4_t vfcvt_rtz_x (vfloat32m4_t src);
vint32m8_t vfcvt_x (vfloat32m8_t src);
vint32m8_t vfcvt_rtz_x (vfloat32m8_t src);
vuint32m1_t vfcvt_xu (vfloat32m1_t src);
vuint32m1_t vfcvt_rtz_xu (vfloat32m1_t src);
vuint32m2_t vfcvt_xu (vfloat32m2_t src);
vuint32m2_t vfcvt_rtz_xu (vfloat32m2_t src);
vuint32m4_t vfcvt_xu (vfloat32m4_t src);
vuint32m4_t vfcvt_rtz_xu (vfloat32m4_t src);
vuint32m8_t vfcvt_xu (vfloat32m8_t src);
vuint32m8_t vfcvt_rtz_xu (vfloat32m8_t src);
vfloat32m1_t vfcvt_f (vint32m1_t src);
vfloat32m2_t vfcvt_f (vint32m2_t src);
vfloat32m4_t vfcvt_f (vint32m4_t src);
vfloat32m8_t vfcvt_f (vint32m8_t src);
vfloat32m1_t vfcvt_f (vuint32m1_t src);
vfloat32m2_t vfcvt_f (vuint32m2_t src);
vfloat32m4_t vfcvt_f (vuint32m4_t src);
vfloat32m8_t vfcvt_f (vuint32m8_t src);
vint64m1_t vfcvt_x (vfloat64m1_t src);
vint64m1_t vfcvt_rtz_x (vfloat64m1_t src);
vint64m2_t vfcvt_x (vfloat64m2_t src);
vint64m2_t vfcvt_rtz_x (vfloat64m2_t src);
vint64m4_t vfcvt_x (vfloat64m4_t src);
vint64m4_t vfcvt_rtz_x (vfloat64m4_t src);
vint64m8_t vfcvt_x (vfloat64m8_t src);
vint64m8_t vfcvt_rtz_x (vfloat64m8_t src);
vuint64m1_t vfcvt_xu (vfloat64m1_t src);
vuint64m1_t vfcvt_rtz_xu (vfloat64m1_t src);
vuint64m2_t vfcvt_xu (vfloat64m2_t src);
vuint64m2_t vfcvt_rtz_xu (vfloat64m2_t src);
vuint64m4_t vfcvt_xu (vfloat64m4_t src);
vuint64m4_t vfcvt_rtz_xu (vfloat64m4_t src);
vuint64m8_t vfcvt_xu (vfloat64m8_t src);
vuint64m8_t vfcvt_rtz_xu (vfloat64m8_t src);
vfloat64m1_t vfcvt_f (vint64m1_t src);
vfloat64m2_t vfcvt_f (vint64m2_t src);
vfloat64m4_t vfcvt_f (vint64m4_t src);
vfloat64m8_t vfcvt_f (vint64m8_t src);
vfloat64m1_t vfcvt_f (vuint64m1_t src);
vfloat64m2_t vfcvt_f (vuint64m2_t src);
vfloat64m4_t vfcvt_f (vuint64m4_t src);
vfloat64m8_t vfcvt_f (vuint64m8_t src);
// masked functions
vint16m1_t vfcvt_x_m (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src);
vint16m1_t vfcvt_rtz_x_m (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src);
vint16m2_t vfcvt_x_m (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src);
vint16m2_t vfcvt_rtz_x_m (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src);
vint16m4_t vfcvt_x_m (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src);
vint16m4_t vfcvt_rtz_x_m (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src);
vint16m8_t vfcvt_x_m (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src);
vint16m8_t vfcvt_rtz_x_m (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src);
vuint16m1_t vfcvt_xu_m (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src);
vuint16m1_t vfcvt_rtz_xu_m (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src);
vuint16m2_t vfcvt_xu_m (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src);
vuint16m2_t vfcvt_rtz_xu_m (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src);
vuint16m4_t vfcvt_xu_m (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src);
vuint16m4_t vfcvt_rtz_xu_m (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src);
vuint16m8_t vfcvt_xu_m (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src);
vuint16m8_t vfcvt_rtz_xu_m (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src);
vfloat16m1_t vfcvt_f_m (vbool16_t mask, vfloat16m1_t maskedoff, vint16m1_t src);
vfloat16m2_t vfcvt_f_m (vbool8_t mask, vfloat16m2_t maskedoff, vint16m2_t src);
vfloat16m4_t vfcvt_f_m (vbool4_t mask, vfloat16m4_t maskedoff, vint16m4_t src);
vfloat16m8_t vfcvt_f_m (vbool2_t mask, vfloat16m8_t maskedoff, vint16m8_t src);
vfloat16m1_t vfcvt_f_m (vbool16_t mask, vfloat16m1_t maskedoff, vuint16m1_t src);
vfloat16m2_t vfcvt_f_m (vbool8_t mask, vfloat16m2_t maskedoff, vuint16m2_t src);
vfloat16m4_t vfcvt_f_m (vbool4_t mask, vfloat16m4_t maskedoff, vuint16m4_t src);
vfloat16m8_t vfcvt_f_m (vbool2_t mask, vfloat16m8_t maskedoff, vuint16m8_t src);
vint32m1_t vfcvt_x_m (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src);
vint32m1_t vfcvt_rtz_x_m (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src);
vint32m2_t vfcvt_x_m (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src);
vint32m2_t vfcvt_rtz_x_m (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src);
vint32m4_t vfcvt_x_m (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src);
vint32m4_t vfcvt_rtz_x_m (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src);
vint32m8_t vfcvt_x_m (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src);
vint32m8_t vfcvt_rtz_x_m (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src);
vuint32m1_t vfcvt_xu_m (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src);
vuint32m1_t vfcvt_rtz_xu_m (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src);
vuint32m2_t vfcvt_xu_m (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src);
vuint32m2_t vfcvt_rtz_xu_m (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src);
vuint32m4_t vfcvt_xu_m (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src);
vuint32m4_t vfcvt_rtz_xu_m (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src);
vuint32m8_t vfcvt_xu_m (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src);
vuint32m8_t vfcvt_rtz_xu_m (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src);
vfloat32m1_t vfcvt_f_m (vbool32_t mask, vfloat32m1_t maskedoff, vint32m1_t src);
vfloat32m2_t vfcvt_f_m (vbool16_t mask, vfloat32m2_t maskedoff, vint32m2_t src);
vfloat32m4_t vfcvt_f_m (vbool8_t mask, vfloat32m4_t maskedoff, vint32m4_t src);
vfloat32m8_t vfcvt_f_m (vbool4_t mask, vfloat32m8_t maskedoff, vint32m8_t src);
vfloat32m1_t vfcvt_f_m (vbool32_t mask, vfloat32m1_t maskedoff, vuint32m1_t src);
vfloat32m2_t vfcvt_f_m (vbool16_t mask, vfloat32m2_t maskedoff, vuint32m2_t src);
vfloat32m4_t vfcvt_f_m (vbool8_t mask, vfloat32m4_t maskedoff, vuint32m4_t src);
vfloat32m8_t vfcvt_f_m (vbool4_t mask, vfloat32m8_t maskedoff, vuint32m8_t src);
vint64m1_t vfcvt_x_m (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src);
vint64m1_t vfcvt_rtz_x_m (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src);
vint64m2_t vfcvt_x_m (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src);
vint64m2_t vfcvt_rtz_x_m (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src);
vint64m4_t vfcvt_x_m (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src);
vint64m4_t vfcvt_rtz_x_m (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src);
vint64m8_t vfcvt_x_m (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src);
vint64m8_t vfcvt_rtz_x_m (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src);
vuint64m1_t vfcvt_xu_m (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src);
vuint64m1_t vfcvt_rtz_xu_m (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src);
vuint64m2_t vfcvt_xu_m (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src);
vuint64m2_t vfcvt_rtz_xu_m (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src);
vuint64m4_t vfcvt_xu_m (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src);
vuint64m4_t vfcvt_rtz_xu_m (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src);
vuint64m8_t vfcvt_xu_m (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src);
vuint64m8_t vfcvt_rtz_xu_m (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src);
vfloat64m1_t vfcvt_f_m (vbool64_t mask, vfloat64m1_t maskedoff, vint64m1_t src);
vfloat64m2_t vfcvt_f_m (vbool32_t mask, vfloat64m2_t maskedoff, vint64m2_t src);
vfloat64m4_t vfcvt_f_m (vbool16_t mask, vfloat64m4_t maskedoff, vint64m4_t src);
vfloat64m8_t vfcvt_f_m (vbool8_t mask, vfloat64m8_t maskedoff, vint64m8_t src);
vfloat64m1_t vfcvt_f_m (vbool64_t mask, vfloat64m1_t maskedoff, vuint64m1_t src);
vfloat64m2_t vfcvt_f_m (vbool32_t mask, vfloat64m2_t maskedoff, vuint64m2_t src);
vfloat64m4_t vfcvt_f_m (vbool16_t mask, vfloat64m4_t maskedoff, vuint64m4_t src);
vfloat64m8_t vfcvt_f_m (vbool8_t mask, vfloat64m8_t maskedoff, vuint64m8_t src);
```
### [Widening Floating-Point/Integer Type-Convert Functions](rvv-intrinsic-api.md#1416-widening-floating-pointinteger-type-convert-operations):

**Prototypes:**
``` C
vint32m2_t vfwcvt_x (vfloat16m1_t src);
vint32m2_t vfwcvt_rtz_x (vfloat16m1_t src);
vint32m4_t vfwcvt_x (vfloat16m2_t src);
vint32m4_t vfwcvt_rtz_x (vfloat16m2_t src);
vint32m8_t vfwcvt_x (vfloat16m4_t src);
vint32m8_t vfwcvt_rtz_x (vfloat16m4_t src);
vint32m2_t vwcvt_x (vint16m1_t src);
vint32m4_t vwcvt_x (vint16m2_t src);
vint32m8_t vwcvt_x (vint16m4_t src);
vuint32m2_t vwcvt_xu (vuint16m1_t src);
vuint32m4_t vwcvt_xu (vuint16m2_t src);
vuint32m8_t vwcvt_xu (vuint16m4_t src);
vuint32m2_t vfwcvt_xu (vfloat16m1_t src);
vuint32m2_t vfwcvt_rtz_xu (vfloat16m1_t src);
vuint32m4_t vfwcvt_xu (vfloat16m2_t src);
vuint32m4_t vfwcvt_rtz_xu (vfloat16m2_t src);
vuint32m8_t vfwcvt_xu (vfloat16m4_t src);
vuint32m8_t vfwcvt_rtz_xu (vfloat16m4_t src);
vfloat32m2_t vfwcvt_f (vint16m1_t src);
vfloat32m4_t vfwcvt_f (vint16m2_t src);
vfloat32m8_t vfwcvt_f (vint16m4_t src);
vfloat32m2_t vfwcvt_f (vuint16m1_t src);
vfloat32m4_t vfwcvt_f (vuint16m2_t src);
vfloat32m8_t vfwcvt_f (vuint16m4_t src);
vfloat32m2_t vfwcvt_f (vfloat16m1_t src);
vfloat32m4_t vfwcvt_f (vfloat16m2_t src);
vfloat32m8_t vfwcvt_f (vfloat16m4_t src);
vint64m2_t vfwcvt_x (vfloat32m1_t src);
vint64m2_t vfwcvt_rtz_x (vfloat32m1_t src);
vint64m4_t vfwcvt_x (vfloat32m2_t src);
vint64m4_t vfwcvt_rtz_x (vfloat32m2_t src);
vint64m8_t vfwcvt_x (vfloat32m4_t src);
vint64m8_t vfwcvt_rtz_x (vfloat32m4_t src);
vint64m2_t vwcvt_x (vint32m1_t src);
vint64m4_t vwcvt_x (vint32m2_t src);
vint64m8_t vwcvt_x (vint32m4_t src);
vuint64m2_t vwcvt_xu (vuint32m1_t src);
vuint64m4_t vwcvt_xu (vuint32m2_t src);
vuint64m8_t vwcvt_xu (vuint32m4_t src);
vuint64m2_t vfwcvt_xu (vfloat32m1_t src);
vuint64m2_t vfwcvt_rtz_xu (vfloat32m1_t src);
vuint64m4_t vfwcvt_xu (vfloat32m2_t src);
vuint64m4_t vfwcvt_rtz_xu (vfloat32m2_t src);
vuint64m8_t vfwcvt_xu (vfloat32m4_t src);
vuint64m8_t vfwcvt_rtz_xu (vfloat32m4_t src);
vfloat64m2_t vfwcvt_f (vint32m1_t src);
vfloat64m4_t vfwcvt_f (vint32m2_t src);
vfloat64m8_t vfwcvt_f (vint32m4_t src);
vfloat64m2_t vfwcvt_f (vuint32m1_t src);
vfloat64m4_t vfwcvt_f (vuint32m2_t src);
vfloat64m8_t vfwcvt_f (vuint32m4_t src);
vfloat64m2_t vfwcvt_f (vfloat32m1_t src);
vfloat64m4_t vfwcvt_f (vfloat32m2_t src);
vfloat64m8_t vfwcvt_f (vfloat32m4_t src);
// masked functions
vint32m2_t vfwcvt_x_m (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src);
vint32m2_t vfwcvt_rtz_x_m (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src);
vint32m4_t vfwcvt_x_m (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src);
vint32m4_t vfwcvt_rtz_x_m (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src);
vint32m8_t vfwcvt_x_m (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src);
vint32m8_t vfwcvt_rtz_x_m (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src);
vint32m2_t vwcvt_x_m (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t src);
vint32m4_t vwcvt_x_m (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t src);
vint32m8_t vwcvt_x_m (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t src);
vuint32m2_t vwcvt_xu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t src);
vuint32m4_t vwcvt_xu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t src);
vuint32m8_t vwcvt_xu_m (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t src);
vuint32m2_t vfwcvt_xu_m (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src);
vuint32m2_t vfwcvt_rtz_xu_m (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src);
vuint32m4_t vfwcvt_xu_m (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src);
vuint32m4_t vfwcvt_rtz_xu_m (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src);
vuint32m8_t vfwcvt_xu_m (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src);
vuint32m8_t vfwcvt_rtz_xu_m (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src);
vfloat32m2_t vfwcvt_f_m (vbool16_t mask, vfloat32m2_t maskedoff, vint16m1_t src);
vfloat32m4_t vfwcvt_f_m (vbool8_t mask, vfloat32m4_t maskedoff, vint16m2_t src);
vfloat32m8_t vfwcvt_f_m (vbool4_t mask, vfloat32m8_t maskedoff, vint16m4_t src);
vfloat32m2_t vfwcvt_f_m (vbool16_t mask, vfloat32m2_t maskedoff, vuint16m1_t src);
vfloat32m4_t vfwcvt_f_m (vbool8_t mask, vfloat32m4_t maskedoff, vuint16m2_t src);
vfloat32m8_t vfwcvt_f_m (vbool4_t mask, vfloat32m8_t maskedoff, vuint16m4_t src);
vfloat32m2_t vfwcvt_f_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t src);
vfloat32m4_t vfwcvt_f_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t src);
vfloat32m8_t vfwcvt_f_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t src);
vint64m2_t vfwcvt_x_m (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src);
vint64m2_t vfwcvt_rtz_x_m (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src);
vint64m4_t vfwcvt_x_m (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src);
vint64m4_t vfwcvt_rtz_x_m (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src);
vint64m8_t vfwcvt_x_m (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src);
vint64m8_t vfwcvt_rtz_x_m (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src);
vint64m2_t vwcvt_x_m (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t src);
vint64m4_t vwcvt_x_m (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t src);
vint64m8_t vwcvt_x_m (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t src);
vuint64m2_t vwcvt_xu_m (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t src);
vuint64m4_t vwcvt_xu_m (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t src);
vuint64m8_t vwcvt_xu_m (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t src);
vuint64m2_t vfwcvt_xu_m (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src);
vuint64m2_t vfwcvt_rtz_xu_m (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src);
vuint64m4_t vfwcvt_xu_m (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src);
vuint64m4_t vfwcvt_rtz_xu_m (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src);
vuint64m8_t vfwcvt_xu_m (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src);
vuint64m8_t vfwcvt_rtz_xu_m (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src);
vfloat64m2_t vfwcvt_f_m (vbool32_t mask, vfloat64m2_t maskedoff, vint32m1_t src);
vfloat64m4_t vfwcvt_f_m (vbool16_t mask, vfloat64m4_t maskedoff, vint32m2_t src);
vfloat64m8_t vfwcvt_f_m (vbool8_t mask, vfloat64m8_t maskedoff, vint32m4_t src);
vfloat64m2_t vfwcvt_f_m (vbool32_t mask, vfloat64m2_t maskedoff, vuint32m1_t src);
vfloat64m4_t vfwcvt_f_m (vbool16_t mask, vfloat64m4_t maskedoff, vuint32m2_t src);
vfloat64m8_t vfwcvt_f_m (vbool8_t mask, vfloat64m8_t maskedoff, vuint32m4_t src);
vfloat64m2_t vfwcvt_f_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t src);
vfloat64m4_t vfwcvt_f_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t src);
vfloat64m8_t vfwcvt_f_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t src);
```
### [Narrowing Floating-Point/Integer Type-Convert Functions](rvv-intrinsic-api.md#1417-narrowing-floating-pointinteger-type-convert-operations):

**Prototypes:**
``` C
vint16m1_t vfncvt_x (vfloat32m2_t src);
vint16m1_t vfncvt_rtz_x (vfloat32m2_t src);
vint16m2_t vfncvt_x (vfloat32m4_t src);
vint16m2_t vfncvt_rtz_x (vfloat32m4_t src);
vint16m4_t vfncvt_x (vfloat32m8_t src);
vint16m4_t vfncvt_rtz_x (vfloat32m8_t src);
vint16m1_t vncvt_x (vint32m2_t src);
vint16m2_t vncvt_x (vint32m4_t src);
vint16m4_t vncvt_x (vint32m8_t src);
vuint16m1_t vncvt_xu (vuint32m2_t src);
vuint16m2_t vncvt_xu (vuint32m4_t src);
vuint16m4_t vncvt_xu (vuint32m8_t src);
vuint16m1_t vfncvt_xu (vfloat32m2_t src);
vuint16m1_t vfncvt_rtz_xu (vfloat32m2_t src);
vuint16m2_t vfncvt_xu (vfloat32m4_t src);
vuint16m2_t vfncvt_rtz_xu (vfloat32m4_t src);
vuint16m4_t vfncvt_xu (vfloat32m8_t src);
vuint16m4_t vfncvt_rtz_xu (vfloat32m8_t src);
vfloat16m1_t vfncvt_f (vint32m2_t src);
vfloat16m2_t vfncvt_f (vint32m4_t src);
vfloat16m4_t vfncvt_f (vint32m8_t src);
vfloat16m1_t vfncvt_f (vuint32m2_t src);
vfloat16m2_t vfncvt_f (vuint32m4_t src);
vfloat16m4_t vfncvt_f (vuint32m8_t src);
vfloat16m1_t vfncvt_f (vfloat32m2_t src);
vfloat16m1_t vfncvt_rod_f (vfloat32m2_t src);
vfloat16m2_t vfncvt_f (vfloat32m4_t src);
vfloat16m2_t vfncvt_rod_f (vfloat32m4_t src);
vfloat16m4_t vfncvt_f (vfloat32m8_t src);
vfloat16m4_t vfncvt_rod_f (vfloat32m8_t src);
vint32m1_t vfncvt_x (vfloat64m2_t src);
vint32m1_t vfncvt_rtz_x (vfloat64m2_t src);
vint32m2_t vfncvt_x (vfloat64m4_t src);
vint32m2_t vfncvt_rtz_x (vfloat64m4_t src);
vint32m4_t vfncvt_x (vfloat64m8_t src);
vint32m4_t vfncvt_rtz_x (vfloat64m8_t src);
vint32m1_t vncvt_x (vint64m2_t src);
vint32m2_t vncvt_x (vint64m4_t src);
vint32m4_t vncvt_x (vint64m8_t src);
vuint32m1_t vncvt_xu (vuint64m2_t src);
vuint32m2_t vncvt_xu (vuint64m4_t src);
vuint32m4_t vncvt_xu (vuint64m8_t src);
vuint32m1_t vfncvt_xu (vfloat64m2_t src);
vuint32m1_t vfncvt_rtz_xu (vfloat64m2_t src);
vuint32m2_t vfncvt_xu (vfloat64m4_t src);
vuint32m2_t vfncvt_rtz_xu (vfloat64m4_t src);
vuint32m4_t vfncvt_xu (vfloat64m8_t src);
vuint32m4_t vfncvt_rtz_xu (vfloat64m8_t src);
vfloat32m1_t vfncvt_f (vint64m2_t src);
vfloat32m2_t vfncvt_f (vint64m4_t src);
vfloat32m4_t vfncvt_f (vint64m8_t src);
vfloat32m1_t vfncvt_f (vuint64m2_t src);
vfloat32m2_t vfncvt_f (vuint64m4_t src);
vfloat32m4_t vfncvt_f (vuint64m8_t src);
vfloat32m1_t vfncvt_f (vfloat64m2_t src);
vfloat32m1_t vfncvt_rod_f (vfloat64m2_t src);
vfloat32m2_t vfncvt_f (vfloat64m4_t src);
vfloat32m2_t vfncvt_rod_f (vfloat64m4_t src);
vfloat32m4_t vfncvt_f (vfloat64m8_t src);
vfloat32m4_t vfncvt_rod_f (vfloat64m8_t src);
// masked functions
vint16m1_t vfncvt_x_m (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src);
vint16m1_t vfncvt_rtz_x_m (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src);
vint16m2_t vfncvt_x_m (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src);
vint16m2_t vfncvt_rtz_x_m (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src);
vint16m4_t vfncvt_x_m (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src);
vint16m4_t vfncvt_rtz_x_m (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src);
vint16m1_t vncvt_x_m (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t src);
vint16m2_t vncvt_x_m (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t src);
vint16m4_t vncvt_x_m (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t src);
vuint16m1_t vncvt_xu_m (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t src);
vuint16m2_t vncvt_xu_m (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t src);
vuint16m4_t vncvt_xu_m (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t src);
vuint16m1_t vfncvt_xu_m (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src);
vuint16m1_t vfncvt_rtz_xu_m (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src);
vuint16m2_t vfncvt_xu_m (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src);
vuint16m2_t vfncvt_rtz_xu_m (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src);
vuint16m4_t vfncvt_xu_m (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src);
vuint16m4_t vfncvt_rtz_xu_m (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src);
vfloat16m1_t vfncvt_f_m (vbool16_t mask, vfloat16m1_t maskedoff, vint32m2_t src);
vfloat16m2_t vfncvt_f_m (vbool8_t mask, vfloat16m2_t maskedoff, vint32m4_t src);
vfloat16m4_t vfncvt_f_m (vbool4_t mask, vfloat16m4_t maskedoff, vint32m8_t src);
vfloat16m1_t vfncvt_f_m (vbool16_t mask, vfloat16m1_t maskedoff, vuint32m2_t src);
vfloat16m2_t vfncvt_f_m (vbool8_t mask, vfloat16m2_t maskedoff, vuint32m4_t src);
vfloat16m4_t vfncvt_f_m (vbool4_t mask, vfloat16m4_t maskedoff, vuint32m8_t src);
vfloat16m1_t vfncvt_f_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src);
vfloat16m1_t vfncvt_rod_f_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src);
vfloat16m2_t vfncvt_f_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src);
vfloat16m2_t vfncvt_rod_f_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src);
vfloat16m4_t vfncvt_f_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src);
vfloat16m4_t vfncvt_rod_f_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src);
vint32m1_t vfncvt_x_m (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src);
vint32m1_t vfncvt_rtz_x_m (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src);
vint32m2_t vfncvt_x_m (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src);
vint32m2_t vfncvt_rtz_x_m (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src);
vint32m4_t vfncvt_x_m (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src);
vint32m4_t vfncvt_rtz_x_m (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src);
vint32m1_t vncvt_x_m (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t src);
vint32m2_t vncvt_x_m (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t src);
vint32m4_t vncvt_x_m (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t src);
vuint32m1_t vncvt_xu_m (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t src);
vuint32m2_t vncvt_xu_m (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t src);
vuint32m4_t vncvt_xu_m (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t src);
vuint32m1_t vfncvt_xu_m (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src);
vuint32m1_t vfncvt_rtz_xu_m (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src);
vuint32m2_t vfncvt_xu_m (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src);
vuint32m2_t vfncvt_rtz_xu_m (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src);
vuint32m4_t vfncvt_xu_m (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src);
vuint32m4_t vfncvt_rtz_xu_m (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src);
vfloat32m1_t vfncvt_f_m (vbool32_t mask, vfloat32m1_t maskedoff, vint64m2_t src);
vfloat32m2_t vfncvt_f_m (vbool16_t mask, vfloat32m2_t maskedoff, vint64m4_t src);
vfloat32m4_t vfncvt_f_m (vbool8_t mask, vfloat32m4_t maskedoff, vint64m8_t src);
vfloat32m1_t vfncvt_f_m (vbool32_t mask, vfloat32m1_t maskedoff, vuint64m2_t src);
vfloat32m2_t vfncvt_f_m (vbool16_t mask, vfloat32m2_t maskedoff, vuint64m4_t src);
vfloat32m4_t vfncvt_f_m (vbool8_t mask, vfloat32m4_t maskedoff, vuint64m8_t src);
vfloat32m1_t vfncvt_f_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src);
vfloat32m1_t vfncvt_rod_f_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src);
vfloat32m2_t vfncvt_f_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src);
vfloat32m2_t vfncvt_rod_f_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src);
vfloat32m4_t vfncvt_f_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src);
vfloat32m4_t vfncvt_rod_f_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src);
```
## Vector Reduction Functions:

### [Vector Single-Width Integer Reduction Functions](rvv-intrinsic-api.md#151-vector-single-width-integer-reduction-operations):

**Prototypes:**
``` C
vint8m1_t vredsum (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredsum (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredsum (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredsum (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredsum (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredsum (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredsum (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredsum (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredsum (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredsum (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredsum (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredsum (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredsum (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredsum (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredsum (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredsum (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredsum (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredsum (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredsum (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredsum (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmax (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmax (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmax (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmax (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmax (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmax (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmax (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmax (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmax (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmax (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmax (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmax (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmax (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmax (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmax (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmax (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmax (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmax (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmax (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmax (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmin (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmin (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmin (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmin (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmin (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmin (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmin (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmin (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmin (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmin (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmin (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmin (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmin (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmin (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmin (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmin (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmin (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmin (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmin (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmin (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredand (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredand (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredand (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredand (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredand (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredand (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredand (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredand (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredand (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredand (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredand (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredand (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredand (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredand (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredand (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredand (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredand (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredand (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredand (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredand (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredand (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredand (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredand (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredand (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredand (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredand (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredand (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredand (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredand (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredand (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredand (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredand (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredor (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredor (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredor (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredor (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredor (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredor (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredor (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredor (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredor (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredor (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredor (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredor (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredor (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredor (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredor (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredor (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredor (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredor (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredor (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredor (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredor (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredor (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredor (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredor (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredor (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredor (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredor (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredor (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredor (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredor (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredor (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredor (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredxor (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredxor (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredxor (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredxor (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredxor (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredxor (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredxor (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredxor (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredxor (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredxor (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredxor (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredxor (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredxor (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredxor (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredxor (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredxor (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredxor (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredxor (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredxor (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredxor (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor (vuint64m8_t vector, vuint64m1_t scalar);
// masked functions
vint8m1_t vredsum_m (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredsum_m (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredsum_m (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredsum_m (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredsum_m (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredsum_m (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredsum_m (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredsum_m (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredsum_m (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredsum_m (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredsum_m (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredsum_m (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredsum_m (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredsum_m (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredsum_m (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredsum_m (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredsum_m (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_m (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_m (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_m (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredsum_m (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_m (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_m (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_m (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredsum_m (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_m (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_m (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_m (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredsum_m (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_m (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_m (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_m (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmax_m (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmax_m (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmax_m (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmax_m (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmax_m (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmax_m (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmax_m (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmax_m (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmax_m (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmax_m (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmax_m (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmax_m (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmax_m (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmax_m (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmax_m (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmax_m (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmax_m (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_m (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_m (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_m (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmax_m (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_m (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_m (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_m (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmax_m (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_m (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_m (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_m (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmax_m (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_m (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_m (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_m (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmin_m (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmin_m (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmin_m (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmin_m (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmin_m (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmin_m (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmin_m (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmin_m (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmin_m (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmin_m (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmin_m (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmin_m (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmin_m (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmin_m (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmin_m (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmin_m (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmin_m (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_m (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_m (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_m (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmin_m (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_m (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_m (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_m (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmin_m (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_m (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_m (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_m (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmin_m (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_m (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_m (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_m (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredand_m (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredand_m (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredand_m (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredand_m (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredand_m (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredand_m (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredand_m (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredand_m (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredand_m (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredand_m (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredand_m (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredand_m (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredand_m (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredand_m (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredand_m (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredand_m (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredand_m (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_m (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_m (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_m (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredand_m (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_m (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_m (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_m (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredand_m (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_m (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_m (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_m (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredand_m (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_m (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_m (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_m (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredor_m (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredor_m (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredor_m (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredor_m (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredor_m (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredor_m (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredor_m (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredor_m (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredor_m (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredor_m (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredor_m (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredor_m (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredor_m (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredor_m (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredor_m (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredor_m (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredor_m (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_m (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_m (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_m (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredor_m (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_m (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_m (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_m (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredor_m (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_m (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_m (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_m (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredor_m (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_m (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_m (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_m (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredxor_m (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredxor_m (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredxor_m (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredxor_m (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredxor_m (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredxor_m (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredxor_m (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredxor_m (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredxor_m (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredxor_m (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredxor_m (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredxor_m (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredxor_m (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredxor_m (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredxor_m (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredxor_m (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredxor_m (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_m (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_m (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_m (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredxor_m (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_m (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_m (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_m (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredxor_m (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_m (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_m (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_m (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredxor_m (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_m (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_m (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_m (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
```
### [Vector Widening Integer Reduction Functions](rvv-intrinsic-api.md##152-vector-widening-integer-reduction-operations):

**Prototypes:**
``` C
vint16m1_t vwredsum (vint8m1_t vector, vint16m1_t scalar);
vint16m1_t vwredsum (vint8m2_t vector, vint16m1_t scalar);
vint16m1_t vwredsum (vint8m4_t vector, vint16m1_t scalar);
vint32m1_t vwredsum (vint16m1_t vector, vint32m1_t scalar);
vint32m1_t vwredsum (vint16m2_t vector, vint32m1_t scalar);
vint32m1_t vwredsum (vint16m4_t vector, vint32m1_t scalar);
vint64m1_t vwredsum (vint32m1_t vector, vint64m1_t scalar);
vint64m1_t vwredsum (vint32m2_t vector, vint64m1_t scalar);
vint64m1_t vwredsum (vint32m4_t vector, vint64m1_t scalar);
vuint16m1_t vwredsumu (vuint8m1_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsumu (vuint8m2_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsumu (vuint8m4_t vector, vuint16m1_t scalar);
vuint32m1_t vwredsumu (vuint16m1_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsumu (vuint16m2_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsumu (vuint16m4_t vector, vuint32m1_t scalar);
vuint64m1_t vwredsumu (vuint32m1_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsumu (vuint32m2_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsumu (vuint32m4_t vector, vuint64m1_t scalar);
// masked functions
vint16m1_t vwredsum_m (vbool8_t mask, vint8m1_t vector, vint16m1_t scalar);
vint16m1_t vwredsum_m (vbool4_t mask, vint8m2_t vector, vint16m1_t scalar);
vint16m1_t vwredsum_m (vbool2_t mask, vint8m4_t vector, vint16m1_t scalar);
vint32m1_t vwredsum_m (vbool16_t mask, vint16m1_t vector, vint32m1_t scalar);
vint32m1_t vwredsum_m (vbool8_t mask, vint16m2_t vector, vint32m1_t scalar);
vint32m1_t vwredsum_m (vbool4_t mask, vint16m4_t vector, vint32m1_t scalar);
vint64m1_t vwredsum_m (vbool32_t mask, vint32m1_t vector, vint64m1_t scalar);
vint64m1_t vwredsum_m (vbool16_t mask, vint32m2_t vector, vint64m1_t scalar);
vint64m1_t vwredsum_m (vbool8_t mask, vint32m4_t vector, vint64m1_t scalar);
vuint16m1_t vwredsumu_m (vbool8_t mask, vuint8m1_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsumu_m (vbool4_t mask, vuint8m2_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsumu_m (vbool2_t mask, vuint8m4_t vector, vuint16m1_t scalar);
vuint32m1_t vwredsumu_m (vbool16_t mask, vuint16m1_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsumu_m (vbool8_t mask, vuint16m2_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsumu_m (vbool4_t mask, vuint16m4_t vector, vuint32m1_t scalar);
vuint64m1_t vwredsumu_m (vbool32_t mask, vuint32m1_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsumu_m (vbool16_t mask, vuint32m2_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsumu_m (vbool8_t mask, vuint32m4_t vector, vuint64m1_t scalar);
```
### [Vector Single-Width Floating-Point Reduction Functions](rvv-intrinsic-api.md#153-vector-single-width-floating-point-reduction-operations):

**Prototypes:**
``` C
vfloat16m1_t vfredosum (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredosum (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredosum (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredosum (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vfredosum (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredosum (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredosum (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredosum (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfredosum (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredosum (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredosum (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredosum (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vfredsum (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredsum (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredsum (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredsum (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vfredsum (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredsum (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredsum (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredsum (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfredsum (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredsum (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredsum (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredsum (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vfredmax (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmax (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmax (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmax (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vfredmax (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmax (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmax (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmax (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfredmax (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmax (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmax (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmax (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vfredmin (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmin (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmin (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmin (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vfredmin (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmin (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmin (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmin (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfredmin (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmin (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmin (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmin (vfloat64m8_t vector, vfloat64m1_t scalar);
// masked functions
vfloat16m1_t vfredosum_m (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredosum_m (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredosum_m (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredosum_m (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vfredosum_m (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredosum_m (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredosum_m (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredosum_m (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfredosum_m (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredosum_m (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredosum_m (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredosum_m (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vfredsum_m (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredsum_m (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredsum_m (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredsum_m (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vfredsum_m (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredsum_m (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredsum_m (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredsum_m (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfredsum_m (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredsum_m (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredsum_m (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredsum_m (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vfredmax_m (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmax_m (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmax_m (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmax_m (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vfredmax_m (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmax_m (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmax_m (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmax_m (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfredmax_m (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmax_m (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmax_m (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmax_m (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vfredmin_m (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmin_m (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmin_m (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vfredmin_m (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vfredmin_m (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmin_m (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmin_m (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfredmin_m (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfredmin_m (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmin_m (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmin_m (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfredmin_m (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
```
### [Vector Widening Floating-Point Reduction Functions](rvv-intrinsic-api.md#154-vector-widening-floating-point-reduction-operations):

**Prototypes:**
``` C
vfloat32m1_t vfwredosum (vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfwredosum (vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfwredosum (vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfwredosum (vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfwredosum (vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfwredosum (vfloat32m4_t vector, vfloat64m1_t scalar);
vfloat32m1_t vfwredsum (vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfwredsum (vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfwredsum (vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfwredsum (vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfwredsum (vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfwredsum (vfloat32m4_t vector, vfloat64m1_t scalar);
// masked functions
vfloat32m1_t vfwredosum_m (vbool16_t mask, vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfwredosum_m (vbool8_t mask, vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfwredosum_m (vbool4_t mask, vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfwredosum_m (vbool32_t mask, vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfwredosum_m (vbool16_t mask, vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfwredosum_m (vbool8_t mask, vfloat32m4_t vector, vfloat64m1_t scalar);
vfloat32m1_t vfwredsum_m (vbool16_t mask, vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfwredsum_m (vbool8_t mask, vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vfwredsum_m (vbool4_t mask, vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vfwredsum_m (vbool32_t mask, vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfwredsum_m (vbool16_t mask, vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vfwredsum_m (vbool8_t mask, vfloat32m4_t vector, vfloat64m1_t scalar);
```
## Vector Mask Functions:

### [Vector Mask-Register Logical Functions](rvv-intrinsic-api.md#161-vector-mask-register-logical-operations):

**Prototypes:**
``` C
vbool1_t vmand (vbool1_t op1, vbool1_t op2);
vbool2_t vmand (vbool2_t op1, vbool2_t op2);
vbool4_t vmand (vbool4_t op1, vbool4_t op2);
vbool8_t vmand (vbool8_t op1, vbool8_t op2);
vbool16_t vmand (vbool16_t op1, vbool16_t op2);
vbool32_t vmand (vbool32_t op1, vbool32_t op2);
vbool64_t vmand (vbool64_t op1, vbool64_t op2);
vbool1_t vmnand (vbool1_t op1, vbool1_t op2);
vbool2_t vmnand (vbool2_t op1, vbool2_t op2);
vbool4_t vmnand (vbool4_t op1, vbool4_t op2);
vbool8_t vmnand (vbool8_t op1, vbool8_t op2);
vbool16_t vmnand (vbool16_t op1, vbool16_t op2);
vbool32_t vmnand (vbool32_t op1, vbool32_t op2);
vbool64_t vmnand (vbool64_t op1, vbool64_t op2);
vbool1_t vmandnot (vbool1_t op1, vbool1_t op2);
vbool2_t vmandnot (vbool2_t op1, vbool2_t op2);
vbool4_t vmandnot (vbool4_t op1, vbool4_t op2);
vbool8_t vmandnot (vbool8_t op1, vbool8_t op2);
vbool16_t vmandnot (vbool16_t op1, vbool16_t op2);
vbool32_t vmandnot (vbool32_t op1, vbool32_t op2);
vbool64_t vmandnot (vbool64_t op1, vbool64_t op2);
vbool1_t vmxor (vbool1_t op1, vbool1_t op2);
vbool2_t vmxor (vbool2_t op1, vbool2_t op2);
vbool4_t vmxor (vbool4_t op1, vbool4_t op2);
vbool8_t vmxor (vbool8_t op1, vbool8_t op2);
vbool16_t vmxor (vbool16_t op1, vbool16_t op2);
vbool32_t vmxor (vbool32_t op1, vbool32_t op2);
vbool64_t vmxor (vbool64_t op1, vbool64_t op2);
vbool1_t vmor (vbool1_t op1, vbool1_t op2);
vbool2_t vmor (vbool2_t op1, vbool2_t op2);
vbool4_t vmor (vbool4_t op1, vbool4_t op2);
vbool8_t vmor (vbool8_t op1, vbool8_t op2);
vbool16_t vmor (vbool16_t op1, vbool16_t op2);
vbool32_t vmor (vbool32_t op1, vbool32_t op2);
vbool64_t vmor (vbool64_t op1, vbool64_t op2);
vbool1_t vmnor (vbool1_t op1, vbool1_t op2);
vbool2_t vmnor (vbool2_t op1, vbool2_t op2);
vbool4_t vmnor (vbool4_t op1, vbool4_t op2);
vbool8_t vmnor (vbool8_t op1, vbool8_t op2);
vbool16_t vmnor (vbool16_t op1, vbool16_t op2);
vbool32_t vmnor (vbool32_t op1, vbool32_t op2);
vbool64_t vmnor (vbool64_t op1, vbool64_t op2);
vbool1_t vmornot (vbool1_t op1, vbool1_t op2);
vbool2_t vmornot (vbool2_t op1, vbool2_t op2);
vbool4_t vmornot (vbool4_t op1, vbool4_t op2);
vbool8_t vmornot (vbool8_t op1, vbool8_t op2);
vbool16_t vmornot (vbool16_t op1, vbool16_t op2);
vbool32_t vmornot (vbool32_t op1, vbool32_t op2);
vbool64_t vmornot (vbool64_t op1, vbool64_t op2);
vbool1_t vmxnor (vbool1_t op1, vbool1_t op2);
vbool2_t vmxnor (vbool2_t op1, vbool2_t op2);
vbool4_t vmxnor (vbool4_t op1, vbool4_t op2);
vbool8_t vmxnor (vbool8_t op1, vbool8_t op2);
vbool16_t vmxnor (vbool16_t op1, vbool16_t op2);
vbool32_t vmxnor (vbool32_t op1, vbool32_t op2);
vbool64_t vmxnor (vbool64_t op1, vbool64_t op2);
vbool1_t vmcpy (vbool1_t op1);
vbool2_t vmcpy (vbool2_t op1);
vbool4_t vmcpy (vbool4_t op1);
vbool8_t vmcpy (vbool8_t op1);
vbool16_t vmcpy (vbool16_t op1);
vbool32_t vmcpy (vbool32_t op1);
vbool64_t vmcpy (vbool64_t op1);
vbool1_t vmclr_b1 ();
vbool2_t vmclr_b2 ();
vbool4_t vmclr_b4 ();
vbool8_t vmclr_b8 ();
vbool16_t vmclr_b16 ();
vbool32_t vmclr_b32 ();
vbool64_t vmclr_b64 ();
vbool1_t vmset_b1 ();
vbool2_t vmset_b2 ();
vbool4_t vmset_b4 ();
vbool8_t vmset_b8 ();
vbool16_t vmset_b16 ();
vbool32_t vmset_b32 ();
vbool64_t vmset_b64 ();
vbool1_t vmnot (vbool1_t op1);
vbool2_t vmnot (vbool2_t op1);
vbool4_t vmnot (vbool4_t op1);
vbool8_t vmnot (vbool8_t op1);
vbool16_t vmnot (vbool16_t op1);
vbool32_t vmnot (vbool32_t op1);
vbool64_t vmnot (vbool64_t op1);
```
### [Vector mask population count Functions](rvv-intrinsic-api.md#162-vector-mask-population-count-vpopc):

**Prototypes:**
``` C
unsigned long vpopc (vbool1_t op1);
unsigned long vpopc (vbool2_t op1);
unsigned long vpopc (vbool4_t op1);
unsigned long vpopc (vbool8_t op1);
unsigned long vpopc (vbool16_t op1);
unsigned long vpopc (vbool32_t op1);
unsigned long vpopc (vbool64_t op1);
// masked functions
unsigned long vpopc_m (vbool1_t mask, vbool1_t op1);
unsigned long vpopc_m (vbool2_t mask, vbool2_t op1);
unsigned long vpopc_m (vbool4_t mask, vbool4_t op1);
unsigned long vpopc_m (vbool8_t mask, vbool8_t op1);
unsigned long vpopc_m (vbool16_t mask, vbool16_t op1);
unsigned long vpopc_m (vbool32_t mask, vbool32_t op1);
unsigned long vpopc_m (vbool64_t mask, vbool64_t op1);
```
### [Find-first-set mask bit Functions](rvv-intrinsic-api.md#163-vfirst-find-first-set-mask-bit):

**Prototypes:**
``` C
long vfirst (vbool1_t op1);
long vfirst (vbool2_t op1);
long vfirst (vbool4_t op1);
long vfirst (vbool8_t op1);
long vfirst (vbool16_t op1);
long vfirst (vbool32_t op1);
long vfirst (vbool64_t op1);
// masked functions
long vfirst_m (vbool1_t mask, vbool1_t op1);
long vfirst_m (vbool2_t mask, vbool2_t op1);
long vfirst_m (vbool4_t mask, vbool4_t op1);
long vfirst_m (vbool8_t mask, vbool8_t op1);
long vfirst_m (vbool16_t mask, vbool16_t op1);
long vfirst_m (vbool32_t mask, vbool32_t op1);
long vfirst_m (vbool64_t mask, vbool64_t op1);
```
### [Set-before-first mask bit Functions](rvv-intrinsic-api.md#164-vmsbfm-set-before-first-mask-bit):

**Prototypes:**
``` C
vbool1_t vmsbf (vbool1_t op1);
vbool2_t vmsbf (vbool2_t op1);
vbool4_t vmsbf (vbool4_t op1);
vbool8_t vmsbf (vbool8_t op1);
vbool16_t vmsbf (vbool16_t op1);
vbool32_t vmsbf (vbool32_t op1);
vbool64_t vmsbf (vbool64_t op1);
// masked functions
vbool1_t vmsbf_m (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vmsbf_m (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vmsbf_m (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vmsbf_m (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vmsbf_m (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vmsbf_m (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vmsbf_m (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### [Set-including-first mask bit Functions](rvv-intrinsic-api.md#165-vmsifm-set-including-first-mask-bit):

**Prototypes:**
``` C
vbool1_t vmsif (vbool1_t op1);
vbool2_t vmsif (vbool2_t op1);
vbool4_t vmsif (vbool4_t op1);
vbool8_t vmsif (vbool8_t op1);
vbool16_t vmsif (vbool16_t op1);
vbool32_t vmsif (vbool32_t op1);
vbool64_t vmsif (vbool64_t op1);
// masked functions
vbool1_t vmsif_m (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vmsif_m (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vmsif_m (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vmsif_m (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vmsif_m (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vmsif_m (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vmsif_m (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### [Set-only-first mask bit Functions](rvv-intrinsic-api.md#166-vmsofm-set-only-first-mask-bit):

**Prototypes:**
``` C
vbool1_t vmsof (vbool1_t op1);
vbool2_t vmsof (vbool2_t op1);
vbool4_t vmsof (vbool4_t op1);
vbool8_t vmsof (vbool8_t op1);
vbool16_t vmsof (vbool16_t op1);
vbool32_t vmsof (vbool32_t op1);
vbool64_t vmsof (vbool64_t op1);
// masked functions
vbool1_t vmsof_m (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vmsof_m (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vmsof_m (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vmsof_m (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vmsof_m (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vmsof_m (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vmsof_m (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### [Vector Iota Functions](rvv-intrinsic-api.md#168-vector-iota-operations):

**Prototypes:**
``` C
vuint8m1_t viota_m_u8m1 (vbool8_t op1);
vuint8m2_t viota_m_u8m2 (vbool4_t op1);
vuint8m4_t viota_m_u8m4 (vbool2_t op1);
vuint8m8_t viota_m_u8m8 (vbool1_t op1);
vuint16m1_t viota_m_u16m1 (vbool16_t op1);
vuint16m2_t viota_m_u16m2 (vbool8_t op1);
vuint16m4_t viota_m_u16m4 (vbool4_t op1);
vuint16m8_t viota_m_u16m8 (vbool2_t op1);
vuint32m1_t viota_m_u32m1 (vbool32_t op1);
vuint32m2_t viota_m_u32m2 (vbool16_t op1);
vuint32m4_t viota_m_u32m4 (vbool8_t op1);
vuint32m8_t viota_m_u32m8 (vbool4_t op1);
vuint64m1_t viota_m_u64m1 (vbool64_t op1);
vuint64m2_t viota_m_u64m2 (vbool32_t op1);
vuint64m4_t viota_m_u64m4 (vbool16_t op1);
vuint64m8_t viota_m_u64m8 (vbool8_t op1);
// masked functions
vuint8m1_t viota_m_u8m1_m (vbool8_t mask, vuint8m1_t maskedoff, vbool8_t op1);
vuint8m2_t viota_m_u8m2_m (vbool4_t mask, vuint8m2_t maskedoff, vbool4_t op1);
vuint8m4_t viota_m_u8m4_m (vbool2_t mask, vuint8m4_t maskedoff, vbool2_t op1);
vuint8m8_t viota_m_u8m8_m (vbool1_t mask, vuint8m8_t maskedoff, vbool1_t op1);
vuint16m1_t viota_m_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff, vbool16_t op1);
vuint16m2_t viota_m_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff, vbool8_t op1);
vuint16m4_t viota_m_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff, vbool4_t op1);
vuint16m8_t viota_m_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff, vbool2_t op1);
vuint32m1_t viota_m_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff, vbool32_t op1);
vuint32m2_t viota_m_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff, vbool16_t op1);
vuint32m4_t viota_m_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff, vbool8_t op1);
vuint32m8_t viota_m_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff, vbool4_t op1);
vuint64m1_t viota_m_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff, vbool64_t op1);
vuint64m2_t viota_m_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff, vbool32_t op1);
vuint64m4_t viota_m_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff, vbool16_t op1);
vuint64m8_t viota_m_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff, vbool8_t op1);
```
### [Vector Element Index Functions](rvv-intrinsic-api.md#169-vector-element-index-operations):

**Prototypes:**
``` C
vuint8m1_t vid_v_u8m1 ();
vuint8m2_t vid_v_u8m2 ();
vuint8m4_t vid_v_u8m4 ();
vuint8m8_t vid_v_u8m8 ();
vuint16m1_t vid_v_u16m1 ();
vuint16m2_t vid_v_u16m2 ();
vuint16m4_t vid_v_u16m4 ();
vuint16m8_t vid_v_u16m8 ();
vuint32m1_t vid_v_u32m1 ();
vuint32m2_t vid_v_u32m2 ();
vuint32m4_t vid_v_u32m4 ();
vuint32m8_t vid_v_u32m8 ();
vuint64m1_t vid_v_u64m1 ();
vuint64m2_t vid_v_u64m2 ();
vuint64m4_t vid_v_u64m4 ();
vuint64m8_t vid_v_u64m8 ();
// masked functions
vuint8m1_t vid_v_u8m1_m (vbool8_t mask, vuint8m1_t maskedoff);
vuint8m2_t vid_v_u8m2_m (vbool4_t mask, vuint8m2_t maskedoff);
vuint8m4_t vid_v_u8m4_m (vbool2_t mask, vuint8m4_t maskedoff);
vuint8m8_t vid_v_u8m8_m (vbool1_t mask, vuint8m8_t maskedoff);
vuint16m1_t vid_v_u16m1_m (vbool16_t mask, vuint16m1_t maskedoff);
vuint16m2_t vid_v_u16m2_m (vbool8_t mask, vuint16m2_t maskedoff);
vuint16m4_t vid_v_u16m4_m (vbool4_t mask, vuint16m4_t maskedoff);
vuint16m8_t vid_v_u16m8_m (vbool2_t mask, vuint16m8_t maskedoff);
vuint32m1_t vid_v_u32m1_m (vbool32_t mask, vuint32m1_t maskedoff);
vuint32m2_t vid_v_u32m2_m (vbool16_t mask, vuint32m2_t maskedoff);
vuint32m4_t vid_v_u32m4_m (vbool8_t mask, vuint32m4_t maskedoff);
vuint32m8_t vid_v_u32m8_m (vbool4_t mask, vuint32m8_t maskedoff);
vuint64m1_t vid_v_u64m1_m (vbool64_t mask, vuint64m1_t maskedoff);
vuint64m2_t vid_v_u64m2_m (vbool32_t mask, vuint64m2_t maskedoff);
vuint64m4_t vid_v_u64m4_m (vbool16_t mask, vuint64m4_t maskedoff);
vuint64m8_t vid_v_u64m8_m (vbool8_t mask, vuint64m8_t maskedoff);
```
## Vector Permutation Functions:

### [Integer and Floating-Point Scalar Move Functions](rvv-intrinsic-api.md#171-integer-scalar-move-operations):

**Prototypes:**
``` C
int8_t vmv_x_s (vint8m1_t src);
vint8m1_t vmv_s_x (vint8m1_t dst, int8_t src);
int8_t vmv_x_s (vint8m2_t src);
vint8m2_t vmv_s_x (vint8m2_t dst, int8_t src);
int8_t vmv_x_s (vint8m4_t src);
vint8m4_t vmv_s_x (vint8m4_t dst, int8_t src);
int8_t vmv_x_s (vint8m8_t src);
vint8m8_t vmv_s_x (vint8m8_t dst, int8_t src);
int16_t vmv_x_s (vint16m1_t src);
vint16m1_t vmv_s_x (vint16m1_t dst, int16_t src);
int16_t vmv_x_s (vint16m2_t src);
vint16m2_t vmv_s_x (vint16m2_t dst, int16_t src);
int16_t vmv_x_s (vint16m4_t src);
vint16m4_t vmv_s_x (vint16m4_t dst, int16_t src);
int16_t vmv_x_s (vint16m8_t src);
vint16m8_t vmv_s_x (vint16m8_t dst, int16_t src);
int32_t vmv_x_s (vint32m1_t src);
vint32m1_t vmv_s_x (vint32m1_t dst, int32_t src);
int32_t vmv_x_s (vint32m2_t src);
vint32m2_t vmv_s_x (vint32m2_t dst, int32_t src);
int32_t vmv_x_s (vint32m4_t src);
vint32m4_t vmv_s_x (vint32m4_t dst, int32_t src);
int32_t vmv_x_s (vint32m8_t src);
vint32m8_t vmv_s_x (vint32m8_t dst, int32_t src);
int64_t vmv_x_s (vint64m1_t src);
vint64m1_t vmv_s_x (vint64m1_t dst, int64_t src);
int64_t vmv_x_s (vint64m2_t src);
vint64m2_t vmv_s_x (vint64m2_t dst, int64_t src);
int64_t vmv_x_s (vint64m4_t src);
vint64m4_t vmv_s_x (vint64m4_t dst, int64_t src);
int64_t vmv_x_s (vint64m8_t src);
vint64m8_t vmv_s_x (vint64m8_t dst, int64_t src);
uint8_t vmv_x_s (vuint8m1_t src);
vuint8m1_t vmv_s_x (vuint8m1_t dst, uint8_t src);
uint8_t vmv_x_s (vuint8m2_t src);
vuint8m2_t vmv_s_x (vuint8m2_t dst, uint8_t src);
uint8_t vmv_x_s (vuint8m4_t src);
vuint8m4_t vmv_s_x (vuint8m4_t dst, uint8_t src);
uint8_t vmv_x_s (vuint8m8_t src);
vuint8m8_t vmv_s_x (vuint8m8_t dst, uint8_t src);
uint16_t vmv_x_s (vuint16m1_t src);
vuint16m1_t vmv_s_x (vuint16m1_t dst, uint16_t src);
uint16_t vmv_x_s (vuint16m2_t src);
vuint16m2_t vmv_s_x (vuint16m2_t dst, uint16_t src);
uint16_t vmv_x_s (vuint16m4_t src);
vuint16m4_t vmv_s_x (vuint16m4_t dst, uint16_t src);
uint16_t vmv_x_s (vuint16m8_t src);
vuint16m8_t vmv_s_x (vuint16m8_t dst, uint16_t src);
uint32_t vmv_x_s (vuint32m1_t src);
vuint32m1_t vmv_s_x (vuint32m1_t dst, uint32_t src);
uint32_t vmv_x_s (vuint32m2_t src);
vuint32m2_t vmv_s_x (vuint32m2_t dst, uint32_t src);
uint32_t vmv_x_s (vuint32m4_t src);
vuint32m4_t vmv_s_x (vuint32m4_t dst, uint32_t src);
uint32_t vmv_x_s (vuint32m8_t src);
vuint32m8_t vmv_s_x (vuint32m8_t dst, uint32_t src);
uint64_t vmv_x_s (vuint64m1_t src);
vuint64m1_t vmv_s_x (vuint64m1_t dst, uint64_t src);
uint64_t vmv_x_s (vuint64m2_t src);
vuint64m2_t vmv_s_x (vuint64m2_t dst, uint64_t src);
uint64_t vmv_x_s (vuint64m4_t src);
vuint64m4_t vmv_s_x (vuint64m4_t dst, uint64_t src);
uint64_t vmv_x_s (vuint64m8_t src);
vuint64m8_t vmv_s_x (vuint64m8_t dst, uint64_t src);
float16_t vfmv_f_s (vfloat16m1_t src);
vfloat16m1_t vfmv_s_f (vfloat16m1_t dst, float16_t src);
float16_t vfmv_f_s (vfloat16m2_t src);
vfloat16m2_t vfmv_s_f (vfloat16m2_t dst, float16_t src);
float16_t vfmv_f_s (vfloat16m4_t src);
vfloat16m4_t vfmv_s_f (vfloat16m4_t dst, float16_t src);
float16_t vfmv_f_s (vfloat16m8_t src);
vfloat16m8_t vfmv_s_f (vfloat16m8_t dst, float16_t src);
float32_t vfmv_f_s (vfloat32m1_t src);
vfloat32m1_t vfmv_s_f (vfloat32m1_t dst, float32_t src);
float32_t vfmv_f_s (vfloat32m2_t src);
vfloat32m2_t vfmv_s_f (vfloat32m2_t dst, float32_t src);
float32_t vfmv_f_s (vfloat32m4_t src);
vfloat32m4_t vfmv_s_f (vfloat32m4_t dst, float32_t src);
float32_t vfmv_f_s (vfloat32m8_t src);
vfloat32m8_t vfmv_s_f (vfloat32m8_t dst, float32_t src);
float64_t vfmv_f_s (vfloat64m1_t src);
vfloat64m1_t vfmv_s_f (vfloat64m1_t dst, float64_t src);
float64_t vfmv_f_s (vfloat64m2_t src);
vfloat64m2_t vfmv_s_f (vfloat64m2_t dst, float64_t src);
float64_t vfmv_f_s (vfloat64m4_t src);
vfloat64m4_t vfmv_s_f (vfloat64m4_t dst, float64_t src);
float64_t vfmv_f_s (vfloat64m8_t src);
vfloat64m8_t vfmv_s_f (vfloat64m8_t dst, float64_t src);
```
### [Vector Slideup and Slidedown Functions](rvv-intrinsic-api.md#173-vector-slide-operations):

**Prototypes:**
``` C
vint8m1_t vslideup (vint8m1_t src, size_t offset);
vint8m2_t vslideup (vint8m2_t src, size_t offset);
vint8m4_t vslideup (vint8m4_t src, size_t offset);
vint8m8_t vslideup (vint8m8_t src, size_t offset);
vint16m1_t vslideup (vint16m1_t src, size_t offset);
vint16m2_t vslideup (vint16m2_t src, size_t offset);
vint16m4_t vslideup (vint16m4_t src, size_t offset);
vint16m8_t vslideup (vint16m8_t src, size_t offset);
vint32m1_t vslideup (vint32m1_t src, size_t offset);
vint32m2_t vslideup (vint32m2_t src, size_t offset);
vint32m4_t vslideup (vint32m4_t src, size_t offset);
vint32m8_t vslideup (vint32m8_t src, size_t offset);
vint64m1_t vslideup (vint64m1_t src, size_t offset);
vint64m2_t vslideup (vint64m2_t src, size_t offset);
vint64m4_t vslideup (vint64m4_t src, size_t offset);
vint64m8_t vslideup (vint64m8_t src, size_t offset);
vuint8m1_t vslideup (vuint8m1_t src, size_t offset);
vuint8m2_t vslideup (vuint8m2_t src, size_t offset);
vuint8m4_t vslideup (vuint8m4_t src, size_t offset);
vuint8m8_t vslideup (vuint8m8_t src, size_t offset);
vuint16m1_t vslideup (vuint16m1_t src, size_t offset);
vuint16m2_t vslideup (vuint16m2_t src, size_t offset);
vuint16m4_t vslideup (vuint16m4_t src, size_t offset);
vuint16m8_t vslideup (vuint16m8_t src, size_t offset);
vuint32m1_t vslideup (vuint32m1_t src, size_t offset);
vuint32m2_t vslideup (vuint32m2_t src, size_t offset);
vuint32m4_t vslideup (vuint32m4_t src, size_t offset);
vuint32m8_t vslideup (vuint32m8_t src, size_t offset);
vuint64m1_t vslideup (vuint64m1_t src, size_t offset);
vuint64m2_t vslideup (vuint64m2_t src, size_t offset);
vuint64m4_t vslideup (vuint64m4_t src, size_t offset);
vuint64m8_t vslideup (vuint64m8_t src, size_t offset);
vfloat16m1_t vfslideup (vfloat16m1_t src, size_t offset);
vfloat16m2_t vfslideup (vfloat16m2_t src, size_t offset);
vfloat16m4_t vfslideup (vfloat16m4_t src, size_t offset);
vfloat16m8_t vfslideup (vfloat16m8_t src, size_t offset);
vfloat32m1_t vfslideup (vfloat32m1_t src, size_t offset);
vfloat32m2_t vfslideup (vfloat32m2_t src, size_t offset);
vfloat32m4_t vfslideup (vfloat32m4_t src, size_t offset);
vfloat32m8_t vfslideup (vfloat32m8_t src, size_t offset);
vfloat64m1_t vfslideup (vfloat64m1_t src, size_t offset);
vfloat64m2_t vfslideup (vfloat64m2_t src, size_t offset);
vfloat64m4_t vfslideup (vfloat64m4_t src, size_t offset);
vfloat64m8_t vfslideup (vfloat64m8_t src, size_t offset);
vint8m1_t vslidedown (vint8m1_t src, size_t offset);
vint8m2_t vslidedown (vint8m2_t src, size_t offset);
vint8m4_t vslidedown (vint8m4_t src, size_t offset);
vint8m8_t vslidedown (vint8m8_t src, size_t offset);
vint16m1_t vslidedown (vint16m1_t src, size_t offset);
vint16m2_t vslidedown (vint16m2_t src, size_t offset);
vint16m4_t vslidedown (vint16m4_t src, size_t offset);
vint16m8_t vslidedown (vint16m8_t src, size_t offset);
vint32m1_t vslidedown (vint32m1_t src, size_t offset);
vint32m2_t vslidedown (vint32m2_t src, size_t offset);
vint32m4_t vslidedown (vint32m4_t src, size_t offset);
vint32m8_t vslidedown (vint32m8_t src, size_t offset);
vint64m1_t vslidedown (vint64m1_t src, size_t offset);
vint64m2_t vslidedown (vint64m2_t src, size_t offset);
vint64m4_t vslidedown (vint64m4_t src, size_t offset);
vint64m8_t vslidedown (vint64m8_t src, size_t offset);
vuint8m1_t vslidedown (vuint8m1_t src, size_t offset);
vuint8m2_t vslidedown (vuint8m2_t src, size_t offset);
vuint8m4_t vslidedown (vuint8m4_t src, size_t offset);
vuint8m8_t vslidedown (vuint8m8_t src, size_t offset);
vuint16m1_t vslidedown (vuint16m1_t src, size_t offset);
vuint16m2_t vslidedown (vuint16m2_t src, size_t offset);
vuint16m4_t vslidedown (vuint16m4_t src, size_t offset);
vuint16m8_t vslidedown (vuint16m8_t src, size_t offset);
vuint32m1_t vslidedown (vuint32m1_t src, size_t offset);
vuint32m2_t vslidedown (vuint32m2_t src, size_t offset);
vuint32m4_t vslidedown (vuint32m4_t src, size_t offset);
vuint32m8_t vslidedown (vuint32m8_t src, size_t offset);
vuint64m1_t vslidedown (vuint64m1_t src, size_t offset);
vuint64m2_t vslidedown (vuint64m2_t src, size_t offset);
vuint64m4_t vslidedown (vuint64m4_t src, size_t offset);
vuint64m8_t vslidedown (vuint64m8_t src, size_t offset);
vfloat16m1_t vfslidedown (vfloat16m1_t src, size_t offset);
vfloat16m2_t vfslidedown (vfloat16m2_t src, size_t offset);
vfloat16m4_t vfslidedown (vfloat16m4_t src, size_t offset);
vfloat16m8_t vfslidedown (vfloat16m8_t src, size_t offset);
vfloat32m1_t vfslidedown (vfloat32m1_t src, size_t offset);
vfloat32m2_t vfslidedown (vfloat32m2_t src, size_t offset);
vfloat32m4_t vfslidedown (vfloat32m4_t src, size_t offset);
vfloat32m8_t vfslidedown (vfloat32m8_t src, size_t offset);
vfloat64m1_t vfslidedown (vfloat64m1_t src, size_t offset);
vfloat64m2_t vfslidedown (vfloat64m2_t src, size_t offset);
vfloat64m4_t vfslidedown (vfloat64m4_t src, size_t offset);
vfloat64m8_t vfslidedown (vfloat64m8_t src, size_t offset);
// masked functions
vint8m1_t vslideup_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset);
vint8m2_t vslideup_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset);
vint8m4_t vslideup_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset);
vint8m8_t vslideup_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset);
vint16m1_t vslideup_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset);
vint16m2_t vslideup_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset);
vint16m4_t vslideup_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset);
vint16m8_t vslideup_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset);
vint32m1_t vslideup_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset);
vint32m2_t vslideup_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset);
vint32m4_t vslideup_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset);
vint32m8_t vslideup_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset);
vint64m1_t vslideup_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset);
vint64m2_t vslideup_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset);
vint64m4_t vslideup_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset);
vint64m8_t vslideup_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset);
vuint8m1_t vslideup_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset);
vuint8m2_t vslideup_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset);
vuint8m4_t vslideup_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset);
vuint8m8_t vslideup_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset);
vuint16m1_t vslideup_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset);
vuint16m2_t vslideup_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset);
vuint16m4_t vslideup_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset);
vuint16m8_t vslideup_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset);
vuint32m1_t vslideup_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset);
vuint32m2_t vslideup_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset);
vuint32m4_t vslideup_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset);
vuint32m8_t vslideup_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset);
vuint64m1_t vslideup_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset);
vuint64m2_t vslideup_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset);
vuint64m4_t vslideup_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset);
vuint64m8_t vslideup_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset);
vfloat16m1_t vfslideup_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset);
vfloat16m2_t vfslideup_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset);
vfloat16m4_t vfslideup_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset);
vfloat16m8_t vfslideup_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset);
vfloat32m1_t vfslideup_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset);
vfloat32m2_t vfslideup_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset);
vfloat32m4_t vfslideup_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset);
vfloat32m8_t vfslideup_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset);
vfloat64m1_t vfslideup_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset);
vfloat64m2_t vfslideup_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset);
vfloat64m4_t vfslideup_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset);
vfloat64m8_t vfslideup_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset);
vint8m1_t vslidedown_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset);
vint8m2_t vslidedown_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset);
vint8m4_t vslidedown_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset);
vint8m8_t vslidedown_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset);
vint16m1_t vslidedown_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset);
vint16m2_t vslidedown_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset);
vint16m4_t vslidedown_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset);
vint16m8_t vslidedown_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset);
vint32m1_t vslidedown_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset);
vint32m2_t vslidedown_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset);
vint32m4_t vslidedown_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset);
vint32m8_t vslidedown_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset);
vint64m1_t vslidedown_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset);
vint64m2_t vslidedown_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset);
vint64m4_t vslidedown_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset);
vint64m8_t vslidedown_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset);
vuint8m1_t vslidedown_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset);
vuint8m2_t vslidedown_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset);
vuint8m4_t vslidedown_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset);
vuint8m8_t vslidedown_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset);
vuint16m1_t vslidedown_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset);
vuint16m2_t vslidedown_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset);
vuint16m4_t vslidedown_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset);
vuint16m8_t vslidedown_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset);
vuint32m1_t vslidedown_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset);
vuint32m2_t vslidedown_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset);
vuint32m4_t vslidedown_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset);
vuint32m8_t vslidedown_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset);
vuint64m1_t vslidedown_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset);
vuint64m2_t vslidedown_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset);
vuint64m4_t vslidedown_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset);
vuint64m8_t vslidedown_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset);
vfloat16m1_t vfslidedown_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset);
vfloat16m2_t vfslidedown_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset);
vfloat16m4_t vfslidedown_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset);
vfloat16m8_t vfslidedown_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset);
vfloat32m1_t vfslidedown_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset);
vfloat32m2_t vfslidedown_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset);
vfloat32m4_t vfslidedown_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset);
vfloat32m8_t vfslidedown_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset);
vfloat64m1_t vfslidedown_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset);
vfloat64m2_t vfslidedown_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset);
vfloat64m4_t vfslidedown_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset);
vfloat64m8_t vfslidedown_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset);
```
### [Vector Slide1up and Slide1down Functions](rvv-intrinsic-api.md#173-vector-slide1up-and-slide1down-functions):

**Prototypes:**
``` C
vint8m1_t vslide1up (vint8m1_t src, long value);
vint8m2_t vslide1up (vint8m2_t src, long value);
vint8m4_t vslide1up (vint8m4_t src, long value);
vint8m8_t vslide1up (vint8m8_t src, long value);
vint16m1_t vslide1up (vint16m1_t src, long value);
vint16m2_t vslide1up (vint16m2_t src, long value);
vint16m4_t vslide1up (vint16m4_t src, long value);
vint16m8_t vslide1up (vint16m8_t src, long value);
vint32m1_t vslide1up (vint32m1_t src, long value);
vint32m2_t vslide1up (vint32m2_t src, long value);
vint32m4_t vslide1up (vint32m4_t src, long value);
vint32m8_t vslide1up (vint32m8_t src, long value);
vint64m1_t vslide1up (vint64m1_t src, long value);
vint64m2_t vslide1up (vint64m2_t src, long value);
vint64m4_t vslide1up (vint64m4_t src, long value);
vint64m8_t vslide1up (vint64m8_t src, long value);
vuint8m1_t vslide1up (vuint8m1_t src, long value);
vuint8m2_t vslide1up (vuint8m2_t src, long value);
vuint8m4_t vslide1up (vuint8m4_t src, long value);
vuint8m8_t vslide1up (vuint8m8_t src, long value);
vuint16m1_t vslide1up (vuint16m1_t src, long value);
vuint16m2_t vslide1up (vuint16m2_t src, long value);
vuint16m4_t vslide1up (vuint16m4_t src, long value);
vuint16m8_t vslide1up (vuint16m8_t src, long value);
vuint32m1_t vslide1up (vuint32m1_t src, long value);
vuint32m2_t vslide1up (vuint32m2_t src, long value);
vuint32m4_t vslide1up (vuint32m4_t src, long value);
vuint32m8_t vslide1up (vuint32m8_t src, long value);
vuint64m1_t vslide1up (vuint64m1_t src, long value);
vuint64m2_t vslide1up (vuint64m2_t src, long value);
vuint64m4_t vslide1up (vuint64m4_t src, long value);
vuint64m8_t vslide1up (vuint64m8_t src, long value);
vfloat16m1_t vfslide1up (vfloat16m1_t src, float16_t value);
vfloat16m2_t vfslide1up (vfloat16m2_t src, float16_t value);
vfloat16m4_t vfslide1up (vfloat16m4_t src, float16_t value);
vfloat16m8_t vfslide1up (vfloat16m8_t src, float16_t value);
vfloat32m1_t vfslide1up (vfloat32m1_t src, float32_t value);
vfloat32m2_t vfslide1up (vfloat32m2_t src, float32_t value);
vfloat32m4_t vfslide1up (vfloat32m4_t src, float32_t value);
vfloat32m8_t vfslide1up (vfloat32m8_t src, float32_t value);
vfloat64m1_t vfslide1up (vfloat64m1_t src, float64_t value);
vfloat64m2_t vfslide1up (vfloat64m2_t src, float64_t value);
vfloat64m4_t vfslide1up (vfloat64m4_t src, float64_t value);
vfloat64m8_t vfslide1up (vfloat64m8_t src, float64_t value);
vint8m1_t vslide1down (vint8m1_t src, long value);
vint8m2_t vslide1down (vint8m2_t src, long value);
vint8m4_t vslide1down (vint8m4_t src, long value);
vint8m8_t vslide1down (vint8m8_t src, long value);
vint16m1_t vslide1down (vint16m1_t src, long value);
vint16m2_t vslide1down (vint16m2_t src, long value);
vint16m4_t vslide1down (vint16m4_t src, long value);
vint16m8_t vslide1down (vint16m8_t src, long value);
vint32m1_t vslide1down (vint32m1_t src, long value);
vint32m2_t vslide1down (vint32m2_t src, long value);
vint32m4_t vslide1down (vint32m4_t src, long value);
vint32m8_t vslide1down (vint32m8_t src, long value);
vint64m1_t vslide1down (vint64m1_t src, long value);
vint64m2_t vslide1down (vint64m2_t src, long value);
vint64m4_t vslide1down (vint64m4_t src, long value);
vint64m8_t vslide1down (vint64m8_t src, long value);
vuint8m1_t vslide1down (vuint8m1_t src, long value);
vuint8m2_t vslide1down (vuint8m2_t src, long value);
vuint8m4_t vslide1down (vuint8m4_t src, long value);
vuint8m8_t vslide1down (vuint8m8_t src, long value);
vuint16m1_t vslide1down (vuint16m1_t src, long value);
vuint16m2_t vslide1down (vuint16m2_t src, long value);
vuint16m4_t vslide1down (vuint16m4_t src, long value);
vuint16m8_t vslide1down (vuint16m8_t src, long value);
vuint32m1_t vslide1down (vuint32m1_t src, long value);
vuint32m2_t vslide1down (vuint32m2_t src, long value);
vuint32m4_t vslide1down (vuint32m4_t src, long value);
vuint32m8_t vslide1down (vuint32m8_t src, long value);
vuint64m1_t vslide1down (vuint64m1_t src, long value);
vuint64m2_t vslide1down (vuint64m2_t src, long value);
vuint64m4_t vslide1down (vuint64m4_t src, long value);
vuint64m8_t vslide1down (vuint64m8_t src, long value);
vfloat16m1_t vfslide1down (vfloat16m1_t src, float16_t value);
vfloat16m2_t vfslide1down (vfloat16m2_t src, float16_t value);
vfloat16m4_t vfslide1down (vfloat16m4_t src, float16_t value);
vfloat16m8_t vfslide1down (vfloat16m8_t src, float16_t value);
vfloat32m1_t vfslide1down (vfloat32m1_t src, float32_t value);
vfloat32m2_t vfslide1down (vfloat32m2_t src, float32_t value);
vfloat32m4_t vfslide1down (vfloat32m4_t src, float32_t value);
vfloat32m8_t vfslide1down (vfloat32m8_t src, float32_t value);
vfloat64m1_t vfslide1down (vfloat64m1_t src, float64_t value);
vfloat64m2_t vfslide1down (vfloat64m2_t src, float64_t value);
vfloat64m4_t vfslide1down (vfloat64m4_t src, float64_t value);
vfloat64m8_t vfslide1down (vfloat64m8_t src, float64_t value);
// masked functions
vint8m1_t vslide1up_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, long value);
vint8m2_t vslide1up_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, long value);
vint8m4_t vslide1up_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, long value);
vint8m8_t vslide1up_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, long value);
vint16m1_t vslide1up_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, long value);
vint16m2_t vslide1up_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, long value);
vint16m4_t vslide1up_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, long value);
vint16m8_t vslide1up_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, long value);
vint32m1_t vslide1up_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, long value);
vint32m2_t vslide1up_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, long value);
vint32m4_t vslide1up_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, long value);
vint32m8_t vslide1up_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, long value);
vint64m1_t vslide1up_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, long value);
vint64m2_t vslide1up_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, long value);
vint64m4_t vslide1up_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, long value);
vint64m8_t vslide1up_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, long value);
vuint8m1_t vslide1up_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, long value);
vuint8m2_t vslide1up_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, long value);
vuint8m4_t vslide1up_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, long value);
vuint8m8_t vslide1up_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, long value);
vuint16m1_t vslide1up_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, long value);
vuint16m2_t vslide1up_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, long value);
vuint16m4_t vslide1up_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, long value);
vuint16m8_t vslide1up_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, long value);
vuint32m1_t vslide1up_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, long value);
vuint32m2_t vslide1up_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, long value);
vuint32m4_t vslide1up_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, long value);
vuint32m8_t vslide1up_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, long value);
vuint64m1_t vslide1up_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, long value);
vuint64m2_t vslide1up_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, long value);
vuint64m4_t vslide1up_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, long value);
vuint64m8_t vslide1up_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, long value);
vfloat16m1_t vfslide1up_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, float16_t value);
vfloat16m2_t vfslide1up_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, float16_t value);
vfloat16m4_t vfslide1up_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, float16_t value);
vfloat16m8_t vfslide1up_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, float16_t value);
vfloat32m1_t vfslide1up_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, float32_t value);
vfloat32m2_t vfslide1up_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, float32_t value);
vfloat32m4_t vfslide1up_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, float32_t value);
vfloat32m8_t vfslide1up_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, float32_t value);
vfloat64m1_t vfslide1up_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, float64_t value);
vfloat64m2_t vfslide1up_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, float64_t value);
vfloat64m4_t vfslide1up_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, float64_t value);
vfloat64m8_t vfslide1up_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, float64_t value);
vint8m1_t vslide1down_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, long value);
vint8m2_t vslide1down_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, long value);
vint8m4_t vslide1down_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, long value);
vint8m8_t vslide1down_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, long value);
vint16m1_t vslide1down_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, long value);
vint16m2_t vslide1down_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, long value);
vint16m4_t vslide1down_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, long value);
vint16m8_t vslide1down_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, long value);
vint32m1_t vslide1down_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, long value);
vint32m2_t vslide1down_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, long value);
vint32m4_t vslide1down_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, long value);
vint32m8_t vslide1down_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, long value);
vint64m1_t vslide1down_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, long value);
vint64m2_t vslide1down_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, long value);
vint64m4_t vslide1down_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, long value);
vint64m8_t vslide1down_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, long value);
vuint8m1_t vslide1down_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, long value);
vuint8m2_t vslide1down_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, long value);
vuint8m4_t vslide1down_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, long value);
vuint8m8_t vslide1down_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, long value);
vuint16m1_t vslide1down_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, long value);
vuint16m2_t vslide1down_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, long value);
vuint16m4_t vslide1down_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, long value);
vuint16m8_t vslide1down_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, long value);
vuint32m1_t vslide1down_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, long value);
vuint32m2_t vslide1down_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, long value);
vuint32m4_t vslide1down_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, long value);
vuint32m8_t vslide1down_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, long value);
vuint64m1_t vslide1down_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, long value);
vuint64m2_t vslide1down_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, long value);
vuint64m4_t vslide1down_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, long value);
vuint64m8_t vslide1down_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, long value);
vfloat16m1_t vfslide1down_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, float16_t value);
vfloat16m2_t vfslide1down_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, float16_t value);
vfloat16m4_t vfslide1down_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, float16_t value);
vfloat16m8_t vfslide1down_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, float16_t value);
vfloat32m1_t vfslide1down_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, float32_t value);
vfloat32m2_t vfslide1down_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, float32_t value);
vfloat32m4_t vfslide1down_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, float32_t value);
vfloat32m8_t vfslide1down_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, float32_t value);
vfloat64m1_t vfslide1down_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, float64_t value);
vfloat64m2_t vfslide1down_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, float64_t value);
vfloat64m4_t vfslide1down_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, float64_t value);
vfloat64m8_t vfslide1down_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, float64_t value);
```
### [Vector Register Gather Functions](rvv-intrinsic-api.md#174-vector-register-gather-operations):

**Prototypes:**
``` C
vint8m1_t vrgather (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vrgather (vint8m1_t op1, uint8_t op2);
vint8m2_t vrgather (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vrgather (vint8m2_t op1, uint8_t op2);
vint8m4_t vrgather (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vrgather (vint8m4_t op1, uint8_t op2);
vint8m8_t vrgather (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vrgather (vint8m8_t op1, uint8_t op2);
vint16m1_t vrgather (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vrgather (vint16m1_t op1, uint16_t op2);
vint16m2_t vrgather (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vrgather (vint16m2_t op1, uint16_t op2);
vint16m4_t vrgather (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vrgather (vint16m4_t op1, uint16_t op2);
vint16m8_t vrgather (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vrgather (vint16m8_t op1, uint16_t op2);
vint32m1_t vrgather (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vrgather (vint32m1_t op1, uint32_t op2);
vint32m2_t vrgather (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vrgather (vint32m2_t op1, uint32_t op2);
vint32m4_t vrgather (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vrgather (vint32m4_t op1, uint32_t op2);
vint32m8_t vrgather (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vrgather (vint32m8_t op1, uint32_t op2);
vint64m1_t vrgather (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vrgather (vint64m1_t op1, uint64_t op2);
vint64m2_t vrgather (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vrgather (vint64m2_t op1, uint64_t op2);
vint64m4_t vrgather (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vrgather (vint64m4_t op1, uint64_t op2);
vint64m8_t vrgather (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vrgather (vint64m8_t op1, uint64_t op2);
vuint8m1_t vrgather (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrgather (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrgather (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrgather (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrgather (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrgather (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrgather (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrgather (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrgather (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrgather (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrgather (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrgather (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrgather (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrgather (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrgather (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrgather (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrgather (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrgather (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrgather (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrgather (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrgather (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrgather (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrgather (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrgather (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrgather (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrgather (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrgather (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrgather (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrgather (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrgather (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrgather (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrgather (vuint64m8_t op1, uint64_t op2);
vfloat16m1_t vrgather (vfloat16m1_t op1, vuint16m1_t op2);
vfloat16m1_t vrgather (vfloat16m1_t op1, uint16_t op2);
vfloat16m2_t vrgather (vfloat16m2_t op1, vuint16m2_t op2);
vfloat16m2_t vrgather (vfloat16m2_t op1, uint16_t op2);
vfloat16m4_t vrgather (vfloat16m4_t op1, vuint16m4_t op2);
vfloat16m4_t vrgather (vfloat16m4_t op1, uint16_t op2);
vfloat16m8_t vrgather (vfloat16m8_t op1, vuint16m8_t op2);
vfloat16m8_t vrgather (vfloat16m8_t op1, uint16_t op2);
vfloat32m1_t vrgather (vfloat32m1_t op1, vuint32m1_t op2);
vfloat32m1_t vrgather (vfloat32m1_t op1, uint32_t op2);
vfloat32m2_t vrgather (vfloat32m2_t op1, vuint32m2_t op2);
vfloat32m2_t vrgather (vfloat32m2_t op1, uint32_t op2);
vfloat32m4_t vrgather (vfloat32m4_t op1, vuint32m4_t op2);
vfloat32m4_t vrgather (vfloat32m4_t op1, uint32_t op2);
vfloat32m8_t vrgather (vfloat32m8_t op1, vuint32m8_t op2);
vfloat32m8_t vrgather (vfloat32m8_t op1, uint32_t op2);
vfloat64m1_t vrgather (vfloat64m1_t op1, vuint64m1_t op2);
vfloat64m1_t vrgather (vfloat64m1_t op1, uint64_t op2);
vfloat64m2_t vrgather (vfloat64m2_t op1, vuint64m2_t op2);
vfloat64m2_t vrgather (vfloat64m2_t op1, uint64_t op2);
vfloat64m4_t vrgather (vfloat64m4_t op1, vuint64m4_t op2);
vfloat64m4_t vrgather (vfloat64m4_t op1, uint64_t op2);
vfloat64m8_t vrgather (vfloat64m8_t op1, vuint64m8_t op2);
vfloat64m8_t vrgather (vfloat64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vrgather_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vrgather_m (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vrgather_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vrgather_m (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vrgather_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vrgather_m (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vrgather_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vrgather_m (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vrgather_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vrgather_m (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2);
vint16m2_t vrgather_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vrgather_m (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2);
vint16m4_t vrgather_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vrgather_m (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2);
vint16m8_t vrgather_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vrgather_m (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2);
vint32m1_t vrgather_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vrgather_m (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2);
vint32m2_t vrgather_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vrgather_m (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2);
vint32m4_t vrgather_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vrgather_m (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2);
vint32m8_t vrgather_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vrgather_m (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2);
vint64m1_t vrgather_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vrgather_m (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2);
vint64m2_t vrgather_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vrgather_m (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2);
vint64m4_t vrgather_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vrgather_m (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2);
vint64m8_t vrgather_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vrgather_m (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2);
vuint8m1_t vrgather_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrgather_m (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrgather_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrgather_m (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrgather_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrgather_m (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrgather_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrgather_m (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrgather_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrgather_m (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrgather_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrgather_m (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrgather_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrgather_m (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrgather_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrgather_m (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrgather_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrgather_m (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrgather_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrgather_m (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrgather_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrgather_m (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrgather_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrgather_m (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrgather_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrgather_m (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrgather_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrgather_m (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrgather_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrgather_m (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrgather_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrgather_m (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vfloat16m1_t vrgather_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t op2);
vfloat16m1_t vrgather_m (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, uint16_t op2);
vfloat16m2_t vrgather_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t op2);
vfloat16m2_t vrgather_m (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, uint16_t op2);
vfloat16m4_t vrgather_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t op2);
vfloat16m4_t vrgather_m (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, uint16_t op2);
vfloat16m8_t vrgather_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t op2);
vfloat16m8_t vrgather_m (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, uint16_t op2);
vfloat32m1_t vrgather_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint32m1_t op2);
vfloat32m1_t vrgather_m (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, uint32_t op2);
vfloat32m2_t vrgather_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint32m2_t op2);
vfloat32m2_t vrgather_m (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, uint32_t op2);
vfloat32m4_t vrgather_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint32m4_t op2);
vfloat32m4_t vrgather_m (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, uint32_t op2);
vfloat32m8_t vrgather_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint32m8_t op2);
vfloat32m8_t vrgather_m (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, uint32_t op2);
vfloat64m1_t vrgather_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint64m1_t op2);
vfloat64m1_t vrgather_m (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, uint64_t op2);
vfloat64m2_t vrgather_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint64m2_t op2);
vfloat64m2_t vrgather_m (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, uint64_t op2);
vfloat64m4_t vrgather_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint64m4_t op2);
vfloat64m4_t vrgather_m (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, uint64_t op2);
vfloat64m8_t vrgather_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint64m8_t op2);
vfloat64m8_t vrgather_m (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, uint64_t op2);
```
### [Vector Compress Functions](rvv-intrinsic-api.md#175-vector-compress-operations):

**Prototypes:**
``` C
vint8m1_t vcompress (vint8m1_t src, vbool8_t mask);
vint8m2_t vcompress (vint8m2_t src, vbool4_t mask);
vint8m4_t vcompress (vint8m4_t src, vbool2_t mask);
vint8m8_t vcompress (vint8m8_t src, vbool1_t mask);
vint16m1_t vcompress (vint16m1_t src, vbool16_t mask);
vint16m2_t vcompress (vint16m2_t src, vbool8_t mask);
vint16m4_t vcompress (vint16m4_t src, vbool4_t mask);
vint16m8_t vcompress (vint16m8_t src, vbool2_t mask);
vint32m1_t vcompress (vint32m1_t src, vbool32_t mask);
vint32m2_t vcompress (vint32m2_t src, vbool16_t mask);
vint32m4_t vcompress (vint32m4_t src, vbool8_t mask);
vint32m8_t vcompress (vint32m8_t src, vbool4_t mask);
vint64m1_t vcompress (vint64m1_t src, vbool64_t mask);
vint64m2_t vcompress (vint64m2_t src, vbool32_t mask);
vint64m4_t vcompress (vint64m4_t src, vbool16_t mask);
vint64m8_t vcompress (vint64m8_t src, vbool8_t mask);
vuint8m1_t vcompress (vuint8m1_t src, vbool8_t mask);
vuint8m2_t vcompress (vuint8m2_t src, vbool4_t mask);
vuint8m4_t vcompress (vuint8m4_t src, vbool2_t mask);
vuint8m8_t vcompress (vuint8m8_t src, vbool1_t mask);
vuint16m1_t vcompress (vuint16m1_t src, vbool16_t mask);
vuint16m2_t vcompress (vuint16m2_t src, vbool8_t mask);
vuint16m4_t vcompress (vuint16m4_t src, vbool4_t mask);
vuint16m8_t vcompress (vuint16m8_t src, vbool2_t mask);
vuint32m1_t vcompress (vuint32m1_t src, vbool32_t mask);
vuint32m2_t vcompress (vuint32m2_t src, vbool16_t mask);
vuint32m4_t vcompress (vuint32m4_t src, vbool8_t mask);
vuint32m8_t vcompress (vuint32m8_t src, vbool4_t mask);
vuint64m1_t vcompress (vuint64m1_t src, vbool64_t mask);
vuint64m2_t vcompress (vuint64m2_t src, vbool32_t mask);
vuint64m4_t vcompress (vuint64m4_t src, vbool16_t mask);
vuint64m8_t vcompress (vuint64m8_t src, vbool8_t mask);
vfloat16m1_t vcompress (vfloat16m1_t src, vbool16_t mask);
vfloat16m2_t vcompress (vfloat16m2_t src, vbool8_t mask);
vfloat16m4_t vcompress (vfloat16m4_t src, vbool4_t mask);
vfloat16m8_t vcompress (vfloat16m8_t src, vbool2_t mask);
vfloat32m1_t vcompress (vfloat32m1_t src, vbool32_t mask);
vfloat32m2_t vcompress (vfloat32m2_t src, vbool16_t mask);
vfloat32m4_t vcompress (vfloat32m4_t src, vbool8_t mask);
vfloat32m8_t vcompress (vfloat32m8_t src, vbool4_t mask);
vfloat64m1_t vcompress (vfloat64m1_t src, vbool64_t mask);
vfloat64m2_t vcompress (vfloat64m2_t src, vbool32_t mask);
vfloat64m4_t vcompress (vfloat64m4_t src, vbool16_t mask);
vfloat64m8_t vcompress (vfloat64m8_t src, vbool8_t mask);
```
## Miscellaneous Vector Functions:

### [Reinterpret Cast Conversion Functions](rvv-intrinsic-api.md#reinterpret-cast-conversion-functions):

**Prototypes:**
``` C
vuint8m1_t vreinterpret_u8 (vint8m1_t src);
vuint8m2_t vreinterpret_u8 (vint8m2_t src);
vuint8m4_t vreinterpret_u8 (vint8m4_t src);
vuint8m8_t vreinterpret_u8 (vint8m8_t src);
vint8m1_t vreinterpret_i8 (vuint8m1_t src);
vint8m2_t vreinterpret_i8 (vuint8m2_t src);
vint8m4_t vreinterpret_i8 (vuint8m4_t src);
vint8m8_t vreinterpret_i8 (vuint8m8_t src);
vuint16m1_t vreinterpret_u16 (vint16m1_t src);
vuint16m2_t vreinterpret_u16 (vint16m2_t src);
vuint16m4_t vreinterpret_u16 (vint16m4_t src);
vuint16m8_t vreinterpret_u16 (vint16m8_t src);
vint16m1_t vreinterpret_i16 (vuint16m1_t src);
vint16m2_t vreinterpret_i16 (vuint16m2_t src);
vint16m4_t vreinterpret_i16 (vuint16m4_t src);
vint16m8_t vreinterpret_i16 (vuint16m8_t src);
vint16m1_t vreinterpret_i16 (vfloat16m1_t src);
vint16m2_t vreinterpret_i16 (vfloat16m2_t src);
vint16m4_t vreinterpret_i16 (vfloat16m4_t src);
vint16m8_t vreinterpret_i16 (vfloat16m8_t src);
vuint16m1_t vreinterpret_u16 (vfloat16m1_t src);
vuint16m2_t vreinterpret_u16 (vfloat16m2_t src);
vuint16m4_t vreinterpret_u16 (vfloat16m4_t src);
vuint16m8_t vreinterpret_u16 (vfloat16m8_t src);
vfloat16m1_t vreinterpret_f16 (vint16m1_t src);
vfloat16m2_t vreinterpret_f16 (vint16m2_t src);
vfloat16m4_t vreinterpret_f16 (vint16m4_t src);
vfloat16m8_t vreinterpret_f16 (vint16m8_t src);
vfloat16m1_t vreinterpret_f16 (vuint16m1_t src);
vfloat16m2_t vreinterpret_f16 (vuint16m2_t src);
vfloat16m4_t vreinterpret_f16 (vuint16m4_t src);
vfloat16m8_t vreinterpret_f16 (vuint16m8_t src);
vuint32m1_t vreinterpret_u32 (vint32m1_t src);
vuint32m2_t vreinterpret_u32 (vint32m2_t src);
vuint32m4_t vreinterpret_u32 (vint32m4_t src);
vuint32m8_t vreinterpret_u32 (vint32m8_t src);
vint32m1_t vreinterpret_i32 (vuint32m1_t src);
vint32m2_t vreinterpret_i32 (vuint32m2_t src);
vint32m4_t vreinterpret_i32 (vuint32m4_t src);
vint32m8_t vreinterpret_i32 (vuint32m8_t src);
vint32m1_t vreinterpret_i32 (vfloat32m1_t src);
vint32m2_t vreinterpret_i32 (vfloat32m2_t src);
vint32m4_t vreinterpret_i32 (vfloat32m4_t src);
vint32m8_t vreinterpret_i32 (vfloat32m8_t src);
vuint32m1_t vreinterpret_u32 (vfloat32m1_t src);
vuint32m2_t vreinterpret_u32 (vfloat32m2_t src);
vuint32m4_t vreinterpret_u32 (vfloat32m4_t src);
vuint32m8_t vreinterpret_u32 (vfloat32m8_t src);
vfloat32m1_t vreinterpret_f32 (vint32m1_t src);
vfloat32m2_t vreinterpret_f32 (vint32m2_t src);
vfloat32m4_t vreinterpret_f32 (vint32m4_t src);
vfloat32m8_t vreinterpret_f32 (vint32m8_t src);
vfloat32m1_t vreinterpret_f32 (vuint32m1_t src);
vfloat32m2_t vreinterpret_f32 (vuint32m2_t src);
vfloat32m4_t vreinterpret_f32 (vuint32m4_t src);
vfloat32m8_t vreinterpret_f32 (vuint32m8_t src);
vuint64m1_t vreinterpret_u64 (vint64m1_t src);
vuint64m2_t vreinterpret_u64 (vint64m2_t src);
vuint64m4_t vreinterpret_u64 (vint64m4_t src);
vuint64m8_t vreinterpret_u64 (vint64m8_t src);
vint64m1_t vreinterpret_i64 (vuint64m1_t src);
vint64m2_t vreinterpret_i64 (vuint64m2_t src);
vint64m4_t vreinterpret_i64 (vuint64m4_t src);
vint64m8_t vreinterpret_i64 (vuint64m8_t src);
vint64m1_t vreinterpret_i64 (vfloat64m1_t src);
vint64m2_t vreinterpret_i64 (vfloat64m2_t src);
vint64m4_t vreinterpret_i64 (vfloat64m4_t src);
vint64m8_t vreinterpret_i64 (vfloat64m8_t src);
vuint64m1_t vreinterpret_u64 (vfloat64m1_t src);
vuint64m2_t vreinterpret_u64 (vfloat64m2_t src);
vuint64m4_t vreinterpret_u64 (vfloat64m4_t src);
vuint64m8_t vreinterpret_u64 (vfloat64m8_t src);
vfloat64m1_t vreinterpret_f64 (vint64m1_t src);
vfloat64m2_t vreinterpret_f64 (vint64m2_t src);
vfloat64m4_t vreinterpret_f64 (vint64m4_t src);
vfloat64m8_t vreinterpret_f64 (vint64m8_t src);
vfloat64m1_t vreinterpret_f64 (vuint64m1_t src);
vfloat64m2_t vreinterpret_f64 (vuint64m2_t src);
vfloat64m4_t vreinterpret_f64 (vuint64m4_t src);
vfloat64m8_t vreinterpret_f64 (vuint64m8_t src);
```
### [Vector Initialization Functions](rvv-intrinsic-api.md#vector-initialization-functions):

**Prototypes:**
``` C
vint8m1_t vzero_i8m1 ();
vint8m2_t vzero_i8m2 ();
vint8m4_t vzero_i8m4 ();
vint8m8_t vzero_i8m8 ();
vint16m1_t vzero_i16m1 ();
vint16m2_t vzero_i16m2 ();
vint16m4_t vzero_i16m4 ();
vint16m8_t vzero_i16m8 ();
vint32m1_t vzero_i32m1 ();
vint32m2_t vzero_i32m2 ();
vint32m4_t vzero_i32m4 ();
vint32m8_t vzero_i32m8 ();
vint64m1_t vzero_i64m1 ();
vint64m2_t vzero_i64m2 ();
vint64m4_t vzero_i64m4 ();
vint64m8_t vzero_i64m8 ();
vuint8m1_t vzero_u8m1 ();
vuint8m2_t vzero_u8m2 ();
vuint8m4_t vzero_u8m4 ();
vuint8m8_t vzero_u8m8 ();
vuint16m1_t vzero_u16m1 ();
vuint16m2_t vzero_u16m2 ();
vuint16m4_t vzero_u16m4 ();
vuint16m8_t vzero_u16m8 ();
vuint32m1_t vzero_u32m1 ();
vuint32m2_t vzero_u32m2 ();
vuint32m4_t vzero_u32m4 ();
vuint32m8_t vzero_u32m8 ();
vuint64m1_t vzero_u64m1 ();
vuint64m2_t vzero_u64m2 ();
vuint64m4_t vzero_u64m4 ();
vuint64m8_t vzero_u64m8 ();
vfloat8m1_t vzero_f8m1 ();
vfloat8m2_t vzero_f8m2 ();
vfloat8m4_t vzero_f8m4 ();
vfloat8m8_t vzero_f8m8 ();
vfloat16m1_t vzero_f16m1 ();
vfloat16m2_t vzero_f16m2 ();
vfloat16m4_t vzero_f16m4 ();
vfloat16m8_t vzero_f16m8 ();
vfloat32m1_t vzero_f32m1 ();
vfloat32m2_t vzero_f32m2 ();
vfloat32m4_t vzero_f32m4 ();
vfloat32m8_t vzero_f32m8 ();
vfloat64m1_t vzero_f64m1 ();
vfloat64m2_t vzero_f64m2 ();
vfloat64m4_t vzero_f64m4 ();
vfloat64m8_t vzero_f64m8 ();
vint8m1_t vundefined_i8m1 ();
vint8m2_t vundefined_i8m2 ();
vint8m4_t vundefined_i8m4 ();
vint8m8_t vundefined_i8m8 ();
vint16m1_t vundefined_i16m1 ();
vint16m2_t vundefined_i16m2 ();
vint16m4_t vundefined_i16m4 ();
vint16m8_t vundefined_i16m8 ();
vint32m1_t vundefined_i32m1 ();
vint32m2_t vundefined_i32m2 ();
vint32m4_t vundefined_i32m4 ();
vint32m8_t vundefined_i32m8 ();
vint64m1_t vundefined_i64m1 ();
vint64m2_t vundefined_i64m2 ();
vint64m4_t vundefined_i64m4 ();
vint64m8_t vundefined_i64m8 ();
vuint8m1_t vundefined_u8m1 ();
vuint8m2_t vundefined_u8m2 ();
vuint8m4_t vundefined_u8m4 ();
vuint8m8_t vundefined_u8m8 ();
vuint16m1_t vundefined_u16m1 ();
vuint16m2_t vundefined_u16m2 ();
vuint16m4_t vundefined_u16m4 ();
vuint16m8_t vundefined_u16m8 ();
vuint32m1_t vundefined_u32m1 ();
vuint32m2_t vundefined_u32m2 ();
vuint32m4_t vundefined_u32m4 ();
vuint32m8_t vundefined_u32m8 ();
vuint64m1_t vundefined_u64m1 ();
vuint64m2_t vundefined_u64m2 ();
vuint64m4_t vundefined_u64m4 ();
vuint64m8_t vundefined_u64m8 ();
vfloat8m1_t vundefined_f8m1 ();
vfloat8m2_t vundefined_f8m2 ();
vfloat8m4_t vundefined_f8m4 ();
vfloat8m8_t vundefined_f8m8 ();
vfloat16m1_t vundefined_f16m1 ();
vfloat16m2_t vundefined_f16m2 ();
vfloat16m4_t vundefined_f16m4 ();
vfloat16m8_t vundefined_f16m8 ();
vfloat32m1_t vundefined_f32m1 ();
vfloat32m2_t vundefined_f32m2 ();
vfloat32m4_t vundefined_f32m4 ();
vfloat32m8_t vundefined_f32m8 ();
vfloat64m1_t vundefined_f64m1 ();
vfloat64m2_t vundefined_f64m2 ();
vfloat64m4_t vundefined_f64m4 ();
vfloat64m8_t vundefined_f64m8 ();
```