<!--NOTE: This file is generated by rvv_intrinsic_gen.py-->

### [RVV C extension types]()

**Prototypes:**
``` C
vint8m1_t
vint8m2_t
vint8m4_t
vint8m8_t
vint16m1_t
vint16m2_t
vint16m4_t
vint16m8_t
vint32m1_t
vint32m2_t
vint32m4_t
vint32m8_t
vint64m1_t
vint64m2_t
vint64m4_t
vint64m8_t
vuint8m1_t
vuint8m2_t
vuint8m4_t
vuint8m8_t
vuint16m1_t
vuint16m2_t
vuint16m4_t
vuint16m8_t
vuint32m1_t
vuint32m2_t
vuint32m4_t
vuint32m8_t
vuint64m1_t
vuint64m2_t
vuint64m4_t
vuint64m8_t
vfloat16m1_t
vfloat16m2_t
vfloat16m4_t
vfloat16m8_t
vfloat32m1_t
vfloat32m2_t
vfloat32m4_t
vfloat32m8_t
vfloat64m1_t
vfloat64m2_t
vfloat64m4_t
vfloat64m8_t
```
### [RVV C extension mask types]()
- The Syntax is `vbool<MLEN>_t`
 - `vbool1_t`
 - `vbool2_t`
 - `vbool4_t`
 - `vbool8_t`
 - `vbool16_t`
 - `vbool32_t`
 - `vbool64_t`

# RVV intrinsic Functions:

## Configuration-Setting Functions:

### [Set `vl` and `vtype` Functions]()

**Prototypes:**
``` C
size_t vsetvl_8m1 (size_t avl);
size_t vsetvl_8m2 (size_t avl);
size_t vsetvl_8m4 (size_t avl);
size_t vsetvl_8m8 (size_t avl);
size_t vsetvl_16m1 (size_t avl);
size_t vsetvl_16m2 (size_t avl);
size_t vsetvl_16m4 (size_t avl);
size_t vsetvl_16m8 (size_t avl);
size_t vsetvl_32m1 (size_t avl);
size_t vsetvl_32m2 (size_t avl);
size_t vsetvl_32m4 (size_t avl);
size_t vsetvl_32m8 (size_t avl);
size_t vsetvl_64m1 (size_t avl);
size_t vsetvl_64m2 (size_t avl);
size_t vsetvl_64m4 (size_t avl);
size_t vsetvl_64m8 (size_t avl);
```
### [Set the vl to VLMAX with specific vtype]()

**Prototypes:**
``` C
size_t vsetvlmax_8m1 ();
size_t vsetvlmax_8m2 ();
size_t vsetvlmax_8m4 ();
size_t vsetvlmax_8m8 ();
size_t vsetvlmax_16m1 ();
size_t vsetvlmax_16m2 ();
size_t vsetvlmax_16m4 ();
size_t vsetvlmax_16m8 ();
size_t vsetvlmax_32m1 ();
size_t vsetvlmax_32m2 ();
size_t vsetvlmax_32m4 ();
size_t vsetvlmax_32m8 ();
size_t vsetvlmax_64m1 ();
size_t vsetvlmax_64m2 ();
size_t vsetvlmax_64m4 ();
size_t vsetvlmax_64m8 ();
```
### [Read the vl]()

**Prototypes:**
``` C
size_t vreadvl ();
```
## Vector Loads and Stores Functions:

### [Vector Unit-Stride Load Functions]()

**Prototypes:**
``` C
vint8m1_t vloadb_i8m1 (const int8_t *base);
vint8m2_t vloadb_i8m2 (const int8_t *base);
vint8m4_t vloadb_i8m4 (const int8_t *base);
vint8m8_t vloadb_i8m8 (const int8_t *base);
vint16m1_t vloadb_i16m1 (const int8_t *base);
vint16m2_t vloadb_i16m2 (const int8_t *base);
vint16m4_t vloadb_i16m4 (const int8_t *base);
vint16m8_t vloadb_i16m8 (const int8_t *base);
vint32m1_t vloadb_i32m1 (const int8_t *base);
vint32m2_t vloadb_i32m2 (const int8_t *base);
vint32m4_t vloadb_i32m4 (const int8_t *base);
vint32m8_t vloadb_i32m8 (const int8_t *base);
vint64m1_t vloadb_i64m1 (const int8_t *base);
vint64m2_t vloadb_i64m2 (const int8_t *base);
vint64m4_t vloadb_i64m4 (const int8_t *base);
vint64m8_t vloadb_i64m8 (const int8_t *base);
vuint8m1_t vloadb_u8m1 (const uint8_t *base);
vuint8m2_t vloadb_u8m2 (const uint8_t *base);
vuint8m4_t vloadb_u8m4 (const uint8_t *base);
vuint8m8_t vloadb_u8m8 (const uint8_t *base);
vuint16m1_t vloadb_u16m1 (const uint8_t *base);
vuint16m2_t vloadb_u16m2 (const uint8_t *base);
vuint16m4_t vloadb_u16m4 (const uint8_t *base);
vuint16m8_t vloadb_u16m8 (const uint8_t *base);
vuint32m1_t vloadb_u32m1 (const uint8_t *base);
vuint32m2_t vloadb_u32m2 (const uint8_t *base);
vuint32m4_t vloadb_u32m4 (const uint8_t *base);
vuint32m8_t vloadb_u32m8 (const uint8_t *base);
vuint64m1_t vloadb_u64m1 (const uint8_t *base);
vuint64m2_t vloadb_u64m2 (const uint8_t *base);
vuint64m4_t vloadb_u64m4 (const uint8_t *base);
vuint64m8_t vloadb_u64m8 (const uint8_t *base);
vint16m1_t vloadh_i16m1 (const int16_t *base);
vint16m2_t vloadh_i16m2 (const int16_t *base);
vint16m4_t vloadh_i16m4 (const int16_t *base);
vint16m8_t vloadh_i16m8 (const int16_t *base);
vint32m1_t vloadh_i32m1 (const int16_t *base);
vint32m2_t vloadh_i32m2 (const int16_t *base);
vint32m4_t vloadh_i32m4 (const int16_t *base);
vint32m8_t vloadh_i32m8 (const int16_t *base);
vint64m1_t vloadh_i64m1 (const int16_t *base);
vint64m2_t vloadh_i64m2 (const int16_t *base);
vint64m4_t vloadh_i64m4 (const int16_t *base);
vint64m8_t vloadh_i64m8 (const int16_t *base);
vuint16m1_t vloadh_u16m1 (const uint16_t *base);
vuint16m2_t vloadh_u16m2 (const uint16_t *base);
vuint16m4_t vloadh_u16m4 (const uint16_t *base);
vuint16m8_t vloadh_u16m8 (const uint16_t *base);
vuint32m1_t vloadh_u32m1 (const uint16_t *base);
vuint32m2_t vloadh_u32m2 (const uint16_t *base);
vuint32m4_t vloadh_u32m4 (const uint16_t *base);
vuint32m8_t vloadh_u32m8 (const uint16_t *base);
vuint64m1_t vloadh_u64m1 (const uint16_t *base);
vuint64m2_t vloadh_u64m2 (const uint16_t *base);
vuint64m4_t vloadh_u64m4 (const uint16_t *base);
vuint64m8_t vloadh_u64m8 (const uint16_t *base);
vint32m1_t vloadw_i32m1 (const int32_t *base);
vint32m2_t vloadw_i32m2 (const int32_t *base);
vint32m4_t vloadw_i32m4 (const int32_t *base);
vint32m8_t vloadw_i32m8 (const int32_t *base);
vint64m1_t vloadw_i64m1 (const int32_t *base);
vint64m2_t vloadw_i64m2 (const int32_t *base);
vint64m4_t vloadw_i64m4 (const int32_t *base);
vint64m8_t vloadw_i64m8 (const int32_t *base);
vuint32m1_t vloadw_u32m1 (const uint32_t *base);
vuint32m2_t vloadw_u32m2 (const uint32_t *base);
vuint32m4_t vloadw_u32m4 (const uint32_t *base);
vuint32m8_t vloadw_u32m8 (const uint32_t *base);
vuint64m1_t vloadw_u64m1 (const uint32_t *base);
vuint64m2_t vloadw_u64m2 (const uint32_t *base);
vuint64m4_t vloadw_u64m4 (const uint32_t *base);
vuint64m8_t vloadw_u64m8 (const uint32_t *base);
vint8m1_t vload_i8m1 (const int8_t *base);
vint8m2_t vload_i8m2 (const int8_t *base);
vint8m4_t vload_i8m4 (const int8_t *base);
vint8m8_t vload_i8m8 (const int8_t *base);
vint16m1_t vload_i16m1 (const int16_t *base);
vint16m2_t vload_i16m2 (const int16_t *base);
vint16m4_t vload_i16m4 (const int16_t *base);
vint16m8_t vload_i16m8 (const int16_t *base);
vint32m1_t vload_i32m1 (const int32_t *base);
vint32m2_t vload_i32m2 (const int32_t *base);
vint32m4_t vload_i32m4 (const int32_t *base);
vint32m8_t vload_i32m8 (const int32_t *base);
vint64m1_t vload_i64m1 (const int64_t *base);
vint64m2_t vload_i64m2 (const int64_t *base);
vint64m4_t vload_i64m4 (const int64_t *base);
vint64m8_t vload_i64m8 (const int64_t *base);
vuint8m1_t vload_u8m1 (const uint8_t *base);
vuint8m2_t vload_u8m2 (const uint8_t *base);
vuint8m4_t vload_u8m4 (const uint8_t *base);
vuint8m8_t vload_u8m8 (const uint8_t *base);
vuint16m1_t vload_u16m1 (const uint16_t *base);
vuint16m2_t vload_u16m2 (const uint16_t *base);
vuint16m4_t vload_u16m4 (const uint16_t *base);
vuint16m8_t vload_u16m8 (const uint16_t *base);
vuint32m1_t vload_u32m1 (const uint32_t *base);
vuint32m2_t vload_u32m2 (const uint32_t *base);
vuint32m4_t vload_u32m4 (const uint32_t *base);
vuint32m8_t vload_u32m8 (const uint32_t *base);
vuint64m1_t vload_u64m1 (const uint64_t *base);
vuint64m2_t vload_u64m2 (const uint64_t *base);
vuint64m4_t vload_u64m4 (const uint64_t *base);
vuint64m8_t vload_u64m8 (const uint64_t *base);
vfloat16m1_t vload_f16m1 (const float16_t *base);
vfloat16m2_t vload_f16m2 (const float16_t *base);
vfloat16m4_t vload_f16m4 (const float16_t *base);
vfloat16m8_t vload_f16m8 (const float16_t *base);
vfloat32m1_t vload_f32m1 (const float32_t *base);
vfloat32m2_t vload_f32m2 (const float32_t *base);
vfloat32m4_t vload_f32m4 (const float32_t *base);
vfloat32m8_t vload_f32m8 (const float32_t *base);
vfloat64m1_t vload_f64m1 (const float64_t *base);
vfloat64m2_t vload_f64m2 (const float64_t *base);
vfloat64m4_t vload_f64m4 (const float64_t *base);
vfloat64m8_t vload_f64m8 (const float64_t *base);
// masked functions
vint8m1_t vloadb_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vloadb_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vloadb_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vloadb_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vloadb_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base);
vint16m2_t vloadb_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base);
vint16m4_t vloadb_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base);
vint16m8_t vloadb_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base);
vint32m1_t vloadb_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base);
vint32m2_t vloadb_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base);
vint32m4_t vloadb_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base);
vint32m8_t vloadb_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base);
vint64m1_t vloadb_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base);
vint64m2_t vloadb_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base);
vint64m4_t vloadb_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base);
vint64m8_t vloadb_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base);
vuint8m1_t vloadb_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vloadb_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vloadb_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vloadb_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vloadb_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base);
vuint16m2_t vloadb_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base);
vuint16m4_t vloadb_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base);
vuint16m8_t vloadb_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base);
vuint32m1_t vloadb_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base);
vuint32m2_t vloadb_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base);
vuint32m4_t vloadb_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base);
vuint32m8_t vloadb_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base);
vuint64m1_t vloadb_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base);
vuint64m2_t vloadb_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base);
vuint64m4_t vloadb_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base);
vuint64m8_t vloadb_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base);
vint16m1_t vloadh_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vloadh_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vloadh_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vloadh_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vloadh_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base);
vint32m2_t vloadh_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base);
vint32m4_t vloadh_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base);
vint32m8_t vloadh_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base);
vint64m1_t vloadh_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base);
vint64m2_t vloadh_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base);
vint64m4_t vloadh_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base);
vint64m8_t vloadh_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base);
vuint16m1_t vloadh_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vloadh_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vloadh_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vloadh_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vloadh_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base);
vuint32m2_t vloadh_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base);
vuint32m4_t vloadh_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base);
vuint32m8_t vloadh_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base);
vuint64m1_t vloadh_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base);
vuint64m2_t vloadh_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base);
vuint64m4_t vloadh_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base);
vuint64m8_t vloadh_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base);
vint32m1_t vloadw_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vloadw_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vloadw_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vloadw_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vloadw_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base);
vint64m2_t vloadw_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base);
vint64m4_t vloadw_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base);
vint64m8_t vloadw_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base);
vuint32m1_t vloadw_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vloadw_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vloadw_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vloadw_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vloadw_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base);
vuint64m2_t vloadw_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base);
vuint64m4_t vloadw_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base);
vuint64m8_t vloadw_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base);
vint8m1_t vload_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vload_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vload_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vload_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vload_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vload_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vload_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vload_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vload_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vload_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vload_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vload_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vload_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base);
vint64m2_t vload_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base);
vint64m4_t vload_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base);
vint64m8_t vload_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base);
vuint8m1_t vload_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vload_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vload_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vload_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vload_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vload_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vload_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vload_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vload_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vload_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vload_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vload_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vload_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base);
vuint64m2_t vload_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base);
vuint64m4_t vload_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base);
vuint64m8_t vload_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base);
vfloat16m1_t vload_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base);
vfloat16m2_t vload_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base);
vfloat16m4_t vload_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base);
vfloat16m8_t vload_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base);
vfloat32m1_t vload_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base);
vfloat32m2_t vload_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base);
vfloat32m4_t vload_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base);
vfloat32m8_t vload_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base);
vfloat64m1_t vload_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base);
vfloat64m2_t vload_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base);
vfloat64m4_t vload_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base);
vfloat64m8_t vload_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base);
```
### [Vector Unit-Stride Store Functions]()

**Prototypes:**
``` C
void vstoreb_i8m1 (int8_t *base, vint8m1_t value);
void vstoreb_i8m2 (int8_t *base, vint8m2_t value);
void vstoreb_i8m4 (int8_t *base, vint8m4_t value);
void vstoreb_i8m8 (int8_t *base, vint8m8_t value);
void vstoreb_i16m1 (int8_t *base, vint16m1_t value);
void vstoreb_i16m2 (int8_t *base, vint16m2_t value);
void vstoreb_i16m4 (int8_t *base, vint16m4_t value);
void vstoreb_i16m8 (int8_t *base, vint16m8_t value);
void vstoreb_i32m1 (int8_t *base, vint32m1_t value);
void vstoreb_i32m2 (int8_t *base, vint32m2_t value);
void vstoreb_i32m4 (int8_t *base, vint32m4_t value);
void vstoreb_i32m8 (int8_t *base, vint32m8_t value);
void vstoreb_i64m1 (int8_t *base, vint64m1_t value);
void vstoreb_i64m2 (int8_t *base, vint64m2_t value);
void vstoreb_i64m4 (int8_t *base, vint64m4_t value);
void vstoreb_i64m8 (int8_t *base, vint64m8_t value);
void vstoreb_u8m1 (uint8_t *base, vuint8m1_t value);
void vstoreb_u8m2 (uint8_t *base, vuint8m2_t value);
void vstoreb_u8m4 (uint8_t *base, vuint8m4_t value);
void vstoreb_u8m8 (uint8_t *base, vuint8m8_t value);
void vstoreb_u16m1 (uint8_t *base, vuint16m1_t value);
void vstoreb_u16m2 (uint8_t *base, vuint16m2_t value);
void vstoreb_u16m4 (uint8_t *base, vuint16m4_t value);
void vstoreb_u16m8 (uint8_t *base, vuint16m8_t value);
void vstoreb_u32m1 (uint8_t *base, vuint32m1_t value);
void vstoreb_u32m2 (uint8_t *base, vuint32m2_t value);
void vstoreb_u32m4 (uint8_t *base, vuint32m4_t value);
void vstoreb_u32m8 (uint8_t *base, vuint32m8_t value);
void vstoreb_u64m1 (uint8_t *base, vuint64m1_t value);
void vstoreb_u64m2 (uint8_t *base, vuint64m2_t value);
void vstoreb_u64m4 (uint8_t *base, vuint64m4_t value);
void vstoreb_u64m8 (uint8_t *base, vuint64m8_t value);
void vstoreh_i16m1 (int16_t *base, vint16m1_t value);
void vstoreh_i16m2 (int16_t *base, vint16m2_t value);
void vstoreh_i16m4 (int16_t *base, vint16m4_t value);
void vstoreh_i16m8 (int16_t *base, vint16m8_t value);
void vstoreh_i32m1 (int16_t *base, vint32m1_t value);
void vstoreh_i32m2 (int16_t *base, vint32m2_t value);
void vstoreh_i32m4 (int16_t *base, vint32m4_t value);
void vstoreh_i32m8 (int16_t *base, vint32m8_t value);
void vstoreh_i64m1 (int16_t *base, vint64m1_t value);
void vstoreh_i64m2 (int16_t *base, vint64m2_t value);
void vstoreh_i64m4 (int16_t *base, vint64m4_t value);
void vstoreh_i64m8 (int16_t *base, vint64m8_t value);
void vstoreh_u16m1 (uint16_t *base, vuint16m1_t value);
void vstoreh_u16m2 (uint16_t *base, vuint16m2_t value);
void vstoreh_u16m4 (uint16_t *base, vuint16m4_t value);
void vstoreh_u16m8 (uint16_t *base, vuint16m8_t value);
void vstoreh_u32m1 (uint16_t *base, vuint32m1_t value);
void vstoreh_u32m2 (uint16_t *base, vuint32m2_t value);
void vstoreh_u32m4 (uint16_t *base, vuint32m4_t value);
void vstoreh_u32m8 (uint16_t *base, vuint32m8_t value);
void vstoreh_u64m1 (uint16_t *base, vuint64m1_t value);
void vstoreh_u64m2 (uint16_t *base, vuint64m2_t value);
void vstoreh_u64m4 (uint16_t *base, vuint64m4_t value);
void vstoreh_u64m8 (uint16_t *base, vuint64m8_t value);
void vstorew_i32m1 (int32_t *base, vint32m1_t value);
void vstorew_i32m2 (int32_t *base, vint32m2_t value);
void vstorew_i32m4 (int32_t *base, vint32m4_t value);
void vstorew_i32m8 (int32_t *base, vint32m8_t value);
void vstorew_i64m1 (int32_t *base, vint64m1_t value);
void vstorew_i64m2 (int32_t *base, vint64m2_t value);
void vstorew_i64m4 (int32_t *base, vint64m4_t value);
void vstorew_i64m8 (int32_t *base, vint64m8_t value);
void vstorew_u32m1 (uint32_t *base, vuint32m1_t value);
void vstorew_u32m2 (uint32_t *base, vuint32m2_t value);
void vstorew_u32m4 (uint32_t *base, vuint32m4_t value);
void vstorew_u32m8 (uint32_t *base, vuint32m8_t value);
void vstorew_u64m1 (uint32_t *base, vuint64m1_t value);
void vstorew_u64m2 (uint32_t *base, vuint64m2_t value);
void vstorew_u64m4 (uint32_t *base, vuint64m4_t value);
void vstorew_u64m8 (uint32_t *base, vuint64m8_t value);
void vstore_i8m1 (int8_t *base, vint8m1_t value);
void vstore_i8m2 (int8_t *base, vint8m2_t value);
void vstore_i8m4 (int8_t *base, vint8m4_t value);
void vstore_i8m8 (int8_t *base, vint8m8_t value);
void vstore_i16m1 (int16_t *base, vint16m1_t value);
void vstore_i16m2 (int16_t *base, vint16m2_t value);
void vstore_i16m4 (int16_t *base, vint16m4_t value);
void vstore_i16m8 (int16_t *base, vint16m8_t value);
void vstore_i32m1 (int32_t *base, vint32m1_t value);
void vstore_i32m2 (int32_t *base, vint32m2_t value);
void vstore_i32m4 (int32_t *base, vint32m4_t value);
void vstore_i32m8 (int32_t *base, vint32m8_t value);
void vstore_i64m1 (int64_t *base, vint64m1_t value);
void vstore_i64m2 (int64_t *base, vint64m2_t value);
void vstore_i64m4 (int64_t *base, vint64m4_t value);
void vstore_i64m8 (int64_t *base, vint64m8_t value);
void vstore_u8m1 (uint8_t *base, vuint8m1_t value);
void vstore_u8m2 (uint8_t *base, vuint8m2_t value);
void vstore_u8m4 (uint8_t *base, vuint8m4_t value);
void vstore_u8m8 (uint8_t *base, vuint8m8_t value);
void vstore_u16m1 (uint16_t *base, vuint16m1_t value);
void vstore_u16m2 (uint16_t *base, vuint16m2_t value);
void vstore_u16m4 (uint16_t *base, vuint16m4_t value);
void vstore_u16m8 (uint16_t *base, vuint16m8_t value);
void vstore_u32m1 (uint32_t *base, vuint32m1_t value);
void vstore_u32m2 (uint32_t *base, vuint32m2_t value);
void vstore_u32m4 (uint32_t *base, vuint32m4_t value);
void vstore_u32m8 (uint32_t *base, vuint32m8_t value);
void vstore_u64m1 (uint64_t *base, vuint64m1_t value);
void vstore_u64m2 (uint64_t *base, vuint64m2_t value);
void vstore_u64m4 (uint64_t *base, vuint64m4_t value);
void vstore_u64m8 (uint64_t *base, vuint64m8_t value);
void vstore_f16m1 (float16_t *base, vfloat16m1_t value);
void vstore_f16m2 (float16_t *base, vfloat16m2_t value);
void vstore_f16m4 (float16_t *base, vfloat16m4_t value);
void vstore_f16m8 (float16_t *base, vfloat16m8_t value);
void vstore_f32m1 (float32_t *base, vfloat32m1_t value);
void vstore_f32m2 (float32_t *base, vfloat32m2_t value);
void vstore_f32m4 (float32_t *base, vfloat32m4_t value);
void vstore_f32m8 (float32_t *base, vfloat32m8_t value);
void vstore_f64m1 (float64_t *base, vfloat64m1_t value);
void vstore_f64m2 (float64_t *base, vfloat64m2_t value);
void vstore_f64m4 (float64_t *base, vfloat64m4_t value);
void vstore_f64m8 (float64_t *base, vfloat64m8_t value);
// masked functions
void vstoreb_i8m1_mask (int8_t *base, vbool8_t mask, vint8m1_t value);
void vstoreb_i8m2_mask (int8_t *base, vbool4_t mask, vint8m2_t value);
void vstoreb_i8m4_mask (int8_t *base, vbool2_t mask, vint8m4_t value);
void vstoreb_i8m8_mask (int8_t *base, vbool1_t mask, vint8m8_t value);
void vstoreb_i16m1_mask (int8_t *base, vbool16_t mask, vint16m1_t value);
void vstoreb_i16m2_mask (int8_t *base, vbool8_t mask, vint16m2_t value);
void vstoreb_i16m4_mask (int8_t *base, vbool4_t mask, vint16m4_t value);
void vstoreb_i16m8_mask (int8_t *base, vbool2_t mask, vint16m8_t value);
void vstoreb_i32m1_mask (int8_t *base, vbool32_t mask, vint32m1_t value);
void vstoreb_i32m2_mask (int8_t *base, vbool16_t mask, vint32m2_t value);
void vstoreb_i32m4_mask (int8_t *base, vbool8_t mask, vint32m4_t value);
void vstoreb_i32m8_mask (int8_t *base, vbool4_t mask, vint32m8_t value);
void vstoreb_i64m1_mask (int8_t *base, vbool64_t mask, vint64m1_t value);
void vstoreb_i64m2_mask (int8_t *base, vbool32_t mask, vint64m2_t value);
void vstoreb_i64m4_mask (int8_t *base, vbool16_t mask, vint64m4_t value);
void vstoreb_i64m8_mask (int8_t *base, vbool8_t mask, vint64m8_t value);
void vstoreb_u8m1_mask (uint8_t *base, vbool8_t mask, vuint8m1_t value);
void vstoreb_u8m2_mask (uint8_t *base, vbool4_t mask, vuint8m2_t value);
void vstoreb_u8m4_mask (uint8_t *base, vbool2_t mask, vuint8m4_t value);
void vstoreb_u8m8_mask (uint8_t *base, vbool1_t mask, vuint8m8_t value);
void vstoreb_u16m1_mask (uint8_t *base, vbool16_t mask, vuint16m1_t value);
void vstoreb_u16m2_mask (uint8_t *base, vbool8_t mask, vuint16m2_t value);
void vstoreb_u16m4_mask (uint8_t *base, vbool4_t mask, vuint16m4_t value);
void vstoreb_u16m8_mask (uint8_t *base, vbool2_t mask, vuint16m8_t value);
void vstoreb_u32m1_mask (uint8_t *base, vbool32_t mask, vuint32m1_t value);
void vstoreb_u32m2_mask (uint8_t *base, vbool16_t mask, vuint32m2_t value);
void vstoreb_u32m4_mask (uint8_t *base, vbool8_t mask, vuint32m4_t value);
void vstoreb_u32m8_mask (uint8_t *base, vbool4_t mask, vuint32m8_t value);
void vstoreb_u64m1_mask (uint8_t *base, vbool64_t mask, vuint64m1_t value);
void vstoreb_u64m2_mask (uint8_t *base, vbool32_t mask, vuint64m2_t value);
void vstoreb_u64m4_mask (uint8_t *base, vbool16_t mask, vuint64m4_t value);
void vstoreb_u64m8_mask (uint8_t *base, vbool8_t mask, vuint64m8_t value);
void vstoreh_i16m1_mask (int16_t *base, vbool16_t mask, vint16m1_t value);
void vstoreh_i16m2_mask (int16_t *base, vbool8_t mask, vint16m2_t value);
void vstoreh_i16m4_mask (int16_t *base, vbool4_t mask, vint16m4_t value);
void vstoreh_i16m8_mask (int16_t *base, vbool2_t mask, vint16m8_t value);
void vstoreh_i32m1_mask (int16_t *base, vbool32_t mask, vint32m1_t value);
void vstoreh_i32m2_mask (int16_t *base, vbool16_t mask, vint32m2_t value);
void vstoreh_i32m4_mask (int16_t *base, vbool8_t mask, vint32m4_t value);
void vstoreh_i32m8_mask (int16_t *base, vbool4_t mask, vint32m8_t value);
void vstoreh_i64m1_mask (int16_t *base, vbool64_t mask, vint64m1_t value);
void vstoreh_i64m2_mask (int16_t *base, vbool32_t mask, vint64m2_t value);
void vstoreh_i64m4_mask (int16_t *base, vbool16_t mask, vint64m4_t value);
void vstoreh_i64m8_mask (int16_t *base, vbool8_t mask, vint64m8_t value);
void vstoreh_u16m1_mask (uint16_t *base, vbool16_t mask, vuint16m1_t value);
void vstoreh_u16m2_mask (uint16_t *base, vbool8_t mask, vuint16m2_t value);
void vstoreh_u16m4_mask (uint16_t *base, vbool4_t mask, vuint16m4_t value);
void vstoreh_u16m8_mask (uint16_t *base, vbool2_t mask, vuint16m8_t value);
void vstoreh_u32m1_mask (uint16_t *base, vbool32_t mask, vuint32m1_t value);
void vstoreh_u32m2_mask (uint16_t *base, vbool16_t mask, vuint32m2_t value);
void vstoreh_u32m4_mask (uint16_t *base, vbool8_t mask, vuint32m4_t value);
void vstoreh_u32m8_mask (uint16_t *base, vbool4_t mask, vuint32m8_t value);
void vstoreh_u64m1_mask (uint16_t *base, vbool64_t mask, vuint64m1_t value);
void vstoreh_u64m2_mask (uint16_t *base, vbool32_t mask, vuint64m2_t value);
void vstoreh_u64m4_mask (uint16_t *base, vbool16_t mask, vuint64m4_t value);
void vstoreh_u64m8_mask (uint16_t *base, vbool8_t mask, vuint64m8_t value);
void vstorew_i32m1_mask (int32_t *base, vbool32_t mask, vint32m1_t value);
void vstorew_i32m2_mask (int32_t *base, vbool16_t mask, vint32m2_t value);
void vstorew_i32m4_mask (int32_t *base, vbool8_t mask, vint32m4_t value);
void vstorew_i32m8_mask (int32_t *base, vbool4_t mask, vint32m8_t value);
void vstorew_i64m1_mask (int32_t *base, vbool64_t mask, vint64m1_t value);
void vstorew_i64m2_mask (int32_t *base, vbool32_t mask, vint64m2_t value);
void vstorew_i64m4_mask (int32_t *base, vbool16_t mask, vint64m4_t value);
void vstorew_i64m8_mask (int32_t *base, vbool8_t mask, vint64m8_t value);
void vstorew_u32m1_mask (uint32_t *base, vbool32_t mask, vuint32m1_t value);
void vstorew_u32m2_mask (uint32_t *base, vbool16_t mask, vuint32m2_t value);
void vstorew_u32m4_mask (uint32_t *base, vbool8_t mask, vuint32m4_t value);
void vstorew_u32m8_mask (uint32_t *base, vbool4_t mask, vuint32m8_t value);
void vstorew_u64m1_mask (uint32_t *base, vbool64_t mask, vuint64m1_t value);
void vstorew_u64m2_mask (uint32_t *base, vbool32_t mask, vuint64m2_t value);
void vstorew_u64m4_mask (uint32_t *base, vbool16_t mask, vuint64m4_t value);
void vstorew_u64m8_mask (uint32_t *base, vbool8_t mask, vuint64m8_t value);
void vstore_i8m1_mask (int8_t *base, vbool8_t mask, vint8m1_t value);
void vstore_i8m2_mask (int8_t *base, vbool4_t mask, vint8m2_t value);
void vstore_i8m4_mask (int8_t *base, vbool2_t mask, vint8m4_t value);
void vstore_i8m8_mask (int8_t *base, vbool1_t mask, vint8m8_t value);
void vstore_i16m1_mask (int16_t *base, vbool16_t mask, vint16m1_t value);
void vstore_i16m2_mask (int16_t *base, vbool8_t mask, vint16m2_t value);
void vstore_i16m4_mask (int16_t *base, vbool4_t mask, vint16m4_t value);
void vstore_i16m8_mask (int16_t *base, vbool2_t mask, vint16m8_t value);
void vstore_i32m1_mask (int32_t *base, vbool32_t mask, vint32m1_t value);
void vstore_i32m2_mask (int32_t *base, vbool16_t mask, vint32m2_t value);
void vstore_i32m4_mask (int32_t *base, vbool8_t mask, vint32m4_t value);
void vstore_i32m8_mask (int32_t *base, vbool4_t mask, vint32m8_t value);
void vstore_i64m1_mask (int64_t *base, vbool64_t mask, vint64m1_t value);
void vstore_i64m2_mask (int64_t *base, vbool32_t mask, vint64m2_t value);
void vstore_i64m4_mask (int64_t *base, vbool16_t mask, vint64m4_t value);
void vstore_i64m8_mask (int64_t *base, vbool8_t mask, vint64m8_t value);
void vstore_u8m1_mask (uint8_t *base, vbool8_t mask, vuint8m1_t value);
void vstore_u8m2_mask (uint8_t *base, vbool4_t mask, vuint8m2_t value);
void vstore_u8m4_mask (uint8_t *base, vbool2_t mask, vuint8m4_t value);
void vstore_u8m8_mask (uint8_t *base, vbool1_t mask, vuint8m8_t value);
void vstore_u16m1_mask (uint16_t *base, vbool16_t mask, vuint16m1_t value);
void vstore_u16m2_mask (uint16_t *base, vbool8_t mask, vuint16m2_t value);
void vstore_u16m4_mask (uint16_t *base, vbool4_t mask, vuint16m4_t value);
void vstore_u16m8_mask (uint16_t *base, vbool2_t mask, vuint16m8_t value);
void vstore_u32m1_mask (uint32_t *base, vbool32_t mask, vuint32m1_t value);
void vstore_u32m2_mask (uint32_t *base, vbool16_t mask, vuint32m2_t value);
void vstore_u32m4_mask (uint32_t *base, vbool8_t mask, vuint32m4_t value);
void vstore_u32m8_mask (uint32_t *base, vbool4_t mask, vuint32m8_t value);
void vstore_u64m1_mask (uint64_t *base, vbool64_t mask, vuint64m1_t value);
void vstore_u64m2_mask (uint64_t *base, vbool32_t mask, vuint64m2_t value);
void vstore_u64m4_mask (uint64_t *base, vbool16_t mask, vuint64m4_t value);
void vstore_u64m8_mask (uint64_t *base, vbool8_t mask, vuint64m8_t value);
void vstore_f16m1_mask (float16_t *base, vbool16_t mask, vfloat16m1_t value);
void vstore_f16m2_mask (float16_t *base, vbool8_t mask, vfloat16m2_t value);
void vstore_f16m4_mask (float16_t *base, vbool4_t mask, vfloat16m4_t value);
void vstore_f16m8_mask (float16_t *base, vbool2_t mask, vfloat16m8_t value);
void vstore_f32m1_mask (float32_t *base, vbool32_t mask, vfloat32m1_t value);
void vstore_f32m2_mask (float32_t *base, vbool16_t mask, vfloat32m2_t value);
void vstore_f32m4_mask (float32_t *base, vbool8_t mask, vfloat32m4_t value);
void vstore_f32m8_mask (float32_t *base, vbool4_t mask, vfloat32m8_t value);
void vstore_f64m1_mask (float64_t *base, vbool64_t mask, vfloat64m1_t value);
void vstore_f64m2_mask (float64_t *base, vbool32_t mask, vfloat64m2_t value);
void vstore_f64m4_mask (float64_t *base, vbool16_t mask, vfloat64m4_t value);
void vstore_f64m8_mask (float64_t *base, vbool8_t mask, vfloat64m8_t value);
```
### [Vector Strided Load Functions]()

**Prototypes:**
``` C
vint8m1_t vloadsb_i8m1 (const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloadsb_i8m2 (const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloadsb_i8m4 (const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloadsb_i8m8 (const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsb_i16m1 (const int8_t *base, ptrdiff_t bstride);
vint16m2_t vloadsb_i16m2 (const int8_t *base, ptrdiff_t bstride);
vint16m4_t vloadsb_i16m4 (const int8_t *base, ptrdiff_t bstride);
vint16m8_t vloadsb_i16m8 (const int8_t *base, ptrdiff_t bstride);
vint32m1_t vloadsb_i32m1 (const int8_t *base, ptrdiff_t bstride);
vint32m2_t vloadsb_i32m2 (const int8_t *base, ptrdiff_t bstride);
vint32m4_t vloadsb_i32m4 (const int8_t *base, ptrdiff_t bstride);
vint32m8_t vloadsb_i32m8 (const int8_t *base, ptrdiff_t bstride);
vint64m1_t vloadsb_i64m1 (const int8_t *base, ptrdiff_t bstride);
vint64m2_t vloadsb_i64m2 (const int8_t *base, ptrdiff_t bstride);
vint64m4_t vloadsb_i64m4 (const int8_t *base, ptrdiff_t bstride);
vint64m8_t vloadsb_i64m8 (const int8_t *base, ptrdiff_t bstride);
vuint8m1_t vloadsb_u8m1 (const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloadsb_u8m2 (const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloadsb_u8m4 (const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloadsb_u8m8 (const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsb_u16m1 (const uint8_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsb_u16m2 (const uint8_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsb_u16m4 (const uint8_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsb_u16m8 (const uint8_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsb_u32m1 (const uint8_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsb_u32m2 (const uint8_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsb_u32m4 (const uint8_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsb_u32m8 (const uint8_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsb_u64m1 (const uint8_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsb_u64m2 (const uint8_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsb_u64m4 (const uint8_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsb_u64m8 (const uint8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsh_i16m1 (const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloadsh_i16m2 (const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloadsh_i16m4 (const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloadsh_i16m8 (const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsh_i32m1 (const int16_t *base, ptrdiff_t bstride);
vint32m2_t vloadsh_i32m2 (const int16_t *base, ptrdiff_t bstride);
vint32m4_t vloadsh_i32m4 (const int16_t *base, ptrdiff_t bstride);
vint32m8_t vloadsh_i32m8 (const int16_t *base, ptrdiff_t bstride);
vint64m1_t vloadsh_i64m1 (const int16_t *base, ptrdiff_t bstride);
vint64m2_t vloadsh_i64m2 (const int16_t *base, ptrdiff_t bstride);
vint64m4_t vloadsh_i64m4 (const int16_t *base, ptrdiff_t bstride);
vint64m8_t vloadsh_i64m8 (const int16_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsh_u16m1 (const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsh_u16m2 (const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsh_u16m4 (const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsh_u16m8 (const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsh_u32m1 (const uint16_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsh_u32m2 (const uint16_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsh_u32m4 (const uint16_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsh_u32m8 (const uint16_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsh_u64m1 (const uint16_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsh_u64m2 (const uint16_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsh_u64m4 (const uint16_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsh_u64m8 (const uint16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsw_i32m1 (const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloadsw_i32m2 (const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloadsw_i32m4 (const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloadsw_i32m8 (const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloadsw_i64m1 (const int32_t *base, ptrdiff_t bstride);
vint64m2_t vloadsw_i64m2 (const int32_t *base, ptrdiff_t bstride);
vint64m4_t vloadsw_i64m4 (const int32_t *base, ptrdiff_t bstride);
vint64m8_t vloadsw_i64m8 (const int32_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsw_u32m1 (const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsw_u32m2 (const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsw_u32m4 (const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsw_u32m8 (const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsw_u64m1 (const uint32_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsw_u64m2 (const uint32_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsw_u64m4 (const uint32_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsw_u64m8 (const uint32_t *base, ptrdiff_t bstride);
vint8m1_t vloads_i8m1 (const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloads_i8m2 (const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloads_i8m4 (const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloads_i8m8 (const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloads_i16m1 (const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloads_i16m2 (const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloads_i16m4 (const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloads_i16m8 (const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloads_i32m1 (const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloads_i32m2 (const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloads_i32m4 (const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloads_i32m8 (const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloads_i64m1 (const int64_t *base, ptrdiff_t bstride);
vint64m2_t vloads_i64m2 (const int64_t *base, ptrdiff_t bstride);
vint64m4_t vloads_i64m4 (const int64_t *base, ptrdiff_t bstride);
vint64m8_t vloads_i64m8 (const int64_t *base, ptrdiff_t bstride);
vuint8m1_t vloads_u8m1 (const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloads_u8m2 (const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloads_u8m4 (const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloads_u8m8 (const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloads_u16m1 (const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloads_u16m2 (const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloads_u16m4 (const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloads_u16m8 (const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloads_u32m1 (const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloads_u32m2 (const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloads_u32m4 (const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloads_u32m8 (const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloads_u64m1 (const uint64_t *base, ptrdiff_t bstride);
vuint64m2_t vloads_u64m2 (const uint64_t *base, ptrdiff_t bstride);
vuint64m4_t vloads_u64m4 (const uint64_t *base, ptrdiff_t bstride);
vuint64m8_t vloads_u64m8 (const uint64_t *base, ptrdiff_t bstride);
vfloat16m1_t vloads_f16m1 (const float16_t *base, ptrdiff_t bstride);
vfloat16m2_t vloads_f16m2 (const float16_t *base, ptrdiff_t bstride);
vfloat16m4_t vloads_f16m4 (const float16_t *base, ptrdiff_t bstride);
vfloat16m8_t vloads_f16m8 (const float16_t *base, ptrdiff_t bstride);
vfloat32m1_t vloads_f32m1 (const float32_t *base, ptrdiff_t bstride);
vfloat32m2_t vloads_f32m2 (const float32_t *base, ptrdiff_t bstride);
vfloat32m4_t vloads_f32m4 (const float32_t *base, ptrdiff_t bstride);
vfloat32m8_t vloads_f32m8 (const float32_t *base, ptrdiff_t bstride);
vfloat64m1_t vloads_f64m1 (const float64_t *base, ptrdiff_t bstride);
vfloat64m2_t vloads_f64m2 (const float64_t *base, ptrdiff_t bstride);
vfloat64m4_t vloads_f64m4 (const float64_t *base, ptrdiff_t bstride);
vfloat64m8_t vloads_f64m8 (const float64_t *base, ptrdiff_t bstride);
// masked functions
vint8m1_t vloadsb_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloadsb_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloadsb_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloadsb_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsb_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m2_t vloadsb_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m4_t vloadsb_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m8_t vloadsb_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m1_t vloadsb_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m2_t vloadsb_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m4_t vloadsb_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m8_t vloadsb_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m1_t vloadsb_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m2_t vloadsb_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m4_t vloadsb_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m8_t vloadsb_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vuint8m1_t vloadsb_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloadsb_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloadsb_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloadsb_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsb_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsb_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsb_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsb_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsb_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsb_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsb_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsb_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsb_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsb_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsb_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsb_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsh_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloadsh_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloadsh_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloadsh_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsh_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m2_t vloadsh_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m4_t vloadsh_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m8_t vloadsh_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m1_t vloadsh_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m2_t vloadsh_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m4_t vloadsh_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m8_t vloadsh_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsh_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsh_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsh_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsh_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsh_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsh_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsh_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsh_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsh_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsh_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsh_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsh_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsw_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloadsw_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloadsw_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloadsw_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloadsw_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m2_t vloadsw_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m4_t vloadsw_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m8_t vloadsw_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsw_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsw_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsw_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsw_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsw_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsw_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsw_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsw_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vint8m1_t vloads_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloads_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloads_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloads_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloads_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloads_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloads_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloads_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloads_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloads_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloads_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloads_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloads_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m2_t vloads_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m4_t vloads_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m8_t vloads_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vuint8m1_t vloads_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloads_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloads_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloads_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloads_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloads_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloads_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloads_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloads_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloads_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloads_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloads_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloads_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m2_t vloads_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m4_t vloads_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m8_t vloads_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vfloat16m1_t vloads_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m2_t vloads_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m4_t vloads_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m8_t vloads_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat32m1_t vloads_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m2_t vloads_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m4_t vloads_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m8_t vloads_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat64m1_t vloads_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m2_t vloads_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m4_t vloads_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m8_t vloads_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, ptrdiff_t bstride);
```
### [Vector Strided Store Functions]()

**Prototypes:**
``` C
void vstoresb_i8m1 (int8_t *base, ptrdiff_t bstride, vint8m1_t value);
void vstoresb_i8m2 (int8_t *base, ptrdiff_t bstride, vint8m2_t value);
void vstoresb_i8m4 (int8_t *base, ptrdiff_t bstride, vint8m4_t value);
void vstoresb_i8m8 (int8_t *base, ptrdiff_t bstride, vint8m8_t value);
void vstoresb_i16m1 (int8_t *base, ptrdiff_t bstride, vint16m1_t value);
void vstoresb_i16m2 (int8_t *base, ptrdiff_t bstride, vint16m2_t value);
void vstoresb_i16m4 (int8_t *base, ptrdiff_t bstride, vint16m4_t value);
void vstoresb_i16m8 (int8_t *base, ptrdiff_t bstride, vint16m8_t value);
void vstoresb_i32m1 (int8_t *base, ptrdiff_t bstride, vint32m1_t value);
void vstoresb_i32m2 (int8_t *base, ptrdiff_t bstride, vint32m2_t value);
void vstoresb_i32m4 (int8_t *base, ptrdiff_t bstride, vint32m4_t value);
void vstoresb_i32m8 (int8_t *base, ptrdiff_t bstride, vint32m8_t value);
void vstoresb_i64m1 (int8_t *base, ptrdiff_t bstride, vint64m1_t value);
void vstoresb_i64m2 (int8_t *base, ptrdiff_t bstride, vint64m2_t value);
void vstoresb_i64m4 (int8_t *base, ptrdiff_t bstride, vint64m4_t value);
void vstoresb_i64m8 (int8_t *base, ptrdiff_t bstride, vint64m8_t value);
void vstoresb_u8m1 (uint8_t *base, ptrdiff_t bstride, vuint8m1_t value);
void vstoresb_u8m2 (uint8_t *base, ptrdiff_t bstride, vuint8m2_t value);
void vstoresb_u8m4 (uint8_t *base, ptrdiff_t bstride, vuint8m4_t value);
void vstoresb_u8m8 (uint8_t *base, ptrdiff_t bstride, vuint8m8_t value);
void vstoresb_u16m1 (uint8_t *base, ptrdiff_t bstride, vuint16m1_t value);
void vstoresb_u16m2 (uint8_t *base, ptrdiff_t bstride, vuint16m2_t value);
void vstoresb_u16m4 (uint8_t *base, ptrdiff_t bstride, vuint16m4_t value);
void vstoresb_u16m8 (uint8_t *base, ptrdiff_t bstride, vuint16m8_t value);
void vstoresb_u32m1 (uint8_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vstoresb_u32m2 (uint8_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vstoresb_u32m4 (uint8_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vstoresb_u32m8 (uint8_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vstoresb_u64m1 (uint8_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vstoresb_u64m2 (uint8_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vstoresb_u64m4 (uint8_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vstoresb_u64m8 (uint8_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vstoresh_i16m1 (int16_t *base, ptrdiff_t bstride, vint16m1_t value);
void vstoresh_i16m2 (int16_t *base, ptrdiff_t bstride, vint16m2_t value);
void vstoresh_i16m4 (int16_t *base, ptrdiff_t bstride, vint16m4_t value);
void vstoresh_i16m8 (int16_t *base, ptrdiff_t bstride, vint16m8_t value);
void vstoresh_i32m1 (int16_t *base, ptrdiff_t bstride, vint32m1_t value);
void vstoresh_i32m2 (int16_t *base, ptrdiff_t bstride, vint32m2_t value);
void vstoresh_i32m4 (int16_t *base, ptrdiff_t bstride, vint32m4_t value);
void vstoresh_i32m8 (int16_t *base, ptrdiff_t bstride, vint32m8_t value);
void vstoresh_i64m1 (int16_t *base, ptrdiff_t bstride, vint64m1_t value);
void vstoresh_i64m2 (int16_t *base, ptrdiff_t bstride, vint64m2_t value);
void vstoresh_i64m4 (int16_t *base, ptrdiff_t bstride, vint64m4_t value);
void vstoresh_i64m8 (int16_t *base, ptrdiff_t bstride, vint64m8_t value);
void vstoresh_u16m1 (uint16_t *base, ptrdiff_t bstride, vuint16m1_t value);
void vstoresh_u16m2 (uint16_t *base, ptrdiff_t bstride, vuint16m2_t value);
void vstoresh_u16m4 (uint16_t *base, ptrdiff_t bstride, vuint16m4_t value);
void vstoresh_u16m8 (uint16_t *base, ptrdiff_t bstride, vuint16m8_t value);
void vstoresh_u32m1 (uint16_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vstoresh_u32m2 (uint16_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vstoresh_u32m4 (uint16_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vstoresh_u32m8 (uint16_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vstoresh_u64m1 (uint16_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vstoresh_u64m2 (uint16_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vstoresh_u64m4 (uint16_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vstoresh_u64m8 (uint16_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vstoresw_i32m1 (int32_t *base, ptrdiff_t bstride, vint32m1_t value);
void vstoresw_i32m2 (int32_t *base, ptrdiff_t bstride, vint32m2_t value);
void vstoresw_i32m4 (int32_t *base, ptrdiff_t bstride, vint32m4_t value);
void vstoresw_i32m8 (int32_t *base, ptrdiff_t bstride, vint32m8_t value);
void vstoresw_i64m1 (int32_t *base, ptrdiff_t bstride, vint64m1_t value);
void vstoresw_i64m2 (int32_t *base, ptrdiff_t bstride, vint64m2_t value);
void vstoresw_i64m4 (int32_t *base, ptrdiff_t bstride, vint64m4_t value);
void vstoresw_i64m8 (int32_t *base, ptrdiff_t bstride, vint64m8_t value);
void vstoresw_u32m1 (uint32_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vstoresw_u32m2 (uint32_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vstoresw_u32m4 (uint32_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vstoresw_u32m8 (uint32_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vstoresw_u64m1 (uint32_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vstoresw_u64m2 (uint32_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vstoresw_u64m4 (uint32_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vstoresw_u64m8 (uint32_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vstores_i8m1 (int8_t *base, ptrdiff_t bstride, vint8m1_t value);
void vstores_i8m2 (int8_t *base, ptrdiff_t bstride, vint8m2_t value);
void vstores_i8m4 (int8_t *base, ptrdiff_t bstride, vint8m4_t value);
void vstores_i8m8 (int8_t *base, ptrdiff_t bstride, vint8m8_t value);
void vstores_i16m1 (int16_t *base, ptrdiff_t bstride, vint16m1_t value);
void vstores_i16m2 (int16_t *base, ptrdiff_t bstride, vint16m2_t value);
void vstores_i16m4 (int16_t *base, ptrdiff_t bstride, vint16m4_t value);
void vstores_i16m8 (int16_t *base, ptrdiff_t bstride, vint16m8_t value);
void vstores_i32m1 (int32_t *base, ptrdiff_t bstride, vint32m1_t value);
void vstores_i32m2 (int32_t *base, ptrdiff_t bstride, vint32m2_t value);
void vstores_i32m4 (int32_t *base, ptrdiff_t bstride, vint32m4_t value);
void vstores_i32m8 (int32_t *base, ptrdiff_t bstride, vint32m8_t value);
void vstores_i64m1 (int64_t *base, ptrdiff_t bstride, vint64m1_t value);
void vstores_i64m2 (int64_t *base, ptrdiff_t bstride, vint64m2_t value);
void vstores_i64m4 (int64_t *base, ptrdiff_t bstride, vint64m4_t value);
void vstores_i64m8 (int64_t *base, ptrdiff_t bstride, vint64m8_t value);
void vstores_u8m1 (uint8_t *base, ptrdiff_t bstride, vuint8m1_t value);
void vstores_u8m2 (uint8_t *base, ptrdiff_t bstride, vuint8m2_t value);
void vstores_u8m4 (uint8_t *base, ptrdiff_t bstride, vuint8m4_t value);
void vstores_u8m8 (uint8_t *base, ptrdiff_t bstride, vuint8m8_t value);
void vstores_u16m1 (uint16_t *base, ptrdiff_t bstride, vuint16m1_t value);
void vstores_u16m2 (uint16_t *base, ptrdiff_t bstride, vuint16m2_t value);
void vstores_u16m4 (uint16_t *base, ptrdiff_t bstride, vuint16m4_t value);
void vstores_u16m8 (uint16_t *base, ptrdiff_t bstride, vuint16m8_t value);
void vstores_u32m1 (uint32_t *base, ptrdiff_t bstride, vuint32m1_t value);
void vstores_u32m2 (uint32_t *base, ptrdiff_t bstride, vuint32m2_t value);
void vstores_u32m4 (uint32_t *base, ptrdiff_t bstride, vuint32m4_t value);
void vstores_u32m8 (uint32_t *base, ptrdiff_t bstride, vuint32m8_t value);
void vstores_u64m1 (uint64_t *base, ptrdiff_t bstride, vuint64m1_t value);
void vstores_u64m2 (uint64_t *base, ptrdiff_t bstride, vuint64m2_t value);
void vstores_u64m4 (uint64_t *base, ptrdiff_t bstride, vuint64m4_t value);
void vstores_u64m8 (uint64_t *base, ptrdiff_t bstride, vuint64m8_t value);
void vstores_f16m1 (float16_t *base, ptrdiff_t bstride, vfloat16m1_t value);
void vstores_f16m2 (float16_t *base, ptrdiff_t bstride, vfloat16m2_t value);
void vstores_f16m4 (float16_t *base, ptrdiff_t bstride, vfloat16m4_t value);
void vstores_f16m8 (float16_t *base, ptrdiff_t bstride, vfloat16m8_t value);
void vstores_f32m1 (float32_t *base, ptrdiff_t bstride, vfloat32m1_t value);
void vstores_f32m2 (float32_t *base, ptrdiff_t bstride, vfloat32m2_t value);
void vstores_f32m4 (float32_t *base, ptrdiff_t bstride, vfloat32m4_t value);
void vstores_f32m8 (float32_t *base, ptrdiff_t bstride, vfloat32m8_t value);
void vstores_f64m1 (float64_t *base, ptrdiff_t bstride, vfloat64m1_t value);
void vstores_f64m2 (float64_t *base, ptrdiff_t bstride, vfloat64m2_t value);
void vstores_f64m4 (float64_t *base, ptrdiff_t bstride, vfloat64m4_t value);
void vstores_f64m8 (float64_t *base, ptrdiff_t bstride, vfloat64m8_t value);
// masked functions
void vstoresb_i8m1_mask (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint8m1_t value);
void vstoresb_i8m2_mask (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint8m2_t value);
void vstoresb_i8m4_mask (int8_t *base, ptrdiff_t bstride, vbool2_t mask, vint8m4_t value);
void vstoresb_i8m8_mask (int8_t *base, ptrdiff_t bstride, vbool1_t mask, vint8m8_t value);
void vstoresb_i16m1_mask (int8_t *base, ptrdiff_t bstride, vbool16_t mask, vint16m1_t value);
void vstoresb_i16m2_mask (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint16m2_t value);
void vstoresb_i16m4_mask (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint16m4_t value);
void vstoresb_i16m8_mask (int8_t *base, ptrdiff_t bstride, vbool2_t mask, vint16m8_t value);
void vstoresb_i32m1_mask (int8_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vstoresb_i32m2_mask (int8_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vstoresb_i32m4_mask (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vstoresb_i32m8_mask (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vstoresb_i64m1_mask (int8_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vstoresb_i64m2_mask (int8_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vstoresb_i64m4_mask (int8_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vstoresb_i64m8_mask (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vstoresb_u8m1_mask (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint8m1_t value);
void vstoresb_u8m2_mask (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint8m2_t value);
void vstoresb_u8m4_mask (uint8_t *base, ptrdiff_t bstride, vbool2_t mask, vuint8m4_t value);
void vstoresb_u8m8_mask (uint8_t *base, ptrdiff_t bstride, vbool1_t mask, vuint8m8_t value);
void vstoresb_u16m1_mask (uint8_t *base, ptrdiff_t bstride, vbool16_t mask, vuint16m1_t value);
void vstoresb_u16m2_mask (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint16m2_t value);
void vstoresb_u16m4_mask (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint16m4_t value);
void vstoresb_u16m8_mask (uint8_t *base, ptrdiff_t bstride, vbool2_t mask, vuint16m8_t value);
void vstoresb_u32m1_mask (uint8_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vstoresb_u32m2_mask (uint8_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vstoresb_u32m4_mask (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vstoresb_u32m8_mask (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vstoresb_u64m1_mask (uint8_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vstoresb_u64m2_mask (uint8_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vstoresb_u64m4_mask (uint8_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vstoresb_u64m8_mask (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vstoresh_i16m1_mask (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint16m1_t value);
void vstoresh_i16m2_mask (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint16m2_t value);
void vstoresh_i16m4_mask (int16_t *base, ptrdiff_t bstride, vbool4_t mask, vint16m4_t value);
void vstoresh_i16m8_mask (int16_t *base, ptrdiff_t bstride, vbool2_t mask, vint16m8_t value);
void vstoresh_i32m1_mask (int16_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vstoresh_i32m2_mask (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vstoresh_i32m4_mask (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vstoresh_i32m8_mask (int16_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vstoresh_i64m1_mask (int16_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vstoresh_i64m2_mask (int16_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vstoresh_i64m4_mask (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vstoresh_i64m8_mask (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vstoresh_u16m1_mask (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint16m1_t value);
void vstoresh_u16m2_mask (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint16m2_t value);
void vstoresh_u16m4_mask (uint16_t *base, ptrdiff_t bstride, vbool4_t mask, vuint16m4_t value);
void vstoresh_u16m8_mask (uint16_t *base, ptrdiff_t bstride, vbool2_t mask, vuint16m8_t value);
void vstoresh_u32m1_mask (uint16_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vstoresh_u32m2_mask (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vstoresh_u32m4_mask (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vstoresh_u32m8_mask (uint16_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vstoresh_u64m1_mask (uint16_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vstoresh_u64m2_mask (uint16_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vstoresh_u64m4_mask (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vstoresh_u64m8_mask (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vstoresw_i32m1_mask (int32_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vstoresw_i32m2_mask (int32_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vstoresw_i32m4_mask (int32_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vstoresw_i32m8_mask (int32_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vstoresw_i64m1_mask (int32_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vstoresw_i64m2_mask (int32_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vstoresw_i64m4_mask (int32_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vstoresw_i64m8_mask (int32_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vstoresw_u32m1_mask (uint32_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vstoresw_u32m2_mask (uint32_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vstoresw_u32m4_mask (uint32_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vstoresw_u32m8_mask (uint32_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vstoresw_u64m1_mask (uint32_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vstoresw_u64m2_mask (uint32_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vstoresw_u64m4_mask (uint32_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vstoresw_u64m8_mask (uint32_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vstores_i8m1_mask (int8_t *base, ptrdiff_t bstride, vbool8_t mask, vint8m1_t value);
void vstores_i8m2_mask (int8_t *base, ptrdiff_t bstride, vbool4_t mask, vint8m2_t value);
void vstores_i8m4_mask (int8_t *base, ptrdiff_t bstride, vbool2_t mask, vint8m4_t value);
void vstores_i8m8_mask (int8_t *base, ptrdiff_t bstride, vbool1_t mask, vint8m8_t value);
void vstores_i16m1_mask (int16_t *base, ptrdiff_t bstride, vbool16_t mask, vint16m1_t value);
void vstores_i16m2_mask (int16_t *base, ptrdiff_t bstride, vbool8_t mask, vint16m2_t value);
void vstores_i16m4_mask (int16_t *base, ptrdiff_t bstride, vbool4_t mask, vint16m4_t value);
void vstores_i16m8_mask (int16_t *base, ptrdiff_t bstride, vbool2_t mask, vint16m8_t value);
void vstores_i32m1_mask (int32_t *base, ptrdiff_t bstride, vbool32_t mask, vint32m1_t value);
void vstores_i32m2_mask (int32_t *base, ptrdiff_t bstride, vbool16_t mask, vint32m2_t value);
void vstores_i32m4_mask (int32_t *base, ptrdiff_t bstride, vbool8_t mask, vint32m4_t value);
void vstores_i32m8_mask (int32_t *base, ptrdiff_t bstride, vbool4_t mask, vint32m8_t value);
void vstores_i64m1_mask (int64_t *base, ptrdiff_t bstride, vbool64_t mask, vint64m1_t value);
void vstores_i64m2_mask (int64_t *base, ptrdiff_t bstride, vbool32_t mask, vint64m2_t value);
void vstores_i64m4_mask (int64_t *base, ptrdiff_t bstride, vbool16_t mask, vint64m4_t value);
void vstores_i64m8_mask (int64_t *base, ptrdiff_t bstride, vbool8_t mask, vint64m8_t value);
void vstores_u8m1_mask (uint8_t *base, ptrdiff_t bstride, vbool8_t mask, vuint8m1_t value);
void vstores_u8m2_mask (uint8_t *base, ptrdiff_t bstride, vbool4_t mask, vuint8m2_t value);
void vstores_u8m4_mask (uint8_t *base, ptrdiff_t bstride, vbool2_t mask, vuint8m4_t value);
void vstores_u8m8_mask (uint8_t *base, ptrdiff_t bstride, vbool1_t mask, vuint8m8_t value);
void vstores_u16m1_mask (uint16_t *base, ptrdiff_t bstride, vbool16_t mask, vuint16m1_t value);
void vstores_u16m2_mask (uint16_t *base, ptrdiff_t bstride, vbool8_t mask, vuint16m2_t value);
void vstores_u16m4_mask (uint16_t *base, ptrdiff_t bstride, vbool4_t mask, vuint16m4_t value);
void vstores_u16m8_mask (uint16_t *base, ptrdiff_t bstride, vbool2_t mask, vuint16m8_t value);
void vstores_u32m1_mask (uint32_t *base, ptrdiff_t bstride, vbool32_t mask, vuint32m1_t value);
void vstores_u32m2_mask (uint32_t *base, ptrdiff_t bstride, vbool16_t mask, vuint32m2_t value);
void vstores_u32m4_mask (uint32_t *base, ptrdiff_t bstride, vbool8_t mask, vuint32m4_t value);
void vstores_u32m8_mask (uint32_t *base, ptrdiff_t bstride, vbool4_t mask, vuint32m8_t value);
void vstores_u64m1_mask (uint64_t *base, ptrdiff_t bstride, vbool64_t mask, vuint64m1_t value);
void vstores_u64m2_mask (uint64_t *base, ptrdiff_t bstride, vbool32_t mask, vuint64m2_t value);
void vstores_u64m4_mask (uint64_t *base, ptrdiff_t bstride, vbool16_t mask, vuint64m4_t value);
void vstores_u64m8_mask (uint64_t *base, ptrdiff_t bstride, vbool8_t mask, vuint64m8_t value);
void vstores_f16m1_mask (float16_t *base, ptrdiff_t bstride, vbool16_t mask, vfloat16m1_t value);
void vstores_f16m2_mask (float16_t *base, ptrdiff_t bstride, vbool8_t mask, vfloat16m2_t value);
void vstores_f16m4_mask (float16_t *base, ptrdiff_t bstride, vbool4_t mask, vfloat16m4_t value);
void vstores_f16m8_mask (float16_t *base, ptrdiff_t bstride, vbool2_t mask, vfloat16m8_t value);
void vstores_f32m1_mask (float32_t *base, ptrdiff_t bstride, vbool32_t mask, vfloat32m1_t value);
void vstores_f32m2_mask (float32_t *base, ptrdiff_t bstride, vbool16_t mask, vfloat32m2_t value);
void vstores_f32m4_mask (float32_t *base, ptrdiff_t bstride, vbool8_t mask, vfloat32m4_t value);
void vstores_f32m8_mask (float32_t *base, ptrdiff_t bstride, vbool4_t mask, vfloat32m8_t value);
void vstores_f64m1_mask (float64_t *base, ptrdiff_t bstride, vbool64_t mask, vfloat64m1_t value);
void vstores_f64m2_mask (float64_t *base, ptrdiff_t bstride, vbool32_t mask, vfloat64m2_t value);
void vstores_f64m4_mask (float64_t *base, ptrdiff_t bstride, vbool16_t mask, vfloat64m4_t value);
void vstores_f64m8_mask (float64_t *base, ptrdiff_t bstride, vbool8_t mask, vfloat64m8_t value);
```
### [Vector Indexed Load Functions]()

**Prototypes:**
``` C
vint8m1_t vloadxb_i8m1 (const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadxb_i8m2 (const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadxb_i8m4 (const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadxb_i8m8 (const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadxb_i16m1 (const int8_t *base, vuint16m1_t bindex);
vint16m2_t vloadxb_i16m2 (const int8_t *base, vuint16m2_t bindex);
vint16m4_t vloadxb_i16m4 (const int8_t *base, vuint16m4_t bindex);
vint16m8_t vloadxb_i16m8 (const int8_t *base, vuint16m8_t bindex);
vint32m1_t vloadxb_i32m1 (const int8_t *base, vuint32m1_t bindex);
vint32m2_t vloadxb_i32m2 (const int8_t *base, vuint32m2_t bindex);
vint32m4_t vloadxb_i32m4 (const int8_t *base, vuint32m4_t bindex);
vint32m8_t vloadxb_i32m8 (const int8_t *base, vuint32m8_t bindex);
vint64m1_t vloadxb_i64m1 (const int8_t *base, vuint64m1_t bindex);
vint64m2_t vloadxb_i64m2 (const int8_t *base, vuint64m2_t bindex);
vint64m4_t vloadxb_i64m4 (const int8_t *base, vuint64m4_t bindex);
vint64m8_t vloadxb_i64m8 (const int8_t *base, vuint64m8_t bindex);
vuint8m1_t vloadxb_u8m1 (const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadxb_u8m2 (const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadxb_u8m4 (const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadxb_u8m8 (const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadxb_u16m1 (const uint8_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxb_u16m2 (const uint8_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxb_u16m4 (const uint8_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxb_u16m8 (const uint8_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxb_u32m1 (const uint8_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxb_u32m2 (const uint8_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxb_u32m4 (const uint8_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxb_u32m8 (const uint8_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxb_u64m1 (const uint8_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxb_u64m2 (const uint8_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxb_u64m4 (const uint8_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxb_u64m8 (const uint8_t *base, vuint64m8_t bindex);
vint16m1_t vloadxh_i16m1 (const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadxh_i16m2 (const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadxh_i16m4 (const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadxh_i16m8 (const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadxh_i32m1 (const int16_t *base, vuint32m1_t bindex);
vint32m2_t vloadxh_i32m2 (const int16_t *base, vuint32m2_t bindex);
vint32m4_t vloadxh_i32m4 (const int16_t *base, vuint32m4_t bindex);
vint32m8_t vloadxh_i32m8 (const int16_t *base, vuint32m8_t bindex);
vint64m1_t vloadxh_i64m1 (const int16_t *base, vuint64m1_t bindex);
vint64m2_t vloadxh_i64m2 (const int16_t *base, vuint64m2_t bindex);
vint64m4_t vloadxh_i64m4 (const int16_t *base, vuint64m4_t bindex);
vint64m8_t vloadxh_i64m8 (const int16_t *base, vuint64m8_t bindex);
vuint16m1_t vloadxh_u16m1 (const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxh_u16m2 (const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxh_u16m4 (const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxh_u16m8 (const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxh_u32m1 (const uint16_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxh_u32m2 (const uint16_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxh_u32m4 (const uint16_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxh_u32m8 (const uint16_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxh_u64m1 (const uint16_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxh_u64m2 (const uint16_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxh_u64m4 (const uint16_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxh_u64m8 (const uint16_t *base, vuint64m8_t bindex);
vint32m1_t vloadxw_i32m1 (const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadxw_i32m2 (const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadxw_i32m4 (const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadxw_i32m8 (const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadxw_i64m1 (const int32_t *base, vuint64m1_t bindex);
vint64m2_t vloadxw_i64m2 (const int32_t *base, vuint64m2_t bindex);
vint64m4_t vloadxw_i64m4 (const int32_t *base, vuint64m4_t bindex);
vint64m8_t vloadxw_i64m8 (const int32_t *base, vuint64m8_t bindex);
vuint32m1_t vloadxw_u32m1 (const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxw_u32m2 (const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxw_u32m4 (const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxw_u32m8 (const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxw_u64m1 (const uint32_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxw_u64m2 (const uint32_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxw_u64m4 (const uint32_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxw_u64m8 (const uint32_t *base, vuint64m8_t bindex);
vint8m1_t vloadx_i8m1 (const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadx_i8m2 (const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadx_i8m4 (const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadx_i8m8 (const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadx_i16m1 (const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadx_i16m2 (const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadx_i16m4 (const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadx_i16m8 (const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadx_i32m1 (const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadx_i32m2 (const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadx_i32m4 (const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadx_i32m8 (const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadx_i64m1 (const int64_t *base, vuint64m1_t bindex);
vint64m2_t vloadx_i64m2 (const int64_t *base, vuint64m2_t bindex);
vint64m4_t vloadx_i64m4 (const int64_t *base, vuint64m4_t bindex);
vint64m8_t vloadx_i64m8 (const int64_t *base, vuint64m8_t bindex);
vuint8m1_t vloadx_u8m1 (const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadx_u8m2 (const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadx_u8m4 (const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadx_u8m8 (const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadx_u16m1 (const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadx_u16m2 (const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadx_u16m4 (const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadx_u16m8 (const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadx_u32m1 (const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadx_u32m2 (const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadx_u32m4 (const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadx_u32m8 (const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadx_u64m1 (const uint64_t *base, vuint64m1_t bindex);
vuint64m2_t vloadx_u64m2 (const uint64_t *base, vuint64m2_t bindex);
vuint64m4_t vloadx_u64m4 (const uint64_t *base, vuint64m4_t bindex);
vuint64m8_t vloadx_u64m8 (const uint64_t *base, vuint64m8_t bindex);
vfloat16m1_t vloadx_f16m1 (const float16_t *base, vuint16m1_t bindex);
vfloat16m2_t vloadx_f16m2 (const float16_t *base, vuint16m2_t bindex);
vfloat16m4_t vloadx_f16m4 (const float16_t *base, vuint16m4_t bindex);
vfloat16m8_t vloadx_f16m8 (const float16_t *base, vuint16m8_t bindex);
vfloat32m1_t vloadx_f32m1 (const float32_t *base, vuint32m1_t bindex);
vfloat32m2_t vloadx_f32m2 (const float32_t *base, vuint32m2_t bindex);
vfloat32m4_t vloadx_f32m4 (const float32_t *base, vuint32m4_t bindex);
vfloat32m8_t vloadx_f32m8 (const float32_t *base, vuint32m8_t bindex);
vfloat64m1_t vloadx_f64m1 (const float64_t *base, vuint64m1_t bindex);
vfloat64m2_t vloadx_f64m2 (const float64_t *base, vuint64m2_t bindex);
vfloat64m4_t vloadx_f64m4 (const float64_t *base, vuint64m4_t bindex);
vfloat64m8_t vloadx_f64m8 (const float64_t *base, vuint64m8_t bindex);
// masked functions
vint8m1_t vloadxb_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadxb_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadxb_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadxb_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadxb_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base, vuint16m1_t bindex);
vint16m2_t vloadxb_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base, vuint16m2_t bindex);
vint16m4_t vloadxb_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base, vuint16m4_t bindex);
vint16m8_t vloadxb_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base, vuint16m8_t bindex);
vint32m1_t vloadxb_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base, vuint32m1_t bindex);
vint32m2_t vloadxb_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base, vuint32m2_t bindex);
vint32m4_t vloadxb_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base, vuint32m4_t bindex);
vint32m8_t vloadxb_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base, vuint32m8_t bindex);
vint64m1_t vloadxb_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base, vuint64m1_t bindex);
vint64m2_t vloadxb_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base, vuint64m2_t bindex);
vint64m4_t vloadxb_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base, vuint64m4_t bindex);
vint64m8_t vloadxb_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base, vuint64m8_t bindex);
vuint8m1_t vloadxb_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadxb_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadxb_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadxb_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadxb_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxb_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxb_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxb_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxb_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxb_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxb_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxb_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxb_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxb_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxb_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxb_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base, vuint64m8_t bindex);
vint16m1_t vloadxh_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadxh_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadxh_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadxh_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadxh_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base, vuint32m1_t bindex);
vint32m2_t vloadxh_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base, vuint32m2_t bindex);
vint32m4_t vloadxh_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base, vuint32m4_t bindex);
vint32m8_t vloadxh_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base, vuint32m8_t bindex);
vint64m1_t vloadxh_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base, vuint64m1_t bindex);
vint64m2_t vloadxh_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base, vuint64m2_t bindex);
vint64m4_t vloadxh_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base, vuint64m4_t bindex);
vint64m8_t vloadxh_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base, vuint64m8_t bindex);
vuint16m1_t vloadxh_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxh_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxh_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxh_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxh_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxh_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxh_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxh_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxh_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxh_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxh_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxh_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base, vuint64m8_t bindex);
vint32m1_t vloadxw_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadxw_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadxw_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadxw_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadxw_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base, vuint64m1_t bindex);
vint64m2_t vloadxw_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base, vuint64m2_t bindex);
vint64m4_t vloadxw_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base, vuint64m4_t bindex);
vint64m8_t vloadxw_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base, vuint64m8_t bindex);
vuint32m1_t vloadxw_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxw_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxw_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxw_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxw_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxw_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxw_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxw_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base, vuint64m8_t bindex);
vint8m1_t vloadx_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadx_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadx_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadx_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadx_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadx_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadx_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadx_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadx_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadx_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadx_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadx_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadx_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex);
vint64m2_t vloadx_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex);
vint64m4_t vloadx_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex);
vint64m8_t vloadx_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex);
vuint8m1_t vloadx_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadx_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadx_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadx_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadx_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadx_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadx_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadx_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadx_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadx_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadx_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadx_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadx_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex);
vuint64m2_t vloadx_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex);
vuint64m4_t vloadx_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex);
vuint64m8_t vloadx_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex);
vfloat16m1_t vloadx_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex);
vfloat16m2_t vloadx_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex);
vfloat16m4_t vloadx_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex);
vfloat16m8_t vloadx_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex);
vfloat32m1_t vloadx_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex);
vfloat32m2_t vloadx_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex);
vfloat32m4_t vloadx_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex);
vfloat32m8_t vloadx_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex);
vfloat64m1_t vloadx_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex);
vfloat64m2_t vloadx_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex);
vfloat64m4_t vloadx_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex);
vfloat64m8_t vloadx_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex);
```
### [Vector Indexed Store Functions]()

**Prototypes:**
``` C
void vstorexb_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstorexb_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstorexb_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstorexb_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstorexb_i16m1 (int8_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstorexb_i16m2 (int8_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstorexb_i16m4 (int8_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstorexb_i16m8 (int8_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstorexb_i32m1 (int8_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorexb_i32m2 (int8_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorexb_i32m4 (int8_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorexb_i32m8 (int8_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorexb_i64m1 (int8_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorexb_i64m2 (int8_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorexb_i64m4 (int8_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorexb_i64m8 (int8_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorexb_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstorexb_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstorexb_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstorexb_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstorexb_u16m1 (uint8_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstorexb_u16m2 (uint8_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstorexb_u16m4 (uint8_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstorexb_u16m8 (uint8_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstorexb_u32m1 (uint8_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorexb_u32m2 (uint8_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorexb_u32m4 (uint8_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorexb_u32m8 (uint8_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorexb_u64m1 (uint8_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorexb_u64m2 (uint8_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorexb_u64m4 (uint8_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorexb_u64m8 (uint8_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorexh_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstorexh_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstorexh_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstorexh_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstorexh_i32m1 (int16_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorexh_i32m2 (int16_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorexh_i32m4 (int16_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorexh_i32m8 (int16_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorexh_i64m1 (int16_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorexh_i64m2 (int16_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorexh_i64m4 (int16_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorexh_i64m8 (int16_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorexh_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstorexh_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstorexh_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstorexh_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstorexh_u32m1 (uint16_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorexh_u32m2 (uint16_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorexh_u32m4 (uint16_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorexh_u32m8 (uint16_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorexh_u64m1 (uint16_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorexh_u64m2 (uint16_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorexh_u64m4 (uint16_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorexh_u64m8 (uint16_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorexw_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorexw_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorexw_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorexw_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorexw_i64m1 (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorexw_i64m2 (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorexw_i64m4 (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorexw_i64m8 (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorexw_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorexw_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorexw_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorexw_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorexw_u64m1 (uint32_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorexw_u64m2 (uint32_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorexw_u64m4 (uint32_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorexw_u64m8 (uint32_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorex_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstorex_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstorex_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstorex_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstorex_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstorex_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstorex_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstorex_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstorex_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorex_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorex_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorex_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorex_i64m1 (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorex_i64m2 (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorex_i64m4 (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorex_i64m8 (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorex_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstorex_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstorex_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstorex_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstorex_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstorex_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstorex_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstorex_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstorex_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorex_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorex_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorex_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorex_u64m1 (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorex_u64m2 (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorex_u64m4 (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorex_u64m8 (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorex_f16m1 (float16_t *base, vuint16m1_t bindex, vfloat16m1_t value);
void vstorex_f16m2 (float16_t *base, vuint16m2_t bindex, vfloat16m2_t value);
void vstorex_f16m4 (float16_t *base, vuint16m4_t bindex, vfloat16m4_t value);
void vstorex_f16m8 (float16_t *base, vuint16m8_t bindex, vfloat16m8_t value);
void vstorex_f32m1 (float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
void vstorex_f32m2 (float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
void vstorex_f32m4 (float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
void vstorex_f32m8 (float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
void vstorex_f64m1 (float64_t *base, vuint64m1_t bindex, vfloat64m1_t value);
void vstorex_f64m2 (float64_t *base, vuint64m2_t bindex, vfloat64m2_t value);
void vstorex_f64m4 (float64_t *base, vuint64m4_t bindex, vfloat64m4_t value);
void vstorex_f64m8 (float64_t *base, vuint64m8_t bindex, vfloat64m8_t value);
void vstoreuxb_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstoreuxb_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstoreuxb_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstoreuxb_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstoreuxb_i16m1 (int8_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstoreuxb_i16m2 (int8_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstoreuxb_i16m4 (int8_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstoreuxb_i16m8 (int8_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstoreuxb_i32m1 (int8_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreuxb_i32m2 (int8_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreuxb_i32m4 (int8_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreuxb_i32m8 (int8_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreuxb_i64m1 (int8_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreuxb_i64m2 (int8_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreuxb_i64m4 (int8_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreuxb_i64m8 (int8_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreuxb_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstoreuxb_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstoreuxb_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstoreuxb_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstoreuxb_u16m1 (uint8_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstoreuxb_u16m2 (uint8_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstoreuxb_u16m4 (uint8_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstoreuxb_u16m8 (uint8_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstoreuxb_u32m1 (uint8_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreuxb_u32m2 (uint8_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreuxb_u32m4 (uint8_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreuxb_u32m8 (uint8_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreuxb_u64m1 (uint8_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreuxb_u64m2 (uint8_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreuxb_u64m4 (uint8_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreuxb_u64m8 (uint8_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreuxh_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstoreuxh_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstoreuxh_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstoreuxh_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstoreuxh_i32m1 (int16_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreuxh_i32m2 (int16_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreuxh_i32m4 (int16_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreuxh_i32m8 (int16_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreuxh_i64m1 (int16_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreuxh_i64m2 (int16_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreuxh_i64m4 (int16_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreuxh_i64m8 (int16_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreuxh_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstoreuxh_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstoreuxh_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstoreuxh_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstoreuxh_u32m1 (uint16_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreuxh_u32m2 (uint16_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreuxh_u32m4 (uint16_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreuxh_u32m8 (uint16_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreuxh_u64m1 (uint16_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreuxh_u64m2 (uint16_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreuxh_u64m4 (uint16_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreuxh_u64m8 (uint16_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreuxw_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreuxw_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreuxw_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreuxw_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreuxw_i64m1 (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreuxw_i64m2 (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreuxw_i64m4 (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreuxw_i64m8 (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreuxw_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreuxw_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreuxw_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreuxw_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreuxw_u64m1 (uint32_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreuxw_u64m2 (uint32_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreuxw_u64m4 (uint32_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreuxw_u64m8 (uint32_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreux_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstoreux_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstoreux_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstoreux_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstoreux_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstoreux_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstoreux_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstoreux_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstoreux_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreux_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreux_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreux_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreux_i64m1 (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreux_i64m2 (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreux_i64m4 (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreux_i64m8 (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreux_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstoreux_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstoreux_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstoreux_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstoreux_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstoreux_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstoreux_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstoreux_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstoreux_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreux_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreux_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreux_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreux_u64m1 (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreux_u64m2 (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreux_u64m4 (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreux_u64m8 (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreux_f16m1 (float16_t *base, vuint16m1_t bindex, vfloat16m1_t value);
void vstoreux_f16m2 (float16_t *base, vuint16m2_t bindex, vfloat16m2_t value);
void vstoreux_f16m4 (float16_t *base, vuint16m4_t bindex, vfloat16m4_t value);
void vstoreux_f16m8 (float16_t *base, vuint16m8_t bindex, vfloat16m8_t value);
void vstoreux_f32m1 (float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
void vstoreux_f32m2 (float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
void vstoreux_f32m4 (float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
void vstoreux_f32m8 (float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
void vstoreux_f64m1 (float64_t *base, vuint64m1_t bindex, vfloat64m1_t value);
void vstoreux_f64m2 (float64_t *base, vuint64m2_t bindex, vfloat64m2_t value);
void vstoreux_f64m4 (float64_t *base, vuint64m4_t bindex, vfloat64m4_t value);
void vstoreux_f64m8 (float64_t *base, vuint64m8_t bindex, vfloat64m8_t value);
// masked functions
void vstorexb_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstorexb_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstorexb_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstorexb_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstorexb_i16m1_mask (int8_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstorexb_i16m2_mask (int8_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstorexb_i16m4_mask (int8_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstorexb_i16m8_mask (int8_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstorexb_i32m1_mask (int8_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorexb_i32m2_mask (int8_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorexb_i32m4_mask (int8_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorexb_i32m8_mask (int8_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorexb_i64m1_mask (int8_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorexb_i64m2_mask (int8_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorexb_i64m4_mask (int8_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorexb_i64m8_mask (int8_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorexb_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstorexb_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstorexb_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstorexb_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstorexb_u16m1_mask (uint8_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstorexb_u16m2_mask (uint8_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstorexb_u16m4_mask (uint8_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstorexb_u16m8_mask (uint8_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstorexb_u32m1_mask (uint8_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorexb_u32m2_mask (uint8_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorexb_u32m4_mask (uint8_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorexb_u32m8_mask (uint8_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorexb_u64m1_mask (uint8_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorexb_u64m2_mask (uint8_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorexb_u64m4_mask (uint8_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorexb_u64m8_mask (uint8_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorexh_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstorexh_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstorexh_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstorexh_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstorexh_i32m1_mask (int16_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorexh_i32m2_mask (int16_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorexh_i32m4_mask (int16_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorexh_i32m8_mask (int16_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorexh_i64m1_mask (int16_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorexh_i64m2_mask (int16_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorexh_i64m4_mask (int16_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorexh_i64m8_mask (int16_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorexh_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstorexh_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstorexh_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstorexh_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstorexh_u32m1_mask (uint16_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorexh_u32m2_mask (uint16_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorexh_u32m4_mask (uint16_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorexh_u32m8_mask (uint16_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorexh_u64m1_mask (uint16_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorexh_u64m2_mask (uint16_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorexh_u64m4_mask (uint16_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorexh_u64m8_mask (uint16_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorexw_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorexw_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorexw_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorexw_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorexw_i64m1_mask (int32_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorexw_i64m2_mask (int32_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorexw_i64m4_mask (int32_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorexw_i64m8_mask (int32_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorexw_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorexw_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorexw_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorexw_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorexw_u64m1_mask (uint32_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorexw_u64m2_mask (uint32_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorexw_u64m4_mask (uint32_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorexw_u64m8_mask (uint32_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorex_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstorex_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstorex_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstorex_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstorex_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstorex_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstorex_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstorex_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstorex_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorex_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorex_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorex_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorex_i64m1_mask (int64_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorex_i64m2_mask (int64_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorex_i64m4_mask (int64_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorex_i64m8_mask (int64_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorex_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstorex_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstorex_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstorex_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstorex_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstorex_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstorex_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstorex_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstorex_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorex_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorex_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorex_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorex_u64m1_mask (uint64_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorex_u64m2_mask (uint64_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorex_u64m4_mask (uint64_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorex_u64m8_mask (uint64_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorex_f16m1_mask (float16_t *base, vuint16m1_t bindex, vbool16_t mask, vfloat16m1_t value);
void vstorex_f16m2_mask (float16_t *base, vuint16m2_t bindex, vbool8_t mask, vfloat16m2_t value);
void vstorex_f16m4_mask (float16_t *base, vuint16m4_t bindex, vbool4_t mask, vfloat16m4_t value);
void vstorex_f16m8_mask (float16_t *base, vuint16m8_t bindex, vbool2_t mask, vfloat16m8_t value);
void vstorex_f32m1_mask (float32_t *base, vuint32m1_t bindex, vbool32_t mask, vfloat32m1_t value);
void vstorex_f32m2_mask (float32_t *base, vuint32m2_t bindex, vbool16_t mask, vfloat32m2_t value);
void vstorex_f32m4_mask (float32_t *base, vuint32m4_t bindex, vbool8_t mask, vfloat32m4_t value);
void vstorex_f32m8_mask (float32_t *base, vuint32m8_t bindex, vbool4_t mask, vfloat32m8_t value);
void vstorex_f64m1_mask (float64_t *base, vuint64m1_t bindex, vbool64_t mask, vfloat64m1_t value);
void vstorex_f64m2_mask (float64_t *base, vuint64m2_t bindex, vbool32_t mask, vfloat64m2_t value);
void vstorex_f64m4_mask (float64_t *base, vuint64m4_t bindex, vbool16_t mask, vfloat64m4_t value);
void vstorex_f64m8_mask (float64_t *base, vuint64m8_t bindex, vbool8_t mask, vfloat64m8_t value);
void vstoreuxb_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstoreuxb_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstoreuxb_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstoreuxb_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstoreuxb_i16m1_mask (int8_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstoreuxb_i16m2_mask (int8_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstoreuxb_i16m4_mask (int8_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstoreuxb_i16m8_mask (int8_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstoreuxb_i32m1_mask (int8_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreuxb_i32m2_mask (int8_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreuxb_i32m4_mask (int8_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreuxb_i32m8_mask (int8_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreuxb_i64m1_mask (int8_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreuxb_i64m2_mask (int8_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreuxb_i64m4_mask (int8_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreuxb_i64m8_mask (int8_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreuxb_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstoreuxb_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstoreuxb_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstoreuxb_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstoreuxb_u16m1_mask (uint8_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstoreuxb_u16m2_mask (uint8_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstoreuxb_u16m4_mask (uint8_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstoreuxb_u16m8_mask (uint8_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstoreuxb_u32m1_mask (uint8_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreuxb_u32m2_mask (uint8_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreuxb_u32m4_mask (uint8_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreuxb_u32m8_mask (uint8_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreuxb_u64m1_mask (uint8_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreuxb_u64m2_mask (uint8_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreuxb_u64m4_mask (uint8_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreuxb_u64m8_mask (uint8_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreuxh_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstoreuxh_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstoreuxh_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstoreuxh_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstoreuxh_i32m1_mask (int16_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreuxh_i32m2_mask (int16_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreuxh_i32m4_mask (int16_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreuxh_i32m8_mask (int16_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreuxh_i64m1_mask (int16_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreuxh_i64m2_mask (int16_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreuxh_i64m4_mask (int16_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreuxh_i64m8_mask (int16_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreuxh_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstoreuxh_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstoreuxh_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstoreuxh_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstoreuxh_u32m1_mask (uint16_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreuxh_u32m2_mask (uint16_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreuxh_u32m4_mask (uint16_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreuxh_u32m8_mask (uint16_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreuxh_u64m1_mask (uint16_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreuxh_u64m2_mask (uint16_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreuxh_u64m4_mask (uint16_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreuxh_u64m8_mask (uint16_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreuxw_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreuxw_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreuxw_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreuxw_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreuxw_i64m1_mask (int32_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreuxw_i64m2_mask (int32_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreuxw_i64m4_mask (int32_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreuxw_i64m8_mask (int32_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreuxw_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreuxw_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreuxw_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreuxw_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreuxw_u64m1_mask (uint32_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreuxw_u64m2_mask (uint32_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreuxw_u64m4_mask (uint32_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreuxw_u64m8_mask (uint32_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreux_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstoreux_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstoreux_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstoreux_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstoreux_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstoreux_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstoreux_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstoreux_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstoreux_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreux_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreux_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreux_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreux_i64m1_mask (int64_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreux_i64m2_mask (int64_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreux_i64m4_mask (int64_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreux_i64m8_mask (int64_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreux_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstoreux_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstoreux_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstoreux_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstoreux_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstoreux_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstoreux_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstoreux_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstoreux_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreux_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreux_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreux_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreux_u64m1_mask (uint64_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreux_u64m2_mask (uint64_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreux_u64m4_mask (uint64_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreux_u64m8_mask (uint64_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreux_f16m1_mask (float16_t *base, vuint16m1_t bindex, vbool16_t mask, vfloat16m1_t value);
void vstoreux_f16m2_mask (float16_t *base, vuint16m2_t bindex, vbool8_t mask, vfloat16m2_t value);
void vstoreux_f16m4_mask (float16_t *base, vuint16m4_t bindex, vbool4_t mask, vfloat16m4_t value);
void vstoreux_f16m8_mask (float16_t *base, vuint16m8_t bindex, vbool2_t mask, vfloat16m8_t value);
void vstoreux_f32m1_mask (float32_t *base, vuint32m1_t bindex, vbool32_t mask, vfloat32m1_t value);
void vstoreux_f32m2_mask (float32_t *base, vuint32m2_t bindex, vbool16_t mask, vfloat32m2_t value);
void vstoreux_f32m4_mask (float32_t *base, vuint32m4_t bindex, vbool8_t mask, vfloat32m4_t value);
void vstoreux_f32m8_mask (float32_t *base, vuint32m8_t bindex, vbool4_t mask, vfloat32m8_t value);
void vstoreux_f64m1_mask (float64_t *base, vuint64m1_t bindex, vbool64_t mask, vfloat64m1_t value);
void vstoreux_f64m2_mask (float64_t *base, vuint64m2_t bindex, vbool32_t mask, vfloat64m2_t value);
void vstoreux_f64m4_mask (float64_t *base, vuint64m4_t bindex, vbool16_t mask, vfloat64m4_t value);
void vstoreux_f64m8_mask (float64_t *base, vuint64m8_t bindex, vbool8_t mask, vfloat64m8_t value);
```
### [Unit-stride Fault-Only-First Loads Functions]()

**Prototypes:**
``` C
vint8m1_t vloadbff_i8m1 (const int8_t *base);
vint8m2_t vloadbff_i8m2 (const int8_t *base);
vint8m4_t vloadbff_i8m4 (const int8_t *base);
vint8m8_t vloadbff_i8m8 (const int8_t *base);
vint16m1_t vloadbff_i16m1 (const int8_t *base);
vint16m2_t vloadbff_i16m2 (const int8_t *base);
vint16m4_t vloadbff_i16m4 (const int8_t *base);
vint16m8_t vloadbff_i16m8 (const int8_t *base);
vint32m1_t vloadbff_i32m1 (const int8_t *base);
vint32m2_t vloadbff_i32m2 (const int8_t *base);
vint32m4_t vloadbff_i32m4 (const int8_t *base);
vint32m8_t vloadbff_i32m8 (const int8_t *base);
vint64m1_t vloadbff_i64m1 (const int8_t *base);
vint64m2_t vloadbff_i64m2 (const int8_t *base);
vint64m4_t vloadbff_i64m4 (const int8_t *base);
vint64m8_t vloadbff_i64m8 (const int8_t *base);
vuint8m1_t vloadbff_u8m1 (const uint8_t *base);
vuint8m2_t vloadbff_u8m2 (const uint8_t *base);
vuint8m4_t vloadbff_u8m4 (const uint8_t *base);
vuint8m8_t vloadbff_u8m8 (const uint8_t *base);
vuint16m1_t vloadbff_u16m1 (const uint8_t *base);
vuint16m2_t vloadbff_u16m2 (const uint8_t *base);
vuint16m4_t vloadbff_u16m4 (const uint8_t *base);
vuint16m8_t vloadbff_u16m8 (const uint8_t *base);
vuint32m1_t vloadbff_u32m1 (const uint8_t *base);
vuint32m2_t vloadbff_u32m2 (const uint8_t *base);
vuint32m4_t vloadbff_u32m4 (const uint8_t *base);
vuint32m8_t vloadbff_u32m8 (const uint8_t *base);
vuint64m1_t vloadbff_u64m1 (const uint8_t *base);
vuint64m2_t vloadbff_u64m2 (const uint8_t *base);
vuint64m4_t vloadbff_u64m4 (const uint8_t *base);
vuint64m8_t vloadbff_u64m8 (const uint8_t *base);
vint16m1_t vloadhff_i16m1 (const int16_t *base);
vint16m2_t vloadhff_i16m2 (const int16_t *base);
vint16m4_t vloadhff_i16m4 (const int16_t *base);
vint16m8_t vloadhff_i16m8 (const int16_t *base);
vint32m1_t vloadhff_i32m1 (const int16_t *base);
vint32m2_t vloadhff_i32m2 (const int16_t *base);
vint32m4_t vloadhff_i32m4 (const int16_t *base);
vint32m8_t vloadhff_i32m8 (const int16_t *base);
vint64m1_t vloadhff_i64m1 (const int16_t *base);
vint64m2_t vloadhff_i64m2 (const int16_t *base);
vint64m4_t vloadhff_i64m4 (const int16_t *base);
vint64m8_t vloadhff_i64m8 (const int16_t *base);
vuint16m1_t vloadhff_u16m1 (const uint16_t *base);
vuint16m2_t vloadhff_u16m2 (const uint16_t *base);
vuint16m4_t vloadhff_u16m4 (const uint16_t *base);
vuint16m8_t vloadhff_u16m8 (const uint16_t *base);
vuint32m1_t vloadhff_u32m1 (const uint16_t *base);
vuint32m2_t vloadhff_u32m2 (const uint16_t *base);
vuint32m4_t vloadhff_u32m4 (const uint16_t *base);
vuint32m8_t vloadhff_u32m8 (const uint16_t *base);
vuint64m1_t vloadhff_u64m1 (const uint16_t *base);
vuint64m2_t vloadhff_u64m2 (const uint16_t *base);
vuint64m4_t vloadhff_u64m4 (const uint16_t *base);
vuint64m8_t vloadhff_u64m8 (const uint16_t *base);
vint32m1_t vloadwff_i32m1 (const int32_t *base);
vint32m2_t vloadwff_i32m2 (const int32_t *base);
vint32m4_t vloadwff_i32m4 (const int32_t *base);
vint32m8_t vloadwff_i32m8 (const int32_t *base);
vint64m1_t vloadwff_i64m1 (const int32_t *base);
vint64m2_t vloadwff_i64m2 (const int32_t *base);
vint64m4_t vloadwff_i64m4 (const int32_t *base);
vint64m8_t vloadwff_i64m8 (const int32_t *base);
vuint32m1_t vloadwff_u32m1 (const uint32_t *base);
vuint32m2_t vloadwff_u32m2 (const uint32_t *base);
vuint32m4_t vloadwff_u32m4 (const uint32_t *base);
vuint32m8_t vloadwff_u32m8 (const uint32_t *base);
vuint64m1_t vloadwff_u64m1 (const uint32_t *base);
vuint64m2_t vloadwff_u64m2 (const uint32_t *base);
vuint64m4_t vloadwff_u64m4 (const uint32_t *base);
vuint64m8_t vloadwff_u64m8 (const uint32_t *base);
vint8m1_t vloadff_i8m1 (const int8_t *base);
vint8m2_t vloadff_i8m2 (const int8_t *base);
vint8m4_t vloadff_i8m4 (const int8_t *base);
vint8m8_t vloadff_i8m8 (const int8_t *base);
vint16m1_t vloadff_i16m1 (const int16_t *base);
vint16m2_t vloadff_i16m2 (const int16_t *base);
vint16m4_t vloadff_i16m4 (const int16_t *base);
vint16m8_t vloadff_i16m8 (const int16_t *base);
vint32m1_t vloadff_i32m1 (const int32_t *base);
vint32m2_t vloadff_i32m2 (const int32_t *base);
vint32m4_t vloadff_i32m4 (const int32_t *base);
vint32m8_t vloadff_i32m8 (const int32_t *base);
vint64m1_t vloadff_i64m1 (const int64_t *base);
vint64m2_t vloadff_i64m2 (const int64_t *base);
vint64m4_t vloadff_i64m4 (const int64_t *base);
vint64m8_t vloadff_i64m8 (const int64_t *base);
vuint8m1_t vloadff_u8m1 (const uint8_t *base);
vuint8m2_t vloadff_u8m2 (const uint8_t *base);
vuint8m4_t vloadff_u8m4 (const uint8_t *base);
vuint8m8_t vloadff_u8m8 (const uint8_t *base);
vuint16m1_t vloadff_u16m1 (const uint16_t *base);
vuint16m2_t vloadff_u16m2 (const uint16_t *base);
vuint16m4_t vloadff_u16m4 (const uint16_t *base);
vuint16m8_t vloadff_u16m8 (const uint16_t *base);
vuint32m1_t vloadff_u32m1 (const uint32_t *base);
vuint32m2_t vloadff_u32m2 (const uint32_t *base);
vuint32m4_t vloadff_u32m4 (const uint32_t *base);
vuint32m8_t vloadff_u32m8 (const uint32_t *base);
vuint64m1_t vloadff_u64m1 (const uint64_t *base);
vuint64m2_t vloadff_u64m2 (const uint64_t *base);
vuint64m4_t vloadff_u64m4 (const uint64_t *base);
vuint64m8_t vloadff_u64m8 (const uint64_t *base);
vfloat16m1_t vloadff_f16m1 (const float16_t *base);
vfloat16m2_t vloadff_f16m2 (const float16_t *base);
vfloat16m4_t vloadff_f16m4 (const float16_t *base);
vfloat16m8_t vloadff_f16m8 (const float16_t *base);
vfloat32m1_t vloadff_f32m1 (const float32_t *base);
vfloat32m2_t vloadff_f32m2 (const float32_t *base);
vfloat32m4_t vloadff_f32m4 (const float32_t *base);
vfloat32m8_t vloadff_f32m8 (const float32_t *base);
vfloat64m1_t vloadff_f64m1 (const float64_t *base);
vfloat64m2_t vloadff_f64m2 (const float64_t *base);
vfloat64m4_t vloadff_f64m4 (const float64_t *base);
vfloat64m8_t vloadff_f64m8 (const float64_t *base);
// masked functions
vint8m1_t vloadbff_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vloadbff_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vloadbff_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vloadbff_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vloadbff_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base);
vint16m2_t vloadbff_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base);
vint16m4_t vloadbff_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base);
vint16m8_t vloadbff_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base);
vint32m1_t vloadbff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base);
vint32m2_t vloadbff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base);
vint32m4_t vloadbff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base);
vint32m8_t vloadbff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base);
vint64m1_t vloadbff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base);
vint64m2_t vloadbff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base);
vint64m4_t vloadbff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base);
vint64m8_t vloadbff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base);
vuint8m1_t vloadbff_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vloadbff_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vloadbff_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vloadbff_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vloadbff_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base);
vuint16m2_t vloadbff_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base);
vuint16m4_t vloadbff_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base);
vuint16m8_t vloadbff_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base);
vuint32m1_t vloadbff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base);
vuint32m2_t vloadbff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base);
vuint32m4_t vloadbff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base);
vuint32m8_t vloadbff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base);
vuint64m1_t vloadbff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base);
vuint64m2_t vloadbff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base);
vuint64m4_t vloadbff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base);
vuint64m8_t vloadbff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base);
vint16m1_t vloadhff_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vloadhff_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vloadhff_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vloadhff_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vloadhff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base);
vint32m2_t vloadhff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base);
vint32m4_t vloadhff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base);
vint32m8_t vloadhff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base);
vint64m1_t vloadhff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base);
vint64m2_t vloadhff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base);
vint64m4_t vloadhff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base);
vint64m8_t vloadhff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base);
vuint16m1_t vloadhff_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vloadhff_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vloadhff_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vloadhff_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vloadhff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base);
vuint32m2_t vloadhff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base);
vuint32m4_t vloadhff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base);
vuint32m8_t vloadhff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base);
vuint64m1_t vloadhff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base);
vuint64m2_t vloadhff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base);
vuint64m4_t vloadhff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base);
vuint64m8_t vloadhff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base);
vint32m1_t vloadwff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vloadwff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vloadwff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vloadwff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vloadwff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base);
vint64m2_t vloadwff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base);
vint64m4_t vloadwff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base);
vint64m8_t vloadwff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base);
vuint32m1_t vloadwff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vloadwff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vloadwff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vloadwff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vloadwff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base);
vuint64m2_t vloadwff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base);
vuint64m4_t vloadwff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base);
vuint64m8_t vloadwff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base);
vint8m1_t vloadff_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vloadff_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vloadff_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vloadff_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vloadff_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vloadff_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vloadff_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vloadff_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vloadff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vloadff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vloadff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vloadff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vloadff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base);
vint64m2_t vloadff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base);
vint64m4_t vloadff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base);
vint64m8_t vloadff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base);
vuint8m1_t vloadff_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vloadff_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vloadff_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vloadff_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vloadff_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vloadff_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vloadff_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vloadff_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vloadff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vloadff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vloadff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vloadff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vloadff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base);
vuint64m2_t vloadff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base);
vuint64m4_t vloadff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base);
vuint64m8_t vloadff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base);
vfloat16m1_t vloadff_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base);
vfloat16m2_t vloadff_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base);
vfloat16m4_t vloadff_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base);
vfloat16m8_t vloadff_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base);
vfloat32m1_t vloadff_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base);
vfloat32m2_t vloadff_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base);
vfloat32m4_t vloadff_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base);
vfloat32m8_t vloadff_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base);
vfloat64m1_t vloadff_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base);
vfloat64m2_t vloadff_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base);
vfloat64m4_t vloadff_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base);
vfloat64m8_t vloadff_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base);
```
## Vector Integer Arithmetic Functions:

### [Vector Single-Width Integer Add and Subtract Functions]()

**Prototypes:**
``` C
vint8m1_t vadd (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vadd (vint8m1_t op1, int8_t op2);
vint8m2_t vadd (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vadd (vint8m2_t op1, int8_t op2);
vint8m4_t vadd (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vadd (vint8m4_t op1, int8_t op2);
vint8m8_t vadd (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vadd (vint8m8_t op1, int8_t op2);
vint16m1_t vadd (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vadd (vint16m1_t op1, int16_t op2);
vint16m2_t vadd (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vadd (vint16m2_t op1, int16_t op2);
vint16m4_t vadd (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vadd (vint16m4_t op1, int16_t op2);
vint16m8_t vadd (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vadd (vint16m8_t op1, int16_t op2);
vint32m1_t vadd (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vadd (vint32m1_t op1, int32_t op2);
vint32m2_t vadd (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vadd (vint32m2_t op1, int32_t op2);
vint32m4_t vadd (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vadd (vint32m4_t op1, int32_t op2);
vint32m8_t vadd (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vadd (vint32m8_t op1, int32_t op2);
vint64m1_t vadd (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vadd (vint64m1_t op1, int64_t op2);
vint64m2_t vadd (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vadd (vint64m2_t op1, int64_t op2);
vint64m4_t vadd (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vadd (vint64m4_t op1, int64_t op2);
vint64m8_t vadd (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vadd (vint64m8_t op1, int64_t op2);
vuint8m1_t vadd (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vadd (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vadd (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vadd (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vadd (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vadd (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vadd (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vadd (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vadd (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vadd (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vadd (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vadd (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vadd (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vadd (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vadd (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vadd (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vadd (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vadd (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vadd (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vadd (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vadd (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vadd (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vadd (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vadd (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vadd (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vadd (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vadd (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vadd (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vadd (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vadd (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vadd (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vadd (vuint64m8_t op1, uint64_t op2);
vint8m1_t vsub (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsub (vint8m1_t op1, int8_t op2);
vint8m2_t vsub (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsub (vint8m2_t op1, int8_t op2);
vint8m4_t vsub (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsub (vint8m4_t op1, int8_t op2);
vint8m8_t vsub (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsub (vint8m8_t op1, int8_t op2);
vint16m1_t vsub (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsub (vint16m1_t op1, int16_t op2);
vint16m2_t vsub (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsub (vint16m2_t op1, int16_t op2);
vint16m4_t vsub (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsub (vint16m4_t op1, int16_t op2);
vint16m8_t vsub (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsub (vint16m8_t op1, int16_t op2);
vint32m1_t vsub (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsub (vint32m1_t op1, int32_t op2);
vint32m2_t vsub (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsub (vint32m2_t op1, int32_t op2);
vint32m4_t vsub (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsub (vint32m4_t op1, int32_t op2);
vint32m8_t vsub (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsub (vint32m8_t op1, int32_t op2);
vint64m1_t vsub (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsub (vint64m1_t op1, int64_t op2);
vint64m2_t vsub (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsub (vint64m2_t op1, int64_t op2);
vint64m4_t vsub (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsub (vint64m4_t op1, int64_t op2);
vint64m8_t vsub (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsub (vint64m8_t op1, int64_t op2);
vuint8m1_t vsub (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsub (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsub (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsub (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsub (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsub (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsub (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsub (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsub (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsub (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsub (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsub (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsub (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsub (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsub (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsub (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsub (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsub (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsub (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsub (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsub (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsub (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsub (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsub (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsub (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsub (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsub (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsub (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsub (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsub (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsub (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsub (vuint64m8_t op1, uint64_t op2);
vint8m1_t vrsub (vint8m1_t op1, int8_t op2);
vint8m2_t vrsub (vint8m2_t op1, int8_t op2);
vint8m4_t vrsub (vint8m4_t op1, int8_t op2);
vint8m8_t vrsub (vint8m8_t op1, int8_t op2);
vint16m1_t vrsub (vint16m1_t op1, int16_t op2);
vint16m2_t vrsub (vint16m2_t op1, int16_t op2);
vint16m4_t vrsub (vint16m4_t op1, int16_t op2);
vint16m8_t vrsub (vint16m8_t op1, int16_t op2);
vint32m1_t vrsub (vint32m1_t op1, int32_t op2);
vint32m2_t vrsub (vint32m2_t op1, int32_t op2);
vint32m4_t vrsub (vint32m4_t op1, int32_t op2);
vint32m8_t vrsub (vint32m8_t op1, int32_t op2);
vint64m1_t vrsub (vint64m1_t op1, int64_t op2);
vint64m2_t vrsub (vint64m2_t op1, int64_t op2);
vint64m4_t vrsub (vint64m4_t op1, int64_t op2);
vint64m8_t vrsub (vint64m8_t op1, int64_t op2);
vuint8m1_t vrsub (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrsub (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrsub (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrsub (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrsub (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrsub (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrsub (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrsub (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrsub (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrsub (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrsub (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrsub (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrsub (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrsub (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrsub (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrsub (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vadd_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vadd_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vadd_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vadd_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vadd_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vadd_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vadd_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vadd_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vadd_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vadd_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vadd_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vadd_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vadd_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vadd_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vadd_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vadd_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vadd_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vadd_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vadd_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vadd_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vadd_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vadd_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vadd_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vadd_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vadd_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vadd_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vadd_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vadd_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vadd_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vadd_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vadd_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vadd_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vadd_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vadd_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vadd_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vadd_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vadd_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vadd_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vadd_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vadd_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vadd_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vadd_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vadd_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vadd_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vadd_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vadd_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vadd_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vadd_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vadd_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vadd_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vadd_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vadd_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vadd_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vadd_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vadd_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vadd_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vadd_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vadd_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vadd_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vadd_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vadd_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vadd_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vadd_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vadd_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vsub_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsub_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsub_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsub_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsub_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsub_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsub_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsub_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsub_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsub_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsub_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsub_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsub_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsub_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsub_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsub_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsub_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsub_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsub_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsub_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsub_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsub_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsub_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsub_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsub_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsub_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsub_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsub_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsub_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsub_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsub_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsub_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsub_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsub_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsub_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsub_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsub_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsub_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsub_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsub_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsub_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsub_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsub_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsub_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsub_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsub_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vrsub_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vrsub_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vrsub_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vrsub_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vrsub_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vrsub_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vrsub_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vrsub_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vrsub_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vrsub_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vrsub_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vrsub_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vrsub_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vrsub_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vrsub_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vrsub_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vrsub_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrsub_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrsub_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrsub_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrsub_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrsub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrsub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrsub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrsub_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrsub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrsub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrsub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrsub_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrsub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrsub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrsub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Widening Integer Add/Subtract Functions]()

**Prototypes:**
``` C
vint16m2_t vwadd (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwadd (vint8m1_t op1, int8_t op2);
vint16m2_t vwadd (vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwadd (vint16m2_t op1, int8_t op2);
vint16m4_t vwadd (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwadd (vint8m2_t op1, int8_t op2);
vint16m4_t vwadd (vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwadd (vint16m4_t op1, int8_t op2);
vint16m8_t vwadd (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwadd (vint8m4_t op1, int8_t op2);
vint16m8_t vwadd (vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwadd (vint16m8_t op1, int8_t op2);
vint32m2_t vwadd (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwadd (vint16m1_t op1, int16_t op2);
vint32m2_t vwadd (vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwadd (vint32m2_t op1, int16_t op2);
vint32m4_t vwadd (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwadd (vint16m2_t op1, int16_t op2);
vint32m4_t vwadd (vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwadd (vint32m4_t op1, int16_t op2);
vint32m8_t vwadd (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwadd (vint16m4_t op1, int16_t op2);
vint32m8_t vwadd (vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwadd (vint32m8_t op1, int16_t op2);
vint64m2_t vwadd (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwadd (vint32m1_t op1, int32_t op2);
vint64m2_t vwadd (vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwadd (vint64m2_t op1, int32_t op2);
vint64m4_t vwadd (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwadd (vint32m2_t op1, int32_t op2);
vint64m4_t vwadd (vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwadd (vint64m4_t op1, int32_t op2);
vint64m8_t vwadd (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwadd (vint32m4_t op1, int32_t op2);
vint64m8_t vwadd (vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwadd (vint64m8_t op1, int32_t op2);
vuint16m2_t vwadd (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwadd (vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwadd (vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwadd (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwadd (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwadd (vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwadd (vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwadd (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwadd (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwadd (vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwadd (vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwadd (vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwadd (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwadd (vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwadd (vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwadd (vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwadd (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwadd (vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwadd (vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwadd (vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwadd (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwadd (vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwadd (vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwadd (vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwadd (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwadd (vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwadd (vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwadd (vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwadd (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwadd (vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwadd (vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwadd (vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwadd (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwadd (vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwadd (vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwadd (vuint64m8_t op1, uint32_t op2);
vint16m2_t vwsub (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwsub (vint8m1_t op1, int8_t op2);
vint16m2_t vwsub (vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwsub (vint16m2_t op1, int8_t op2);
vint16m4_t vwsub (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwsub (vint8m2_t op1, int8_t op2);
vint16m4_t vwsub (vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwsub (vint16m4_t op1, int8_t op2);
vint16m8_t vwsub (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwsub (vint8m4_t op1, int8_t op2);
vint16m8_t vwsub (vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwsub (vint16m8_t op1, int8_t op2);
vint32m2_t vwsub (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwsub (vint16m1_t op1, int16_t op2);
vint32m2_t vwsub (vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwsub (vint32m2_t op1, int16_t op2);
vint32m4_t vwsub (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwsub (vint16m2_t op1, int16_t op2);
vint32m4_t vwsub (vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwsub (vint32m4_t op1, int16_t op2);
vint32m8_t vwsub (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwsub (vint16m4_t op1, int16_t op2);
vint32m8_t vwsub (vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwsub (vint32m8_t op1, int16_t op2);
vint64m2_t vwsub (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwsub (vint32m1_t op1, int32_t op2);
vint64m2_t vwsub (vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwsub (vint64m2_t op1, int32_t op2);
vint64m4_t vwsub (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwsub (vint32m2_t op1, int32_t op2);
vint64m4_t vwsub (vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwsub (vint64m4_t op1, int32_t op2);
vint64m8_t vwsub (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwsub (vint32m4_t op1, int32_t op2);
vint64m8_t vwsub (vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwsub (vint64m8_t op1, int32_t op2);
vuint16m2_t vwsub (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwsub (vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwsub (vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwsub (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwsub (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwsub (vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwsub (vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwsub (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwsub (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwsub (vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwsub (vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwsub (vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwsub (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwsub (vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwsub (vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwsub (vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwsub (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwsub (vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwsub (vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwsub (vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwsub (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwsub (vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwsub (vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwsub (vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwsub (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwsub (vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwsub (vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwsub (vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwsub (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwsub (vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwsub (vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwsub (vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwsub (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwsub (vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwsub (vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwsub (vuint64m8_t op1, uint32_t op2);
// masked functions
vint16m2_t vwadd_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwadd_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m2_t vwadd_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwadd_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2);
vint16m4_t vwadd_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwadd_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m4_t vwadd_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwadd_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2);
vint16m8_t vwadd_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwadd_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint16m8_t vwadd_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwadd_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2);
vint32m2_t vwadd_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwadd_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m2_t vwadd_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwadd_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2);
vint32m4_t vwadd_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwadd_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m4_t vwadd_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwadd_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2);
vint32m8_t vwadd_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwadd_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint32m8_t vwadd_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwadd_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2);
vint64m2_t vwadd_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwadd_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m2_t vwadd_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwadd_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2);
vint64m4_t vwadd_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwadd_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m4_t vwadd_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwadd_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2);
vint64m8_t vwadd_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwadd_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vint64m8_t vwadd_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwadd_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2);
vuint16m2_t vwadd_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwadd_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwadd_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwadd_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwadd_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwadd_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwadd_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwadd_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwadd_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwadd_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwadd_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwadd_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwadd_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwadd_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwadd_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwadd_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwadd_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwadd_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwadd_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwadd_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwadd_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwadd_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwadd_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwadd_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwadd_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwadd_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwadd_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwadd_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwadd_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwadd_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwadd_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwadd_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwadd_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwadd_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwadd_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwadd_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2);
vint16m2_t vwsub_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwsub_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m2_t vwsub_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwsub_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2);
vint16m4_t vwsub_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwsub_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m4_t vwsub_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwsub_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2);
vint16m8_t vwsub_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwsub_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint16m8_t vwsub_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwsub_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2);
vint32m2_t vwsub_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwsub_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m2_t vwsub_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwsub_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2);
vint32m4_t vwsub_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwsub_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m4_t vwsub_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwsub_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2);
vint32m8_t vwsub_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwsub_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint32m8_t vwsub_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwsub_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2);
vint64m2_t vwsub_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwsub_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m2_t vwsub_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwsub_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2);
vint64m4_t vwsub_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwsub_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m4_t vwsub_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwsub_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2);
vint64m8_t vwsub_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwsub_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vint64m8_t vwsub_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwsub_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2);
vuint16m2_t vwsub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwsub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwsub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwsub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwsub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwsub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwsub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwsub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwsub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwsub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwsub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwsub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwsub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwsub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwsub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwsub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwsub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwsub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwsub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwsub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwsub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwsub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwsub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwsub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwsub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwsub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwsub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwsub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwsub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwsub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwsub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwsub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwsub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwsub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwsub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwsub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2);
```
### [Vector Integer Add-with-Carry / Subtract-with-Borrow Functions]()

**Prototypes:**
``` C
vint8m1_t vadc_vvm (vint8m1_t op1, vint8m1_t op2, vbool8_t carryin);
vint8m1_t vadc_vsm (vint8m1_t op1, int8_t op2, vbool8_t carryin);
vint8m2_t vadc_vvm (vint8m2_t op1, vint8m2_t op2, vbool4_t carryin);
vint8m2_t vadc_vsm (vint8m2_t op1, int8_t op2, vbool4_t carryin);
vint8m4_t vadc_vvm (vint8m4_t op1, vint8m4_t op2, vbool2_t carryin);
vint8m4_t vadc_vsm (vint8m4_t op1, int8_t op2, vbool2_t carryin);
vint8m8_t vadc_vvm (vint8m8_t op1, vint8m8_t op2, vbool1_t carryin);
vint8m8_t vadc_vsm (vint8m8_t op1, int8_t op2, vbool1_t carryin);
vint16m1_t vadc_vvm (vint16m1_t op1, vint16m1_t op2, vbool16_t carryin);
vint16m1_t vadc_vsm (vint16m1_t op1, int16_t op2, vbool16_t carryin);
vint16m2_t vadc_vvm (vint16m2_t op1, vint16m2_t op2, vbool8_t carryin);
vint16m2_t vadc_vsm (vint16m2_t op1, int16_t op2, vbool8_t carryin);
vint16m4_t vadc_vvm (vint16m4_t op1, vint16m4_t op2, vbool4_t carryin);
vint16m4_t vadc_vsm (vint16m4_t op1, int16_t op2, vbool4_t carryin);
vint16m8_t vadc_vvm (vint16m8_t op1, vint16m8_t op2, vbool2_t carryin);
vint16m8_t vadc_vsm (vint16m8_t op1, int16_t op2, vbool2_t carryin);
vint32m1_t vadc_vvm (vint32m1_t op1, vint32m1_t op2, vbool32_t carryin);
vint32m1_t vadc_vsm (vint32m1_t op1, int32_t op2, vbool32_t carryin);
vint32m2_t vadc_vvm (vint32m2_t op1, vint32m2_t op2, vbool16_t carryin);
vint32m2_t vadc_vsm (vint32m2_t op1, int32_t op2, vbool16_t carryin);
vint32m4_t vadc_vvm (vint32m4_t op1, vint32m4_t op2, vbool8_t carryin);
vint32m4_t vadc_vsm (vint32m4_t op1, int32_t op2, vbool8_t carryin);
vint32m8_t vadc_vvm (vint32m8_t op1, vint32m8_t op2, vbool4_t carryin);
vint32m8_t vadc_vsm (vint32m8_t op1, int32_t op2, vbool4_t carryin);
vint64m1_t vadc_vvm (vint64m1_t op1, vint64m1_t op2, vbool64_t carryin);
vint64m1_t vadc_vsm (vint64m1_t op1, int64_t op2, vbool64_t carryin);
vint64m2_t vadc_vvm (vint64m2_t op1, vint64m2_t op2, vbool32_t carryin);
vint64m2_t vadc_vsm (vint64m2_t op1, int64_t op2, vbool32_t carryin);
vint64m4_t vadc_vvm (vint64m4_t op1, vint64m4_t op2, vbool16_t carryin);
vint64m4_t vadc_vsm (vint64m4_t op1, int64_t op2, vbool16_t carryin);
vint64m8_t vadc_vvm (vint64m8_t op1, vint64m8_t op2, vbool8_t carryin);
vint64m8_t vadc_vsm (vint64m8_t op1, int64_t op2, vbool8_t carryin);
vuint8m1_t vadc_vvm (vuint8m1_t op1, vuint8m1_t op2, vbool8_t carryin);
vuint8m1_t vadc_vsm (vuint8m1_t op1, uint8_t op2, vbool8_t carryin);
vuint8m2_t vadc_vvm (vuint8m2_t op1, vuint8m2_t op2, vbool4_t carryin);
vuint8m2_t vadc_vsm (vuint8m2_t op1, uint8_t op2, vbool4_t carryin);
vuint8m4_t vadc_vvm (vuint8m4_t op1, vuint8m4_t op2, vbool2_t carryin);
vuint8m4_t vadc_vsm (vuint8m4_t op1, uint8_t op2, vbool2_t carryin);
vuint8m8_t vadc_vvm (vuint8m8_t op1, vuint8m8_t op2, vbool1_t carryin);
vuint8m8_t vadc_vsm (vuint8m8_t op1, uint8_t op2, vbool1_t carryin);
vuint16m1_t vadc_vvm (vuint16m1_t op1, vuint16m1_t op2, vbool16_t carryin);
vuint16m1_t vadc_vsm (vuint16m1_t op1, uint16_t op2, vbool16_t carryin);
vuint16m2_t vadc_vvm (vuint16m2_t op1, vuint16m2_t op2, vbool8_t carryin);
vuint16m2_t vadc_vsm (vuint16m2_t op1, uint16_t op2, vbool8_t carryin);
vuint16m4_t vadc_vvm (vuint16m4_t op1, vuint16m4_t op2, vbool4_t carryin);
vuint16m4_t vadc_vsm (vuint16m4_t op1, uint16_t op2, vbool4_t carryin);
vuint16m8_t vadc_vvm (vuint16m8_t op1, vuint16m8_t op2, vbool2_t carryin);
vuint16m8_t vadc_vsm (vuint16m8_t op1, uint16_t op2, vbool2_t carryin);
vuint32m1_t vadc_vvm (vuint32m1_t op1, vuint32m1_t op2, vbool32_t carryin);
vuint32m1_t vadc_vsm (vuint32m1_t op1, uint32_t op2, vbool32_t carryin);
vuint32m2_t vadc_vvm (vuint32m2_t op1, vuint32m2_t op2, vbool16_t carryin);
vuint32m2_t vadc_vsm (vuint32m2_t op1, uint32_t op2, vbool16_t carryin);
vuint32m4_t vadc_vvm (vuint32m4_t op1, vuint32m4_t op2, vbool8_t carryin);
vuint32m4_t vadc_vsm (vuint32m4_t op1, uint32_t op2, vbool8_t carryin);
vuint32m8_t vadc_vvm (vuint32m8_t op1, vuint32m8_t op2, vbool4_t carryin);
vuint32m8_t vadc_vsm (vuint32m8_t op1, uint32_t op2, vbool4_t carryin);
vuint64m1_t vadc_vvm (vuint64m1_t op1, vuint64m1_t op2, vbool64_t carryin);
vuint64m1_t vadc_vsm (vuint64m1_t op1, uint64_t op2, vbool64_t carryin);
vuint64m2_t vadc_vvm (vuint64m2_t op1, vuint64m2_t op2, vbool32_t carryin);
vuint64m2_t vadc_vsm (vuint64m2_t op1, uint64_t op2, vbool32_t carryin);
vuint64m4_t vadc_vvm (vuint64m4_t op1, vuint64m4_t op2, vbool16_t carryin);
vuint64m4_t vadc_vsm (vuint64m4_t op1, uint64_t op2, vbool16_t carryin);
vuint64m8_t vadc_vvm (vuint64m8_t op1, vuint64m8_t op2, vbool8_t carryin);
vuint64m8_t vadc_vsm (vuint64m8_t op1, uint64_t op2, vbool8_t carryin);
vbool8_t vmadc_vvm (vint8m1_t op1, vint8m1_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm (vint8m1_t op1, int8_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmadc_vs (vint8m1_t op1, int8_t op2);
vbool4_t vmadc_vvm (vint8m2_t op1, vint8m2_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm (vint8m2_t op1, int8_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmadc_vs (vint8m2_t op1, int8_t op2);
vbool2_t vmadc_vvm (vint8m4_t op1, vint8m4_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm (vint8m4_t op1, int8_t op2, vbool2_t carryin);
vbool2_t vmadc_vv (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmadc_vs (vint8m4_t op1, int8_t op2);
vbool1_t vmadc_vvm (vint8m8_t op1, vint8m8_t op2, vbool1_t carryin);
vbool1_t vmadc_vsm (vint8m8_t op1, int8_t op2, vbool1_t carryin);
vbool1_t vmadc_vv (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmadc_vs (vint8m8_t op1, int8_t op2);
vbool16_t vmadc_vvm (vint16m1_t op1, vint16m1_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm (vint16m1_t op1, int16_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmadc_vs (vint16m1_t op1, int16_t op2);
vbool8_t vmadc_vvm (vint16m2_t op1, vint16m2_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm (vint16m2_t op1, int16_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmadc_vs (vint16m2_t op1, int16_t op2);
vbool4_t vmadc_vvm (vint16m4_t op1, vint16m4_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm (vint16m4_t op1, int16_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmadc_vs (vint16m4_t op1, int16_t op2);
vbool2_t vmadc_vvm (vint16m8_t op1, vint16m8_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm (vint16m8_t op1, int16_t op2, vbool2_t carryin);
vbool2_t vmadc_vv (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmadc_vs (vint16m8_t op1, int16_t op2);
vbool32_t vmadc_vvm (vint32m1_t op1, vint32m1_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm (vint32m1_t op1, int32_t op2, vbool32_t carryin);
vbool32_t vmadc_vv (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmadc_vs (vint32m1_t op1, int32_t op2);
vbool16_t vmadc_vvm (vint32m2_t op1, vint32m2_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm (vint32m2_t op1, int32_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmadc_vs (vint32m2_t op1, int32_t op2);
vbool8_t vmadc_vvm (vint32m4_t op1, vint32m4_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm (vint32m4_t op1, int32_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmadc_vs (vint32m4_t op1, int32_t op2);
vbool4_t vmadc_vvm (vint32m8_t op1, vint32m8_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm (vint32m8_t op1, int32_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmadc_vs (vint32m8_t op1, int32_t op2);
vbool64_t vmadc_vvm (vint64m1_t op1, vint64m1_t op2, vbool64_t carryin);
vbool64_t vmadc_vsm (vint64m1_t op1, int64_t op2, vbool64_t carryin);
vbool64_t vmadc_vv (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmadc_vs (vint64m1_t op1, int64_t op2);
vbool32_t vmadc_vvm (vint64m2_t op1, vint64m2_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm (vint64m2_t op1, int64_t op2, vbool32_t carryin);
vbool32_t vmadc_vv (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmadc_vs (vint64m2_t op1, int64_t op2);
vbool16_t vmadc_vvm (vint64m4_t op1, vint64m4_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm (vint64m4_t op1, int64_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmadc_vs (vint64m4_t op1, int64_t op2);
vbool8_t vmadc_vvm (vint64m8_t op1, vint64m8_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm (vint64m8_t op1, int64_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmadc_vs (vint64m8_t op1, int64_t op2);
vbool8_t vmadc_vvm (vuint8m1_t op1, vuint8m1_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm (vuint8m1_t op1, uint8_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmadc_vs (vuint8m1_t op1, uint8_t op2);
vbool4_t vmadc_vvm (vuint8m2_t op1, vuint8m2_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm (vuint8m2_t op1, uint8_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmadc_vs (vuint8m2_t op1, uint8_t op2);
vbool2_t vmadc_vvm (vuint8m4_t op1, vuint8m4_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm (vuint8m4_t op1, uint8_t op2, vbool2_t carryin);
vbool2_t vmadc_vv (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmadc_vs (vuint8m4_t op1, uint8_t op2);
vbool1_t vmadc_vvm (vuint8m8_t op1, vuint8m8_t op2, vbool1_t carryin);
vbool1_t vmadc_vsm (vuint8m8_t op1, uint8_t op2, vbool1_t carryin);
vbool1_t vmadc_vv (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmadc_vs (vuint8m8_t op1, uint8_t op2);
vbool16_t vmadc_vvm (vuint16m1_t op1, vuint16m1_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm (vuint16m1_t op1, uint16_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmadc_vs (vuint16m1_t op1, uint16_t op2);
vbool8_t vmadc_vvm (vuint16m2_t op1, vuint16m2_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm (vuint16m2_t op1, uint16_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmadc_vs (vuint16m2_t op1, uint16_t op2);
vbool4_t vmadc_vvm (vuint16m4_t op1, vuint16m4_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm (vuint16m4_t op1, uint16_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmadc_vs (vuint16m4_t op1, uint16_t op2);
vbool2_t vmadc_vvm (vuint16m8_t op1, vuint16m8_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm (vuint16m8_t op1, uint16_t op2, vbool2_t carryin);
vbool2_t vmadc_vv (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmadc_vs (vuint16m8_t op1, uint16_t op2);
vbool32_t vmadc_vvm (vuint32m1_t op1, vuint32m1_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm (vuint32m1_t op1, uint32_t op2, vbool32_t carryin);
vbool32_t vmadc_vv (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmadc_vs (vuint32m1_t op1, uint32_t op2);
vbool16_t vmadc_vvm (vuint32m2_t op1, vuint32m2_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm (vuint32m2_t op1, uint32_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmadc_vs (vuint32m2_t op1, uint32_t op2);
vbool8_t vmadc_vvm (vuint32m4_t op1, vuint32m4_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm (vuint32m4_t op1, uint32_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmadc_vs (vuint32m4_t op1, uint32_t op2);
vbool4_t vmadc_vvm (vuint32m8_t op1, vuint32m8_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm (vuint32m8_t op1, uint32_t op2, vbool4_t carryin);
vbool4_t vmadc_vv (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmadc_vs (vuint32m8_t op1, uint32_t op2);
vbool64_t vmadc_vvm (vuint64m1_t op1, vuint64m1_t op2, vbool64_t carryin);
vbool64_t vmadc_vsm (vuint64m1_t op1, uint64_t op2, vbool64_t carryin);
vbool64_t vmadc_vv (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmadc_vs (vuint64m1_t op1, uint64_t op2);
vbool32_t vmadc_vvm (vuint64m2_t op1, vuint64m2_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm (vuint64m2_t op1, uint64_t op2, vbool32_t carryin);
vbool32_t vmadc_vv (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmadc_vs (vuint64m2_t op1, uint64_t op2);
vbool16_t vmadc_vvm (vuint64m4_t op1, vuint64m4_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm (vuint64m4_t op1, uint64_t op2, vbool16_t carryin);
vbool16_t vmadc_vv (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmadc_vs (vuint64m4_t op1, uint64_t op2);
vbool8_t vmadc_vvm (vuint64m8_t op1, vuint64m8_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm (vuint64m8_t op1, uint64_t op2, vbool8_t carryin);
vbool8_t vmadc_vv (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmadc_vs (vuint64m8_t op1, uint64_t op2);
vint8m1_t vsbc_vvm (vint8m1_t op1, vint8m1_t op2, vbool8_t borrowin);
vint8m1_t vsbc_vsm (vint8m1_t op1, int8_t op2, vbool8_t borrowin);
vint8m2_t vsbc_vvm (vint8m2_t op1, vint8m2_t op2, vbool4_t borrowin);
vint8m2_t vsbc_vsm (vint8m2_t op1, int8_t op2, vbool4_t borrowin);
vint8m4_t vsbc_vvm (vint8m4_t op1, vint8m4_t op2, vbool2_t borrowin);
vint8m4_t vsbc_vsm (vint8m4_t op1, int8_t op2, vbool2_t borrowin);
vint8m8_t vsbc_vvm (vint8m8_t op1, vint8m8_t op2, vbool1_t borrowin);
vint8m8_t vsbc_vsm (vint8m8_t op1, int8_t op2, vbool1_t borrowin);
vint16m1_t vsbc_vvm (vint16m1_t op1, vint16m1_t op2, vbool16_t borrowin);
vint16m1_t vsbc_vsm (vint16m1_t op1, int16_t op2, vbool16_t borrowin);
vint16m2_t vsbc_vvm (vint16m2_t op1, vint16m2_t op2, vbool8_t borrowin);
vint16m2_t vsbc_vsm (vint16m2_t op1, int16_t op2, vbool8_t borrowin);
vint16m4_t vsbc_vvm (vint16m4_t op1, vint16m4_t op2, vbool4_t borrowin);
vint16m4_t vsbc_vsm (vint16m4_t op1, int16_t op2, vbool4_t borrowin);
vint16m8_t vsbc_vvm (vint16m8_t op1, vint16m8_t op2, vbool2_t borrowin);
vint16m8_t vsbc_vsm (vint16m8_t op1, int16_t op2, vbool2_t borrowin);
vint32m1_t vsbc_vvm (vint32m1_t op1, vint32m1_t op2, vbool32_t borrowin);
vint32m1_t vsbc_vsm (vint32m1_t op1, int32_t op2, vbool32_t borrowin);
vint32m2_t vsbc_vvm (vint32m2_t op1, vint32m2_t op2, vbool16_t borrowin);
vint32m2_t vsbc_vsm (vint32m2_t op1, int32_t op2, vbool16_t borrowin);
vint32m4_t vsbc_vvm (vint32m4_t op1, vint32m4_t op2, vbool8_t borrowin);
vint32m4_t vsbc_vsm (vint32m4_t op1, int32_t op2, vbool8_t borrowin);
vint32m8_t vsbc_vvm (vint32m8_t op1, vint32m8_t op2, vbool4_t borrowin);
vint32m8_t vsbc_vsm (vint32m8_t op1, int32_t op2, vbool4_t borrowin);
vint64m1_t vsbc_vvm (vint64m1_t op1, vint64m1_t op2, vbool64_t borrowin);
vint64m1_t vsbc_vsm (vint64m1_t op1, int64_t op2, vbool64_t borrowin);
vint64m2_t vsbc_vvm (vint64m2_t op1, vint64m2_t op2, vbool32_t borrowin);
vint64m2_t vsbc_vsm (vint64m2_t op1, int64_t op2, vbool32_t borrowin);
vint64m4_t vsbc_vvm (vint64m4_t op1, vint64m4_t op2, vbool16_t borrowin);
vint64m4_t vsbc_vsm (vint64m4_t op1, int64_t op2, vbool16_t borrowin);
vint64m8_t vsbc_vvm (vint64m8_t op1, vint64m8_t op2, vbool8_t borrowin);
vint64m8_t vsbc_vsm (vint64m8_t op1, int64_t op2, vbool8_t borrowin);
vuint8m1_t vsbc_vvm (vuint8m1_t op1, vuint8m1_t op2, vbool8_t borrowin);
vuint8m1_t vsbc_vsm (vuint8m1_t op1, uint8_t op2, vbool8_t borrowin);
vuint8m2_t vsbc_vvm (vuint8m2_t op1, vuint8m2_t op2, vbool4_t borrowin);
vuint8m2_t vsbc_vsm (vuint8m2_t op1, uint8_t op2, vbool4_t borrowin);
vuint8m4_t vsbc_vvm (vuint8m4_t op1, vuint8m4_t op2, vbool2_t borrowin);
vuint8m4_t vsbc_vsm (vuint8m4_t op1, uint8_t op2, vbool2_t borrowin);
vuint8m8_t vsbc_vvm (vuint8m8_t op1, vuint8m8_t op2, vbool1_t borrowin);
vuint8m8_t vsbc_vsm (vuint8m8_t op1, uint8_t op2, vbool1_t borrowin);
vuint16m1_t vsbc_vvm (vuint16m1_t op1, vuint16m1_t op2, vbool16_t borrowin);
vuint16m1_t vsbc_vsm (vuint16m1_t op1, uint16_t op2, vbool16_t borrowin);
vuint16m2_t vsbc_vvm (vuint16m2_t op1, vuint16m2_t op2, vbool8_t borrowin);
vuint16m2_t vsbc_vsm (vuint16m2_t op1, uint16_t op2, vbool8_t borrowin);
vuint16m4_t vsbc_vvm (vuint16m4_t op1, vuint16m4_t op2, vbool4_t borrowin);
vuint16m4_t vsbc_vsm (vuint16m4_t op1, uint16_t op2, vbool4_t borrowin);
vuint16m8_t vsbc_vvm (vuint16m8_t op1, vuint16m8_t op2, vbool2_t borrowin);
vuint16m8_t vsbc_vsm (vuint16m8_t op1, uint16_t op2, vbool2_t borrowin);
vuint32m1_t vsbc_vvm (vuint32m1_t op1, vuint32m1_t op2, vbool32_t borrowin);
vuint32m1_t vsbc_vsm (vuint32m1_t op1, uint32_t op2, vbool32_t borrowin);
vuint32m2_t vsbc_vvm (vuint32m2_t op1, vuint32m2_t op2, vbool16_t borrowin);
vuint32m2_t vsbc_vsm (vuint32m2_t op1, uint32_t op2, vbool16_t borrowin);
vuint32m4_t vsbc_vvm (vuint32m4_t op1, vuint32m4_t op2, vbool8_t borrowin);
vuint32m4_t vsbc_vsm (vuint32m4_t op1, uint32_t op2, vbool8_t borrowin);
vuint32m8_t vsbc_vvm (vuint32m8_t op1, vuint32m8_t op2, vbool4_t borrowin);
vuint32m8_t vsbc_vsm (vuint32m8_t op1, uint32_t op2, vbool4_t borrowin);
vuint64m1_t vsbc_vvm (vuint64m1_t op1, vuint64m1_t op2, vbool64_t borrowin);
vuint64m1_t vsbc_vsm (vuint64m1_t op1, uint64_t op2, vbool64_t borrowin);
vuint64m2_t vsbc_vvm (vuint64m2_t op1, vuint64m2_t op2, vbool32_t borrowin);
vuint64m2_t vsbc_vsm (vuint64m2_t op1, uint64_t op2, vbool32_t borrowin);
vuint64m4_t vsbc_vvm (vuint64m4_t op1, vuint64m4_t op2, vbool16_t borrowin);
vuint64m4_t vsbc_vsm (vuint64m4_t op1, uint64_t op2, vbool16_t borrowin);
vuint64m8_t vsbc_vvm (vuint64m8_t op1, vuint64m8_t op2, vbool8_t borrowin);
vuint64m8_t vsbc_vsm (vuint64m8_t op1, uint64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vvm (vint8m1_t op1, vint8m1_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm (vint8m1_t op1, int8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsbc_vs (vint8m1_t op1, int8_t op2);
vbool4_t vmsbc_vvm (vint8m2_t op1, vint8m2_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm (vint8m2_t op1, int8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsbc_vs (vint8m2_t op1, int8_t op2);
vbool2_t vmsbc_vvm (vint8m4_t op1, vint8m4_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm (vint8m4_t op1, int8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsbc_vs (vint8m4_t op1, int8_t op2);
vbool1_t vmsbc_vvm (vint8m8_t op1, vint8m8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vsm (vint8m8_t op1, int8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vv (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsbc_vs (vint8m8_t op1, int8_t op2);
vbool16_t vmsbc_vvm (vint16m1_t op1, vint16m1_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm (vint16m1_t op1, int16_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsbc_vs (vint16m1_t op1, int16_t op2);
vbool8_t vmsbc_vvm (vint16m2_t op1, vint16m2_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm (vint16m2_t op1, int16_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsbc_vs (vint16m2_t op1, int16_t op2);
vbool4_t vmsbc_vvm (vint16m4_t op1, vint16m4_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm (vint16m4_t op1, int16_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsbc_vs (vint16m4_t op1, int16_t op2);
vbool2_t vmsbc_vvm (vint16m8_t op1, vint16m8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm (vint16m8_t op1, int16_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsbc_vs (vint16m8_t op1, int16_t op2);
vbool32_t vmsbc_vvm (vint32m1_t op1, vint32m1_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm (vint32m1_t op1, int32_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsbc_vs (vint32m1_t op1, int32_t op2);
vbool16_t vmsbc_vvm (vint32m2_t op1, vint32m2_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm (vint32m2_t op1, int32_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsbc_vs (vint32m2_t op1, int32_t op2);
vbool8_t vmsbc_vvm (vint32m4_t op1, vint32m4_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm (vint32m4_t op1, int32_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsbc_vs (vint32m4_t op1, int32_t op2);
vbool4_t vmsbc_vvm (vint32m8_t op1, vint32m8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm (vint32m8_t op1, int32_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsbc_vs (vint32m8_t op1, int32_t op2);
vbool64_t vmsbc_vvm (vint64m1_t op1, vint64m1_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vsm (vint64m1_t op1, int64_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vv (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsbc_vs (vint64m1_t op1, int64_t op2);
vbool32_t vmsbc_vvm (vint64m2_t op1, vint64m2_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm (vint64m2_t op1, int64_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsbc_vs (vint64m2_t op1, int64_t op2);
vbool16_t vmsbc_vvm (vint64m4_t op1, vint64m4_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm (vint64m4_t op1, int64_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsbc_vs (vint64m4_t op1, int64_t op2);
vbool8_t vmsbc_vvm (vint64m8_t op1, vint64m8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm (vint64m8_t op1, int64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsbc_vs (vint64m8_t op1, int64_t op2);
vbool8_t vmsbc_vvm (vuint8m1_t op1, vuint8m1_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm (vuint8m1_t op1, uint8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsbc_vs (vuint8m1_t op1, uint8_t op2);
vbool4_t vmsbc_vvm (vuint8m2_t op1, vuint8m2_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm (vuint8m2_t op1, uint8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsbc_vs (vuint8m2_t op1, uint8_t op2);
vbool2_t vmsbc_vvm (vuint8m4_t op1, vuint8m4_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm (vuint8m4_t op1, uint8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsbc_vs (vuint8m4_t op1, uint8_t op2);
vbool1_t vmsbc_vvm (vuint8m8_t op1, vuint8m8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vsm (vuint8m8_t op1, uint8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vv (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsbc_vs (vuint8m8_t op1, uint8_t op2);
vbool16_t vmsbc_vvm (vuint16m1_t op1, vuint16m1_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm (vuint16m1_t op1, uint16_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsbc_vs (vuint16m1_t op1, uint16_t op2);
vbool8_t vmsbc_vvm (vuint16m2_t op1, vuint16m2_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm (vuint16m2_t op1, uint16_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsbc_vs (vuint16m2_t op1, uint16_t op2);
vbool4_t vmsbc_vvm (vuint16m4_t op1, vuint16m4_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm (vuint16m4_t op1, uint16_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsbc_vs (vuint16m4_t op1, uint16_t op2);
vbool2_t vmsbc_vvm (vuint16m8_t op1, vuint16m8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm (vuint16m8_t op1, uint16_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsbc_vs (vuint16m8_t op1, uint16_t op2);
vbool32_t vmsbc_vvm (vuint32m1_t op1, vuint32m1_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm (vuint32m1_t op1, uint32_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsbc_vs (vuint32m1_t op1, uint32_t op2);
vbool16_t vmsbc_vvm (vuint32m2_t op1, vuint32m2_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm (vuint32m2_t op1, uint32_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsbc_vs (vuint32m2_t op1, uint32_t op2);
vbool8_t vmsbc_vvm (vuint32m4_t op1, vuint32m4_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm (vuint32m4_t op1, uint32_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsbc_vs (vuint32m4_t op1, uint32_t op2);
vbool4_t vmsbc_vvm (vuint32m8_t op1, vuint32m8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm (vuint32m8_t op1, uint32_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsbc_vs (vuint32m8_t op1, uint32_t op2);
vbool64_t vmsbc_vvm (vuint64m1_t op1, vuint64m1_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vsm (vuint64m1_t op1, uint64_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vv (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsbc_vs (vuint64m1_t op1, uint64_t op2);
vbool32_t vmsbc_vvm (vuint64m2_t op1, vuint64m2_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm (vuint64m2_t op1, uint64_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsbc_vs (vuint64m2_t op1, uint64_t op2);
vbool16_t vmsbc_vvm (vuint64m4_t op1, vuint64m4_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm (vuint64m4_t op1, uint64_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsbc_vs (vuint64m4_t op1, uint64_t op2);
vbool8_t vmsbc_vvm (vuint64m8_t op1, vuint64m8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm (vuint64m8_t op1, uint64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsbc_vs (vuint64m8_t op1, uint64_t op2);
```
### [Vector Bitwise Logical Functions]()

**Prototypes:**
``` C
vuint8m1_t vand (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vand (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vand (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vand (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vand (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vand (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vand (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vand (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vand (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vand (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vand (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vand (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vand (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vand (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vand (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vand (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vand (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vand (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vand (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vand (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vand (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vand (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vand (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vand (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vand (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vand (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vand (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vand (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vand (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vand (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vand (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vand (vuint64m8_t op1, uint64_t op2);
vuint8m1_t vor (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vor (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vor (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vor (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vor (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vor (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vor (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vor (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vor (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vor (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vor (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vor (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vor (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vor (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vor (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vor (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vor (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vor (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vor (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vor (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vor (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vor (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vor (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vor (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vor (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vor (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vor (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vor (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vor (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vor (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vor (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vor (vuint64m8_t op1, uint64_t op2);
vuint8m1_t vxor (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vxor (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vxor (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vxor (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vxor (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vxor (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vxor (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vxor (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vxor (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vxor (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vxor (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vxor (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vxor (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vxor (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vxor (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vxor (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vxor (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vxor (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vxor (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vxor (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vxor (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vxor (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vxor (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vxor (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vxor (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vxor (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vxor (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vxor (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vxor (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vxor (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vxor (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vxor (vuint64m8_t op1, uint64_t op2);
// masked functions
vuint8m1_t vand_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vand_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vand_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vand_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vand_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vand_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vand_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vand_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vand_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vand_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vand_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vand_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vand_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vand_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vand_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vand_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vand_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vand_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vand_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vand_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vand_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vand_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vand_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vand_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vand_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vand_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vand_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vand_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vand_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vand_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vand_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vand_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vuint8m1_t vor_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vor_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vor_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vor_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vor_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vor_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vor_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vor_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vor_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vor_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vor_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vor_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vor_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vor_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vor_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vor_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vor_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vor_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vor_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vor_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vor_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vor_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vor_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vor_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vor_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vor_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vor_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vor_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vor_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vor_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vor_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vor_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vuint8m1_t vxor_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vxor_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vxor_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vxor_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vxor_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vxor_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vxor_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vxor_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vxor_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vxor_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vxor_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vxor_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vxor_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vxor_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vxor_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vxor_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vxor_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vxor_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vxor_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vxor_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vxor_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vxor_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vxor_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vxor_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vxor_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vxor_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vxor_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vxor_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vxor_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vxor_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vxor_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vxor_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Bit Shift Functions]()

**Prototypes:**
``` C
vuint8m1_t vsll (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsll (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsll (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsll (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsll (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsll (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsll (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsll (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsll (vuint16m1_t op1, vuint8m1_t op2);
vuint16m1_t vsll (vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsll (vuint16m2_t op1, vuint8m2_t op2);
vuint16m2_t vsll (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsll (vuint16m4_t op1, vuint8m4_t op2);
vuint16m4_t vsll (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsll (vuint16m8_t op1, vuint8m8_t op2);
vuint16m8_t vsll (vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsll (vuint32m1_t op1, vuint8m1_t op2);
vuint32m1_t vsll (vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsll (vuint32m2_t op1, vuint8m2_t op2);
vuint32m2_t vsll (vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsll (vuint32m4_t op1, vuint8m4_t op2);
vuint32m4_t vsll (vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsll (vuint32m8_t op1, vuint8m8_t op2);
vuint32m8_t vsll (vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsll (vuint64m1_t op1, vuint8m1_t op2);
vuint64m1_t vsll (vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsll (vuint64m2_t op1, vuint8m2_t op2);
vuint64m2_t vsll (vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsll (vuint64m4_t op1, vuint8m4_t op2);
vuint64m4_t vsll (vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsll (vuint64m8_t op1, vuint8m8_t op2);
vuint64m8_t vsll (vuint64m8_t op1, uint8_t op2);
vuint8m1_t vsrl (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsrl (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsrl (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsrl (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsrl (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsrl (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsrl (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsrl (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsrl (vuint16m1_t op1, vuint8m1_t op2);
vuint16m1_t vsrl (vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsrl (vuint16m2_t op1, vuint8m2_t op2);
vuint16m2_t vsrl (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsrl (vuint16m4_t op1, vuint8m4_t op2);
vuint16m4_t vsrl (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsrl (vuint16m8_t op1, vuint8m8_t op2);
vuint16m8_t vsrl (vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsrl (vuint32m1_t op1, vuint8m1_t op2);
vuint32m1_t vsrl (vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsrl (vuint32m2_t op1, vuint8m2_t op2);
vuint32m2_t vsrl (vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsrl (vuint32m4_t op1, vuint8m4_t op2);
vuint32m4_t vsrl (vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsrl (vuint32m8_t op1, vuint8m8_t op2);
vuint32m8_t vsrl (vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsrl (vuint64m1_t op1, vuint8m1_t op2);
vuint64m1_t vsrl (vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsrl (vuint64m2_t op1, vuint8m2_t op2);
vuint64m2_t vsrl (vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsrl (vuint64m4_t op1, vuint8m4_t op2);
vuint64m4_t vsrl (vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsrl (vuint64m8_t op1, vuint8m8_t op2);
vuint64m8_t vsrl (vuint64m8_t op1, uint8_t op2);
vint8m1_t vsra (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vsra (vint8m1_t op1, uint8_t op2);
vint8m2_t vsra (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vsra (vint8m2_t op1, uint8_t op2);
vint8m4_t vsra (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vsra (vint8m4_t op1, uint8_t op2);
vint8m8_t vsra (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vsra (vint8m8_t op1, uint8_t op2);
vint16m1_t vsra (vint16m1_t op1, vuint8m1_t op2);
vint16m1_t vsra (vint16m1_t op1, uint8_t op2);
vint16m2_t vsra (vint16m2_t op1, vuint8m2_t op2);
vint16m2_t vsra (vint16m2_t op1, uint8_t op2);
vint16m4_t vsra (vint16m4_t op1, vuint8m4_t op2);
vint16m4_t vsra (vint16m4_t op1, uint8_t op2);
vint16m8_t vsra (vint16m8_t op1, vuint8m8_t op2);
vint16m8_t vsra (vint16m8_t op1, uint8_t op2);
vint32m1_t vsra (vint32m1_t op1, vuint8m1_t op2);
vint32m1_t vsra (vint32m1_t op1, uint8_t op2);
vint32m2_t vsra (vint32m2_t op1, vuint8m2_t op2);
vint32m2_t vsra (vint32m2_t op1, uint8_t op2);
vint32m4_t vsra (vint32m4_t op1, vuint8m4_t op2);
vint32m4_t vsra (vint32m4_t op1, uint8_t op2);
vint32m8_t vsra (vint32m8_t op1, vuint8m8_t op2);
vint32m8_t vsra (vint32m8_t op1, uint8_t op2);
vint64m1_t vsra (vint64m1_t op1, vuint8m1_t op2);
vint64m1_t vsra (vint64m1_t op1, uint8_t op2);
vint64m2_t vsra (vint64m2_t op1, vuint8m2_t op2);
vint64m2_t vsra (vint64m2_t op1, uint8_t op2);
vint64m4_t vsra (vint64m4_t op1, vuint8m4_t op2);
vint64m4_t vsra (vint64m4_t op1, uint8_t op2);
vint64m8_t vsra (vint64m8_t op1, vuint8m8_t op2);
vint64m8_t vsra (vint64m8_t op1, uint8_t op2);
// masked functions
vuint8m1_t vsll_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsll_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsll_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsll_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsll_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsll_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsll_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsll_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsll_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint8m1_t op2);
vuint16m1_t vsll_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsll_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m2_t op2);
vuint16m2_t vsll_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsll_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m4_t op2);
vuint16m4_t vsll_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsll_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m8_t op2);
vuint16m8_t vsll_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsll_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint8m1_t op2);
vuint32m1_t vsll_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsll_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint8m2_t op2);
vuint32m2_t vsll_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsll_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint8m4_t op2);
vuint32m4_t vsll_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsll_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint8m8_t op2);
vuint32m8_t vsll_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsll_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint8m1_t op2);
vuint64m1_t vsll_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsll_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint8m2_t op2);
vuint64m2_t vsll_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsll_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint8m4_t op2);
vuint64m4_t vsll_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsll_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint8m8_t op2);
vuint64m8_t vsll_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint8_t op2);
vuint8m1_t vsrl_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsrl_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsrl_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsrl_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsrl_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsrl_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsrl_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsrl_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsrl_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint8m1_t op2);
vuint16m1_t vsrl_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint8_t op2);
vuint16m2_t vsrl_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m2_t op2);
vuint16m2_t vsrl_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vsrl_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m4_t op2);
vuint16m4_t vsrl_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vsrl_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m8_t op2);
vuint16m8_t vsrl_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m1_t vsrl_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint8m1_t op2);
vuint32m1_t vsrl_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint8_t op2);
vuint32m2_t vsrl_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint8m2_t op2);
vuint32m2_t vsrl_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint32m4_t vsrl_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint8m4_t op2);
vuint32m4_t vsrl_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint32m8_t vsrl_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint8m8_t op2);
vuint32m8_t vsrl_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint64m1_t vsrl_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint8m1_t op2);
vuint64m1_t vsrl_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint8_t op2);
vuint64m2_t vsrl_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint8m2_t op2);
vuint64m2_t vsrl_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint64m4_t vsrl_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint8m4_t op2);
vuint64m4_t vsrl_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint64m8_t vsrl_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint8m8_t op2);
vuint64m8_t vsrl_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint8_t op2);
vint8m1_t vsra_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vsra_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vsra_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vsra_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vsra_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vsra_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vsra_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vsra_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vsra_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint8m1_t op2);
vint16m1_t vsra_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint8_t op2);
vint16m2_t vsra_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint8m2_t op2);
vint16m2_t vsra_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint8_t op2);
vint16m4_t vsra_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint8m4_t op2);
vint16m4_t vsra_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint8_t op2);
vint16m8_t vsra_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint8m8_t op2);
vint16m8_t vsra_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint8_t op2);
vint32m1_t vsra_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint8m1_t op2);
vint32m1_t vsra_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint8_t op2);
vint32m2_t vsra_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint8m2_t op2);
vint32m2_t vsra_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint8_t op2);
vint32m4_t vsra_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint8m4_t op2);
vint32m4_t vsra_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint8_t op2);
vint32m8_t vsra_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint8m8_t op2);
vint32m8_t vsra_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint8_t op2);
vint64m1_t vsra_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint8m1_t op2);
vint64m1_t vsra_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint8_t op2);
vint64m2_t vsra_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint8m2_t op2);
vint64m2_t vsra_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint8_t op2);
vint64m4_t vsra_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint8m4_t op2);
vint64m4_t vsra_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint8_t op2);
vint64m8_t vsra_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint8m8_t op2);
vint64m8_t vsra_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint8_t op2);
```
### [Vector Narrowing Integer Right Shift Functions]()

**Prototypes:**
``` C
vuint8m1_t vnsrl (vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnsrl (vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnsrl (vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnsrl (vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnsrl (vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnsrl (vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnsrl (vuint32m2_t op1, vuint8m1_t op2);
vuint16m1_t vnsrl (vuint32m2_t op1, uint8_t op2);
vuint16m2_t vnsrl (vuint32m4_t op1, vuint8m2_t op2);
vuint16m2_t vnsrl (vuint32m4_t op1, uint8_t op2);
vuint16m4_t vnsrl (vuint32m8_t op1, vuint8m4_t op2);
vuint16m4_t vnsrl (vuint32m8_t op1, uint8_t op2);
vuint32m1_t vnsrl (vuint64m2_t op1, vuint8m1_t op2);
vuint32m1_t vnsrl (vuint64m2_t op1, uint8_t op2);
vuint32m2_t vnsrl (vuint64m4_t op1, vuint8m2_t op2);
vuint32m2_t vnsrl (vuint64m4_t op1, uint8_t op2);
vuint32m4_t vnsrl (vuint64m8_t op1, vuint8m4_t op2);
vuint32m4_t vnsrl (vuint64m8_t op1, uint8_t op2);
vint8m1_t vnsra (vint16m2_t op1, vuint8m1_t op2);
vint8m1_t vnsra (vint16m2_t op1, uint8_t op2);
vint8m2_t vnsra (vint16m4_t op1, vuint8m2_t op2);
vint8m2_t vnsra (vint16m4_t op1, uint8_t op2);
vint8m4_t vnsra (vint16m8_t op1, vuint8m4_t op2);
vint8m4_t vnsra (vint16m8_t op1, uint8_t op2);
vint16m1_t vnsra (vint32m2_t op1, vuint8m1_t op2);
vint16m1_t vnsra (vint32m2_t op1, uint8_t op2);
vint16m2_t vnsra (vint32m4_t op1, vuint8m2_t op2);
vint16m2_t vnsra (vint32m4_t op1, uint8_t op2);
vint16m4_t vnsra (vint32m8_t op1, vuint8m4_t op2);
vint16m4_t vnsra (vint32m8_t op1, uint8_t op2);
vint32m1_t vnsra (vint64m2_t op1, vuint8m1_t op2);
vint32m1_t vnsra (vint64m2_t op1, uint8_t op2);
vint32m2_t vnsra (vint64m4_t op1, vuint8m2_t op2);
vint32m2_t vnsra (vint64m4_t op1, uint8_t op2);
vint32m4_t vnsra (vint64m8_t op1, vuint8m4_t op2);
vint32m4_t vnsra (vint64m8_t op1, uint8_t op2);
// masked functions
vuint8m1_t vnsrl_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnsrl_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnsrl_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnsrl_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnsrl_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnsrl_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnsrl_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint8m1_t op2);
vuint16m1_t vnsrl_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, uint8_t op2);
vuint16m2_t vnsrl_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint8m2_t op2);
vuint16m2_t vnsrl_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, uint8_t op2);
vuint16m4_t vnsrl_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint8m4_t op2);
vuint16m4_t vnsrl_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, uint8_t op2);
vuint32m1_t vnsrl_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint8m1_t op2);
vuint32m1_t vnsrl_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, uint8_t op2);
vuint32m2_t vnsrl_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint8m2_t op2);
vuint32m2_t vnsrl_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, uint8_t op2);
vuint32m4_t vnsrl_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint8m4_t op2);
vuint32m4_t vnsrl_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, uint8_t op2);
vint8m1_t vnsra_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t op2);
vint8m1_t vnsra_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, uint8_t op2);
vint8m2_t vnsra_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t op2);
vint8m2_t vnsra_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, uint8_t op2);
vint8m4_t vnsra_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t op2);
vint8m4_t vnsra_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, uint8_t op2);
vint16m1_t vnsra_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint8m1_t op2);
vint16m1_t vnsra_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, uint8_t op2);
vint16m2_t vnsra_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint8m2_t op2);
vint16m2_t vnsra_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, uint8_t op2);
vint16m4_t vnsra_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint8m4_t op2);
vint16m4_t vnsra_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, uint8_t op2);
vint32m1_t vnsra_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint8m1_t op2);
vint32m1_t vnsra_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, uint8_t op2);
vint32m2_t vnsra_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint8m2_t op2);
vint32m2_t vnsra_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, uint8_t op2);
vint32m4_t vnsra_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint8m4_t op2);
vint32m4_t vnsra_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, uint8_t op2);
```
### [Vector Integer Comparison Functions]()

**Prototypes:**
``` C
vbool8_t vseteq (vint8m1_t op1, vint8m1_t op2);
vbool8_t vseteq (vint8m1_t op1, int8_t op2);
vbool4_t vseteq (vint8m2_t op1, vint8m2_t op2);
vbool4_t vseteq (vint8m2_t op1, int8_t op2);
vbool2_t vseteq (vint8m4_t op1, vint8m4_t op2);
vbool2_t vseteq (vint8m4_t op1, int8_t op2);
vbool1_t vseteq (vint8m8_t op1, vint8m8_t op2);
vbool1_t vseteq (vint8m8_t op1, int8_t op2);
vbool16_t vseteq (vint16m1_t op1, vint16m1_t op2);
vbool16_t vseteq (vint16m1_t op1, int16_t op2);
vbool8_t vseteq (vint16m2_t op1, vint16m2_t op2);
vbool8_t vseteq (vint16m2_t op1, int16_t op2);
vbool4_t vseteq (vint16m4_t op1, vint16m4_t op2);
vbool4_t vseteq (vint16m4_t op1, int16_t op2);
vbool2_t vseteq (vint16m8_t op1, vint16m8_t op2);
vbool2_t vseteq (vint16m8_t op1, int16_t op2);
vbool32_t vseteq (vint32m1_t op1, vint32m1_t op2);
vbool32_t vseteq (vint32m1_t op1, int32_t op2);
vbool16_t vseteq (vint32m2_t op1, vint32m2_t op2);
vbool16_t vseteq (vint32m2_t op1, int32_t op2);
vbool8_t vseteq (vint32m4_t op1, vint32m4_t op2);
vbool8_t vseteq (vint32m4_t op1, int32_t op2);
vbool4_t vseteq (vint32m8_t op1, vint32m8_t op2);
vbool4_t vseteq (vint32m8_t op1, int32_t op2);
vbool64_t vseteq (vint64m1_t op1, vint64m1_t op2);
vbool64_t vseteq (vint64m1_t op1, int64_t op2);
vbool32_t vseteq (vint64m2_t op1, vint64m2_t op2);
vbool32_t vseteq (vint64m2_t op1, int64_t op2);
vbool16_t vseteq (vint64m4_t op1, vint64m4_t op2);
vbool16_t vseteq (vint64m4_t op1, int64_t op2);
vbool8_t vseteq (vint64m8_t op1, vint64m8_t op2);
vbool8_t vseteq (vint64m8_t op1, int64_t op2);
vbool8_t vseteq (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vseteq (vuint8m1_t op1, uint8_t op2);
vbool4_t vseteq (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vseteq (vuint8m2_t op1, uint8_t op2);
vbool2_t vseteq (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vseteq (vuint8m4_t op1, uint8_t op2);
vbool1_t vseteq (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vseteq (vuint8m8_t op1, uint8_t op2);
vbool16_t vseteq (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vseteq (vuint16m1_t op1, uint16_t op2);
vbool8_t vseteq (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vseteq (vuint16m2_t op1, uint16_t op2);
vbool4_t vseteq (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vseteq (vuint16m4_t op1, uint16_t op2);
vbool2_t vseteq (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vseteq (vuint16m8_t op1, uint16_t op2);
vbool32_t vseteq (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vseteq (vuint32m1_t op1, uint32_t op2);
vbool16_t vseteq (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vseteq (vuint32m2_t op1, uint32_t op2);
vbool8_t vseteq (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vseteq (vuint32m4_t op1, uint32_t op2);
vbool4_t vseteq (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vseteq (vuint32m8_t op1, uint32_t op2);
vbool64_t vseteq (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vseteq (vuint64m1_t op1, uint64_t op2);
vbool32_t vseteq (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vseteq (vuint64m2_t op1, uint64_t op2);
vbool16_t vseteq (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vseteq (vuint64m4_t op1, uint64_t op2);
vbool8_t vseteq (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vseteq (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetne (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetne (vint8m1_t op1, int8_t op2);
vbool4_t vsetne (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetne (vint8m2_t op1, int8_t op2);
vbool2_t vsetne (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetne (vint8m4_t op1, int8_t op2);
vbool1_t vsetne (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetne (vint8m8_t op1, int8_t op2);
vbool16_t vsetne (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetne (vint16m1_t op1, int16_t op2);
vbool8_t vsetne (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetne (vint16m2_t op1, int16_t op2);
vbool4_t vsetne (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetne (vint16m4_t op1, int16_t op2);
vbool2_t vsetne (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetne (vint16m8_t op1, int16_t op2);
vbool32_t vsetne (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetne (vint32m1_t op1, int32_t op2);
vbool16_t vsetne (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetne (vint32m2_t op1, int32_t op2);
vbool8_t vsetne (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetne (vint32m4_t op1, int32_t op2);
vbool4_t vsetne (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetne (vint32m8_t op1, int32_t op2);
vbool64_t vsetne (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetne (vint64m1_t op1, int64_t op2);
vbool32_t vsetne (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetne (vint64m2_t op1, int64_t op2);
vbool16_t vsetne (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetne (vint64m4_t op1, int64_t op2);
vbool8_t vsetne (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetne (vint64m8_t op1, int64_t op2);
vbool8_t vsetne (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetne (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetne (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetne (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetne (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetne (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetne (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetne (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetne (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetne (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetne (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetne (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetne (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetne (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetne (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetne (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetne (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetne (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetne (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetne (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetne (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetne (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetne (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetne (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetne (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetne (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetne (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetne (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetne (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetne (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetne (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetne (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetlt (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetlt (vint8m1_t op1, int8_t op2);
vbool4_t vsetlt (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetlt (vint8m2_t op1, int8_t op2);
vbool2_t vsetlt (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetlt (vint8m4_t op1, int8_t op2);
vbool1_t vsetlt (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetlt (vint8m8_t op1, int8_t op2);
vbool16_t vsetlt (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetlt (vint16m1_t op1, int16_t op2);
vbool8_t vsetlt (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetlt (vint16m2_t op1, int16_t op2);
vbool4_t vsetlt (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetlt (vint16m4_t op1, int16_t op2);
vbool2_t vsetlt (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetlt (vint16m8_t op1, int16_t op2);
vbool32_t vsetlt (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetlt (vint32m1_t op1, int32_t op2);
vbool16_t vsetlt (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetlt (vint32m2_t op1, int32_t op2);
vbool8_t vsetlt (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetlt (vint32m4_t op1, int32_t op2);
vbool4_t vsetlt (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetlt (vint32m8_t op1, int32_t op2);
vbool64_t vsetlt (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetlt (vint64m1_t op1, int64_t op2);
vbool32_t vsetlt (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetlt (vint64m2_t op1, int64_t op2);
vbool16_t vsetlt (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetlt (vint64m4_t op1, int64_t op2);
vbool8_t vsetlt (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetlt (vint64m8_t op1, int64_t op2);
vbool8_t vsetlt (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetlt (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetlt (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetlt (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetlt (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetlt (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetlt (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetlt (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetlt (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetlt (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetlt (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetlt (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetlt (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetlt (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetlt (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetlt (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetlt (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetlt (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetlt (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetlt (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetlt (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetlt (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetlt (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetlt (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetlt (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetlt (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetlt (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetlt (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetlt (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetlt (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetlt (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetlt (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetle (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetle (vint8m1_t op1, int8_t op2);
vbool4_t vsetle (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetle (vint8m2_t op1, int8_t op2);
vbool2_t vsetle (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetle (vint8m4_t op1, int8_t op2);
vbool1_t vsetle (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetle (vint8m8_t op1, int8_t op2);
vbool16_t vsetle (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetle (vint16m1_t op1, int16_t op2);
vbool8_t vsetle (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetle (vint16m2_t op1, int16_t op2);
vbool4_t vsetle (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetle (vint16m4_t op1, int16_t op2);
vbool2_t vsetle (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetle (vint16m8_t op1, int16_t op2);
vbool32_t vsetle (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetle (vint32m1_t op1, int32_t op2);
vbool16_t vsetle (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetle (vint32m2_t op1, int32_t op2);
vbool8_t vsetle (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetle (vint32m4_t op1, int32_t op2);
vbool4_t vsetle (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetle (vint32m8_t op1, int32_t op2);
vbool64_t vsetle (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetle (vint64m1_t op1, int64_t op2);
vbool32_t vsetle (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetle (vint64m2_t op1, int64_t op2);
vbool16_t vsetle (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetle (vint64m4_t op1, int64_t op2);
vbool8_t vsetle (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetle (vint64m8_t op1, int64_t op2);
vbool8_t vsetle (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetle (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetle (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetle (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetle (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetle (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetle (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetle (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetle (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetle (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetle (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetle (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetle (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetle (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetle (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetle (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetle (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetle (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetle (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetle (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetle (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetle (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetle (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetle (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetle (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetle (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetle (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetle (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetle (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetle (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetle (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetle (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetgt (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetgt (vint8m1_t op1, int8_t op2);
vbool4_t vsetgt (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetgt (vint8m2_t op1, int8_t op2);
vbool2_t vsetgt (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetgt (vint8m4_t op1, int8_t op2);
vbool1_t vsetgt (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetgt (vint8m8_t op1, int8_t op2);
vbool16_t vsetgt (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetgt (vint16m1_t op1, int16_t op2);
vbool8_t vsetgt (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetgt (vint16m2_t op1, int16_t op2);
vbool4_t vsetgt (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetgt (vint16m4_t op1, int16_t op2);
vbool2_t vsetgt (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetgt (vint16m8_t op1, int16_t op2);
vbool32_t vsetgt (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetgt (vint32m1_t op1, int32_t op2);
vbool16_t vsetgt (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetgt (vint32m2_t op1, int32_t op2);
vbool8_t vsetgt (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetgt (vint32m4_t op1, int32_t op2);
vbool4_t vsetgt (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetgt (vint32m8_t op1, int32_t op2);
vbool64_t vsetgt (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetgt (vint64m1_t op1, int64_t op2);
vbool32_t vsetgt (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetgt (vint64m2_t op1, int64_t op2);
vbool16_t vsetgt (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetgt (vint64m4_t op1, int64_t op2);
vbool8_t vsetgt (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetgt (vint64m8_t op1, int64_t op2);
vbool8_t vsetgt (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetgt (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetgt (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetgt (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetgt (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetgt (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetgt (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetgt (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetgt (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetgt (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetgt (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetgt (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetgt (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetgt (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetgt (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetgt (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetgt (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetgt (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetgt (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetgt (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetgt (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetgt (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetgt (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetgt (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetgt (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetgt (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetgt (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetgt (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetgt (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetgt (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetgt (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetgt (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetge (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetge (vint8m1_t op1, int8_t op2);
vbool4_t vsetge (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetge (vint8m2_t op1, int8_t op2);
vbool2_t vsetge (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetge (vint8m4_t op1, int8_t op2);
vbool1_t vsetge (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetge (vint8m8_t op1, int8_t op2);
vbool16_t vsetge (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetge (vint16m1_t op1, int16_t op2);
vbool8_t vsetge (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetge (vint16m2_t op1, int16_t op2);
vbool4_t vsetge (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetge (vint16m4_t op1, int16_t op2);
vbool2_t vsetge (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetge (vint16m8_t op1, int16_t op2);
vbool32_t vsetge (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetge (vint32m1_t op1, int32_t op2);
vbool16_t vsetge (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetge (vint32m2_t op1, int32_t op2);
vbool8_t vsetge (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetge (vint32m4_t op1, int32_t op2);
vbool4_t vsetge (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetge (vint32m8_t op1, int32_t op2);
vbool64_t vsetge (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetge (vint64m1_t op1, int64_t op2);
vbool32_t vsetge (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetge (vint64m2_t op1, int64_t op2);
vbool16_t vsetge (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetge (vint64m4_t op1, int64_t op2);
vbool8_t vsetge (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetge (vint64m8_t op1, int64_t op2);
vbool8_t vsetge (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetge (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetge (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetge (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetge (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetge (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetge (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetge (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetge (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetge (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetge (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetge (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetge (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetge (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetge (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetge (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetge (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetge (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetge (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetge (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetge (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetge (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetge (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetge (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetge (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetge (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetge (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetge (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetge (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetge (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetge (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetge (vuint64m8_t op1, uint64_t op2);
// masked functions
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vseteq_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vseteq_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vseteq_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vseteq_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vseteq_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vseteq_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vseteq_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vseteq_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vseteq_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vseteq_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vseteq_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vseteq_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vseteq_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vseteq_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vseteq_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vseteq_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetne_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetne_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetne_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetne_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetne_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetne_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetne_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetne_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetne_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetne_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetne_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetne_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetne_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetne_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetne_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetne_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetlt_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetlt_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetlt_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetlt_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetlt_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetlt_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetlt_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetlt_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetlt_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetlt_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetlt_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetlt_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetlt_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetlt_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetlt_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetlt_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetle_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetle_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetle_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetle_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetle_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetle_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetle_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetle_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetle_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetle_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetle_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetle_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetle_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetle_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetle_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetle_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetgt_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetgt_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetgt_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetgt_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetgt_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetgt_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetgt_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetgt_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetgt_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetgt_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetgt_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetgt_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetgt_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetgt_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetgt_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetgt_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetge_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetge_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetge_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetge_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetge_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetge_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetge_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetge_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetge_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetge_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetge_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetge_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetge_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetge_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetge_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetge_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Integer Min/Max Functions]()

**Prototypes:**
``` C
vint8m1_t vmin (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmin (vint8m1_t op1, int8_t op2);
vint8m2_t vmin (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmin (vint8m2_t op1, int8_t op2);
vint8m4_t vmin (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmin (vint8m4_t op1, int8_t op2);
vint8m8_t vmin (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmin (vint8m8_t op1, int8_t op2);
vint16m1_t vmin (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmin (vint16m1_t op1, int16_t op2);
vint16m2_t vmin (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmin (vint16m2_t op1, int16_t op2);
vint16m4_t vmin (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmin (vint16m4_t op1, int16_t op2);
vint16m8_t vmin (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmin (vint16m8_t op1, int16_t op2);
vint32m1_t vmin (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmin (vint32m1_t op1, int32_t op2);
vint32m2_t vmin (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmin (vint32m2_t op1, int32_t op2);
vint32m4_t vmin (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmin (vint32m4_t op1, int32_t op2);
vint32m8_t vmin (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmin (vint32m8_t op1, int32_t op2);
vint64m1_t vmin (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmin (vint64m1_t op1, int64_t op2);
vint64m2_t vmin (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmin (vint64m2_t op1, int64_t op2);
vint64m4_t vmin (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmin (vint64m4_t op1, int64_t op2);
vint64m8_t vmin (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmin (vint64m8_t op1, int64_t op2);
vuint8m1_t vmin (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmin (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmin (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmin (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmin (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmin (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmin (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmin (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmin (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmin (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmin (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmin (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmin (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmin (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmin (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmin (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmin (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmin (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmin (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmin (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmin (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmin (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmin (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmin (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmin (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmin (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmin (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmin (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmin (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmin (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmin (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmin (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmax (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmax (vint8m1_t op1, int8_t op2);
vint8m2_t vmax (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmax (vint8m2_t op1, int8_t op2);
vint8m4_t vmax (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmax (vint8m4_t op1, int8_t op2);
vint8m8_t vmax (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmax (vint8m8_t op1, int8_t op2);
vint16m1_t vmax (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmax (vint16m1_t op1, int16_t op2);
vint16m2_t vmax (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmax (vint16m2_t op1, int16_t op2);
vint16m4_t vmax (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmax (vint16m4_t op1, int16_t op2);
vint16m8_t vmax (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmax (vint16m8_t op1, int16_t op2);
vint32m1_t vmax (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmax (vint32m1_t op1, int32_t op2);
vint32m2_t vmax (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmax (vint32m2_t op1, int32_t op2);
vint32m4_t vmax (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmax (vint32m4_t op1, int32_t op2);
vint32m8_t vmax (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmax (vint32m8_t op1, int32_t op2);
vint64m1_t vmax (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmax (vint64m1_t op1, int64_t op2);
vint64m2_t vmax (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmax (vint64m2_t op1, int64_t op2);
vint64m4_t vmax (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmax (vint64m4_t op1, int64_t op2);
vint64m8_t vmax (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmax (vint64m8_t op1, int64_t op2);
vuint8m1_t vmax (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmax (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmax (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmax (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmax (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmax (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmax (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmax (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmax (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmax (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmax (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmax (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmax (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmax (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmax (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmax (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmax (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmax (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmax (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmax (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmax (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmax (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmax (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmax (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmax (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmax (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmax (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmax (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmax (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmax (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmax (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmax (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vmin_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmin_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmin_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmin_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmin_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmin_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmin_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmin_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmin_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmin_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmin_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmin_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmin_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmin_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmin_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmin_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmin_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmin_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmin_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmin_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmin_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmin_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmin_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmin_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmin_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmin_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmin_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmin_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmin_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmin_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmin_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmin_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmin_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmin_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmin_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmin_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmin_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmin_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmin_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmin_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmin_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmin_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmin_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmin_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmin_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmin_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmin_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmin_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmin_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmin_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmin_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmin_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmin_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmin_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmin_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmin_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmin_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmin_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmin_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmin_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmin_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmin_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmin_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmin_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmax_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmax_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmax_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmax_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmax_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmax_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmax_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmax_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmax_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmax_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmax_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmax_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmax_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmax_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmax_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmax_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmax_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmax_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmax_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmax_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmax_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmax_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmax_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmax_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmax_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmax_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmax_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmax_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmax_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmax_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmax_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmax_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmax_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmax_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmax_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmax_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmax_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmax_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmax_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmax_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmax_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmax_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmax_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmax_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmax_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmax_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmax_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmax_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmax_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmax_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmax_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmax_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmax_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmax_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmax_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmax_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmax_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmax_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmax_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmax_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmax_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmax_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmax_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmax_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Integer Multiply Functions]()

**Prototypes:**
``` C
vint8m1_t vmul (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmul (vint8m1_t op1, int8_t op2);
vint8m2_t vmul (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmul (vint8m2_t op1, int8_t op2);
vint8m4_t vmul (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmul (vint8m4_t op1, int8_t op2);
vint8m8_t vmul (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmul (vint8m8_t op1, int8_t op2);
vint16m1_t vmul (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmul (vint16m1_t op1, int16_t op2);
vint16m2_t vmul (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmul (vint16m2_t op1, int16_t op2);
vint16m4_t vmul (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmul (vint16m4_t op1, int16_t op2);
vint16m8_t vmul (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmul (vint16m8_t op1, int16_t op2);
vint32m1_t vmul (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmul (vint32m1_t op1, int32_t op2);
vint32m2_t vmul (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmul (vint32m2_t op1, int32_t op2);
vint32m4_t vmul (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmul (vint32m4_t op1, int32_t op2);
vint32m8_t vmul (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmul (vint32m8_t op1, int32_t op2);
vint64m1_t vmul (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmul (vint64m1_t op1, int64_t op2);
vint64m2_t vmul (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmul (vint64m2_t op1, int64_t op2);
vint64m4_t vmul (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmul (vint64m4_t op1, int64_t op2);
vint64m8_t vmul (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmul (vint64m8_t op1, int64_t op2);
vuint8m1_t vmul (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmul (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmul (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmul (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmul (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmul (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmul (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmul (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmul (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmul (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmul (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmul (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmul (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmul (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmul (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmul (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmul (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmul (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmul (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmul (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmul (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmul (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmul (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmul (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmul (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmul (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmul (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmul (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmul (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmul (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmul (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmul (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulh (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmulh (vint8m1_t op1, int8_t op2);
vint8m2_t vmulh (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmulh (vint8m2_t op1, int8_t op2);
vint8m4_t vmulh (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmulh (vint8m4_t op1, int8_t op2);
vint8m8_t vmulh (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmulh (vint8m8_t op1, int8_t op2);
vint16m1_t vmulh (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmulh (vint16m1_t op1, int16_t op2);
vint16m2_t vmulh (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmulh (vint16m2_t op1, int16_t op2);
vint16m4_t vmulh (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmulh (vint16m4_t op1, int16_t op2);
vint16m8_t vmulh (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmulh (vint16m8_t op1, int16_t op2);
vint32m1_t vmulh (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmulh (vint32m1_t op1, int32_t op2);
vint32m2_t vmulh (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmulh (vint32m2_t op1, int32_t op2);
vint32m4_t vmulh (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmulh (vint32m4_t op1, int32_t op2);
vint32m8_t vmulh (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmulh (vint32m8_t op1, int32_t op2);
vint64m1_t vmulh (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmulh (vint64m1_t op1, int64_t op2);
vint64m2_t vmulh (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmulh (vint64m2_t op1, int64_t op2);
vint64m4_t vmulh (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmulh (vint64m4_t op1, int64_t op2);
vint64m8_t vmulh (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmulh (vint64m8_t op1, int64_t op2);
vuint8m1_t vmulh (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmulh (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmulh (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmulh (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmulh (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmulh (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmulh (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmulh (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmulh (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmulh (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmulh (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmulh (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmulh (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmulh (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmulh (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmulh (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmulh (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmulh (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmulh (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmulh (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmulh (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmulh (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmulh (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmulh (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmulh (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmulh (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmulh (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmulh (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmulh (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmulh (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmulh (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmulh (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulhsu (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmulhsu (vint8m1_t op1, uint8_t op2);
vint8m2_t vmulhsu (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmulhsu (vint8m2_t op1, uint8_t op2);
vint8m4_t vmulhsu (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmulhsu (vint8m4_t op1, uint8_t op2);
vint8m8_t vmulhsu (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmulhsu (vint8m8_t op1, uint8_t op2);
vint16m1_t vmulhsu (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmulhsu (vint16m1_t op1, uint16_t op2);
vint16m2_t vmulhsu (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmulhsu (vint16m2_t op1, uint16_t op2);
vint16m4_t vmulhsu (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmulhsu (vint16m4_t op1, uint16_t op2);
vint16m8_t vmulhsu (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmulhsu (vint16m8_t op1, uint16_t op2);
vint32m1_t vmulhsu (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmulhsu (vint32m1_t op1, uint32_t op2);
vint32m2_t vmulhsu (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmulhsu (vint32m2_t op1, uint32_t op2);
vint32m4_t vmulhsu (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmulhsu (vint32m4_t op1, uint32_t op2);
vint32m8_t vmulhsu (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmulhsu (vint32m8_t op1, uint32_t op2);
vint64m1_t vmulhsu (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmulhsu (vint64m1_t op1, uint64_t op2);
vint64m2_t vmulhsu (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmulhsu (vint64m2_t op1, uint64_t op2);
vint64m4_t vmulhsu (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmulhsu (vint64m4_t op1, uint64_t op2);
vint64m8_t vmulhsu (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmulhsu (vint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vmul_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmul_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmul_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmul_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmul_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmul_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmul_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmul_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmul_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmul_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmul_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmul_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmul_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmul_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmul_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmul_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmul_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmul_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmul_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmul_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmul_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmul_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmul_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmul_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmul_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmul_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmul_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmul_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmul_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmul_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmul_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmul_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmul_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmul_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmul_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmul_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmul_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmul_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmul_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmul_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmul_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmul_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmul_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmul_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmul_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmul_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmul_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmul_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmul_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmul_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmul_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmul_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmul_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmul_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmul_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmul_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmul_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmul_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmul_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmul_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmul_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmul_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmul_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmul_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulh_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmulh_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmulh_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmulh_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmulh_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmulh_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmulh_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmulh_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmulh_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmulh_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmulh_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmulh_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmulh_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmulh_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmulh_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmulh_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmulh_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmulh_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmulh_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmulh_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmulh_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmulh_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmulh_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmulh_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmulh_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmulh_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmulh_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmulh_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmulh_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmulh_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmulh_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmulh_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmulh_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmulh_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmulh_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmulh_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmulh_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmulh_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmulh_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmulh_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmulh_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmulh_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmulh_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmulh_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmulh_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmulh_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmulh_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmulh_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmulh_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmulh_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmulh_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmulh_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmulh_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmulh_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmulh_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmulh_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmulh_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmulh_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmulh_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmulh_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmulh_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmulh_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmulh_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmulh_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulhsu_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmulhsu_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vmulhsu_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmulhsu_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vmulhsu_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmulhsu_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vmulhsu_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmulhsu_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vmulhsu_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmulhsu_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2);
vint16m2_t vmulhsu_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmulhsu_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2);
vint16m4_t vmulhsu_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmulhsu_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2);
vint16m8_t vmulhsu_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmulhsu_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2);
vint32m1_t vmulhsu_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmulhsu_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2);
vint32m2_t vmulhsu_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmulhsu_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2);
vint32m4_t vmulhsu_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmulhsu_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2);
vint32m8_t vmulhsu_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmulhsu_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2);
vint64m1_t vmulhsu_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmulhsu_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2);
vint64m2_t vmulhsu_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmulhsu_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2);
vint64m4_t vmulhsu_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmulhsu_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2);
vint64m8_t vmulhsu_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmulhsu_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2);
```
### [Vector Integer Divide Functions]()

**Prototypes:**
``` C
vint8m1_t vdiv (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vdiv (vint8m1_t op1, int8_t op2);
vint8m2_t vdiv (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vdiv (vint8m2_t op1, int8_t op2);
vint8m4_t vdiv (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vdiv (vint8m4_t op1, int8_t op2);
vint8m8_t vdiv (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vdiv (vint8m8_t op1, int8_t op2);
vint16m1_t vdiv (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vdiv (vint16m1_t op1, int16_t op2);
vint16m2_t vdiv (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vdiv (vint16m2_t op1, int16_t op2);
vint16m4_t vdiv (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vdiv (vint16m4_t op1, int16_t op2);
vint16m8_t vdiv (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vdiv (vint16m8_t op1, int16_t op2);
vint32m1_t vdiv (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vdiv (vint32m1_t op1, int32_t op2);
vint32m2_t vdiv (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vdiv (vint32m2_t op1, int32_t op2);
vint32m4_t vdiv (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vdiv (vint32m4_t op1, int32_t op2);
vint32m8_t vdiv (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vdiv (vint32m8_t op1, int32_t op2);
vint64m1_t vdiv (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vdiv (vint64m1_t op1, int64_t op2);
vint64m2_t vdiv (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vdiv (vint64m2_t op1, int64_t op2);
vint64m4_t vdiv (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vdiv (vint64m4_t op1, int64_t op2);
vint64m8_t vdiv (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vdiv (vint64m8_t op1, int64_t op2);
vuint8m1_t vdiv (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vdiv (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vdiv (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vdiv (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vdiv (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vdiv (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vdiv (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vdiv (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vdiv (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vdiv (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vdiv (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vdiv (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vdiv (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vdiv (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vdiv (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vdiv (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vdiv (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vdiv (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vdiv (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vdiv (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vdiv (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vdiv (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vdiv (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vdiv (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vdiv (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vdiv (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vdiv (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vdiv (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vdiv (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vdiv (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vdiv (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vdiv (vuint64m8_t op1, uint64_t op2);
vint8m1_t vrem (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vrem (vint8m1_t op1, int8_t op2);
vint8m2_t vrem (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vrem (vint8m2_t op1, int8_t op2);
vint8m4_t vrem (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vrem (vint8m4_t op1, int8_t op2);
vint8m8_t vrem (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vrem (vint8m8_t op1, int8_t op2);
vint16m1_t vrem (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vrem (vint16m1_t op1, int16_t op2);
vint16m2_t vrem (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vrem (vint16m2_t op1, int16_t op2);
vint16m4_t vrem (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vrem (vint16m4_t op1, int16_t op2);
vint16m8_t vrem (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vrem (vint16m8_t op1, int16_t op2);
vint32m1_t vrem (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vrem (vint32m1_t op1, int32_t op2);
vint32m2_t vrem (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vrem (vint32m2_t op1, int32_t op2);
vint32m4_t vrem (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vrem (vint32m4_t op1, int32_t op2);
vint32m8_t vrem (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vrem (vint32m8_t op1, int32_t op2);
vint64m1_t vrem (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vrem (vint64m1_t op1, int64_t op2);
vint64m2_t vrem (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vrem (vint64m2_t op1, int64_t op2);
vint64m4_t vrem (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vrem (vint64m4_t op1, int64_t op2);
vint64m8_t vrem (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vrem (vint64m8_t op1, int64_t op2);
vuint8m1_t vrem (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrem (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrem (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrem (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrem (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrem (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrem (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrem (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrem (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrem (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrem (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrem (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrem (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrem (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrem (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrem (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrem (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrem (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrem (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrem (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrem (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrem (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrem (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrem (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrem (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrem (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrem (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrem (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrem (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrem (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrem (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrem (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vdiv_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vdiv_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vdiv_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vdiv_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vdiv_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vdiv_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vdiv_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vdiv_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vdiv_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vdiv_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vdiv_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vdiv_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vdiv_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vdiv_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vdiv_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vdiv_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vdiv_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vdiv_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vdiv_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vdiv_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vdiv_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vdiv_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vdiv_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vdiv_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vdiv_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vdiv_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vdiv_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vdiv_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vdiv_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vdiv_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vdiv_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vdiv_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vdiv_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vdiv_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vdiv_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vdiv_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vdiv_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vdiv_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vdiv_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vdiv_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vdiv_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vdiv_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vdiv_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vdiv_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vdiv_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vdiv_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vdiv_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vdiv_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vdiv_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vdiv_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vdiv_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vdiv_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vdiv_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vdiv_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vdiv_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vdiv_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vdiv_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vdiv_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vdiv_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vdiv_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vdiv_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vdiv_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vdiv_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vdiv_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vrem_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vrem_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vrem_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vrem_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vrem_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vrem_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vrem_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vrem_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vrem_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vrem_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vrem_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vrem_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vrem_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vrem_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vrem_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vrem_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vrem_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vrem_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vrem_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vrem_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vrem_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vrem_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vrem_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vrem_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vrem_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vrem_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vrem_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vrem_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vrem_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vrem_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vrem_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vrem_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vrem_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrem_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrem_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrem_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrem_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrem_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrem_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrem_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrem_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrem_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrem_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrem_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrem_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrem_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrem_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrem_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrem_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrem_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrem_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrem_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrem_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrem_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrem_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrem_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrem_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrem_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrem_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrem_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrem_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrem_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrem_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrem_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Widening Integer Multiply Functions]()

**Prototypes:**
``` C
vint16m2_t vwmul (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmul (vint8m1_t op1, int8_t op2);
vint16m4_t vwmul (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmul (vint8m2_t op1, int8_t op2);
vint16m8_t vwmul (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmul (vint8m4_t op1, int8_t op2);
vint32m2_t vwmul (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmul (vint16m1_t op1, int16_t op2);
vint32m4_t vwmul (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmul (vint16m2_t op1, int16_t op2);
vint32m8_t vwmul (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmul (vint16m4_t op1, int16_t op2);
vint64m2_t vwmul (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmul (vint32m1_t op1, int32_t op2);
vint64m4_t vwmul (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmul (vint32m2_t op1, int32_t op2);
vint64m8_t vwmul (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmul (vint32m4_t op1, int32_t op2);
vuint16m2_t vwmul (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmul (vuint8m1_t op1, uint8_t op2);
vuint16m4_t vwmul (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmul (vuint8m2_t op1, uint8_t op2);
vuint16m8_t vwmul (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmul (vuint8m4_t op1, uint8_t op2);
vuint32m2_t vwmul (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmul (vuint16m1_t op1, uint16_t op2);
vuint32m4_t vwmul (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmul (vuint16m2_t op1, uint16_t op2);
vuint32m8_t vwmul (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmul (vuint16m4_t op1, uint16_t op2);
vuint64m2_t vwmul (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmul (vuint32m1_t op1, uint32_t op2);
vuint64m4_t vwmul (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmul (vuint32m2_t op1, uint32_t op2);
vuint64m8_t vwmul (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmul (vuint32m4_t op1, uint32_t op2);
vint16m2_t vwmulsu (vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmulsu (vint8m1_t op1, uint8_t op2);
vint16m4_t vwmulsu (vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmulsu (vint8m2_t op1, uint8_t op2);
vint16m8_t vwmulsu (vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmulsu (vint8m4_t op1, uint8_t op2);
vint32m2_t vwmulsu (vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmulsu (vint16m1_t op1, uint16_t op2);
vint32m4_t vwmulsu (vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmulsu (vint16m2_t op1, uint16_t op2);
vint32m8_t vwmulsu (vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmulsu (vint16m4_t op1, uint16_t op2);
vint64m2_t vwmulsu (vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmulsu (vint32m1_t op1, uint32_t op2);
vint64m4_t vwmulsu (vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmulsu (vint32m2_t op1, uint32_t op2);
vint64m8_t vwmulsu (vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmulsu (vint32m4_t op1, uint32_t op2);
// masked functions
vint16m2_t vwmul_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmul_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m4_t vwmul_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmul_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m8_t vwmul_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmul_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint32m2_t vwmul_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmul_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m4_t vwmul_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmul_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m8_t vwmul_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmul_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint64m2_t vwmul_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmul_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m4_t vwmul_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmul_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m8_t vwmul_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmul_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vuint16m2_t vwmul_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmul_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m4_t vwmul_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmul_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m8_t vwmul_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmul_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint32m2_t vwmul_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmul_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m4_t vwmul_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmul_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m8_t vwmul_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmul_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint64m2_t vwmul_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmul_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m4_t vwmul_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmul_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m8_t vwmul_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmul_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vint16m2_t vwmulsu_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmulsu_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, uint8_t op2);
vint16m4_t vwmulsu_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmulsu_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, uint8_t op2);
vint16m8_t vwmulsu_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmulsu_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, uint8_t op2);
vint32m2_t vwmulsu_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmulsu_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, uint16_t op2);
vint32m4_t vwmulsu_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmulsu_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, uint16_t op2);
vint32m8_t vwmulsu_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmulsu_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, uint16_t op2);
vint64m2_t vwmulsu_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmulsu_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, uint32_t op2);
vint64m4_t vwmulsu_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmulsu_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, uint32_t op2);
vint64m8_t vwmulsu_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmulsu_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, uint32_t op2);
```
### [Vector Single-Width Integer Multiply-Add Functions]()

**Prototypes:**
``` C
vint8m1_t vmacc (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmacc (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmacc (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmacc (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmacc (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmacc (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmacc (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmacc (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmacc (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmacc (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmacc (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmacc (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmacc (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmacc (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmacc (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmacc (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmacc (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmacc (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmacc (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmacc (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmacc (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmacc (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmacc (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmacc (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmacc (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmacc (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmacc (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmacc (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmacc (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmacc (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmacc (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmacc (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmacc (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmacc (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmacc (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmacc (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmacc (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmacc (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmacc (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmacc (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmacc (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmacc (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmacc (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmacc (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmacc (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmacc (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmacc (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmacc (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmacc (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmacc (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmacc (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmacc (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmacc (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmacc (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmacc (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmacc (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmacc (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmacc (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmacc (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmacc (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmacc (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmacc (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmacc (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmacc (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsac (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsac (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsac (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsac (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsac (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsac (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsac (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsac (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsac (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsac (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsac (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsac (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsac (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsac (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsac (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsac (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsac (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsac (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsac (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsac (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsac (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsac (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsac (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsac (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsac (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsac (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsac (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsac (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsac (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsac (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsac (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsac (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsac (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsac (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsac (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsac (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsac (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsac (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsac (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsac (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsac (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsac (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsac (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsac (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsac (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsac (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsac (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsac (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsac (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsac (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsac (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsac (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsac (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsac (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsac (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsac (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsac (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsac (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsac (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsac (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsac (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsac (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsac (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsac (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vmadd (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmadd (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmadd (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmadd (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmadd (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmadd (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmadd (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmadd (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmadd (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmadd (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmadd (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmadd (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmadd (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmadd (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmadd (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmadd (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmadd (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmadd (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmadd (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmadd (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmadd (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmadd (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmadd (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmadd (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmadd (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmadd (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmadd (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmadd (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmadd (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmadd (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmadd (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmadd (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmadd (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmadd (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmadd (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmadd (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmadd (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmadd (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmadd (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmadd (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmadd (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmadd (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmadd (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmadd (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmadd (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmadd (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmadd (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmadd (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmadd (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmadd (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmadd (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmadd (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmadd (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmadd (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmadd (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmadd (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmadd (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmadd (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmadd (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmadd (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmadd (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmadd (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmadd (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmadd (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsub (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsub (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsub (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsub (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsub (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsub (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsub (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsub (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsub (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsub (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsub (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsub (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsub (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsub (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsub (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsub (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsub (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsub (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsub (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsub (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsub (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsub (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsub (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsub (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsub (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsub (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsub (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsub (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsub (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsub (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsub (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsub (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsub (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsub (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsub (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsub (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsub (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsub (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsub (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsub (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsub (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsub (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsub (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsub (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsub (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsub (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsub (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsub (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsub (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsub (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsub (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsub (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsub (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsub (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsub (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsub (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsub (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsub (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsub (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsub (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsub (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsub (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsub (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsub (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
// masked functions
vint8m1_t vmacc_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmacc_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmacc_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmacc_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmacc_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmacc_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmacc_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmacc_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmacc_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmacc_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmacc_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmacc_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmacc_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmacc_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmacc_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmacc_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmacc_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmacc_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmacc_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmacc_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmacc_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmacc_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmacc_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmacc_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmacc_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmacc_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmacc_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmacc_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmacc_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmacc_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmacc_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmacc_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmacc_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmacc_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmacc_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmacc_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmacc_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmacc_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmacc_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmacc_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmacc_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmacc_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmacc_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmacc_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmacc_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmacc_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmacc_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmacc_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmacc_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmacc_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmacc_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmacc_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmacc_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmacc_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmacc_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmacc_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmacc_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmacc_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmacc_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmacc_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmacc_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmacc_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmacc_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmacc_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsac_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsac_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsac_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsac_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsac_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsac_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsac_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsac_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsac_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsac_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsac_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsac_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsac_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsac_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsac_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsac_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsac_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsac_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsac_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsac_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsac_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsac_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsac_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsac_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsac_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsac_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsac_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsac_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsac_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsac_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsac_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsac_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsac_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsac_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsac_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsac_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsac_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsac_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsac_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsac_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsac_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsac_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsac_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsac_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsac_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsac_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsac_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsac_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsac_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsac_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsac_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsac_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsac_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsac_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsac_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsac_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsac_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsac_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsac_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsac_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsac_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsac_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsac_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsac_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vmadd_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmadd_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmadd_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmadd_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmadd_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmadd_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmadd_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmadd_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmadd_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmadd_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmadd_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmadd_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmadd_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmadd_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmadd_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmadd_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmadd_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmadd_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmadd_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmadd_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmadd_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmadd_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmadd_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmadd_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmadd_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmadd_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmadd_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmadd_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmadd_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmadd_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmadd_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmadd_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmadd_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmadd_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmadd_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmadd_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmadd_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmadd_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmadd_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmadd_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmadd_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmadd_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmadd_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmadd_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmadd_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmadd_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmadd_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmadd_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmadd_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmadd_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmadd_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmadd_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmadd_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmadd_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmadd_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmadd_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmadd_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmadd_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmadd_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmadd_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmadd_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmadd_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmadd_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmadd_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsub_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsub_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsub_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsub_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsub_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsub_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsub_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsub_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsub_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsub_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsub_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsub_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsub_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsub_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsub_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsub_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsub_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsub_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsub_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsub_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsub_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsub_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsub_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsub_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsub_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsub_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsub_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsub_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsub_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsub_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsub_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsub_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsub_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsub_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsub_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsub_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsub_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsub_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsub_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsub_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsub_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsub_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsub_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsub_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsub_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsub_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsub_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsub_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsub_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsub_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsub_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsub_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsub_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsub_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsub_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsub_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsub_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsub_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsub_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsub_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsub_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsub_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsub_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsub_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
```
### [Vector Widening Integer Multiply-Add Functions]()

**Prototypes:**
``` C
vint16m2_t vwmacc (vint16m2_t acc, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmacc (vint16m2_t acc, int8_t op1, vint8m1_t op2);
vint16m4_t vwmacc (vint16m4_t acc, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmacc (vint16m4_t acc, int8_t op1, vint8m2_t op2);
vint16m8_t vwmacc (vint16m8_t acc, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmacc (vint16m8_t acc, int8_t op1, vint8m4_t op2);
vint32m2_t vwmacc (vint32m2_t acc, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmacc (vint32m2_t acc, int16_t op1, vint16m1_t op2);
vint32m4_t vwmacc (vint32m4_t acc, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmacc (vint32m4_t acc, int16_t op1, vint16m2_t op2);
vint32m8_t vwmacc (vint32m8_t acc, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmacc (vint32m8_t acc, int16_t op1, vint16m4_t op2);
vint64m2_t vwmacc (vint64m2_t acc, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmacc (vint64m2_t acc, int32_t op1, vint32m1_t op2);
vint64m4_t vwmacc (vint64m4_t acc, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmacc (vint64m4_t acc, int32_t op1, vint32m2_t op2);
vint64m8_t vwmacc (vint64m8_t acc, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmacc (vint64m8_t acc, int32_t op1, vint32m4_t op2);
vuint16m2_t vwmacc (vuint16m2_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmacc (vuint16m2_t acc, uint8_t op1, vuint8m1_t op2);
vuint16m4_t vwmacc (vuint16m4_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmacc (vuint16m4_t acc, uint8_t op1, vuint8m2_t op2);
vuint16m8_t vwmacc (vuint16m8_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmacc (vuint16m8_t acc, uint8_t op1, vuint8m4_t op2);
vuint32m2_t vwmacc (vuint32m2_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmacc (vuint32m2_t acc, uint16_t op1, vuint16m1_t op2);
vuint32m4_t vwmacc (vuint32m4_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmacc (vuint32m4_t acc, uint16_t op1, vuint16m2_t op2);
vuint32m8_t vwmacc (vuint32m8_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmacc (vuint32m8_t acc, uint16_t op1, vuint16m4_t op2);
vuint64m2_t vwmacc (vuint64m2_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmacc (vuint64m2_t acc, uint32_t op1, vuint32m1_t op2);
vuint64m4_t vwmacc (vuint64m4_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmacc (vuint64m4_t acc, uint32_t op1, vuint32m2_t op2);
vuint64m8_t vwmacc (vuint64m8_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmacc (vuint64m8_t acc, uint32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccsu (vint16m2_t acc, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmaccsu (vint16m2_t acc, int8_t op1, vuint8m1_t op2);
vint16m4_t vwmaccsu (vint16m4_t acc, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmaccsu (vint16m4_t acc, int8_t op1, vuint8m2_t op2);
vint16m8_t vwmaccsu (vint16m8_t acc, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmaccsu (vint16m8_t acc, int8_t op1, vuint8m4_t op2);
vint32m2_t vwmaccsu (vint32m2_t acc, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmaccsu (vint32m2_t acc, int16_t op1, vuint16m1_t op2);
vint32m4_t vwmaccsu (vint32m4_t acc, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmaccsu (vint32m4_t acc, int16_t op1, vuint16m2_t op2);
vint32m8_t vwmaccsu (vint32m8_t acc, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmaccsu (vint32m8_t acc, int16_t op1, vuint16m4_t op2);
vint64m2_t vwmaccsu (vint64m2_t acc, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmaccsu (vint64m2_t acc, int32_t op1, vuint32m1_t op2);
vint64m4_t vwmaccsu (vint64m4_t acc, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmaccsu (vint64m4_t acc, int32_t op1, vuint32m2_t op2);
vint64m8_t vwmaccsu (vint64m8_t acc, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmaccsu (vint64m8_t acc, int32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccus (vint16m2_t acc, uint8_t op1, vint8m1_t op2);
vint16m4_t vwmaccus (vint16m4_t acc, uint8_t op1, vint8m2_t op2);
vint16m8_t vwmaccus (vint16m8_t acc, uint8_t op1, vint8m4_t op2);
vint32m2_t vwmaccus (vint32m2_t acc, uint16_t op1, vint16m1_t op2);
vint32m4_t vwmaccus (vint32m4_t acc, uint16_t op1, vint16m2_t op2);
vint32m8_t vwmaccus (vint32m8_t acc, uint16_t op1, vint16m4_t op2);
vint64m2_t vwmaccus (vint64m2_t acc, uint32_t op1, vint32m1_t op2);
vint64m4_t vwmaccus (vint64m4_t acc, uint32_t op1, vint32m2_t op2);
vint64m8_t vwmaccus (vint64m8_t acc, uint32_t op1, vint32m4_t op2);
// masked functions
vint16m2_t vwmacc_mask (vbool8_t mask, vint16m2_t acc, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmacc_mask (vbool8_t mask, vint16m2_t acc, int8_t op1, vint8m1_t op2);
vint16m4_t vwmacc_mask (vbool4_t mask, vint16m4_t acc, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmacc_mask (vbool4_t mask, vint16m4_t acc, int8_t op1, vint8m2_t op2);
vint16m8_t vwmacc_mask (vbool2_t mask, vint16m8_t acc, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmacc_mask (vbool2_t mask, vint16m8_t acc, int8_t op1, vint8m4_t op2);
vint32m2_t vwmacc_mask (vbool16_t mask, vint32m2_t acc, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmacc_mask (vbool16_t mask, vint32m2_t acc, int16_t op1, vint16m1_t op2);
vint32m4_t vwmacc_mask (vbool8_t mask, vint32m4_t acc, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmacc_mask (vbool8_t mask, vint32m4_t acc, int16_t op1, vint16m2_t op2);
vint32m8_t vwmacc_mask (vbool4_t mask, vint32m8_t acc, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmacc_mask (vbool4_t mask, vint32m8_t acc, int16_t op1, vint16m4_t op2);
vint64m2_t vwmacc_mask (vbool32_t mask, vint64m2_t acc, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmacc_mask (vbool32_t mask, vint64m2_t acc, int32_t op1, vint32m1_t op2);
vint64m4_t vwmacc_mask (vbool16_t mask, vint64m4_t acc, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmacc_mask (vbool16_t mask, vint64m4_t acc, int32_t op1, vint32m2_t op2);
vint64m8_t vwmacc_mask (vbool8_t mask, vint64m8_t acc, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmacc_mask (vbool8_t mask, vint64m8_t acc, int32_t op1, vint32m4_t op2);
vuint16m2_t vwmacc_mask (vbool8_t mask, vuint16m2_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmacc_mask (vbool8_t mask, vuint16m2_t acc, uint8_t op1, vuint8m1_t op2);
vuint16m4_t vwmacc_mask (vbool4_t mask, vuint16m4_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmacc_mask (vbool4_t mask, vuint16m4_t acc, uint8_t op1, vuint8m2_t op2);
vuint16m8_t vwmacc_mask (vbool2_t mask, vuint16m8_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmacc_mask (vbool2_t mask, vuint16m8_t acc, uint8_t op1, vuint8m4_t op2);
vuint32m2_t vwmacc_mask (vbool16_t mask, vuint32m2_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmacc_mask (vbool16_t mask, vuint32m2_t acc, uint16_t op1, vuint16m1_t op2);
vuint32m4_t vwmacc_mask (vbool8_t mask, vuint32m4_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmacc_mask (vbool8_t mask, vuint32m4_t acc, uint16_t op1, vuint16m2_t op2);
vuint32m8_t vwmacc_mask (vbool4_t mask, vuint32m8_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmacc_mask (vbool4_t mask, vuint32m8_t acc, uint16_t op1, vuint16m4_t op2);
vuint64m2_t vwmacc_mask (vbool32_t mask, vuint64m2_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmacc_mask (vbool32_t mask, vuint64m2_t acc, uint32_t op1, vuint32m1_t op2);
vuint64m4_t vwmacc_mask (vbool16_t mask, vuint64m4_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmacc_mask (vbool16_t mask, vuint64m4_t acc, uint32_t op1, vuint32m2_t op2);
vuint64m8_t vwmacc_mask (vbool8_t mask, vuint64m8_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmacc_mask (vbool8_t mask, vuint64m8_t acc, uint32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccsu_mask (vbool8_t mask, vint16m2_t acc, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmaccsu_mask (vbool8_t mask, vint16m2_t acc, int8_t op1, vuint8m1_t op2);
vint16m4_t vwmaccsu_mask (vbool4_t mask, vint16m4_t acc, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmaccsu_mask (vbool4_t mask, vint16m4_t acc, int8_t op1, vuint8m2_t op2);
vint16m8_t vwmaccsu_mask (vbool2_t mask, vint16m8_t acc, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmaccsu_mask (vbool2_t mask, vint16m8_t acc, int8_t op1, vuint8m4_t op2);
vint32m2_t vwmaccsu_mask (vbool16_t mask, vint32m2_t acc, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmaccsu_mask (vbool16_t mask, vint32m2_t acc, int16_t op1, vuint16m1_t op2);
vint32m4_t vwmaccsu_mask (vbool8_t mask, vint32m4_t acc, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmaccsu_mask (vbool8_t mask, vint32m4_t acc, int16_t op1, vuint16m2_t op2);
vint32m8_t vwmaccsu_mask (vbool4_t mask, vint32m8_t acc, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmaccsu_mask (vbool4_t mask, vint32m8_t acc, int16_t op1, vuint16m4_t op2);
vint64m2_t vwmaccsu_mask (vbool32_t mask, vint64m2_t acc, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmaccsu_mask (vbool32_t mask, vint64m2_t acc, int32_t op1, vuint32m1_t op2);
vint64m4_t vwmaccsu_mask (vbool16_t mask, vint64m4_t acc, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmaccsu_mask (vbool16_t mask, vint64m4_t acc, int32_t op1, vuint32m2_t op2);
vint64m8_t vwmaccsu_mask (vbool8_t mask, vint64m8_t acc, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmaccsu_mask (vbool8_t mask, vint64m8_t acc, int32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccus_mask (vbool8_t mask, vint16m2_t acc, uint8_t op1, vint8m1_t op2);
vint16m4_t vwmaccus_mask (vbool4_t mask, vint16m4_t acc, uint8_t op1, vint8m2_t op2);
vint16m8_t vwmaccus_mask (vbool2_t mask, vint16m8_t acc, uint8_t op1, vint8m4_t op2);
vint32m2_t vwmaccus_mask (vbool16_t mask, vint32m2_t acc, uint16_t op1, vint16m1_t op2);
vint32m4_t vwmaccus_mask (vbool8_t mask, vint32m4_t acc, uint16_t op1, vint16m2_t op2);
vint32m8_t vwmaccus_mask (vbool4_t mask, vint32m8_t acc, uint16_t op1, vint16m4_t op2);
vint64m2_t vwmaccus_mask (vbool32_t mask, vint64m2_t acc, uint32_t op1, vint32m1_t op2);
vint64m4_t vwmaccus_mask (vbool16_t mask, vint64m4_t acc, uint32_t op1, vint32m2_t op2);
vint64m8_t vwmaccus_mask (vbool8_t mask, vint64m8_t acc, uint32_t op1, vint32m4_t op2);
```
### [Vector Quad-Widening Integer Multiply-Add Functions]()

**Prototypes:**
``` C
vint32m4_t vqmacc (vint32m4_t acc, vint8m1_t op1, vint8m1_t op2);
vint32m4_t vqmacc (vint32m4_t acc, int8_t op1, vint8m1_t op2);
vint32m8_t vqmacc (vint32m8_t acc, vint8m2_t op1, vint8m2_t op2);
vint32m8_t vqmacc (vint32m8_t acc, int8_t op1, vint8m2_t op2);
vint64m4_t vqmacc (vint64m4_t acc, vint16m1_t op1, vint16m1_t op2);
vint64m4_t vqmacc (vint64m4_t acc, int16_t op1, vint16m1_t op2);
vint64m8_t vqmacc (vint64m8_t acc, vint16m2_t op1, vint16m2_t op2);
vint64m8_t vqmacc (vint64m8_t acc, int16_t op1, vint16m2_t op2);
vuint32m4_t vqmacc (vuint32m4_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint32m4_t vqmacc (vuint32m4_t acc, uint8_t op1, vuint8m1_t op2);
vuint32m8_t vqmacc (vuint32m8_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint32m8_t vqmacc (vuint32m8_t acc, uint8_t op1, vuint8m2_t op2);
vuint64m4_t vqmacc (vuint64m4_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint64m4_t vqmacc (vuint64m4_t acc, uint16_t op1, vuint16m1_t op2);
vuint64m8_t vqmacc (vuint64m8_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint64m8_t vqmacc (vuint64m8_t acc, uint16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccsu (vint32m4_t acc, vint8m1_t op1, vuint8m1_t op2);
vint32m4_t vqmaccsu (vint32m4_t acc, int8_t op1, vuint8m1_t op2);
vint32m8_t vqmaccsu (vint32m8_t acc, vint8m2_t op1, vuint8m2_t op2);
vint32m8_t vqmaccsu (vint32m8_t acc, int8_t op1, vuint8m2_t op2);
vint64m4_t vqmaccsu (vint64m4_t acc, vint16m1_t op1, vuint16m1_t op2);
vint64m4_t vqmaccsu (vint64m4_t acc, int16_t op1, vuint16m1_t op2);
vint64m8_t vqmaccsu (vint64m8_t acc, vint16m2_t op1, vuint16m2_t op2);
vint64m8_t vqmaccsu (vint64m8_t acc, int16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccus (vint32m4_t acc, uint8_t op1, vint8m1_t op2);
vint32m8_t vqmaccus (vint32m8_t acc, uint8_t op1, vint8m2_t op2);
vint64m4_t vqmaccus (vint64m4_t acc, uint16_t op1, vint16m1_t op2);
vint64m8_t vqmaccus (vint64m8_t acc, uint16_t op1, vint16m2_t op2);
// masked functions
vint32m4_t vqmacc_mask (vbool8_t mask, vint32m4_t acc, vint8m1_t op1, vint8m1_t op2);
vint32m4_t vqmacc_mask (vbool8_t mask, vint32m4_t acc, int8_t op1, vint8m1_t op2);
vint32m8_t vqmacc_mask (vbool4_t mask, vint32m8_t acc, vint8m2_t op1, vint8m2_t op2);
vint32m8_t vqmacc_mask (vbool4_t mask, vint32m8_t acc, int8_t op1, vint8m2_t op2);
vint64m4_t vqmacc_mask (vbool16_t mask, vint64m4_t acc, vint16m1_t op1, vint16m1_t op2);
vint64m4_t vqmacc_mask (vbool16_t mask, vint64m4_t acc, int16_t op1, vint16m1_t op2);
vint64m8_t vqmacc_mask (vbool8_t mask, vint64m8_t acc, vint16m2_t op1, vint16m2_t op2);
vint64m8_t vqmacc_mask (vbool8_t mask, vint64m8_t acc, int16_t op1, vint16m2_t op2);
vuint32m4_t vqmacc_mask (vbool8_t mask, vuint32m4_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint32m4_t vqmacc_mask (vbool8_t mask, vuint32m4_t acc, uint8_t op1, vuint8m1_t op2);
vuint32m8_t vqmacc_mask (vbool4_t mask, vuint32m8_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint32m8_t vqmacc_mask (vbool4_t mask, vuint32m8_t acc, uint8_t op1, vuint8m2_t op2);
vuint64m4_t vqmacc_mask (vbool16_t mask, vuint64m4_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint64m4_t vqmacc_mask (vbool16_t mask, vuint64m4_t acc, uint16_t op1, vuint16m1_t op2);
vuint64m8_t vqmacc_mask (vbool8_t mask, vuint64m8_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint64m8_t vqmacc_mask (vbool8_t mask, vuint64m8_t acc, uint16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccsu_mask (vbool8_t mask, vint32m4_t acc, vint8m1_t op1, vuint8m1_t op2);
vint32m4_t vqmaccsu_mask (vbool8_t mask, vint32m4_t acc, int8_t op1, vuint8m1_t op2);
vint32m8_t vqmaccsu_mask (vbool4_t mask, vint32m8_t acc, vint8m2_t op1, vuint8m2_t op2);
vint32m8_t vqmaccsu_mask (vbool4_t mask, vint32m8_t acc, int8_t op1, vuint8m2_t op2);
vint64m4_t vqmaccsu_mask (vbool16_t mask, vint64m4_t acc, vint16m1_t op1, vuint16m1_t op2);
vint64m4_t vqmaccsu_mask (vbool16_t mask, vint64m4_t acc, int16_t op1, vuint16m1_t op2);
vint64m8_t vqmaccsu_mask (vbool8_t mask, vint64m8_t acc, vint16m2_t op1, vuint16m2_t op2);
vint64m8_t vqmaccsu_mask (vbool8_t mask, vint64m8_t acc, int16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccus_mask (vbool8_t mask, vint32m4_t acc, uint8_t op1, vint8m1_t op2);
vint32m8_t vqmaccus_mask (vbool4_t mask, vint32m8_t acc, uint8_t op1, vint8m2_t op2);
vint64m4_t vqmaccus_mask (vbool16_t mask, vint64m4_t acc, uint16_t op1, vint16m1_t op2);
vint64m8_t vqmaccus_mask (vbool8_t mask, vint64m8_t acc, uint16_t op1, vint16m2_t op2);
```
### [Vector Integer Merge Functions]()

**Prototypes:**
``` C
vint8m1_t vmerge_mask (vbool8_t mask, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmerge_mask (vbool8_t mask, vint8m1_t op1, int8_t op2);
vint8m2_t vmerge_mask (vbool4_t mask, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmerge_mask (vbool4_t mask, vint8m2_t op1, int8_t op2);
vint8m4_t vmerge_mask (vbool2_t mask, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmerge_mask (vbool2_t mask, vint8m4_t op1, int8_t op2);
vint8m8_t vmerge_mask (vbool1_t mask, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmerge_mask (vbool1_t mask, vint8m8_t op1, int8_t op2);
vint16m1_t vmerge_mask (vbool16_t mask, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmerge_mask (vbool16_t mask, vint16m1_t op1, int16_t op2);
vint16m2_t vmerge_mask (vbool8_t mask, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmerge_mask (vbool8_t mask, vint16m2_t op1, int16_t op2);
vint16m4_t vmerge_mask (vbool4_t mask, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmerge_mask (vbool4_t mask, vint16m4_t op1, int16_t op2);
vint16m8_t vmerge_mask (vbool2_t mask, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmerge_mask (vbool2_t mask, vint16m8_t op1, int16_t op2);
vint32m1_t vmerge_mask (vbool32_t mask, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmerge_mask (vbool32_t mask, vint32m1_t op1, int32_t op2);
vint32m2_t vmerge_mask (vbool16_t mask, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmerge_mask (vbool16_t mask, vint32m2_t op1, int32_t op2);
vint32m4_t vmerge_mask (vbool8_t mask, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmerge_mask (vbool8_t mask, vint32m4_t op1, int32_t op2);
vint32m8_t vmerge_mask (vbool4_t mask, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmerge_mask (vbool4_t mask, vint32m8_t op1, int32_t op2);
vint64m1_t vmerge_mask (vbool64_t mask, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmerge_mask (vbool64_t mask, vint64m1_t op1, int64_t op2);
vint64m2_t vmerge_mask (vbool32_t mask, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmerge_mask (vbool32_t mask, vint64m2_t op1, int64_t op2);
vint64m4_t vmerge_mask (vbool16_t mask, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmerge_mask (vbool16_t mask, vint64m4_t op1, int64_t op2);
vint64m8_t vmerge_mask (vbool8_t mask, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmerge_mask (vbool8_t mask, vint64m8_t op1, int64_t op2);
vuint8m1_t vmerge_mask (vbool8_t mask, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmerge_mask (vbool8_t mask, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmerge_mask (vbool4_t mask, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmerge_mask (vbool4_t mask, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmerge_mask (vbool2_t mask, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmerge_mask (vbool2_t mask, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmerge_mask (vbool1_t mask, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmerge_mask (vbool1_t mask, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmerge_mask (vbool16_t mask, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmerge_mask (vbool16_t mask, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmerge_mask (vbool8_t mask, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmerge_mask (vbool8_t mask, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmerge_mask (vbool4_t mask, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmerge_mask (vbool4_t mask, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmerge_mask (vbool2_t mask, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmerge_mask (vbool2_t mask, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmerge_mask (vbool32_t mask, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmerge_mask (vbool32_t mask, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmerge_mask (vbool16_t mask, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmerge_mask (vbool16_t mask, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmerge_mask (vbool8_t mask, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmerge_mask (vbool8_t mask, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmerge_mask (vbool4_t mask, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmerge_mask (vbool4_t mask, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmerge_mask (vbool64_t mask, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmerge_mask (vbool64_t mask, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmerge_mask (vbool32_t mask, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmerge_mask (vbool32_t mask, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmerge_mask (vbool16_t mask, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmerge_mask (vbool16_t mask, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmerge_mask (vbool8_t mask, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmerge_mask (vbool8_t mask, vuint64m8_t op1, uint64_t op2);
```
### [Vector Integer Move Functions]()

**Prototypes:**
``` C
vint8m1_t vcopy (vint8m1_t src);
vint8m1_t vsplat_s_i8m1 (int8_t src);
vint8m2_t vcopy (vint8m2_t src);
vint8m2_t vsplat_s_i8m2 (int8_t src);
vint8m4_t vcopy (vint8m4_t src);
vint8m4_t vsplat_s_i8m4 (int8_t src);
vint8m8_t vcopy (vint8m8_t src);
vint8m8_t vsplat_s_i8m8 (int8_t src);
vint16m1_t vcopy (vint16m1_t src);
vint16m1_t vsplat_s_i16m1 (int16_t src);
vint16m2_t vcopy (vint16m2_t src);
vint16m2_t vsplat_s_i16m2 (int16_t src);
vint16m4_t vcopy (vint16m4_t src);
vint16m4_t vsplat_s_i16m4 (int16_t src);
vint16m8_t vcopy (vint16m8_t src);
vint16m8_t vsplat_s_i16m8 (int16_t src);
vint32m1_t vcopy (vint32m1_t src);
vint32m1_t vsplat_s_i32m1 (int32_t src);
vint32m2_t vcopy (vint32m2_t src);
vint32m2_t vsplat_s_i32m2 (int32_t src);
vint32m4_t vcopy (vint32m4_t src);
vint32m4_t vsplat_s_i32m4 (int32_t src);
vint32m8_t vcopy (vint32m8_t src);
vint32m8_t vsplat_s_i32m8 (int32_t src);
vint64m1_t vcopy (vint64m1_t src);
vint64m1_t vsplat_s_i64m1 (int64_t src);
vint64m2_t vcopy (vint64m2_t src);
vint64m2_t vsplat_s_i64m2 (int64_t src);
vint64m4_t vcopy (vint64m4_t src);
vint64m4_t vsplat_s_i64m4 (int64_t src);
vint64m8_t vcopy (vint64m8_t src);
vint64m8_t vsplat_s_i64m8 (int64_t src);
vuint8m1_t vcopy (vuint8m1_t src);
vuint8m1_t vsplat_s_u8m1 (uint8_t src);
vuint8m2_t vcopy (vuint8m2_t src);
vuint8m2_t vsplat_s_u8m2 (uint8_t src);
vuint8m4_t vcopy (vuint8m4_t src);
vuint8m4_t vsplat_s_u8m4 (uint8_t src);
vuint8m8_t vcopy (vuint8m8_t src);
vuint8m8_t vsplat_s_u8m8 (uint8_t src);
vuint16m1_t vcopy (vuint16m1_t src);
vuint16m1_t vsplat_s_u16m1 (uint16_t src);
vuint16m2_t vcopy (vuint16m2_t src);
vuint16m2_t vsplat_s_u16m2 (uint16_t src);
vuint16m4_t vcopy (vuint16m4_t src);
vuint16m4_t vsplat_s_u16m4 (uint16_t src);
vuint16m8_t vcopy (vuint16m8_t src);
vuint16m8_t vsplat_s_u16m8 (uint16_t src);
vuint32m1_t vcopy (vuint32m1_t src);
vuint32m1_t vsplat_s_u32m1 (uint32_t src);
vuint32m2_t vcopy (vuint32m2_t src);
vuint32m2_t vsplat_s_u32m2 (uint32_t src);
vuint32m4_t vcopy (vuint32m4_t src);
vuint32m4_t vsplat_s_u32m4 (uint32_t src);
vuint32m8_t vcopy (vuint32m8_t src);
vuint32m8_t vsplat_s_u32m8 (uint32_t src);
vuint64m1_t vcopy (vuint64m1_t src);
vuint64m1_t vsplat_s_u64m1 (uint64_t src);
vuint64m2_t vcopy (vuint64m2_t src);
vuint64m2_t vsplat_s_u64m2 (uint64_t src);
vuint64m4_t vcopy (vuint64m4_t src);
vuint64m4_t vsplat_s_u64m4 (uint64_t src);
vuint64m8_t vcopy (vuint64m8_t src);
vuint64m8_t vsplat_s_u64m8 (uint64_t src);
```
## Vector Fixed-Point Arithmetic Functions:

### [Vector Single-Width Saturating Add and Subtract Functions]()

**Prototypes:**
``` C
vint8m1_t vsadd (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsadd (vint8m1_t op1, int8_t op2);
vint8m2_t vsadd (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsadd (vint8m2_t op1, int8_t op2);
vint8m4_t vsadd (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsadd (vint8m4_t op1, int8_t op2);
vint8m8_t vsadd (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsadd (vint8m8_t op1, int8_t op2);
vint16m1_t vsadd (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsadd (vint16m1_t op1, int16_t op2);
vint16m2_t vsadd (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsadd (vint16m2_t op1, int16_t op2);
vint16m4_t vsadd (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsadd (vint16m4_t op1, int16_t op2);
vint16m8_t vsadd (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsadd (vint16m8_t op1, int16_t op2);
vint32m1_t vsadd (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsadd (vint32m1_t op1, int32_t op2);
vint32m2_t vsadd (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsadd (vint32m2_t op1, int32_t op2);
vint32m4_t vsadd (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsadd (vint32m4_t op1, int32_t op2);
vint32m8_t vsadd (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsadd (vint32m8_t op1, int32_t op2);
vint64m1_t vsadd (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsadd (vint64m1_t op1, int64_t op2);
vint64m2_t vsadd (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsadd (vint64m2_t op1, int64_t op2);
vint64m4_t vsadd (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsadd (vint64m4_t op1, int64_t op2);
vint64m8_t vsadd (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsadd (vint64m8_t op1, int64_t op2);
vuint8m1_t vsadd (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsadd (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsadd (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsadd (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsadd (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsadd (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsadd (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsadd (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsadd (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsadd (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsadd (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsadd (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsadd (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsadd (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsadd (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsadd (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsadd (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsadd (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsadd (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsadd (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsadd (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsadd (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsadd (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsadd (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsadd (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsadd (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsadd (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsadd (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsadd (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsadd (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsadd (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsadd (vuint64m8_t op1, uint64_t op2);
vint8m1_t vssub (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssub (vint8m1_t op1, int8_t op2);
vint8m2_t vssub (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssub (vint8m2_t op1, int8_t op2);
vint8m4_t vssub (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssub (vint8m4_t op1, int8_t op2);
vint8m8_t vssub (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssub (vint8m8_t op1, int8_t op2);
vint16m1_t vssub (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssub (vint16m1_t op1, int16_t op2);
vint16m2_t vssub (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssub (vint16m2_t op1, int16_t op2);
vint16m4_t vssub (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssub (vint16m4_t op1, int16_t op2);
vint16m8_t vssub (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssub (vint16m8_t op1, int16_t op2);
vint32m1_t vssub (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssub (vint32m1_t op1, int32_t op2);
vint32m2_t vssub (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssub (vint32m2_t op1, int32_t op2);
vint32m4_t vssub (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssub (vint32m4_t op1, int32_t op2);
vint32m8_t vssub (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssub (vint32m8_t op1, int32_t op2);
vint64m1_t vssub (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssub (vint64m1_t op1, int64_t op2);
vint64m2_t vssub (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssub (vint64m2_t op1, int64_t op2);
vint64m4_t vssub (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssub (vint64m4_t op1, int64_t op2);
vint64m8_t vssub (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssub (vint64m8_t op1, int64_t op2);
vuint8m1_t vssub (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssub (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssub (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssub (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssub (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssub (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssub (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssub (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssub (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssub (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssub (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssub (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssub (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssub (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssub (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssub (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssub (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssub (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssub (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssub (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssub (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssub (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssub (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssub (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssub (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssub (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssub (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssub (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssub (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssub (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssub (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssub (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vsadd_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsadd_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsadd_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsadd_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsadd_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsadd_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsadd_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsadd_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsadd_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsadd_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsadd_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsadd_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsadd_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsadd_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsadd_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsadd_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsadd_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsadd_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsadd_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsadd_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsadd_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsadd_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsadd_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsadd_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsadd_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsadd_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsadd_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsadd_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsadd_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsadd_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsadd_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsadd_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsadd_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsadd_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsadd_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsadd_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsadd_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsadd_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsadd_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsadd_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsadd_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsadd_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsadd_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsadd_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsadd_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsadd_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsadd_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsadd_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsadd_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsadd_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsadd_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsadd_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsadd_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsadd_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsadd_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsadd_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsadd_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsadd_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsadd_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsadd_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsadd_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsadd_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsadd_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsadd_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vssub_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssub_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vssub_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssub_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vssub_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssub_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vssub_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssub_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vssub_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssub_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vssub_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssub_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vssub_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssub_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vssub_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssub_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vssub_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssub_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vssub_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssub_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vssub_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssub_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vssub_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssub_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vssub_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssub_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vssub_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssub_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vssub_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssub_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vssub_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssub_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vssub_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssub_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssub_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssub_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssub_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssub_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssub_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssub_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssub_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssub_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssub_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssub_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssub_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssub_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Averaging Add and Subtract Functions]()

**Prototypes:**
``` C
vint8m1_t vaadd (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vaadd (vint8m1_t op1, int8_t op2);
vint8m2_t vaadd (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vaadd (vint8m2_t op1, int8_t op2);
vint8m4_t vaadd (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vaadd (vint8m4_t op1, int8_t op2);
vint8m8_t vaadd (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vaadd (vint8m8_t op1, int8_t op2);
vint16m1_t vaadd (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vaadd (vint16m1_t op1, int16_t op2);
vint16m2_t vaadd (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vaadd (vint16m2_t op1, int16_t op2);
vint16m4_t vaadd (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vaadd (vint16m4_t op1, int16_t op2);
vint16m8_t vaadd (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vaadd (vint16m8_t op1, int16_t op2);
vint32m1_t vaadd (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vaadd (vint32m1_t op1, int32_t op2);
vint32m2_t vaadd (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vaadd (vint32m2_t op1, int32_t op2);
vint32m4_t vaadd (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vaadd (vint32m4_t op1, int32_t op2);
vint32m8_t vaadd (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vaadd (vint32m8_t op1, int32_t op2);
vint64m1_t vaadd (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vaadd (vint64m1_t op1, int64_t op2);
vint64m2_t vaadd (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vaadd (vint64m2_t op1, int64_t op2);
vint64m4_t vaadd (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vaadd (vint64m4_t op1, int64_t op2);
vint64m8_t vaadd (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vaadd (vint64m8_t op1, int64_t op2);
vuint8m1_t vaadd (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vaadd (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vaadd (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vaadd (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vaadd (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vaadd (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vaadd (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vaadd (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vaadd (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vaadd (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vaadd (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vaadd (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vaadd (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vaadd (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vaadd (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vaadd (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vaadd (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vaadd (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vaadd (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vaadd (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vaadd (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vaadd (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vaadd (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vaadd (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vaadd (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vaadd (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vaadd (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vaadd (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vaadd (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vaadd (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vaadd (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vaadd (vuint64m8_t op1, uint64_t op2);
vint8m1_t vasub (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vasub (vint8m1_t op1, int8_t op2);
vint8m2_t vasub (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vasub (vint8m2_t op1, int8_t op2);
vint8m4_t vasub (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vasub (vint8m4_t op1, int8_t op2);
vint8m8_t vasub (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vasub (vint8m8_t op1, int8_t op2);
vint16m1_t vasub (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vasub (vint16m1_t op1, int16_t op2);
vint16m2_t vasub (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vasub (vint16m2_t op1, int16_t op2);
vint16m4_t vasub (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vasub (vint16m4_t op1, int16_t op2);
vint16m8_t vasub (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vasub (vint16m8_t op1, int16_t op2);
vint32m1_t vasub (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vasub (vint32m1_t op1, int32_t op2);
vint32m2_t vasub (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vasub (vint32m2_t op1, int32_t op2);
vint32m4_t vasub (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vasub (vint32m4_t op1, int32_t op2);
vint32m8_t vasub (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vasub (vint32m8_t op1, int32_t op2);
vint64m1_t vasub (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vasub (vint64m1_t op1, int64_t op2);
vint64m2_t vasub (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vasub (vint64m2_t op1, int64_t op2);
vint64m4_t vasub (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vasub (vint64m4_t op1, int64_t op2);
vint64m8_t vasub (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vasub (vint64m8_t op1, int64_t op2);
vuint8m1_t vasub (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vasub (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vasub (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vasub (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vasub (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vasub (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vasub (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vasub (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vasub (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vasub (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vasub (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vasub (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vasub (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vasub (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vasub (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vasub (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vasub (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vasub (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vasub (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vasub (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vasub (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vasub (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vasub (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vasub (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vasub (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vasub (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vasub (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vasub (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vasub (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vasub (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vasub (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vasub (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vaadd_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vaadd_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vaadd_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vaadd_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vaadd_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vaadd_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vaadd_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vaadd_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vaadd_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vaadd_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vaadd_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vaadd_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vaadd_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vaadd_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vaadd_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vaadd_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vaadd_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vaadd_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vaadd_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vaadd_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vaadd_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vaadd_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vaadd_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vaadd_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vaadd_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vaadd_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vaadd_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vaadd_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vaadd_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vaadd_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vaadd_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vaadd_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vaadd_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vaadd_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vaadd_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vaadd_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vaadd_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vaadd_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vaadd_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vaadd_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vaadd_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vaadd_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vaadd_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vaadd_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vaadd_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vaadd_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vaadd_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vaadd_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vaadd_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vaadd_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vaadd_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vaadd_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vaadd_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vaadd_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vaadd_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vaadd_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vaadd_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vaadd_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vaadd_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vaadd_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vaadd_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vaadd_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vaadd_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vaadd_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vasub_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vasub_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vasub_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vasub_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vasub_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vasub_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vasub_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vasub_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vasub_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vasub_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vasub_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vasub_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vasub_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vasub_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vasub_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vasub_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vasub_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vasub_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vasub_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vasub_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vasub_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vasub_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vasub_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vasub_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vasub_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vasub_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vasub_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vasub_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vasub_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vasub_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vasub_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vasub_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vasub_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vasub_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vasub_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vasub_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vasub_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vasub_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vasub_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vasub_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vasub_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vasub_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vasub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vasub_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vasub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vasub_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vasub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vasub_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vasub_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vasub_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vasub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vasub_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vasub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vasub_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vasub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vasub_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vasub_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vasub_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vasub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vasub_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vasub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vasub_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vasub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vasub_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### [Vector Single-Width Fractional Multiply with Rounding and Saturation Functions]()

**Prototypes:**
``` C
vint8m1_t vsmul (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsmul (vint8m1_t op1, int8_t op2);
vint8m2_t vsmul (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsmul (vint8m2_t op1, int8_t op2);
vint8m4_t vsmul (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsmul (vint8m4_t op1, int8_t op2);
vint8m8_t vsmul (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsmul (vint8m8_t op1, int8_t op2);
vint16m1_t vsmul (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsmul (vint16m1_t op1, int16_t op2);
vint16m2_t vsmul (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsmul (vint16m2_t op1, int16_t op2);
vint16m4_t vsmul (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsmul (vint16m4_t op1, int16_t op2);
vint16m8_t vsmul (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsmul (vint16m8_t op1, int16_t op2);
vint32m1_t vsmul (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsmul (vint32m1_t op1, int32_t op2);
vint32m2_t vsmul (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsmul (vint32m2_t op1, int32_t op2);
vint32m4_t vsmul (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsmul (vint32m4_t op1, int32_t op2);
vint32m8_t vsmul (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsmul (vint32m8_t op1, int32_t op2);
vint64m1_t vsmul (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsmul (vint64m1_t op1, int64_t op2);
vint64m2_t vsmul (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsmul (vint64m2_t op1, int64_t op2);
vint64m4_t vsmul (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsmul (vint64m4_t op1, int64_t op2);
vint64m8_t vsmul (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsmul (vint64m8_t op1, int64_t op2);
// masked functions
vint8m1_t vsmul_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsmul_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsmul_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsmul_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsmul_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsmul_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsmul_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsmul_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsmul_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsmul_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsmul_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsmul_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsmul_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsmul_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsmul_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsmul_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsmul_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsmul_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsmul_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsmul_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsmul_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsmul_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsmul_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsmul_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsmul_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsmul_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsmul_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsmul_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsmul_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsmul_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsmul_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsmul_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
```
### [Vector Single-Width Scaling Shift Functions]()

**Prototypes:**
``` C
vuint8m1_t vssrl (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssrl (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssrl (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssrl (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssrl (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssrl (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssrl (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssrl (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssrl (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssrl (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssrl (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssrl (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssrl (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssrl (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssrl (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssrl (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssrl (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssrl (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssrl (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssrl (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssrl (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssrl (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssrl (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssrl (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssrl (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssrl (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssrl (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssrl (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssrl (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssrl (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssrl (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssrl (vuint64m8_t op1, uint64_t op2);
vint8m1_t vssra (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssra (vint8m1_t op1, int8_t op2);
vint8m2_t vssra (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssra (vint8m2_t op1, int8_t op2);
vint8m4_t vssra (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssra (vint8m4_t op1, int8_t op2);
vint8m8_t vssra (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssra (vint8m8_t op1, int8_t op2);
vint16m1_t vssra (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssra (vint16m1_t op1, int16_t op2);
vint16m2_t vssra (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssra (vint16m2_t op1, int16_t op2);
vint16m4_t vssra (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssra (vint16m4_t op1, int16_t op2);
vint16m8_t vssra (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssra (vint16m8_t op1, int16_t op2);
vint32m1_t vssra (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssra (vint32m1_t op1, int32_t op2);
vint32m2_t vssra (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssra (vint32m2_t op1, int32_t op2);
vint32m4_t vssra (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssra (vint32m4_t op1, int32_t op2);
vint32m8_t vssra (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssra (vint32m8_t op1, int32_t op2);
vint64m1_t vssra (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssra (vint64m1_t op1, int64_t op2);
vint64m2_t vssra (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssra (vint64m2_t op1, int64_t op2);
vint64m4_t vssra (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssra (vint64m4_t op1, int64_t op2);
vint64m8_t vssra (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssra (vint64m8_t op1, int64_t op2);
// masked functions
vuint8m1_t vssrl_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssrl_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssrl_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssrl_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssrl_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssrl_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssrl_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssrl_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssrl_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssrl_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssrl_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssrl_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssrl_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssrl_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssrl_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssrl_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssrl_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssrl_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssrl_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssrl_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssrl_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssrl_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssrl_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssrl_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssrl_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssrl_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssrl_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssrl_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssrl_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssrl_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssrl_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssrl_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vssra_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssra_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vssra_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssra_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vssra_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssra_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vssra_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssra_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vssra_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssra_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vssra_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssra_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vssra_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssra_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vssra_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssra_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vssra_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssra_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vssra_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssra_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vssra_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssra_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vssra_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssra_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vssra_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssra_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vssra_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssra_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vssra_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssra_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vssra_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssra_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
```
### [Vector Narrowing Fixed-Point Clip Functions]()

**Prototypes:**
``` C
vint8m1_t vnclip (vint16m2_t op1, vint8m1_t op2);
vint8m1_t vnclip (vint16m2_t op1, int8_t op2);
vint8m2_t vnclip (vint16m4_t op1, vint8m2_t op2);
vint8m2_t vnclip (vint16m4_t op1, int8_t op2);
vint8m4_t vnclip (vint16m8_t op1, vint8m4_t op2);
vint8m4_t vnclip (vint16m8_t op1, int8_t op2);
vint16m1_t vnclip (vint32m2_t op1, vint16m1_t op2);
vint16m1_t vnclip (vint32m2_t op1, int16_t op2);
vint16m2_t vnclip (vint32m4_t op1, vint16m2_t op2);
vint16m2_t vnclip (vint32m4_t op1, int16_t op2);
vint16m4_t vnclip (vint32m8_t op1, vint16m4_t op2);
vint16m4_t vnclip (vint32m8_t op1, int16_t op2);
vint32m1_t vnclip (vint64m2_t op1, vint32m1_t op2);
vint32m1_t vnclip (vint64m2_t op1, int32_t op2);
vint32m2_t vnclip (vint64m4_t op1, vint32m2_t op2);
vint32m2_t vnclip (vint64m4_t op1, int32_t op2);
vint32m4_t vnclip (vint64m8_t op1, vint32m4_t op2);
vint32m4_t vnclip (vint64m8_t op1, int32_t op2);
vuint8m1_t vnclip (vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnclip (vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnclip (vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnclip (vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnclip (vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnclip (vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnclip (vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnclip (vuint32m2_t op1, uint16_t op2);
vuint16m2_t vnclip (vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnclip (vuint32m4_t op1, uint16_t op2);
vuint16m4_t vnclip (vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnclip (vuint32m8_t op1, uint16_t op2);
vuint32m1_t vnclip (vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnclip (vuint64m2_t op1, uint32_t op2);
vuint32m2_t vnclip (vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnclip (vuint64m4_t op1, uint32_t op2);
vuint32m4_t vnclip (vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnclip (vuint64m8_t op1, uint32_t op2);
// masked functions
vint8m1_t vnclip_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint8m1_t vnclip_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, int8_t op2);
vint8m2_t vnclip_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint8m2_t vnclip_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, int8_t op2);
vint8m4_t vnclip_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint8m4_t vnclip_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, int8_t op2);
vint16m1_t vnclip_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint16m1_t vnclip_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, int16_t op2);
vint16m2_t vnclip_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint16m2_t vnclip_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, int16_t op2);
vint16m4_t vnclip_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint16m4_t vnclip_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, int16_t op2);
vint32m1_t vnclip_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint32m1_t vnclip_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, int32_t op2);
vint32m2_t vnclip_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint32m2_t vnclip_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, int32_t op2);
vint32m4_t vnclip_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint32m4_t vnclip_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, int32_t op2);
vuint8m1_t vnclip_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnclip_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnclip_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnclip_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnclip_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnclip_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnclip_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnclip_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint16m2_t vnclip_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnclip_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint16m4_t vnclip_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnclip_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint32m1_t vnclip_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnclip_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint32m2_t vnclip_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnclip_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint32m4_t vnclip_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnclip_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, uint32_t op2);
```
## Vector floating-Point Functions:

### [Vector Single-Width Floating-Point Add/Subtract Functions]()

**Prototypes:**
``` C
vfloat16m1_t vadd (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vadd (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vadd (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vadd (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vadd (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vadd (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vadd (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vadd (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vadd (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vadd (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vadd (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vadd (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vadd (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vadd (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vadd (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vadd (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vadd (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vadd (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vadd (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vadd (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vadd (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vadd (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vadd (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vadd (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsub (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsub (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsub (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsub (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsub (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsub (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsub (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsub (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsub (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsub (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsub (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsub (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsub (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsub (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsub (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsub (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsub (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsub (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsub (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsub (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsub (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsub (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsub (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsub (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrsub (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrsub (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrsub (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrsub (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrsub (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrsub (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrsub (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrsub (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrsub (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrsub (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrsub (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrsub (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vadd_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vadd_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vadd_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vadd_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vadd_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vadd_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vadd_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vadd_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vadd_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vadd_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vadd_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vadd_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vadd_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vadd_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vadd_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vadd_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vadd_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vadd_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vadd_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vadd_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vadd_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vadd_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vadd_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vadd_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsub_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsub_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsub_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsub_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsub_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsub_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsub_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsub_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsub_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsub_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsub_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsub_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsub_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsub_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsub_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsub_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsub_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsub_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsub_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsub_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsub_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsub_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsub_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsub_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrsub_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrsub_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrsub_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrsub_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrsub_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrsub_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrsub_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrsub_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrsub_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrsub_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrsub_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrsub_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Widening Floating-Point Add/Subtract Functions]()

**Prototypes:**
``` C
vfloat32m2_t vwadd (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd (vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwadd (vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd (vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwadd (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd (vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwadd (vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd (vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwadd (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd (vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwadd (vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd (vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwadd (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd (vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwadd (vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd (vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwadd (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd (vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwadd (vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd (vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwadd (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd (vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwadd (vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd (vfloat64m8_t op1, float32_t op2);
vfloat32m2_t vwsub (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub (vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwsub (vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub (vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwsub (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub (vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwsub (vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub (vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwsub (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub (vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwsub (vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub (vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwsub (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub (vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwsub (vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub (vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwsub (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub (vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwsub (vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub (vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwsub (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub (vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwsub (vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub (vfloat64m8_t op1, float32_t op2);
// masked functions
vfloat32m2_t vwadd_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwadd_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwadd_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwadd_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwadd_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwadd_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwadd_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwadd_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwadd_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwadd_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwadd_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwadd_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2);
vfloat32m2_t vwsub_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwsub_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwsub_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwsub_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwsub_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwsub_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwsub_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwsub_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwsub_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwsub_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwsub_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwsub_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2);
```
### [Vector Single-Width Floating-Point Multiply/Divide Functions]()

**Prototypes:**
``` C
vfloat16m1_t vmul (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmul (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmul (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmul (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmul (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmul (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmul (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmul (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmul (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmul (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmul (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmul (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmul (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmul (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmul (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmul (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmul (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmul (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmul (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmul (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmul (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmul (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmul (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmul (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vdiv (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vdiv (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vdiv (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vdiv (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vdiv (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vdiv (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vdiv (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vdiv (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vdiv (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vdiv (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vdiv (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vdiv (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vdiv (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vdiv (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vdiv (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vdiv (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vdiv (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vdiv (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vdiv (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vdiv (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vdiv (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vdiv (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vdiv (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vdiv (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrdiv (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrdiv (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrdiv (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrdiv (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrdiv (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrdiv (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrdiv (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrdiv (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrdiv (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrdiv (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrdiv (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrdiv (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vmul_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmul_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmul_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmul_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmul_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmul_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmul_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmul_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmul_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmul_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmul_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmul_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmul_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmul_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmul_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmul_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmul_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmul_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmul_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmul_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmul_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmul_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmul_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmul_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vdiv_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vdiv_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vdiv_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vdiv_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vdiv_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vdiv_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vdiv_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vdiv_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vdiv_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vdiv_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vdiv_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vdiv_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vdiv_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vdiv_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vdiv_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vdiv_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vdiv_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vdiv_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vdiv_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vdiv_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vdiv_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vdiv_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vdiv_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vdiv_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrdiv_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrdiv_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrdiv_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrdiv_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrdiv_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrdiv_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrdiv_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrdiv_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrdiv_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrdiv_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrdiv_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrdiv_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Widening Floating-Point Multiply Functions]()

**Prototypes:**
``` C
vfloat32m2_t vwmul (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmul (vfloat16m1_t op1, float16_t op2);
vfloat32m4_t vwmul (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmul (vfloat16m2_t op1, float16_t op2);
vfloat32m8_t vwmul (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmul (vfloat16m4_t op1, float16_t op2);
vfloat64m2_t vwmul (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmul (vfloat32m1_t op1, float32_t op2);
vfloat64m4_t vwmul (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmul (vfloat32m2_t op1, float32_t op2);
vfloat64m8_t vwmul (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmul (vfloat32m4_t op1, float32_t op2);
// masked functions
vfloat32m2_t vwmul_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmul_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m4_t vwmul_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmul_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m8_t vwmul_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmul_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat64m2_t vwmul_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmul_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m4_t vwmul_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmul_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m8_t vwmul_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmul_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
```
### [Vector Single-Width Floating-Point Fused Multiply-Add Functions]()

**Prototypes:**
``` C
vfloat16m1_t vmacc (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmacc (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmacc (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmacc (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmacc (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmacc (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmacc (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmacc (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmacc (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmacc (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmacc (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmacc (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmacc (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmacc (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmacc (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmacc (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmacc (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmacc (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmacc (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmacc (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmacc (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmacc (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmacc (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmacc (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmacc (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmacc (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmacc (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmacc (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmacc (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmacc (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmacc (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmacc (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmacc (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmacc (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmacc (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmacc (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmacc (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmacc (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmacc (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmacc (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmacc (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmacc (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmacc (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmacc (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmacc (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmacc (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmacc (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmacc (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsac (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsac (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsac (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsac (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsac (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsac (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsac (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsac (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsac (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsac (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsac (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsac (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsac (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsac (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsac (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsac (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsac (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsac (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsac (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsac (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsac (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsac (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsac (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsac (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsac (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsac (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsac (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsac (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsac (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsac (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsac (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsac (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsac (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsac (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsac (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsac (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsac (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsac (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsac (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsac (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsac (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsac (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsac (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsac (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsac (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsac (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsac (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsac (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmadd (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmadd (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmadd (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmadd (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmadd (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmadd (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmadd (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmadd (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmadd (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmadd (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmadd (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmadd (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmadd (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmadd (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmadd (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmadd (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmadd (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmadd (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmadd (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmadd (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmadd (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmadd (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmadd (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmadd (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmadd (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmadd (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmadd (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmadd (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmadd (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmadd (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmadd (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmadd (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmadd (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmadd (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmadd (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmadd (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmadd (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmadd (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmadd (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmadd (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmadd (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmadd (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmadd (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmadd (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmadd (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmadd (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmadd (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmadd (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsub (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsub (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsub (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsub (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsub (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsub (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsub (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsub (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsub (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsub (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsub (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsub (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsub (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsub (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsub (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsub (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsub (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsub (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsub (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsub (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsub (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsub (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsub (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsub (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsub (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsub (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsub (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsub (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsub (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsub (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsub (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsub (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsub (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsub (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsub (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsub (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsub (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsub (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsub (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsub (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsub (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsub (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsub (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsub (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsub (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsub (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsub (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsub (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
// masked functions
vfloat16m1_t vmacc_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmacc_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmacc_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmacc_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmacc_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmacc_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmacc_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmacc_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmacc_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmacc_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmacc_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmacc_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmacc_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmacc_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmacc_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmacc_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmacc_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmacc_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmacc_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmacc_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmacc_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmacc_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmacc_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmacc_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmacc_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmacc_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmacc_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmacc_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmacc_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmacc_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmacc_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmacc_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmacc_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmacc_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmacc_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmacc_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmacc_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmacc_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmacc_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmacc_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmacc_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmacc_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmacc_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmacc_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmacc_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmacc_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmacc_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmacc_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsac_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsac_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsac_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsac_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsac_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsac_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsac_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsac_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsac_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsac_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsac_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsac_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsac_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsac_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsac_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsac_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsac_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsac_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsac_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsac_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsac_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsac_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsac_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsac_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsac_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsac_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsac_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsac_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsac_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsac_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsac_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsac_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsac_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsac_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsac_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsac_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsac_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsac_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsac_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsac_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsac_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsac_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsac_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsac_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsac_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsac_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsac_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsac_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmadd_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmadd_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmadd_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmadd_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmadd_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmadd_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmadd_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmadd_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmadd_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmadd_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmadd_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmadd_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmadd_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmadd_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmadd_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmadd_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmadd_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmadd_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmadd_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmadd_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmadd_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmadd_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmadd_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmadd_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmadd_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmadd_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmadd_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmadd_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmadd_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmadd_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmadd_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmadd_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmadd_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmadd_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmadd_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmadd_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmadd_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmadd_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmadd_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmadd_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmadd_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmadd_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmadd_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmadd_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmadd_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmadd_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmadd_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmadd_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsub_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsub_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsub_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsub_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsub_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsub_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsub_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsub_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsub_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsub_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsub_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsub_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsub_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsub_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsub_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsub_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsub_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsub_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsub_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsub_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsub_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsub_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsub_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsub_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsub_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsub_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsub_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsub_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsub_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsub_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsub_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsub_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsub_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsub_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsub_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsub_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsub_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsub_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsub_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsub_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsub_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsub_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsub_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsub_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsub_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsub_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsub_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsub_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
```
### [Vector Widening Floating-Point Fused Multiply-Add Functions]()

**Prototypes:**
``` C
vfloat32m2_t vwmacc (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmacc (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmacc (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmacc (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmacc (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmacc (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmacc (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmacc (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmacc (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmacc (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmacc (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmacc (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmacc (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmacc (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmacc (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmacc (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmacc (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmacc (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmacc (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmacc (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmacc (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmacc (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmacc (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmacc (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwmsac (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmsac (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmsac (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmsac (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmsac (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmsac (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmsac (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmsac (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmsac (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmsac (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmsac (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmsac (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmsac (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmsac (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmsac (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmsac (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmsac (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmsac (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmsac (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmsac (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmsac (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmsac (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmsac (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmsac (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
// masked functions
vfloat32m2_t vwmacc_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmacc_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmacc_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmacc_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmacc_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmacc_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmacc_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmacc_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmacc_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmacc_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmacc_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmacc_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmacc_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmacc_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmacc_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmacc_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmacc_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmacc_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmacc_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmacc_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmacc_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmacc_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmacc_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmacc_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwmsac_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmsac_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmsac_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmsac_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmsac_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmsac_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmsac_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmsac_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmsac_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmsac_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmsac_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmsac_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmsac_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmsac_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmsac_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmsac_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmsac_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmsac_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmsac_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmsac_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmsac_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmsac_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmsac_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmsac_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
```
### [Vector Floating-Point Square-Root Functions]()

**Prototypes:**
``` C
vfloat16m1_t vsqrt (vfloat16m1_t op1);
vfloat16m2_t vsqrt (vfloat16m2_t op1);
vfloat16m4_t vsqrt (vfloat16m4_t op1);
vfloat16m8_t vsqrt (vfloat16m8_t op1);
vfloat32m1_t vsqrt (vfloat32m1_t op1);
vfloat32m2_t vsqrt (vfloat32m2_t op1);
vfloat32m4_t vsqrt (vfloat32m4_t op1);
vfloat32m8_t vsqrt (vfloat32m8_t op1);
vfloat64m1_t vsqrt (vfloat64m1_t op1);
vfloat64m2_t vsqrt (vfloat64m2_t op1);
vfloat64m4_t vsqrt (vfloat64m4_t op1);
vfloat64m8_t vsqrt (vfloat64m8_t op1);
// masked functions
vfloat16m1_t vsqrt_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1);
vfloat16m2_t vsqrt_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1);
vfloat16m4_t vsqrt_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1);
vfloat16m8_t vsqrt_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1);
vfloat32m1_t vsqrt_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1);
vfloat32m2_t vsqrt_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1);
vfloat32m4_t vsqrt_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1);
vfloat32m8_t vsqrt_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1);
vfloat64m1_t vsqrt_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1);
vfloat64m2_t vsqrt_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1);
vfloat64m4_t vsqrt_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1);
vfloat64m8_t vsqrt_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1);
```
### [Vector Floating-Point MIN/MAX Functions]()

**Prototypes:**
``` C
vfloat16m1_t vmin (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmin (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmin (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmin (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmin (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmin (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmin (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmin (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmin (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmin (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmin (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmin (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmin (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmin (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmin (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmin (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmin (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmin (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmin (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmin (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmin (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmin (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmin (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmin (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vmax (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmax (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmax (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmax (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmax (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmax (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmax (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmax (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmax (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmax (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmax (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmax (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmax (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmax (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmax (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmax (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmax (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmax (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmax (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmax (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmax (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmax (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmax (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmax (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vmin_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmin_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmin_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmin_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmin_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmin_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmin_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmin_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmin_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmin_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmin_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmin_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmin_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmin_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmin_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmin_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmin_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmin_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmin_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmin_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmin_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmin_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmin_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmin_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vmax_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmax_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmax_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmax_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmax_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmax_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmax_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmax_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmax_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmax_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmax_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmax_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmax_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmax_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmax_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmax_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmax_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmax_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmax_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmax_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmax_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmax_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmax_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmax_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Sign-Injection Functions]()

**Prototypes:**
``` C
vfloat16m1_t vsgnj (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnj (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnj (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnj (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnj (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnj (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnj (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnj (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnj (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnj (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnj (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnj (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnj (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnj (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnj (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnj (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnj (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnj (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnj (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnj (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnj (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnj (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnj (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnj (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjn (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjn (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjn (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjn (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjn (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjn (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjn (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjn (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjn (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjn (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjn (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjn (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjn (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjn (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjn (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjn (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjn (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjn (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjn (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjn (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjn (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjn (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjn (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjn (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjx (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjx (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjx (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjx (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjx (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjx (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjx (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjx (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjx (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjx (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjx (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjx (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjx (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjx (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjx (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjx (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjx (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjx (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjx (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjx (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjx (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjx (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjx (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjx (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vsgnj_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnj_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnj_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnj_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnj_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnj_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnj_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnj_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnj_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnj_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnj_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnj_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnj_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnj_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnj_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnj_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnj_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnj_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnj_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnj_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnj_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnj_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnj_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnj_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjn_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjn_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjn_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjn_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjn_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjn_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjn_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjn_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjn_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjn_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjn_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjn_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjn_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjn_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjn_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjn_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjn_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjn_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjn_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjn_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjn_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjn_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjn_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjn_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjx_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjx_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjx_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjx_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjx_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjx_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjx_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjx_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjx_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjx_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjx_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjx_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjx_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjx_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjx_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjx_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjx_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjx_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjx_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjx_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjx_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjx_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjx_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjx_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Compare Functions]()

**Prototypes:**
``` C
vbool16_t vseteq (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vseteq (vfloat16m1_t op1, float16_t op2);
vbool8_t vseteq (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vseteq (vfloat16m2_t op1, float16_t op2);
vbool4_t vseteq (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vseteq (vfloat16m4_t op1, float16_t op2);
vbool2_t vseteq (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vseteq (vfloat16m8_t op1, float16_t op2);
vbool32_t vseteq (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vseteq (vfloat32m1_t op1, float32_t op2);
vbool16_t vseteq (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vseteq (vfloat32m2_t op1, float32_t op2);
vbool8_t vseteq (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vseteq (vfloat32m4_t op1, float32_t op2);
vbool4_t vseteq (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vseteq (vfloat32m8_t op1, float32_t op2);
vbool64_t vseteq (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vseteq (vfloat64m1_t op1, float64_t op2);
vbool32_t vseteq (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vseteq (vfloat64m2_t op1, float64_t op2);
vbool16_t vseteq (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vseteq (vfloat64m4_t op1, float64_t op2);
vbool8_t vseteq (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vseteq (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetne (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetne (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetne (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetne (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetne (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetne (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetne (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetne (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetne (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetne (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetne (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetne (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetne (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetne (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetne (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetne (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetne (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetne (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetne (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetne (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetne (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetne (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetne (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetne (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetlt (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetlt (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetlt (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetlt (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetlt (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetlt (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetlt (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetlt (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetlt (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetlt (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetlt (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetlt (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetlt (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetlt (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetlt (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetlt (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetlt (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetlt (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetlt (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetlt (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetlt (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetlt (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetlt (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetlt (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetle (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetle (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetle (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetle (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetle (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetle (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetle (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetle (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetle (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetle (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetle (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetle (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetle (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetle (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetle (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetle (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetle (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetle (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetle (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetle (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetle (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetle (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetle (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetle (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetgt (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetgt (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetgt (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetgt (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetgt (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetgt (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetgt (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetgt (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetgt (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetgt (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetgt (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetgt (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetgt (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetgt (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetgt (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetgt (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetgt (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetgt (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetgt (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetgt (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetgt (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetgt (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetgt (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetgt (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetge (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetge (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetge (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetge (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetge (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetge (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetge (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetge (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetge (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetge (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetge (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetge (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetge (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetge (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetge (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetge (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetge (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetge (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetge (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetge (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetge (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetge (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetge (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetge (vfloat64m8_t op1, float64_t op2);
// masked functions
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vseteq_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vseteq_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vseteq_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vseteq_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vseteq_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vseteq_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vseteq_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vseteq_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetne_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetne_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetne_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetne_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetne_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetne_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetne_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetne_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetlt_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetlt_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetlt_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetlt_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetlt_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetlt_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetlt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetlt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetle_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetle_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetle_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetle_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetle_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetle_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetle_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetle_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetgt_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetgt_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetgt_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetgt_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetgt_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetgt_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetgt_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetgt_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetge_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetge_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetge_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetge_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetge_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetge_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetge_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetge_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Classify Functions]()

**Prototypes:**
``` C
vuint16m1_t vclass (vfloat16m1_t op1);
vuint16m2_t vclass (vfloat16m2_t op1);
vuint16m4_t vclass (vfloat16m4_t op1);
vuint16m8_t vclass (vfloat16m8_t op1);
vuint32m1_t vclass (vfloat32m1_t op1);
vuint32m2_t vclass (vfloat32m2_t op1);
vuint32m4_t vclass (vfloat32m4_t op1);
vuint32m8_t vclass (vfloat32m8_t op1);
vuint64m1_t vclass (vfloat64m1_t op1);
vuint64m2_t vclass (vfloat64m2_t op1);
vuint64m4_t vclass (vfloat64m4_t op1);
vuint64m8_t vclass (vfloat64m8_t op1);
// masked functions
vuint16m1_t vclass_mask (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t op1);
vuint16m2_t vclass_mask (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t op1);
vuint16m4_t vclass_mask (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t op1);
vuint16m8_t vclass_mask (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t op1);
vuint32m1_t vclass_mask (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t op1);
vuint32m2_t vclass_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t op1);
vuint32m4_t vclass_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t op1);
vuint32m8_t vclass_mask (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t op1);
vuint64m1_t vclass_mask (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t op1);
vuint64m2_t vclass_mask (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t op1);
vuint64m4_t vclass_mask (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t op1);
vuint64m8_t vclass_mask (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t op1);
```
### [Vector Floating-Point Merge Functions]()

**Prototypes:**
``` C
vfloat16m1_t vmerge_mask (vbool16_t mask, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmerge_mask (vbool8_t mask, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmerge_mask (vbool4_t mask, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmerge_mask (vbool2_t mask, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmerge_mask (vbool32_t mask, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmerge_mask (vbool16_t mask, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmerge_mask (vbool8_t mask, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmerge_mask (vbool4_t mask, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmerge_mask (vbool64_t mask, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmerge_mask (vbool32_t mask, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmerge_mask (vbool16_t mask, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmerge_mask (vbool8_t mask, vfloat64m8_t op1, float64_t op2);
```
### [Vector Floating-Point Move Functions]()

**Prototypes:**
``` C
vfloat16m1_t vsplat_s_f16m1 (float16_t src);
vfloat16m2_t vsplat_s_f16m2 (float16_t src);
vfloat16m4_t vsplat_s_f16m4 (float16_t src);
vfloat16m8_t vsplat_s_f16m8 (float16_t src);
vfloat32m1_t vsplat_s_f32m1 (float32_t src);
vfloat32m2_t vsplat_s_f32m2 (float32_t src);
vfloat32m4_t vsplat_s_f32m4 (float32_t src);
vfloat32m8_t vsplat_s_f32m8 (float32_t src);
vfloat64m1_t vsplat_s_f64m1 (float64_t src);
vfloat64m2_t vsplat_s_f64m2 (float64_t src);
vfloat64m4_t vsplat_s_f64m4 (float64_t src);
vfloat64m8_t vsplat_s_f64m8 (float64_t src);
```
### [Single-Width Floating-Point/Integer Type-Convert Functions]()

**Prototypes:**
``` C
vint16m1_t vcvt_i16 (vfloat16m1_t src);
vint16m2_t vcvt_i16 (vfloat16m2_t src);
vint16m4_t vcvt_i16 (vfloat16m4_t src);
vint16m8_t vcvt_i16 (vfloat16m8_t src);
vuint16m1_t vcvt_u16 (vfloat16m1_t src);
vuint16m2_t vcvt_u16 (vfloat16m2_t src);
vuint16m4_t vcvt_u16 (vfloat16m4_t src);
vuint16m8_t vcvt_u16 (vfloat16m8_t src);
vfloat16m1_t vcvt_f16 (vint16m1_t src);
vfloat16m2_t vcvt_f16 (vint16m2_t src);
vfloat16m4_t vcvt_f16 (vint16m4_t src);
vfloat16m8_t vcvt_f16 (vint16m8_t src);
vfloat16m1_t vcvt_f16 (vuint16m1_t src);
vfloat16m2_t vcvt_f16 (vuint16m2_t src);
vfloat16m4_t vcvt_f16 (vuint16m4_t src);
vfloat16m8_t vcvt_f16 (vuint16m8_t src);
vint32m1_t vcvt_i32 (vfloat32m1_t src);
vint32m2_t vcvt_i32 (vfloat32m2_t src);
vint32m4_t vcvt_i32 (vfloat32m4_t src);
vint32m8_t vcvt_i32 (vfloat32m8_t src);
vuint32m1_t vcvt_u32 (vfloat32m1_t src);
vuint32m2_t vcvt_u32 (vfloat32m2_t src);
vuint32m4_t vcvt_u32 (vfloat32m4_t src);
vuint32m8_t vcvt_u32 (vfloat32m8_t src);
vfloat32m1_t vcvt_f32 (vint32m1_t src);
vfloat32m2_t vcvt_f32 (vint32m2_t src);
vfloat32m4_t vcvt_f32 (vint32m4_t src);
vfloat32m8_t vcvt_f32 (vint32m8_t src);
vfloat32m1_t vcvt_f32 (vuint32m1_t src);
vfloat32m2_t vcvt_f32 (vuint32m2_t src);
vfloat32m4_t vcvt_f32 (vuint32m4_t src);
vfloat32m8_t vcvt_f32 (vuint32m8_t src);
vint64m1_t vcvt_i64 (vfloat64m1_t src);
vint64m2_t vcvt_i64 (vfloat64m2_t src);
vint64m4_t vcvt_i64 (vfloat64m4_t src);
vint64m8_t vcvt_i64 (vfloat64m8_t src);
vuint64m1_t vcvt_u64 (vfloat64m1_t src);
vuint64m2_t vcvt_u64 (vfloat64m2_t src);
vuint64m4_t vcvt_u64 (vfloat64m4_t src);
vuint64m8_t vcvt_u64 (vfloat64m8_t src);
vfloat64m1_t vcvt_f64 (vint64m1_t src);
vfloat64m2_t vcvt_f64 (vint64m2_t src);
vfloat64m4_t vcvt_f64 (vint64m4_t src);
vfloat64m8_t vcvt_f64 (vint64m8_t src);
vfloat64m1_t vcvt_f64 (vuint64m1_t src);
vfloat64m2_t vcvt_f64 (vuint64m2_t src);
vfloat64m4_t vcvt_f64 (vuint64m4_t src);
vfloat64m8_t vcvt_f64 (vuint64m8_t src);
// masked functions
vint16m1_t vcvt_i16_mask (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src);
vint16m2_t vcvt_i16_mask (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src);
vint16m4_t vcvt_i16_mask (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src);
vint16m8_t vcvt_i16_mask (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src);
vuint16m1_t vcvt_u16_mask (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src);
vuint16m2_t vcvt_u16_mask (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src);
vuint16m4_t vcvt_u16_mask (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src);
vuint16m8_t vcvt_u16_mask (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src);
vfloat16m1_t vcvt_f16_mask (vbool16_t mask, vfloat16m1_t maskedoff, vint16m1_t src);
vfloat16m2_t vcvt_f16_mask (vbool8_t mask, vfloat16m2_t maskedoff, vint16m2_t src);
vfloat16m4_t vcvt_f16_mask (vbool4_t mask, vfloat16m4_t maskedoff, vint16m4_t src);
vfloat16m8_t vcvt_f16_mask (vbool2_t mask, vfloat16m8_t maskedoff, vint16m8_t src);
vfloat16m1_t vcvt_f16_mask (vbool16_t mask, vfloat16m1_t maskedoff, vuint16m1_t src);
vfloat16m2_t vcvt_f16_mask (vbool8_t mask, vfloat16m2_t maskedoff, vuint16m2_t src);
vfloat16m4_t vcvt_f16_mask (vbool4_t mask, vfloat16m4_t maskedoff, vuint16m4_t src);
vfloat16m8_t vcvt_f16_mask (vbool2_t mask, vfloat16m8_t maskedoff, vuint16m8_t src);
vint32m1_t vcvt_i32_mask (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src);
vint32m2_t vcvt_i32_mask (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src);
vint32m4_t vcvt_i32_mask (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src);
vint32m8_t vcvt_i32_mask (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src);
vuint32m1_t vcvt_u32_mask (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src);
vuint32m2_t vcvt_u32_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src);
vuint32m4_t vcvt_u32_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src);
vuint32m8_t vcvt_u32_mask (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src);
vfloat32m1_t vcvt_f32_mask (vbool32_t mask, vfloat32m1_t maskedoff, vint32m1_t src);
vfloat32m2_t vcvt_f32_mask (vbool16_t mask, vfloat32m2_t maskedoff, vint32m2_t src);
vfloat32m4_t vcvt_f32_mask (vbool8_t mask, vfloat32m4_t maskedoff, vint32m4_t src);
vfloat32m8_t vcvt_f32_mask (vbool4_t mask, vfloat32m8_t maskedoff, vint32m8_t src);
vfloat32m1_t vcvt_f32_mask (vbool32_t mask, vfloat32m1_t maskedoff, vuint32m1_t src);
vfloat32m2_t vcvt_f32_mask (vbool16_t mask, vfloat32m2_t maskedoff, vuint32m2_t src);
vfloat32m4_t vcvt_f32_mask (vbool8_t mask, vfloat32m4_t maskedoff, vuint32m4_t src);
vfloat32m8_t vcvt_f32_mask (vbool4_t mask, vfloat32m8_t maskedoff, vuint32m8_t src);
vint64m1_t vcvt_i64_mask (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src);
vint64m2_t vcvt_i64_mask (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src);
vint64m4_t vcvt_i64_mask (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src);
vint64m8_t vcvt_i64_mask (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src);
vuint64m1_t vcvt_u64_mask (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src);
vuint64m2_t vcvt_u64_mask (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src);
vuint64m4_t vcvt_u64_mask (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src);
vuint64m8_t vcvt_u64_mask (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src);
vfloat64m1_t vcvt_f64_mask (vbool64_t mask, vfloat64m1_t maskedoff, vint64m1_t src);
vfloat64m2_t vcvt_f64_mask (vbool32_t mask, vfloat64m2_t maskedoff, vint64m2_t src);
vfloat64m4_t vcvt_f64_mask (vbool16_t mask, vfloat64m4_t maskedoff, vint64m4_t src);
vfloat64m8_t vcvt_f64_mask (vbool8_t mask, vfloat64m8_t maskedoff, vint64m8_t src);
vfloat64m1_t vcvt_f64_mask (vbool64_t mask, vfloat64m1_t maskedoff, vuint64m1_t src);
vfloat64m2_t vcvt_f64_mask (vbool32_t mask, vfloat64m2_t maskedoff, vuint64m2_t src);
vfloat64m4_t vcvt_f64_mask (vbool16_t mask, vfloat64m4_t maskedoff, vuint64m4_t src);
vfloat64m8_t vcvt_f64_mask (vbool8_t mask, vfloat64m8_t maskedoff, vuint64m8_t src);
```
### [Widening Floating-Point/Integer Type-Convert Functions]()

**Prototypes:**
``` C
vint32m2_t vcvt_i32 (vfloat16m1_t src);
vint32m4_t vcvt_i32 (vfloat16m2_t src);
vint32m8_t vcvt_i32 (vfloat16m4_t src);
vint32m2_t vcvt_i32 (vint16m1_t src);
vint32m4_t vcvt_i32 (vint16m2_t src);
vint32m8_t vcvt_i32 (vint16m4_t src);
vuint32m2_t vcvt_u32 (vuint16m1_t src);
vuint32m4_t vcvt_u32 (vuint16m2_t src);
vuint32m8_t vcvt_u32 (vuint16m4_t src);
vuint32m2_t vcvt_u32 (vfloat16m1_t src);
vuint32m4_t vcvt_u32 (vfloat16m2_t src);
vuint32m8_t vcvt_u32 (vfloat16m4_t src);
vfloat32m2_t vcvt_f32 (vint16m1_t src);
vfloat32m4_t vcvt_f32 (vint16m2_t src);
vfloat32m8_t vcvt_f32 (vint16m4_t src);
vfloat32m2_t vcvt_f32 (vuint16m1_t src);
vfloat32m4_t vcvt_f32 (vuint16m2_t src);
vfloat32m8_t vcvt_f32 (vuint16m4_t src);
vfloat32m2_t vcvt_f32 (vfloat16m1_t src);
vfloat32m4_t vcvt_f32 (vfloat16m2_t src);
vfloat32m8_t vcvt_f32 (vfloat16m4_t src);
vint64m2_t vcvt_i64 (vfloat32m1_t src);
vint64m4_t vcvt_i64 (vfloat32m2_t src);
vint64m8_t vcvt_i64 (vfloat32m4_t src);
vint64m2_t vcvt_i64 (vint32m1_t src);
vint64m4_t vcvt_i64 (vint32m2_t src);
vint64m8_t vcvt_i64 (vint32m4_t src);
vuint64m2_t vcvt_u64 (vuint32m1_t src);
vuint64m4_t vcvt_u64 (vuint32m2_t src);
vuint64m8_t vcvt_u64 (vuint32m4_t src);
vuint64m2_t vcvt_u64 (vfloat32m1_t src);
vuint64m4_t vcvt_u64 (vfloat32m2_t src);
vuint64m8_t vcvt_u64 (vfloat32m4_t src);
vfloat64m2_t vcvt_f64 (vint32m1_t src);
vfloat64m4_t vcvt_f64 (vint32m2_t src);
vfloat64m8_t vcvt_f64 (vint32m4_t src);
vfloat64m2_t vcvt_f64 (vuint32m1_t src);
vfloat64m4_t vcvt_f64 (vuint32m2_t src);
vfloat64m8_t vcvt_f64 (vuint32m4_t src);
vfloat64m2_t vcvt_f64 (vfloat32m1_t src);
vfloat64m4_t vcvt_f64 (vfloat32m2_t src);
vfloat64m8_t vcvt_f64 (vfloat32m4_t src);
// masked functions
vint32m2_t vcvt_i32_mask (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src);
vint32m4_t vcvt_i32_mask (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src);
vint32m8_t vcvt_i32_mask (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src);
vint32m2_t vcvt_i32_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t src);
vint32m4_t vcvt_i32_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t src);
vint32m8_t vcvt_i32_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t src);
vuint32m2_t vcvt_u32_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t src);
vuint32m4_t vcvt_u32_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t src);
vuint32m8_t vcvt_u32_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t src);
vuint32m2_t vcvt_u32_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src);
vuint32m4_t vcvt_u32_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src);
vuint32m8_t vcvt_u32_mask (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src);
vfloat32m2_t vcvt_f32_mask (vbool16_t mask, vfloat32m2_t maskedoff, vint16m1_t src);
vfloat32m4_t vcvt_f32_mask (vbool8_t mask, vfloat32m4_t maskedoff, vint16m2_t src);
vfloat32m8_t vcvt_f32_mask (vbool4_t mask, vfloat32m8_t maskedoff, vint16m4_t src);
vfloat32m2_t vcvt_f32_mask (vbool16_t mask, vfloat32m2_t maskedoff, vuint16m1_t src);
vfloat32m4_t vcvt_f32_mask (vbool8_t mask, vfloat32m4_t maskedoff, vuint16m2_t src);
vfloat32m8_t vcvt_f32_mask (vbool4_t mask, vfloat32m8_t maskedoff, vuint16m4_t src);
vfloat32m2_t vcvt_f32_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t src);
vfloat32m4_t vcvt_f32_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t src);
vfloat32m8_t vcvt_f32_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t src);
vint64m2_t vcvt_i64_mask (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src);
vint64m4_t vcvt_i64_mask (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src);
vint64m8_t vcvt_i64_mask (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src);
vint64m2_t vcvt_i64_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t src);
vint64m4_t vcvt_i64_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t src);
vint64m8_t vcvt_i64_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t src);
vuint64m2_t vcvt_u64_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t src);
vuint64m4_t vcvt_u64_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t src);
vuint64m8_t vcvt_u64_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t src);
vuint64m2_t vcvt_u64_mask (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src);
vuint64m4_t vcvt_u64_mask (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src);
vuint64m8_t vcvt_u64_mask (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src);
vfloat64m2_t vcvt_f64_mask (vbool32_t mask, vfloat64m2_t maskedoff, vint32m1_t src);
vfloat64m4_t vcvt_f64_mask (vbool16_t mask, vfloat64m4_t maskedoff, vint32m2_t src);
vfloat64m8_t vcvt_f64_mask (vbool8_t mask, vfloat64m8_t maskedoff, vint32m4_t src);
vfloat64m2_t vcvt_f64_mask (vbool32_t mask, vfloat64m2_t maskedoff, vuint32m1_t src);
vfloat64m4_t vcvt_f64_mask (vbool16_t mask, vfloat64m4_t maskedoff, vuint32m2_t src);
vfloat64m8_t vcvt_f64_mask (vbool8_t mask, vfloat64m8_t maskedoff, vuint32m4_t src);
vfloat64m2_t vcvt_f64_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t src);
vfloat64m4_t vcvt_f64_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t src);
vfloat64m8_t vcvt_f64_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t src);
```
### [Narrowing Floating-Point/Integer Type-Convert Functions]()

**Prototypes:**
``` C
vint16m1_t vcvt_i16 (vfloat32m2_t src);
vint16m2_t vcvt_i16 (vfloat32m4_t src);
vint16m4_t vcvt_i16 (vfloat32m8_t src);
vuint16m1_t vcvt_u16 (vfloat32m2_t src);
vuint16m2_t vcvt_u16 (vfloat32m4_t src);
vuint16m4_t vcvt_u16 (vfloat32m8_t src);
vfloat16m1_t vcvt_f16 (vint32m2_t src);
vfloat16m2_t vcvt_f16 (vint32m4_t src);
vfloat16m4_t vcvt_f16 (vint32m8_t src);
vfloat16m1_t vcvt_f16 (vuint32m2_t src);
vfloat16m2_t vcvt_f16 (vuint32m4_t src);
vfloat16m4_t vcvt_f16 (vuint32m8_t src);
vfloat16m1_t vcvt_f16 (vfloat32m2_t src);
vfloat16m1_t vcvt_rod_f16 (vfloat32m2_t src);
vfloat16m2_t vcvt_f16 (vfloat32m4_t src);
vfloat16m2_t vcvt_rod_f16 (vfloat32m4_t src);
vfloat16m4_t vcvt_f16 (vfloat32m8_t src);
vfloat16m4_t vcvt_rod_f16 (vfloat32m8_t src);
vint32m1_t vcvt_i32 (vfloat64m2_t src);
vint32m2_t vcvt_i32 (vfloat64m4_t src);
vint32m4_t vcvt_i32 (vfloat64m8_t src);
vuint32m1_t vcvt_u32 (vfloat64m2_t src);
vuint32m2_t vcvt_u32 (vfloat64m4_t src);
vuint32m4_t vcvt_u32 (vfloat64m8_t src);
vfloat32m1_t vcvt_f32 (vint64m2_t src);
vfloat32m2_t vcvt_f32 (vint64m4_t src);
vfloat32m4_t vcvt_f32 (vint64m8_t src);
vfloat32m1_t vcvt_f32 (vuint64m2_t src);
vfloat32m2_t vcvt_f32 (vuint64m4_t src);
vfloat32m4_t vcvt_f32 (vuint64m8_t src);
vfloat32m1_t vcvt_f32 (vfloat64m2_t src);
vfloat32m1_t vcvt_rod_f32 (vfloat64m2_t src);
vfloat32m2_t vcvt_f32 (vfloat64m4_t src);
vfloat32m2_t vcvt_rod_f32 (vfloat64m4_t src);
vfloat32m4_t vcvt_f32 (vfloat64m8_t src);
vfloat32m4_t vcvt_rod_f32 (vfloat64m8_t src);
// masked functions
vint16m1_t vcvt_i16_mask (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src);
vint16m2_t vcvt_i16_mask (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src);
vint16m4_t vcvt_i16_mask (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src);
vuint16m1_t vcvt_u16_mask (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src);
vuint16m2_t vcvt_u16_mask (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src);
vuint16m4_t vcvt_u16_mask (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src);
vfloat16m1_t vcvt_f16_mask (vbool16_t mask, vfloat16m1_t maskedoff, vint32m2_t src);
vfloat16m2_t vcvt_f16_mask (vbool8_t mask, vfloat16m2_t maskedoff, vint32m4_t src);
vfloat16m4_t vcvt_f16_mask (vbool4_t mask, vfloat16m4_t maskedoff, vint32m8_t src);
vfloat16m1_t vcvt_f16_mask (vbool16_t mask, vfloat16m1_t maskedoff, vuint32m2_t src);
vfloat16m2_t vcvt_f16_mask (vbool8_t mask, vfloat16m2_t maskedoff, vuint32m4_t src);
vfloat16m4_t vcvt_f16_mask (vbool4_t mask, vfloat16m4_t maskedoff, vuint32m8_t src);
vfloat16m1_t vcvt_f16_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src);
vfloat16m1_t vcvt_rod_f16_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src);
vfloat16m2_t vcvt_f16_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src);
vfloat16m2_t vcvt_rod_f16_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src);
vfloat16m4_t vcvt_f16_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src);
vfloat16m4_t vcvt_rod_f16_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src);
vint32m1_t vcvt_i32_mask (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src);
vint32m2_t vcvt_i32_mask (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src);
vint32m4_t vcvt_i32_mask (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src);
vuint32m1_t vcvt_u32_mask (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src);
vuint32m2_t vcvt_u32_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src);
vuint32m4_t vcvt_u32_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src);
vfloat32m1_t vcvt_f32_mask (vbool32_t mask, vfloat32m1_t maskedoff, vint64m2_t src);
vfloat32m2_t vcvt_f32_mask (vbool16_t mask, vfloat32m2_t maskedoff, vint64m4_t src);
vfloat32m4_t vcvt_f32_mask (vbool8_t mask, vfloat32m4_t maskedoff, vint64m8_t src);
vfloat32m1_t vcvt_f32_mask (vbool32_t mask, vfloat32m1_t maskedoff, vuint64m2_t src);
vfloat32m2_t vcvt_f32_mask (vbool16_t mask, vfloat32m2_t maskedoff, vuint64m4_t src);
vfloat32m4_t vcvt_f32_mask (vbool8_t mask, vfloat32m4_t maskedoff, vuint64m8_t src);
vfloat32m1_t vcvt_f32_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src);
vfloat32m1_t vcvt_rod_f32_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src);
vfloat32m2_t vcvt_f32_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src);
vfloat32m2_t vcvt_rod_f32_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src);
vfloat32m4_t vcvt_f32_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src);
vfloat32m4_t vcvt_rod_f32_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src);
```
## Vector Reduction Functions:

### [Vector Single-Width Integer Reduction Functions]()

**Prototypes:**
``` C
vint8m1_t vredsum (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredsum (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredsum (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredsum (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredsum (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredsum (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredsum (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredsum (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredsum (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredsum (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredsum (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredsum (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredsum (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredsum (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredsum (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredsum (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredsum (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredsum (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredsum (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredsum (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmax (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmax (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmax (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmax (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmax (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmax (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmax (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmax (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmax (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmax (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmax (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmax (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmax (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmax (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmax (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmax (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmax (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmax (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmax (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmax (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmin (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmin (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmin (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmin (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmin (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmin (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmin (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmin (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmin (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmin (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmin (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmin (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmin (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmin (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmin (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmin (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmin (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmin (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmin (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmin (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredand (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredand (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredand (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredand (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredand (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredand (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredand (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredand (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredand (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredand (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredand (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredand (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredand (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredand (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredand (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredand (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredand (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredand (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredand (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredand (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredand (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredand (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredand (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredand (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredand (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredand (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredand (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredand (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredand (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredand (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredand (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredand (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredor (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredor (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredor (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredor (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredor (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredor (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredor (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredor (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredor (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredor (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredor (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredor (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredor (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredor (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredor (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredor (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredor (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredor (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredor (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredor (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredor (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredor (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredor (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredor (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredor (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredor (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredor (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredor (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredor (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredor (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredor (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredor (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredxor (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredxor (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredxor (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredxor (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredxor (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredxor (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredxor (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredxor (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredxor (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredxor (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredxor (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredxor (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredxor (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredxor (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredxor (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredxor (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredxor (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredxor (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredxor (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredxor (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor (vuint64m8_t vector, vuint64m1_t scalar);
// masked functions
vint8m1_t vredsum_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredsum_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredsum_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredsum_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredsum_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredsum_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredsum_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredsum_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredsum_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredsum_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredsum_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredsum_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredsum_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredsum_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredsum_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredsum_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredsum_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredsum_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredsum_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredsum_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmax_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmax_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmax_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmax_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmax_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmax_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmax_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmax_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmax_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmax_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmax_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmax_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmax_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmax_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmax_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmax_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmax_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmax_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmax_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmax_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmin_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmin_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmin_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmin_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmin_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmin_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmin_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmin_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmin_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmin_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmin_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmin_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmin_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmin_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmin_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmin_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmin_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmin_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmin_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmin_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredand_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredand_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredand_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredand_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredand_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredand_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredand_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredand_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredand_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredand_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredand_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredand_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredand_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredand_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredand_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredand_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredand_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredand_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredand_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredand_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredand_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredand_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredand_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredand_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredor_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredor_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredor_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredor_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredor_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredor_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredor_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredor_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredor_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredor_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredor_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredor_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredor_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredor_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredor_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredor_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredor_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredor_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredor_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredor_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredor_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredor_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredor_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredor_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredxor_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredxor_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredxor_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredxor_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredxor_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredxor_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredxor_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredxor_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredxor_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredxor_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredxor_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredxor_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredxor_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredxor_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredxor_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredxor_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredxor_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredxor_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredxor_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredxor_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
```
### [Vector Widening Integer Reduction Functions]()https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#152-vector-widening-integer-reduction-instructions):

**Prototypes:**
``` C
vint16m1_t vwredsum (vint8m1_t vector, vint16m1_t scalar);
vint16m1_t vwredsum (vint8m2_t vector, vint16m1_t scalar);
vint16m1_t vwredsum (vint8m4_t vector, vint16m1_t scalar);
vint32m1_t vwredsum (vint16m1_t vector, vint32m1_t scalar);
vint32m1_t vwredsum (vint16m2_t vector, vint32m1_t scalar);
vint32m1_t vwredsum (vint16m4_t vector, vint32m1_t scalar);
vint64m1_t vwredsum (vint32m1_t vector, vint64m1_t scalar);
vint64m1_t vwredsum (vint32m2_t vector, vint64m1_t scalar);
vint64m1_t vwredsum (vint32m4_t vector, vint64m1_t scalar);
vuint16m1_t vwredsum (vuint8m1_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum (vuint8m2_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum (vuint8m4_t vector, vuint16m1_t scalar);
vuint32m1_t vwredsum (vuint16m1_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum (vuint16m2_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum (vuint16m4_t vector, vuint32m1_t scalar);
vuint64m1_t vwredsum (vuint32m1_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum (vuint32m2_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum (vuint32m4_t vector, vuint64m1_t scalar);
// masked functions
vint16m1_t vwredsum_mask (vbool8_t mask, vint8m1_t vector, vint16m1_t scalar);
vint16m1_t vwredsum_mask (vbool4_t mask, vint8m2_t vector, vint16m1_t scalar);
vint16m1_t vwredsum_mask (vbool2_t mask, vint8m4_t vector, vint16m1_t scalar);
vint32m1_t vwredsum_mask (vbool16_t mask, vint16m1_t vector, vint32m1_t scalar);
vint32m1_t vwredsum_mask (vbool8_t mask, vint16m2_t vector, vint32m1_t scalar);
vint32m1_t vwredsum_mask (vbool4_t mask, vint16m4_t vector, vint32m1_t scalar);
vint64m1_t vwredsum_mask (vbool32_t mask, vint32m1_t vector, vint64m1_t scalar);
vint64m1_t vwredsum_mask (vbool16_t mask, vint32m2_t vector, vint64m1_t scalar);
vint64m1_t vwredsum_mask (vbool8_t mask, vint32m4_t vector, vint64m1_t scalar);
vuint16m1_t vwredsum_mask (vbool8_t mask, vuint8m1_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum_mask (vbool4_t mask, vuint8m2_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum_mask (vbool2_t mask, vuint8m4_t vector, vuint16m1_t scalar);
vuint32m1_t vwredsum_mask (vbool16_t mask, vuint16m1_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum_mask (vbool8_t mask, vuint16m2_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum_mask (vbool4_t mask, vuint16m4_t vector, vuint32m1_t scalar);
vuint64m1_t vwredsum_mask (vbool32_t mask, vuint32m1_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum_mask (vbool16_t mask, vuint32m2_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum_mask (vbool8_t mask, vuint32m4_t vector, vuint64m1_t scalar);
```
### [Vector Single-Width Floating-Point Reduction Functions]()

**Prototypes:**
``` C
vfloat16m1_t vredosum (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredosum (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredosum (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredsum (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredsum (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredsum (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmax (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmax (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmax (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmin (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmin (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmin (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin (vfloat64m8_t vector, vfloat64m1_t scalar);
// masked functions
vfloat16m1_t vredosum_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredosum_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredosum_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredsum_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredsum_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredsum_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmax_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmax_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmax_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmin_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmin_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmin_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
```
### [Vector Widening Floating-Point Reduction Functions]()

**Prototypes:**
``` C
vfloat32m1_t vwredosum (vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum (vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum (vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredosum (vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum (vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum (vfloat32m4_t vector, vfloat64m1_t scalar);
vfloat32m1_t vwredsum (vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum (vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum (vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredsum (vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum (vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum (vfloat32m4_t vector, vfloat64m1_t scalar);
// masked functions
vfloat32m1_t vwredosum_mask (vbool16_t mask, vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum_mask (vbool8_t mask, vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum_mask (vbool4_t mask, vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredosum_mask (vbool32_t mask, vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum_mask (vbool16_t mask, vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum_mask (vbool8_t mask, vfloat32m4_t vector, vfloat64m1_t scalar);
vfloat32m1_t vwredsum_mask (vbool16_t mask, vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum_mask (vbool8_t mask, vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum_mask (vbool4_t mask, vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredsum_mask (vbool32_t mask, vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum_mask (vbool16_t mask, vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum_mask (vbool8_t mask, vfloat32m4_t vector, vfloat64m1_t scalar);
```
## Vector Mask Functions:

### [Vector Mask-Register Logical Functions]()

**Prototypes:**
``` C
vbool1_t vand (vbool1_t op1, vbool1_t op2);
vbool2_t vand (vbool2_t op1, vbool2_t op2);
vbool4_t vand (vbool4_t op1, vbool4_t op2);
vbool8_t vand (vbool8_t op1, vbool8_t op2);
vbool16_t vand (vbool16_t op1, vbool16_t op2);
vbool32_t vand (vbool32_t op1, vbool32_t op2);
vbool64_t vand (vbool64_t op1, vbool64_t op2);
vbool1_t vnand (vbool1_t op1, vbool1_t op2);
vbool2_t vnand (vbool2_t op1, vbool2_t op2);
vbool4_t vnand (vbool4_t op1, vbool4_t op2);
vbool8_t vnand (vbool8_t op1, vbool8_t op2);
vbool16_t vnand (vbool16_t op1, vbool16_t op2);
vbool32_t vnand (vbool32_t op1, vbool32_t op2);
vbool64_t vnand (vbool64_t op1, vbool64_t op2);
vbool1_t vandnot (vbool1_t op1, vbool1_t op2);
vbool2_t vandnot (vbool2_t op1, vbool2_t op2);
vbool4_t vandnot (vbool4_t op1, vbool4_t op2);
vbool8_t vandnot (vbool8_t op1, vbool8_t op2);
vbool16_t vandnot (vbool16_t op1, vbool16_t op2);
vbool32_t vandnot (vbool32_t op1, vbool32_t op2);
vbool64_t vandnot (vbool64_t op1, vbool64_t op2);
vbool1_t vxor (vbool1_t op1, vbool1_t op2);
vbool2_t vxor (vbool2_t op1, vbool2_t op2);
vbool4_t vxor (vbool4_t op1, vbool4_t op2);
vbool8_t vxor (vbool8_t op1, vbool8_t op2);
vbool16_t vxor (vbool16_t op1, vbool16_t op2);
vbool32_t vxor (vbool32_t op1, vbool32_t op2);
vbool64_t vxor (vbool64_t op1, vbool64_t op2);
vbool1_t vor (vbool1_t op1, vbool1_t op2);
vbool2_t vor (vbool2_t op1, vbool2_t op2);
vbool4_t vor (vbool4_t op1, vbool4_t op2);
vbool8_t vor (vbool8_t op1, vbool8_t op2);
vbool16_t vor (vbool16_t op1, vbool16_t op2);
vbool32_t vor (vbool32_t op1, vbool32_t op2);
vbool64_t vor (vbool64_t op1, vbool64_t op2);
vbool1_t vnor (vbool1_t op1, vbool1_t op2);
vbool2_t vnor (vbool2_t op1, vbool2_t op2);
vbool4_t vnor (vbool4_t op1, vbool4_t op2);
vbool8_t vnor (vbool8_t op1, vbool8_t op2);
vbool16_t vnor (vbool16_t op1, vbool16_t op2);
vbool32_t vnor (vbool32_t op1, vbool32_t op2);
vbool64_t vnor (vbool64_t op1, vbool64_t op2);
vbool1_t vornot (vbool1_t op1, vbool1_t op2);
vbool2_t vornot (vbool2_t op1, vbool2_t op2);
vbool4_t vornot (vbool4_t op1, vbool4_t op2);
vbool8_t vornot (vbool8_t op1, vbool8_t op2);
vbool16_t vornot (vbool16_t op1, vbool16_t op2);
vbool32_t vornot (vbool32_t op1, vbool32_t op2);
vbool64_t vornot (vbool64_t op1, vbool64_t op2);
vbool1_t vxnor (vbool1_t op1, vbool1_t op2);
vbool2_t vxnor (vbool2_t op1, vbool2_t op2);
vbool4_t vxnor (vbool4_t op1, vbool4_t op2);
vbool8_t vxnor (vbool8_t op1, vbool8_t op2);
vbool16_t vxnor (vbool16_t op1, vbool16_t op2);
vbool32_t vxnor (vbool32_t op1, vbool32_t op2);
vbool64_t vxnor (vbool64_t op1, vbool64_t op2);
vbool1_t vcpy (vbool1_t op1);
vbool2_t vcpy (vbool2_t op1);
vbool4_t vcpy (vbool4_t op1);
vbool8_t vcpy (vbool8_t op1);
vbool16_t vcpy (vbool16_t op1);
vbool32_t vcpy (vbool32_t op1);
vbool64_t vcpy (vbool64_t op1);
vbool1_t vclr_b1 ();
vbool2_t vclr_b2 ();
vbool4_t vclr_b4 ();
vbool8_t vclr_b8 ();
vbool16_t vclr_b16 ();
vbool32_t vclr_b32 ();
vbool64_t vclr_b64 ();
vbool1_t vset_b1 ();
vbool2_t vset_b2 ();
vbool4_t vset_b4 ();
vbool8_t vset_b8 ();
vbool16_t vset_b16 ();
vbool32_t vset_b32 ();
vbool64_t vset_b64 ();
vbool1_t vnot (vbool1_t op1);
vbool2_t vnot (vbool2_t op1);
vbool4_t vnot (vbool4_t op1);
vbool8_t vnot (vbool8_t op1);
vbool16_t vnot (vbool16_t op1);
vbool32_t vnot (vbool32_t op1);
vbool64_t vnot (vbool64_t op1);
```
### [Vector mask population count Functions]()

**Prototypes:**
``` C
unsigned long vpopc (vbool1_t op1);
unsigned long vpopc (vbool2_t op1);
unsigned long vpopc (vbool4_t op1);
unsigned long vpopc (vbool8_t op1);
unsigned long vpopc (vbool16_t op1);
unsigned long vpopc (vbool32_t op1);
unsigned long vpopc (vbool64_t op1);
// masked functions
unsigned long vpopc_mask (vbool1_t mask, vbool1_t op1);
unsigned long vpopc_mask (vbool2_t mask, vbool2_t op1);
unsigned long vpopc_mask (vbool4_t mask, vbool4_t op1);
unsigned long vpopc_mask (vbool8_t mask, vbool8_t op1);
unsigned long vpopc_mask (vbool16_t mask, vbool16_t op1);
unsigned long vpopc_mask (vbool32_t mask, vbool32_t op1);
unsigned long vpopc_mask (vbool64_t mask, vbool64_t op1);
```
### [Find-first-set mask bit Functions]()

**Prototypes:**
``` C
long vfirst (vbool1_t op1);
long vfirst (vbool2_t op1);
long vfirst (vbool4_t op1);
long vfirst (vbool8_t op1);
long vfirst (vbool16_t op1);
long vfirst (vbool32_t op1);
long vfirst (vbool64_t op1);
// masked functions
long vfirst_mask (vbool1_t mask, vbool1_t op1);
long vfirst_mask (vbool2_t mask, vbool2_t op1);
long vfirst_mask (vbool4_t mask, vbool4_t op1);
long vfirst_mask (vbool8_t mask, vbool8_t op1);
long vfirst_mask (vbool16_t mask, vbool16_t op1);
long vfirst_mask (vbool32_t mask, vbool32_t op1);
long vfirst_mask (vbool64_t mask, vbool64_t op1);
```
### [Set-before-first mask bit Functions]()

**Prototypes:**
``` C
vbool1_t vsbf (vbool1_t op1);
vbool2_t vsbf (vbool2_t op1);
vbool4_t vsbf (vbool4_t op1);
vbool8_t vsbf (vbool8_t op1);
vbool16_t vsbf (vbool16_t op1);
vbool32_t vsbf (vbool32_t op1);
vbool64_t vsbf (vbool64_t op1);
// masked functions
vbool1_t vsbf_mask (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vsbf_mask (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vsbf_mask (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vsbf_mask (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vsbf_mask (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vsbf_mask (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vsbf_mask (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### [Set-including-first mask bit Functions]()

**Prototypes:**
``` C
vbool1_t vsif (vbool1_t op1);
vbool2_t vsif (vbool2_t op1);
vbool4_t vsif (vbool4_t op1);
vbool8_t vsif (vbool8_t op1);
vbool16_t vsif (vbool16_t op1);
vbool32_t vsif (vbool32_t op1);
vbool64_t vsif (vbool64_t op1);
// masked functions
vbool1_t vsif_mask (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vsif_mask (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vsif_mask (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vsif_mask (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vsif_mask (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vsif_mask (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vsif_mask (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### [Set-only-first mask bit Functions]()

**Prototypes:**
``` C
vbool1_t vsof (vbool1_t op1);
vbool2_t vsof (vbool2_t op1);
vbool4_t vsof (vbool4_t op1);
vbool8_t vsof (vbool8_t op1);
vbool16_t vsof (vbool16_t op1);
vbool32_t vsof (vbool32_t op1);
vbool64_t vsof (vbool64_t op1);
// masked functions
vbool1_t vsof_mask (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vsof_mask (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vsof_mask (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vsof_mask (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vsof_mask (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vsof_mask (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vsof_mask (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### [Vector Iota Functions]()

**Prototypes:**
``` C
vuint8m1_t viota_m_8m1 (vbool8_t op1);
vuint8m2_t viota_m_8m2 (vbool4_t op1);
vuint8m4_t viota_m_8m4 (vbool2_t op1);
vuint8m8_t viota_m_8m8 (vbool1_t op1);
vuint16m1_t viota_m_16m1 (vbool16_t op1);
vuint16m2_t viota_m_16m2 (vbool8_t op1);
vuint16m4_t viota_m_16m4 (vbool4_t op1);
vuint16m8_t viota_m_16m8 (vbool2_t op1);
vuint32m1_t viota_m_32m1 (vbool32_t op1);
vuint32m2_t viota_m_32m2 (vbool16_t op1);
vuint32m4_t viota_m_32m4 (vbool8_t op1);
vuint32m8_t viota_m_32m8 (vbool4_t op1);
vuint64m1_t viota_m_64m1 (vbool64_t op1);
vuint64m2_t viota_m_64m2 (vbool32_t op1);
vuint64m4_t viota_m_64m4 (vbool16_t op1);
vuint64m8_t viota_m_64m8 (vbool8_t op1);
// masked functions
vuint8m1_t viota_m_8m1_mask (vbool8_t mask, vbool8_t op1);
vuint8m2_t viota_m_8m2_mask (vbool4_t mask, vbool4_t op1);
vuint8m4_t viota_m_8m4_mask (vbool2_t mask, vbool2_t op1);
vuint8m8_t viota_m_8m8_mask (vbool1_t mask, vbool1_t op1);
vuint16m1_t viota_m_16m1_mask (vbool16_t mask, vbool16_t op1);
vuint16m2_t viota_m_16m2_mask (vbool8_t mask, vbool8_t op1);
vuint16m4_t viota_m_16m4_mask (vbool4_t mask, vbool4_t op1);
vuint16m8_t viota_m_16m8_mask (vbool2_t mask, vbool2_t op1);
vuint32m1_t viota_m_32m1_mask (vbool32_t mask, vbool32_t op1);
vuint32m2_t viota_m_32m2_mask (vbool16_t mask, vbool16_t op1);
vuint32m4_t viota_m_32m4_mask (vbool8_t mask, vbool8_t op1);
vuint32m8_t viota_m_32m8_mask (vbool4_t mask, vbool4_t op1);
vuint64m1_t viota_m_64m1_mask (vbool64_t mask, vbool64_t op1);
vuint64m2_t viota_m_64m2_mask (vbool32_t mask, vbool32_t op1);
vuint64m4_t viota_m_64m4_mask (vbool16_t mask, vbool16_t op1);
vuint64m8_t viota_m_64m8_mask (vbool8_t mask, vbool8_t op1);
```
### [Vector Element Index Functions]()

**Prototypes:**
``` C
vuint8m1_t vid_8m1 ();
vuint8m2_t vid_8m2 ();
vuint8m4_t vid_8m4 ();
vuint8m8_t vid_8m8 ();
vuint16m1_t vid_16m1 ();
vuint16m2_t vid_16m2 ();
vuint16m4_t vid_16m4 ();
vuint16m8_t vid_16m8 ();
vuint32m1_t vid_32m1 ();
vuint32m2_t vid_32m2 ();
vuint32m4_t vid_32m4 ();
vuint32m8_t vid_32m8 ();
vuint64m1_t vid_64m1 ();
vuint64m2_t vid_64m2 ();
vuint64m4_t vid_64m4 ();
vuint64m8_t vid_64m8 ();
// masked functions
vuint8m1_t vid_8m1_mask (vbool8_t mask, vuint8m1_t maskedoff);
vuint8m2_t vid_8m2_mask (vbool4_t mask, vuint8m2_t maskedoff);
vuint8m4_t vid_8m4_mask (vbool2_t mask, vuint8m4_t maskedoff);
vuint8m8_t vid_8m8_mask (vbool1_t mask, vuint8m8_t maskedoff);
vuint16m1_t vid_16m1_mask (vbool16_t mask, vuint16m1_t maskedoff);
vuint16m2_t vid_16m2_mask (vbool8_t mask, vuint16m2_t maskedoff);
vuint16m4_t vid_16m4_mask (vbool4_t mask, vuint16m4_t maskedoff);
vuint16m8_t vid_16m8_mask (vbool2_t mask, vuint16m8_t maskedoff);
vuint32m1_t vid_32m1_mask (vbool32_t mask, vuint32m1_t maskedoff);
vuint32m2_t vid_32m2_mask (vbool16_t mask, vuint32m2_t maskedoff);
vuint32m4_t vid_32m4_mask (vbool8_t mask, vuint32m4_t maskedoff);
vuint32m8_t vid_32m8_mask (vbool4_t mask, vuint32m8_t maskedoff);
vuint64m1_t vid_64m1_mask (vbool64_t mask, vuint64m1_t maskedoff);
vuint64m2_t vid_64m2_mask (vbool32_t mask, vuint64m2_t maskedoff);
vuint64m4_t vid_64m4_mask (vbool16_t mask, vuint64m4_t maskedoff);
vuint64m8_t vid_64m8_mask (vbool8_t mask, vuint64m8_t maskedoff);
```
## Vector Permutation Functions:

### [Integer and Floating-Point Scalar Move Functions]()

**Prototypes:**
``` C
int8_t vmv_v (vint8m1_t src);
vint8m1_t vmv_s (vint8m1_t dst, int8_t src);
int8_t vmv_v (vint8m2_t src);
vint8m2_t vmv_s (vint8m2_t dst, int8_t src);
int8_t vmv_v (vint8m4_t src);
vint8m4_t vmv_s (vint8m4_t dst, int8_t src);
int8_t vmv_v (vint8m8_t src);
vint8m8_t vmv_s (vint8m8_t dst, int8_t src);
int16_t vmv_v (vint16m1_t src);
vint16m1_t vmv_s (vint16m1_t dst, int16_t src);
int16_t vmv_v (vint16m2_t src);
vint16m2_t vmv_s (vint16m2_t dst, int16_t src);
int16_t vmv_v (vint16m4_t src);
vint16m4_t vmv_s (vint16m4_t dst, int16_t src);
int16_t vmv_v (vint16m8_t src);
vint16m8_t vmv_s (vint16m8_t dst, int16_t src);
int32_t vmv_v (vint32m1_t src);
vint32m1_t vmv_s (vint32m1_t dst, int32_t src);
int32_t vmv_v (vint32m2_t src);
vint32m2_t vmv_s (vint32m2_t dst, int32_t src);
int32_t vmv_v (vint32m4_t src);
vint32m4_t vmv_s (vint32m4_t dst, int32_t src);
int32_t vmv_v (vint32m8_t src);
vint32m8_t vmv_s (vint32m8_t dst, int32_t src);
int64_t vmv_v (vint64m1_t src);
vint64m1_t vmv_s (vint64m1_t dst, int64_t src);
int64_t vmv_v (vint64m2_t src);
vint64m2_t vmv_s (vint64m2_t dst, int64_t src);
int64_t vmv_v (vint64m4_t src);
vint64m4_t vmv_s (vint64m4_t dst, int64_t src);
int64_t vmv_v (vint64m8_t src);
vint64m8_t vmv_s (vint64m8_t dst, int64_t src);
uint8_t vmv_v (vuint8m1_t src);
vuint8m1_t vmv_s (vuint8m1_t dst, uint8_t src);
uint8_t vmv_v (vuint8m2_t src);
vuint8m2_t vmv_s (vuint8m2_t dst, uint8_t src);
uint8_t vmv_v (vuint8m4_t src);
vuint8m4_t vmv_s (vuint8m4_t dst, uint8_t src);
uint8_t vmv_v (vuint8m8_t src);
vuint8m8_t vmv_s (vuint8m8_t dst, uint8_t src);
uint16_t vmv_v (vuint16m1_t src);
vuint16m1_t vmv_s (vuint16m1_t dst, uint16_t src);
uint16_t vmv_v (vuint16m2_t src);
vuint16m2_t vmv_s (vuint16m2_t dst, uint16_t src);
uint16_t vmv_v (vuint16m4_t src);
vuint16m4_t vmv_s (vuint16m4_t dst, uint16_t src);
uint16_t vmv_v (vuint16m8_t src);
vuint16m8_t vmv_s (vuint16m8_t dst, uint16_t src);
uint32_t vmv_v (vuint32m1_t src);
vuint32m1_t vmv_s (vuint32m1_t dst, uint32_t src);
uint32_t vmv_v (vuint32m2_t src);
vuint32m2_t vmv_s (vuint32m2_t dst, uint32_t src);
uint32_t vmv_v (vuint32m4_t src);
vuint32m4_t vmv_s (vuint32m4_t dst, uint32_t src);
uint32_t vmv_v (vuint32m8_t src);
vuint32m8_t vmv_s (vuint32m8_t dst, uint32_t src);
uint64_t vmv_v (vuint64m1_t src);
vuint64m1_t vmv_s (vuint64m1_t dst, uint64_t src);
uint64_t vmv_v (vuint64m2_t src);
vuint64m2_t vmv_s (vuint64m2_t dst, uint64_t src);
uint64_t vmv_v (vuint64m4_t src);
vuint64m4_t vmv_s (vuint64m4_t dst, uint64_t src);
uint64_t vmv_v (vuint64m8_t src);
vuint64m8_t vmv_s (vuint64m8_t dst, uint64_t src);
float16_t vmv_v (vfloat16m1_t src);
vfloat16m1_t vmv_s (vfloat16m1_t dst, float16_t src);
float16_t vmv_v (vfloat16m2_t src);
vfloat16m2_t vmv_s (vfloat16m2_t dst, float16_t src);
float16_t vmv_v (vfloat16m4_t src);
vfloat16m4_t vmv_s (vfloat16m4_t dst, float16_t src);
float16_t vmv_v (vfloat16m8_t src);
vfloat16m8_t vmv_s (vfloat16m8_t dst, float16_t src);
float32_t vmv_v (vfloat32m1_t src);
vfloat32m1_t vmv_s (vfloat32m1_t dst, float32_t src);
float32_t vmv_v (vfloat32m2_t src);
vfloat32m2_t vmv_s (vfloat32m2_t dst, float32_t src);
float32_t vmv_v (vfloat32m4_t src);
vfloat32m4_t vmv_s (vfloat32m4_t dst, float32_t src);
float32_t vmv_v (vfloat32m8_t src);
vfloat32m8_t vmv_s (vfloat32m8_t dst, float32_t src);
float64_t vmv_v (vfloat64m1_t src);
vfloat64m1_t vmv_s (vfloat64m1_t dst, float64_t src);
float64_t vmv_v (vfloat64m2_t src);
vfloat64m2_t vmv_s (vfloat64m2_t dst, float64_t src);
float64_t vmv_v (vfloat64m4_t src);
vfloat64m4_t vmv_s (vfloat64m4_t dst, float64_t src);
float64_t vmv_v (vfloat64m8_t src);
vfloat64m8_t vmv_s (vfloat64m8_t dst, float64_t src);
```
### [Vector Slideup and Slidedown Functions]()

**Prototypes:**
``` C
vint8m1_t vslideup (vint8m1_t src, size_t offset);
vint8m2_t vslideup (vint8m2_t src, size_t offset);
vint8m4_t vslideup (vint8m4_t src, size_t offset);
vint8m8_t vslideup (vint8m8_t src, size_t offset);
vint16m1_t vslideup (vint16m1_t src, size_t offset);
vint16m2_t vslideup (vint16m2_t src, size_t offset);
vint16m4_t vslideup (vint16m4_t src, size_t offset);
vint16m8_t vslideup (vint16m8_t src, size_t offset);
vint32m1_t vslideup (vint32m1_t src, size_t offset);
vint32m2_t vslideup (vint32m2_t src, size_t offset);
vint32m4_t vslideup (vint32m4_t src, size_t offset);
vint32m8_t vslideup (vint32m8_t src, size_t offset);
vint64m1_t vslideup (vint64m1_t src, size_t offset);
vint64m2_t vslideup (vint64m2_t src, size_t offset);
vint64m4_t vslideup (vint64m4_t src, size_t offset);
vint64m8_t vslideup (vint64m8_t src, size_t offset);
vuint8m1_t vslideup (vuint8m1_t src, size_t offset);
vuint8m2_t vslideup (vuint8m2_t src, size_t offset);
vuint8m4_t vslideup (vuint8m4_t src, size_t offset);
vuint8m8_t vslideup (vuint8m8_t src, size_t offset);
vuint16m1_t vslideup (vuint16m1_t src, size_t offset);
vuint16m2_t vslideup (vuint16m2_t src, size_t offset);
vuint16m4_t vslideup (vuint16m4_t src, size_t offset);
vuint16m8_t vslideup (vuint16m8_t src, size_t offset);
vuint32m1_t vslideup (vuint32m1_t src, size_t offset);
vuint32m2_t vslideup (vuint32m2_t src, size_t offset);
vuint32m4_t vslideup (vuint32m4_t src, size_t offset);
vuint32m8_t vslideup (vuint32m8_t src, size_t offset);
vuint64m1_t vslideup (vuint64m1_t src, size_t offset);
vuint64m2_t vslideup (vuint64m2_t src, size_t offset);
vuint64m4_t vslideup (vuint64m4_t src, size_t offset);
vuint64m8_t vslideup (vuint64m8_t src, size_t offset);
vfloat16m1_t vslideup (vfloat16m1_t src, size_t offset);
vfloat16m2_t vslideup (vfloat16m2_t src, size_t offset);
vfloat16m4_t vslideup (vfloat16m4_t src, size_t offset);
vfloat16m8_t vslideup (vfloat16m8_t src, size_t offset);
vfloat32m1_t vslideup (vfloat32m1_t src, size_t offset);
vfloat32m2_t vslideup (vfloat32m2_t src, size_t offset);
vfloat32m4_t vslideup (vfloat32m4_t src, size_t offset);
vfloat32m8_t vslideup (vfloat32m8_t src, size_t offset);
vfloat64m1_t vslideup (vfloat64m1_t src, size_t offset);
vfloat64m2_t vslideup (vfloat64m2_t src, size_t offset);
vfloat64m4_t vslideup (vfloat64m4_t src, size_t offset);
vfloat64m8_t vslideup (vfloat64m8_t src, size_t offset);
vint8m1_t vslidedown (vint8m1_t src, size_t offset);
vint8m2_t vslidedown (vint8m2_t src, size_t offset);
vint8m4_t vslidedown (vint8m4_t src, size_t offset);
vint8m8_t vslidedown (vint8m8_t src, size_t offset);
vint16m1_t vslidedown (vint16m1_t src, size_t offset);
vint16m2_t vslidedown (vint16m2_t src, size_t offset);
vint16m4_t vslidedown (vint16m4_t src, size_t offset);
vint16m8_t vslidedown (vint16m8_t src, size_t offset);
vint32m1_t vslidedown (vint32m1_t src, size_t offset);
vint32m2_t vslidedown (vint32m2_t src, size_t offset);
vint32m4_t vslidedown (vint32m4_t src, size_t offset);
vint32m8_t vslidedown (vint32m8_t src, size_t offset);
vint64m1_t vslidedown (vint64m1_t src, size_t offset);
vint64m2_t vslidedown (vint64m2_t src, size_t offset);
vint64m4_t vslidedown (vint64m4_t src, size_t offset);
vint64m8_t vslidedown (vint64m8_t src, size_t offset);
vuint8m1_t vslidedown (vuint8m1_t src, size_t offset);
vuint8m2_t vslidedown (vuint8m2_t src, size_t offset);
vuint8m4_t vslidedown (vuint8m4_t src, size_t offset);
vuint8m8_t vslidedown (vuint8m8_t src, size_t offset);
vuint16m1_t vslidedown (vuint16m1_t src, size_t offset);
vuint16m2_t vslidedown (vuint16m2_t src, size_t offset);
vuint16m4_t vslidedown (vuint16m4_t src, size_t offset);
vuint16m8_t vslidedown (vuint16m8_t src, size_t offset);
vuint32m1_t vslidedown (vuint32m1_t src, size_t offset);
vuint32m2_t vslidedown (vuint32m2_t src, size_t offset);
vuint32m4_t vslidedown (vuint32m4_t src, size_t offset);
vuint32m8_t vslidedown (vuint32m8_t src, size_t offset);
vuint64m1_t vslidedown (vuint64m1_t src, size_t offset);
vuint64m2_t vslidedown (vuint64m2_t src, size_t offset);
vuint64m4_t vslidedown (vuint64m4_t src, size_t offset);
vuint64m8_t vslidedown (vuint64m8_t src, size_t offset);
vfloat16m1_t vslidedown (vfloat16m1_t src, size_t offset);
vfloat16m2_t vslidedown (vfloat16m2_t src, size_t offset);
vfloat16m4_t vslidedown (vfloat16m4_t src, size_t offset);
vfloat16m8_t vslidedown (vfloat16m8_t src, size_t offset);
vfloat32m1_t vslidedown (vfloat32m1_t src, size_t offset);
vfloat32m2_t vslidedown (vfloat32m2_t src, size_t offset);
vfloat32m4_t vslidedown (vfloat32m4_t src, size_t offset);
vfloat32m8_t vslidedown (vfloat32m8_t src, size_t offset);
vfloat64m1_t vslidedown (vfloat64m1_t src, size_t offset);
vfloat64m2_t vslidedown (vfloat64m2_t src, size_t offset);
vfloat64m4_t vslidedown (vfloat64m4_t src, size_t offset);
vfloat64m8_t vslidedown (vfloat64m8_t src, size_t offset);
// masked functions
vint8m1_t vslideup_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset);
vint8m2_t vslideup_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset);
vint8m4_t vslideup_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset);
vint8m8_t vslideup_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset);
vint16m1_t vslideup_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset);
vint16m2_t vslideup_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset);
vint16m4_t vslideup_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset);
vint16m8_t vslideup_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset);
vint32m1_t vslideup_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset);
vint32m2_t vslideup_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset);
vint32m4_t vslideup_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset);
vint32m8_t vslideup_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset);
vint64m1_t vslideup_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset);
vint64m2_t vslideup_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset);
vint64m4_t vslideup_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset);
vint64m8_t vslideup_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset);
vuint8m1_t vslideup_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset);
vuint8m2_t vslideup_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset);
vuint8m4_t vslideup_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset);
vuint8m8_t vslideup_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset);
vuint16m1_t vslideup_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset);
vuint16m2_t vslideup_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset);
vuint16m4_t vslideup_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset);
vuint16m8_t vslideup_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset);
vuint32m1_t vslideup_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset);
vuint32m2_t vslideup_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset);
vuint32m4_t vslideup_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset);
vuint32m8_t vslideup_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset);
vuint64m1_t vslideup_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset);
vuint64m2_t vslideup_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset);
vuint64m4_t vslideup_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset);
vuint64m8_t vslideup_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset);
vfloat16m1_t vslideup_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset);
vfloat16m2_t vslideup_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset);
vfloat16m4_t vslideup_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset);
vfloat16m8_t vslideup_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset);
vfloat32m1_t vslideup_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset);
vfloat32m2_t vslideup_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset);
vfloat32m4_t vslideup_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset);
vfloat32m8_t vslideup_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset);
vfloat64m1_t vslideup_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset);
vfloat64m2_t vslideup_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset);
vfloat64m4_t vslideup_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset);
vfloat64m8_t vslideup_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset);
vint8m1_t vslidedown_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset);
vint8m2_t vslidedown_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset);
vint8m4_t vslidedown_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset);
vint8m8_t vslidedown_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset);
vint16m1_t vslidedown_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset);
vint16m2_t vslidedown_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset);
vint16m4_t vslidedown_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset);
vint16m8_t vslidedown_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset);
vint32m1_t vslidedown_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset);
vint32m2_t vslidedown_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset);
vint32m4_t vslidedown_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset);
vint32m8_t vslidedown_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset);
vint64m1_t vslidedown_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset);
vint64m2_t vslidedown_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset);
vint64m4_t vslidedown_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset);
vint64m8_t vslidedown_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset);
vuint8m1_t vslidedown_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset);
vuint8m2_t vslidedown_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset);
vuint8m4_t vslidedown_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset);
vuint8m8_t vslidedown_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset);
vuint16m1_t vslidedown_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset);
vuint16m2_t vslidedown_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset);
vuint16m4_t vslidedown_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset);
vuint16m8_t vslidedown_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset);
vuint32m1_t vslidedown_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset);
vuint32m2_t vslidedown_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset);
vuint32m4_t vslidedown_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset);
vuint32m8_t vslidedown_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset);
vuint64m1_t vslidedown_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset);
vuint64m2_t vslidedown_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset);
vuint64m4_t vslidedown_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset);
vuint64m8_t vslidedown_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset);
vfloat16m1_t vslidedown_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset);
vfloat16m2_t vslidedown_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset);
vfloat16m4_t vslidedown_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset);
vfloat16m8_t vslidedown_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset);
vfloat32m1_t vslidedown_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset);
vfloat32m2_t vslidedown_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset);
vfloat32m4_t vslidedown_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset);
vfloat32m8_t vslidedown_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset);
vfloat64m1_t vslidedown_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset);
vfloat64m2_t vslidedown_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset);
vfloat64m4_t vslidedown_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset);
vfloat64m8_t vslidedown_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset);
```
### [Vector Slide1up and Slide1down Functions]()

**Prototypes:**
``` C
vint8m1_t vslide1up (vint8m1_t src, long value);
vint8m2_t vslide1up (vint8m2_t src, long value);
vint8m4_t vslide1up (vint8m4_t src, long value);
vint8m8_t vslide1up (vint8m8_t src, long value);
vint16m1_t vslide1up (vint16m1_t src, long value);
vint16m2_t vslide1up (vint16m2_t src, long value);
vint16m4_t vslide1up (vint16m4_t src, long value);
vint16m8_t vslide1up (vint16m8_t src, long value);
vint32m1_t vslide1up (vint32m1_t src, long value);
vint32m2_t vslide1up (vint32m2_t src, long value);
vint32m4_t vslide1up (vint32m4_t src, long value);
vint32m8_t vslide1up (vint32m8_t src, long value);
vint64m1_t vslide1up (vint64m1_t src, long value);
vint64m2_t vslide1up (vint64m2_t src, long value);
vint64m4_t vslide1up (vint64m4_t src, long value);
vint64m8_t vslide1up (vint64m8_t src, long value);
vuint8m1_t vslide1up (vuint8m1_t src, long value);
vuint8m2_t vslide1up (vuint8m2_t src, long value);
vuint8m4_t vslide1up (vuint8m4_t src, long value);
vuint8m8_t vslide1up (vuint8m8_t src, long value);
vuint16m1_t vslide1up (vuint16m1_t src, long value);
vuint16m2_t vslide1up (vuint16m2_t src, long value);
vuint16m4_t vslide1up (vuint16m4_t src, long value);
vuint16m8_t vslide1up (vuint16m8_t src, long value);
vuint32m1_t vslide1up (vuint32m1_t src, long value);
vuint32m2_t vslide1up (vuint32m2_t src, long value);
vuint32m4_t vslide1up (vuint32m4_t src, long value);
vuint32m8_t vslide1up (vuint32m8_t src, long value);
vuint64m1_t vslide1up (vuint64m1_t src, long value);
vuint64m2_t vslide1up (vuint64m2_t src, long value);
vuint64m4_t vslide1up (vuint64m4_t src, long value);
vuint64m8_t vslide1up (vuint64m8_t src, long value);
vint8m1_t vslide1down (vint8m1_t src, long value);
vint8m2_t vslide1down (vint8m2_t src, long value);
vint8m4_t vslide1down (vint8m4_t src, long value);
vint8m8_t vslide1down (vint8m8_t src, long value);
vint16m1_t vslide1down (vint16m1_t src, long value);
vint16m2_t vslide1down (vint16m2_t src, long value);
vint16m4_t vslide1down (vint16m4_t src, long value);
vint16m8_t vslide1down (vint16m8_t src, long value);
vint32m1_t vslide1down (vint32m1_t src, long value);
vint32m2_t vslide1down (vint32m2_t src, long value);
vint32m4_t vslide1down (vint32m4_t src, long value);
vint32m8_t vslide1down (vint32m8_t src, long value);
vint64m1_t vslide1down (vint64m1_t src, long value);
vint64m2_t vslide1down (vint64m2_t src, long value);
vint64m4_t vslide1down (vint64m4_t src, long value);
vint64m8_t vslide1down (vint64m8_t src, long value);
vuint8m1_t vslide1down (vuint8m1_t src, long value);
vuint8m2_t vslide1down (vuint8m2_t src, long value);
vuint8m4_t vslide1down (vuint8m4_t src, long value);
vuint8m8_t vslide1down (vuint8m8_t src, long value);
vuint16m1_t vslide1down (vuint16m1_t src, long value);
vuint16m2_t vslide1down (vuint16m2_t src, long value);
vuint16m4_t vslide1down (vuint16m4_t src, long value);
vuint16m8_t vslide1down (vuint16m8_t src, long value);
vuint32m1_t vslide1down (vuint32m1_t src, long value);
vuint32m2_t vslide1down (vuint32m2_t src, long value);
vuint32m4_t vslide1down (vuint32m4_t src, long value);
vuint32m8_t vslide1down (vuint32m8_t src, long value);
vuint64m1_t vslide1down (vuint64m1_t src, long value);
vuint64m2_t vslide1down (vuint64m2_t src, long value);
vuint64m4_t vslide1down (vuint64m4_t src, long value);
vuint64m8_t vslide1down (vuint64m8_t src, long value);
// masked functions
vint8m1_t vslide1up_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, long value);
vint8m2_t vslide1up_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, long value);
vint8m4_t vslide1up_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, long value);
vint8m8_t vslide1up_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, long value);
vint16m1_t vslide1up_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, long value);
vint16m2_t vslide1up_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, long value);
vint16m4_t vslide1up_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, long value);
vint16m8_t vslide1up_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, long value);
vint32m1_t vslide1up_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, long value);
vint32m2_t vslide1up_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, long value);
vint32m4_t vslide1up_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, long value);
vint32m8_t vslide1up_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, long value);
vint64m1_t vslide1up_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, long value);
vint64m2_t vslide1up_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, long value);
vint64m4_t vslide1up_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, long value);
vint64m8_t vslide1up_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, long value);
vuint8m1_t vslide1up_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, long value);
vuint8m2_t vslide1up_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, long value);
vuint8m4_t vslide1up_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, long value);
vuint8m8_t vslide1up_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, long value);
vuint16m1_t vslide1up_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, long value);
vuint16m2_t vslide1up_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, long value);
vuint16m4_t vslide1up_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, long value);
vuint16m8_t vslide1up_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, long value);
vuint32m1_t vslide1up_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, long value);
vuint32m2_t vslide1up_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, long value);
vuint32m4_t vslide1up_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, long value);
vuint32m8_t vslide1up_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, long value);
vuint64m1_t vslide1up_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, long value);
vuint64m2_t vslide1up_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, long value);
vuint64m4_t vslide1up_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, long value);
vuint64m8_t vslide1up_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, long value);
vint8m1_t vslide1down_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, long value);
vint8m2_t vslide1down_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, long value);
vint8m4_t vslide1down_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, long value);
vint8m8_t vslide1down_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, long value);
vint16m1_t vslide1down_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, long value);
vint16m2_t vslide1down_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, long value);
vint16m4_t vslide1down_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, long value);
vint16m8_t vslide1down_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, long value);
vint32m1_t vslide1down_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, long value);
vint32m2_t vslide1down_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, long value);
vint32m4_t vslide1down_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, long value);
vint32m8_t vslide1down_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, long value);
vint64m1_t vslide1down_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, long value);
vint64m2_t vslide1down_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, long value);
vint64m4_t vslide1down_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, long value);
vint64m8_t vslide1down_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, long value);
vuint8m1_t vslide1down_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, long value);
vuint8m2_t vslide1down_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, long value);
vuint8m4_t vslide1down_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, long value);
vuint8m8_t vslide1down_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, long value);
vuint16m1_t vslide1down_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, long value);
vuint16m2_t vslide1down_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, long value);
vuint16m4_t vslide1down_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, long value);
vuint16m8_t vslide1down_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, long value);
vuint32m1_t vslide1down_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, long value);
vuint32m2_t vslide1down_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, long value);
vuint32m4_t vslide1down_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, long value);
vuint32m8_t vslide1down_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, long value);
vuint64m1_t vslide1down_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, long value);
vuint64m2_t vslide1down_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, long value);
vuint64m4_t vslide1down_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, long value);
vuint64m8_t vslide1down_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, long value);
```
### [Vector Register Gather Functions]()

**Prototypes:**
``` C
vint8m1_t vrgather (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vrgather (vint8m1_t op1, uint8_t op2);
vint8m2_t vrgather (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vrgather (vint8m2_t op1, uint8_t op2);
vint8m4_t vrgather (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vrgather (vint8m4_t op1, uint8_t op2);
vint8m8_t vrgather (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vrgather (vint8m8_t op1, uint8_t op2);
vint16m1_t vrgather (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vrgather (vint16m1_t op1, uint16_t op2);
vint16m2_t vrgather (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vrgather (vint16m2_t op1, uint16_t op2);
vint16m4_t vrgather (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vrgather (vint16m4_t op1, uint16_t op2);
vint16m8_t vrgather (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vrgather (vint16m8_t op1, uint16_t op2);
vint32m1_t vrgather (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vrgather (vint32m1_t op1, uint32_t op2);
vint32m2_t vrgather (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vrgather (vint32m2_t op1, uint32_t op2);
vint32m4_t vrgather (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vrgather (vint32m4_t op1, uint32_t op2);
vint32m8_t vrgather (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vrgather (vint32m8_t op1, uint32_t op2);
vint64m1_t vrgather (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vrgather (vint64m1_t op1, uint64_t op2);
vint64m2_t vrgather (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vrgather (vint64m2_t op1, uint64_t op2);
vint64m4_t vrgather (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vrgather (vint64m4_t op1, uint64_t op2);
vint64m8_t vrgather (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vrgather (vint64m8_t op1, uint64_t op2);
vuint8m1_t vrgather (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrgather (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrgather (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrgather (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrgather (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrgather (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrgather (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrgather (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrgather (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrgather (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrgather (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrgather (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrgather (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrgather (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrgather (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrgather (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrgather (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrgather (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrgather (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrgather (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrgather (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrgather (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrgather (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrgather (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrgather (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrgather (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrgather (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrgather (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrgather (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrgather (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrgather (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrgather (vuint64m8_t op1, uint64_t op2);
vfloat16m1_t vrgather (vfloat16m1_t op1, vuint16m1_t op2);
vfloat16m1_t vrgather (vfloat16m1_t op1, uint16_t op2);
vfloat16m2_t vrgather (vfloat16m2_t op1, vuint16m2_t op2);
vfloat16m2_t vrgather (vfloat16m2_t op1, uint16_t op2);
vfloat16m4_t vrgather (vfloat16m4_t op1, vuint16m4_t op2);
vfloat16m4_t vrgather (vfloat16m4_t op1, uint16_t op2);
vfloat16m8_t vrgather (vfloat16m8_t op1, vuint16m8_t op2);
vfloat16m8_t vrgather (vfloat16m8_t op1, uint16_t op2);
vfloat32m1_t vrgather (vfloat32m1_t op1, vuint32m1_t op2);
vfloat32m1_t vrgather (vfloat32m1_t op1, uint32_t op2);
vfloat32m2_t vrgather (vfloat32m2_t op1, vuint32m2_t op2);
vfloat32m2_t vrgather (vfloat32m2_t op1, uint32_t op2);
vfloat32m4_t vrgather (vfloat32m4_t op1, vuint32m4_t op2);
vfloat32m4_t vrgather (vfloat32m4_t op1, uint32_t op2);
vfloat32m8_t vrgather (vfloat32m8_t op1, vuint32m8_t op2);
vfloat32m8_t vrgather (vfloat32m8_t op1, uint32_t op2);
vfloat64m1_t vrgather (vfloat64m1_t op1, vuint64m1_t op2);
vfloat64m1_t vrgather (vfloat64m1_t op1, uint64_t op2);
vfloat64m2_t vrgather (vfloat64m2_t op1, vuint64m2_t op2);
vfloat64m2_t vrgather (vfloat64m2_t op1, uint64_t op2);
vfloat64m4_t vrgather (vfloat64m4_t op1, vuint64m4_t op2);
vfloat64m4_t vrgather (vfloat64m4_t op1, uint64_t op2);
vfloat64m8_t vrgather (vfloat64m8_t op1, vuint64m8_t op2);
vfloat64m8_t vrgather (vfloat64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vrgather_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vrgather_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vrgather_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vrgather_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vrgather_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vrgather_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vrgather_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vrgather_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vrgather_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vrgather_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2);
vint16m2_t vrgather_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vrgather_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2);
vint16m4_t vrgather_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vrgather_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2);
vint16m8_t vrgather_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vrgather_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2);
vint32m1_t vrgather_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vrgather_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2);
vint32m2_t vrgather_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vrgather_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2);
vint32m4_t vrgather_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vrgather_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2);
vint32m8_t vrgather_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vrgather_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2);
vint64m1_t vrgather_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vrgather_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2);
vint64m2_t vrgather_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vrgather_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2);
vint64m4_t vrgather_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vrgather_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2);
vint64m8_t vrgather_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vrgather_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2);
vuint8m1_t vrgather_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrgather_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrgather_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrgather_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrgather_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrgather_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrgather_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrgather_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrgather_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrgather_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrgather_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrgather_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrgather_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrgather_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrgather_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrgather_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrgather_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrgather_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrgather_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrgather_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrgather_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrgather_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrgather_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrgather_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrgather_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrgather_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrgather_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrgather_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrgather_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrgather_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrgather_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrgather_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vfloat16m1_t vrgather_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t op2);
vfloat16m1_t vrgather_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, uint16_t op2);
vfloat16m2_t vrgather_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t op2);
vfloat16m2_t vrgather_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, uint16_t op2);
vfloat16m4_t vrgather_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t op2);
vfloat16m4_t vrgather_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, uint16_t op2);
vfloat16m8_t vrgather_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t op2);
vfloat16m8_t vrgather_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, uint16_t op2);
vfloat32m1_t vrgather_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint32m1_t op2);
vfloat32m1_t vrgather_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, uint32_t op2);
vfloat32m2_t vrgather_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint32m2_t op2);
vfloat32m2_t vrgather_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, uint32_t op2);
vfloat32m4_t vrgather_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint32m4_t op2);
vfloat32m4_t vrgather_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, uint32_t op2);
vfloat32m8_t vrgather_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint32m8_t op2);
vfloat32m8_t vrgather_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, uint32_t op2);
vfloat64m1_t vrgather_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint64m1_t op2);
vfloat64m1_t vrgather_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, uint64_t op2);
vfloat64m2_t vrgather_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint64m2_t op2);
vfloat64m2_t vrgather_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, uint64_t op2);
vfloat64m4_t vrgather_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint64m4_t op2);
vfloat64m4_t vrgather_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, uint64_t op2);
vfloat64m8_t vrgather_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint64m8_t op2);
vfloat64m8_t vrgather_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, uint64_t op2);
```
### [Vector Compress Functions]()

**Prototypes:**
``` C
vint8m1_t vcompress (vint8m1_t src, vbool8_t mask);
vint8m2_t vcompress (vint8m2_t src, vbool4_t mask);
vint8m4_t vcompress (vint8m4_t src, vbool2_t mask);
vint8m8_t vcompress (vint8m8_t src, vbool1_t mask);
vint16m1_t vcompress (vint16m1_t src, vbool16_t mask);
vint16m2_t vcompress (vint16m2_t src, vbool8_t mask);
vint16m4_t vcompress (vint16m4_t src, vbool4_t mask);
vint16m8_t vcompress (vint16m8_t src, vbool2_t mask);
vint32m1_t vcompress (vint32m1_t src, vbool32_t mask);
vint32m2_t vcompress (vint32m2_t src, vbool16_t mask);
vint32m4_t vcompress (vint32m4_t src, vbool8_t mask);
vint32m8_t vcompress (vint32m8_t src, vbool4_t mask);
vint64m1_t vcompress (vint64m1_t src, vbool64_t mask);
vint64m2_t vcompress (vint64m2_t src, vbool32_t mask);
vint64m4_t vcompress (vint64m4_t src, vbool16_t mask);
vint64m8_t vcompress (vint64m8_t src, vbool8_t mask);
vuint8m1_t vcompress (vuint8m1_t src, vbool8_t mask);
vuint8m2_t vcompress (vuint8m2_t src, vbool4_t mask);
vuint8m4_t vcompress (vuint8m4_t src, vbool2_t mask);
vuint8m8_t vcompress (vuint8m8_t src, vbool1_t mask);
vuint16m1_t vcompress (vuint16m1_t src, vbool16_t mask);
vuint16m2_t vcompress (vuint16m2_t src, vbool8_t mask);
vuint16m4_t vcompress (vuint16m4_t src, vbool4_t mask);
vuint16m8_t vcompress (vuint16m8_t src, vbool2_t mask);
vuint32m1_t vcompress (vuint32m1_t src, vbool32_t mask);
vuint32m2_t vcompress (vuint32m2_t src, vbool16_t mask);
vuint32m4_t vcompress (vuint32m4_t src, vbool8_t mask);
vuint32m8_t vcompress (vuint32m8_t src, vbool4_t mask);
vuint64m1_t vcompress (vuint64m1_t src, vbool64_t mask);
vuint64m2_t vcompress (vuint64m2_t src, vbool32_t mask);
vuint64m4_t vcompress (vuint64m4_t src, vbool16_t mask);
vuint64m8_t vcompress (vuint64m8_t src, vbool8_t mask);
vfloat16m1_t vcompress (vfloat16m1_t src, vbool16_t mask);
vfloat16m2_t vcompress (vfloat16m2_t src, vbool8_t mask);
vfloat16m4_t vcompress (vfloat16m4_t src, vbool4_t mask);
vfloat16m8_t vcompress (vfloat16m8_t src, vbool2_t mask);
vfloat32m1_t vcompress (vfloat32m1_t src, vbool32_t mask);
vfloat32m2_t vcompress (vfloat32m2_t src, vbool16_t mask);
vfloat32m4_t vcompress (vfloat32m4_t src, vbool8_t mask);
vfloat32m8_t vcompress (vfloat32m8_t src, vbool4_t mask);
vfloat64m1_t vcompress (vfloat64m1_t src, vbool64_t mask);
vfloat64m2_t vcompress (vfloat64m2_t src, vbool32_t mask);
vfloat64m4_t vcompress (vfloat64m4_t src, vbool16_t mask);
vfloat64m8_t vcompress (vfloat64m8_t src, vbool8_t mask);
```
## Miscellaneous Vector Functions:

### [Reinterpret Cast Conversion Functions]()

**Prototypes:**
``` C
vuint8m1_t vreinterpret_u8 (vint8m1_t src);
vuint8m2_t vreinterpret_u8 (vint8m2_t src);
vuint8m4_t vreinterpret_u8 (vint8m4_t src);
vuint8m8_t vreinterpret_u8 (vint8m8_t src);
vint8m1_t vreinterpret_i8 (vuint8m1_t src);
vint8m2_t vreinterpret_i8 (vuint8m2_t src);
vint8m4_t vreinterpret_i8 (vuint8m4_t src);
vint8m8_t vreinterpret_i8 (vuint8m8_t src);
vuint16m1_t vreinterpret_u16 (vint16m1_t src);
vuint16m2_t vreinterpret_u16 (vint16m2_t src);
vuint16m4_t vreinterpret_u16 (vint16m4_t src);
vuint16m8_t vreinterpret_u16 (vint16m8_t src);
vint16m1_t vreinterpret_i16 (vuint16m1_t src);
vint16m2_t vreinterpret_i16 (vuint16m2_t src);
vint16m4_t vreinterpret_i16 (vuint16m4_t src);
vint16m8_t vreinterpret_i16 (vuint16m8_t src);
vint16m1_t vreinterpret_i16 (vfloat16m1_t src);
vint16m2_t vreinterpret_i16 (vfloat16m2_t src);
vint16m4_t vreinterpret_i16 (vfloat16m4_t src);
vint16m8_t vreinterpret_i16 (vfloat16m8_t src);
vuint16m1_t vreinterpret_u16 (vfloat16m1_t src);
vuint16m2_t vreinterpret_u16 (vfloat16m2_t src);
vuint16m4_t vreinterpret_u16 (vfloat16m4_t src);
vuint16m8_t vreinterpret_u16 (vfloat16m8_t src);
vfloat16m1_t vreinterpret_f16 (vint16m1_t src);
vfloat16m2_t vreinterpret_f16 (vint16m2_t src);
vfloat16m4_t vreinterpret_f16 (vint16m4_t src);
vfloat16m8_t vreinterpret_f16 (vint16m8_t src);
vfloat16m1_t vreinterpret_f16 (vuint16m1_t src);
vfloat16m2_t vreinterpret_f16 (vuint16m2_t src);
vfloat16m4_t vreinterpret_f16 (vuint16m4_t src);
vfloat16m8_t vreinterpret_f16 (vuint16m8_t src);
vuint32m1_t vreinterpret_u32 (vint32m1_t src);
vuint32m2_t vreinterpret_u32 (vint32m2_t src);
vuint32m4_t vreinterpret_u32 (vint32m4_t src);
vuint32m8_t vreinterpret_u32 (vint32m8_t src);
vint32m1_t vreinterpret_i32 (vuint32m1_t src);
vint32m2_t vreinterpret_i32 (vuint32m2_t src);
vint32m4_t vreinterpret_i32 (vuint32m4_t src);
vint32m8_t vreinterpret_i32 (vuint32m8_t src);
vint32m1_t vreinterpret_i32 (vfloat32m1_t src);
vint32m2_t vreinterpret_i32 (vfloat32m2_t src);
vint32m4_t vreinterpret_i32 (vfloat32m4_t src);
vint32m8_t vreinterpret_i32 (vfloat32m8_t src);
vuint32m1_t vreinterpret_u32 (vfloat32m1_t src);
vuint32m2_t vreinterpret_u32 (vfloat32m2_t src);
vuint32m4_t vreinterpret_u32 (vfloat32m4_t src);
vuint32m8_t vreinterpret_u32 (vfloat32m8_t src);
vfloat32m1_t vreinterpret_f32 (vint32m1_t src);
vfloat32m2_t vreinterpret_f32 (vint32m2_t src);
vfloat32m4_t vreinterpret_f32 (vint32m4_t src);
vfloat32m8_t vreinterpret_f32 (vint32m8_t src);
vfloat32m1_t vreinterpret_f32 (vuint32m1_t src);
vfloat32m2_t vreinterpret_f32 (vuint32m2_t src);
vfloat32m4_t vreinterpret_f32 (vuint32m4_t src);
vfloat32m8_t vreinterpret_f32 (vuint32m8_t src);
vuint64m1_t vreinterpret_u64 (vint64m1_t src);
vuint64m2_t vreinterpret_u64 (vint64m2_t src);
vuint64m4_t vreinterpret_u64 (vint64m4_t src);
vuint64m8_t vreinterpret_u64 (vint64m8_t src);
vint64m1_t vreinterpret_i64 (vuint64m1_t src);
vint64m2_t vreinterpret_i64 (vuint64m2_t src);
vint64m4_t vreinterpret_i64 (vuint64m4_t src);
vint64m8_t vreinterpret_i64 (vuint64m8_t src);
vint64m1_t vreinterpret_i64 (vfloat64m1_t src);
vint64m2_t vreinterpret_i64 (vfloat64m2_t src);
vint64m4_t vreinterpret_i64 (vfloat64m4_t src);
vint64m8_t vreinterpret_i64 (vfloat64m8_t src);
vuint64m1_t vreinterpret_u64 (vfloat64m1_t src);
vuint64m2_t vreinterpret_u64 (vfloat64m2_t src);
vuint64m4_t vreinterpret_u64 (vfloat64m4_t src);
vuint64m8_t vreinterpret_u64 (vfloat64m8_t src);
vfloat64m1_t vreinterpret_f64 (vint64m1_t src);
vfloat64m2_t vreinterpret_f64 (vint64m2_t src);
vfloat64m4_t vreinterpret_f64 (vint64m4_t src);
vfloat64m8_t vreinterpret_f64 (vint64m8_t src);
vfloat64m1_t vreinterpret_f64 (vuint64m1_t src);
vfloat64m2_t vreinterpret_f64 (vuint64m2_t src);
vfloat64m4_t vreinterpret_f64 (vuint64m4_t src);
vfloat64m8_t vreinterpret_f64 (vuint64m8_t src);
```
